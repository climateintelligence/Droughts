{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2333,"status":"ok","timestamp":1684763999729,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"_Q-9-_Ldoy_t"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1684763999730,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"N4mlPbfnozfO"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks/scripts\n"]}],"source":["cd drive/MyDrive/Colab\\ Notebooks/scripts"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":1115,"status":"ok","timestamp":1684764000839,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"87a19403"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","import numpy as np\n","import sys\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import r2_score\n","import os\n","from collections import Counter\n","from imblearn.over_sampling import SMOTE"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":370,"status":"ok","timestamp":1684764001205,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"t4O3GfTbop-R"},"outputs":[],"source":["from feature_selection import forwardFeatureSelection\n","\n","from NonLinCFA import NonLinCFA\n","from aux_GenLinCFA import prepare_target_binary\n","\n","from aux_NonLinCFA import *\n","import random"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1684764001206,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"tkkdaNmFRP4N"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["cd .."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":714,"status":"ok","timestamp":1684764004093,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"4rJdT2IB_NyB"},"outputs":[],"source":["def compute_random_seeds(num_seeds, limit):\n","  random.seed(12)\n","  randomlist = []\n","  for i in range(0,num_seeds):\n","    n = random.randint(1,limit)\n","    randomlist.append(n)\n","  return randomlist"]},{"cell_type":"markdown","metadata":{"id":"PqNz4kWf-tga"},"source":["# NonLinCFA aggregations standardized target, moving avg\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":893,"status":"ok","timestamp":1684764006014,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"MGxM2f40-tgl","outputId":"2106c372-043b-43a7-d1dc-5a53b404f097"},"outputs":[{"data":{"text/plain":["[61, 35, 85, 68, 86, 45, 19, 49, 2, 48]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import random\n","\n","path_target = './csv/'\n","path_features = './features_allvalues/'\n","random.seed(12)\n","\n","randomlist = []\n","for i in range(0,10):\n","  n = random.randint(1,100)\n","  randomlist.append(n)\n","randomlist"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":842},"executionInfo":{"elapsed":10261,"status":"error","timestamp":1684762879555,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"v10LEEKjrw5s","outputId":"23a3b075-f930-460a-caeb-ba02581f09ef"},"outputs":[{"name":"stdout","output_type":"stream","text":["####################Emiliani1####################\n","Number of features: 172\n","\n","Index(['mean_12.149860342381333_43.74986055078544',\n","       'mean_12.149860342381333_43.8498605504681',\n","       'mean_12.149860342381333_43.94986055015075',\n","       'mean_12.149860342381333_44.04986054983341',\n","       'mean_12.149860342381333_44.14986054951606',\n","       'mean_12.149860342381333_44.24986054919872',\n","       'mean_12.149860342381333_44.34986054888138',\n","       'mean_12.149860342381333_44.44986054856403',\n","       'mean_12.149860342381333_44.54986054824669',\n","       'mean_12.149860342381333_44.64986054792934',\n","       ...\n","       'mean_11.349860345581744_44.849860547294654',\n","       'mean_11.449860345181692_44.14986054951606',\n","       'mean_11.449860345181692_44.24986054919872',\n","       'mean_11.449860345181692_44.34986054888138',\n","       'mean_11.449860345181692_44.44986054856403',\n","       'mean_11.449860345181692_44.54986054824669',\n","       'mean_11.449860345181692_44.64986054792934',\n","       'mean_11.449860345181692_44.749860547612',\n","       'mean_11.449860345181692_44.849860547294654',\n","       'mean_10.749860347982052_44.24986054919872'],\n","      dtype='object', length=172)\n","Normal starting point: \n","mean_12.149860342381333_43.74986055078544\n","Actual starting point after shuffling: \n","mean_11.54986034478164_44.14986054951606\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-9-b525f9448ef2\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 8\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mactual_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_features\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbasin\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_aggreg.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 8\u001b[0;31m output, aggregate_trainVal, aggregate_test = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg', \n\u001b[0m\u001b[1;32m      9\u001b[0m                                                                               \u001b[0;34m'cyclostationary_mean_tg_1w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                                               \u001b[0;34m'cyclostationary_mean_tg_4w'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/scripts/aux_NonLinCFA.py\u001b[0m in \u001b[0;36maggregate_unfolded_data\u001b[0;34m(path, colnames, target_df_trainVal, eps, multiple, max_train, max_val, max_test, neigh, curr_seed, shuffle, no_tiny_aggregations, exclude_lowcorr, shuffle_starting_point_only)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Number of features: {df_train_unfolded_std.shape[1]}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 296\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNonLinCFA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_trainVal_unfolded_std_withTar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mean_std'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mneigh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshuffle_starting_point_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle_starting_point_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurr_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/scripts/NonLinCFA.py\u001b[0m in \u001b[0;36mcompute_clusters\u001b[0;34m(self, shuffle_starting_point_only, random_seed)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mactual_col\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# remove actual column from the ones not assigned yet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 120\u001b[0;31m             \u001b[0mcol_to_aggr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_aggregation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_cluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcol_to_aggr\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mactual_cluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_to_aggr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/scripts/NonLinCFA.py\u001b[0m in \u001b[0;36mfind_aggregation\u001b[0;34m(self, actual_clust, cols)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_CVscores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_clust\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 91\u001b[0;31m                 \u001b[0mr1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_VALscores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual_clust\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m             \u001b[0;31m#print(r1,r2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr1\u001b[0m\u001b[0;34m\u003c=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/scripts/NonLinCFA.py\u001b[0m in \u001b[0;36mcompute_VALscores\u001b[0;34m(self, column1_list, column2)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0maggr_regr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mbivariate_regr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 69\u001b[0;31m         \u001b[0maggr_r2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggr_regr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_aggr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTimeSeriesSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mbivariate_r2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbivariate_regr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTimeSeriesSplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maggr_r2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbivariate_r2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 515\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 266\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    267\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---\u003e 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-\u003e 1088\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 901\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 819\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    595\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 597\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m\u003clistcomp\u003e\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 288\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    289\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 686\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    654\u001b[0m         )\n\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 656\u001b[0;31m         X, y, X_offset, y_offset, X_scale = _preprocess_data(\n\u001b[0m\u001b[1;32m    657\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[0;34m(X, y, fit_intercept, normalize, copy, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 230\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;31m# Cython implementation to prevent false positives and provide a detailed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;31m# error message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 121\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mover\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mfirst_pass_isfinite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfirst_pass_isfinite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_ufunc_config.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 430\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moldstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseterr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_Unspecified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moldcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseterrcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_ufunc_config.py\u001b[0m in \u001b[0;36mseterr\u001b[0;34m(all, divide, over, under, invalid)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0mpyvals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaskvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 127\u001b[0;31m     \u001b[0mumath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseterrobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["random_seed = randomlist[0]\n","basin = \"Emiliani1\"\n","print('####################' + basin + '####################')\n","target_df_train, target_df_val, target_df_test, target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', \n","    path=path_target+basin+'.csv', window_size = 1)\n","eps = 0.001\n","actual_path = path_features+basin+'_aggreg.csv'\n","output, aggregate_trainVal, aggregate_test, x = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg', \n","                                                                              'cyclostationary_mean_tg_1w',\n","                                                                              'cyclostationary_mean_tg_4w', \n","                                                                              'cyclostationary_mean_tg_8w',\n","                                                                              'cyclostationary_mean_tg_12w', \n","                                                                              'cyclostationary_mean_tg_16w',\n","                                                                              'cyclostationary_mean_tg_24w',\n","                                                                              'cyclostationary_mean_rr', \n","                                                                              'cyclostationary_mean_rr_1w',\n","                                                                              'cyclostationary_mean_rr_4w', \n","                                                                              'cyclostationary_mean_rr_8w',\n","                                                                              'cyclostationary_mean_rr_12w', \n","                                                                              'cyclostationary_mean_rr_16w',\n","                                                                              'cyclostationary_mean_rr_24w'\n","                                                                              ],\n","                                                                        target_df_trainVal, eps=eps,\n","                                                                        max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01',\n","                                                                        curr_seed=random_seed, shuffle=False, shuffle_starting_point_only = True)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":207848,"status":"ok","timestamp":1684764445207,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"h0lawHx_kQMs","outputId":"6435ef43-004d-43c8-c954-fcff7ee24b4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["####################Garda_Mincio####################\n","Number of features: 67\n","\n","Index(['mean_11.349860345581742_44.94986054697731',\n","       'mean_11.349860345581742_45.04986054665997',\n","       'mean_11.449860345181692_44.94986054697731',\n","       'mean_11.449860345181692_45.04986054665997',\n","       'mean_11.54986034478164_44.94986054697731',\n","       'mean_11.54986034478164_45.04986054665997',\n","       'mean_11.64986034438159_44.94986054697731',\n","       'mean_11.749860343981538_44.94986054697731',\n","       'mean_11.849860343581486_44.94986054697731',\n","       'mean_11.849860343581486_45.04986054665997',\n","       'mean_11.949860343181436_44.94986054697731',\n","       'mean_11.949860343181436_45.04986054665997',\n","       'mean_12.34986034158123_44.94986054697731',\n","       'mean_12.34986034158123_45.04986054665997',\n","       'mean_12.44986034118118_44.94986054697731',\n","       'mean_11.049860346781898_45.04986054665997',\n","       'mean_11.049860346781898_45.14986054634262',\n","       'mean_11.049860346781898_45.24986054602528',\n","       'mean_11.049860346781898_45.349860545707934',\n","       'mean_11.149860346381846_45.04986054665997',\n","       'mean_11.149860346381846_45.14986054634262',\n","       'mean_11.149860346381846_45.24986054602528',\n","       'mean_11.249860345981794_45.04986054665997',\n","       'mean_11.249860345981794_45.14986054634262',\n","       'mean_12.049860342781384_45.04986054665997',\n","       'mean_12.149860342381333_45.04986054665997',\n","       'mean_12.24986034198128_45.04986054665997',\n","       'mean_10.649860348382102_45.14986054634262',\n","       'mean_10.649860348382102_45.24986054602528',\n","       'mean_10.649860348382102_45.349860545707934',\n","       'mean_10.649860348382102_45.44986054539059',\n","       'mean_10.649860348382102_45.54986054507325',\n","       'mean_10.649860348382102_45.6498605447559',\n","       'mean_10.649860348382102_45.74986054443856',\n","       'mean_10.649860348382102_45.84986054412121',\n","       'mean_10.649860348382102_46.04986054348653',\n","       'mean_10.649860348382102_46.14986054316918',\n","       'mean_10.749860347982052_45.14986054634262',\n","       'mean_10.749860347982052_45.24986054602528',\n","       'mean_10.749860347982052_45.349860545707934',\n","       'mean_10.749860347982052_45.44986054539059',\n","       'mean_10.749860347982052_45.54986054507325',\n","       'mean_10.749860347982052_45.6498605447559',\n","       'mean_10.749860347982052_45.74986054443856',\n","       'mean_10.749860347982052_45.84986054412121',\n","       'mean_10.749860347982052_45.94986054380387',\n","       'mean_10.749860347982052_46.04986054348653',\n","       'mean_10.749860347982052_46.14986054316918',\n","       'mean_10.849860347582_45.14986054634262',\n","       'mean_10.849860347582_45.24986054602528',\n","       'mean_10.849860347582_45.349860545707934',\n","       'mean_10.849860347582_45.44986054539059',\n","       'mean_10.849860347582_45.74986054443856',\n","       'mean_10.849860347582_45.84986054412121',\n","       'mean_10.849860347582_45.94986054380387',\n","       'mean_10.849860347582_46.04986054348653',\n","       'mean_10.849860347582_46.14986054316918',\n","       'mean_10.949860347181948_45.14986054634262',\n","       'mean_10.949860347181948_45.24986054602528',\n","       'mean_10.949860347181948_45.349860545707934',\n","       'mean_10.949860347181948_45.94986054380387',\n","       'mean_10.949860347181948_46.04986054348653',\n","       'mean_10.949860347181948_46.14986054316918',\n","       'mean_10.549860348782154_45.44986054539059',\n","       'mean_10.549860348782154_45.54986054507325',\n","       'mean_10.549860348782154_45.6498605447559',\n","       'mean_10.549860348782154_45.74986054443856'],\n","      dtype='object')\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.549860348782154_45.44986054539059\n","Normal starting point: \n","mean_10.849860347582_46.14986054316918\n","Actual starting point after shuffling: \n","mean_10.849860347582_46.14986054316918\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Index(['mean_11.349860345581742_44.94986054697731',\n","       'mean_11.349860345581742_45.04986054665997',\n","       'mean_11.449860345181692_44.94986054697731',\n","       'mean_11.449860345181692_45.04986054665997',\n","       'mean_11.54986034478164_44.94986054697731',\n","       'mean_11.54986034478164_45.04986054665997',\n","       'mean_11.64986034438159_44.94986054697731',\n","       'mean_11.749860343981538_44.94986054697731',\n","       'mean_11.849860343581486_44.94986054697731',\n","       'mean_11.849860343581486_45.04986054665997',\n","       'mean_11.949860343181436_44.94986054697731',\n","       'mean_11.949860343181436_45.04986054665997',\n","       'mean_12.34986034158123_44.94986054697731',\n","       'mean_12.34986034158123_45.04986054665997',\n","       'mean_12.44986034118118_44.94986054697731',\n","       'mean_11.049860346781898_45.04986054665997',\n","       'mean_11.049860346781898_45.14986054634262',\n","       'mean_11.049860346781898_45.24986054602528',\n","       'mean_11.049860346781898_45.349860545707934',\n","       'mean_11.149860346381846_45.04986054665997',\n","       'mean_11.149860346381846_45.14986054634262',\n","       'mean_11.149860346381846_45.24986054602528',\n","       'mean_11.249860345981794_45.04986054665997',\n","       'mean_11.249860345981794_45.14986054634262',\n","       'mean_12.049860342781384_45.04986054665997',\n","       'mean_12.149860342381333_45.04986054665997',\n","       'mean_12.24986034198128_45.04986054665997',\n","       'mean_10.649860348382102_45.14986054634262',\n","       'mean_10.649860348382102_45.24986054602528',\n","       'mean_10.649860348382102_45.349860545707934',\n","       'mean_10.649860348382102_45.44986054539059',\n","       'mean_10.649860348382102_45.54986054507325',\n","       'mean_10.649860348382102_45.6498605447559',\n","       'mean_10.649860348382102_45.74986054443856',\n","       'mean_10.649860348382102_45.84986054412121',\n","       'mean_10.649860348382102_46.04986054348653',\n","       'mean_10.649860348382102_46.14986054316918',\n","       'mean_10.749860347982052_45.14986054634262',\n","       'mean_10.749860347982052_45.24986054602528',\n","       'mean_10.749860347982052_45.349860545707934',\n","       'mean_10.749860347982052_45.44986054539059',\n","       'mean_10.749860347982052_45.54986054507325',\n","       'mean_10.749860347982052_45.6498605447559',\n","       'mean_10.749860347982052_45.74986054443856',\n","       'mean_10.749860347982052_45.84986054412121',\n","       'mean_10.749860347982052_45.94986054380387',\n","       'mean_10.749860347982052_46.04986054348653',\n","       'mean_10.749860347982052_46.14986054316918',\n","       'mean_10.849860347582_45.14986054634262',\n","       'mean_10.849860347582_45.24986054602528',\n","       'mean_10.849860347582_45.349860545707934',\n","       'mean_10.849860347582_45.44986054539059',\n","       'mean_10.849860347582_45.74986054443856',\n","       'mean_10.849860347582_45.84986054412121',\n","       'mean_10.849860347582_45.94986054380387',\n","       'mean_10.849860347582_46.04986054348653',\n","       'mean_10.849860347582_46.14986054316918',\n","       'mean_10.949860347181948_45.14986054634262',\n","       'mean_10.949860347181948_45.24986054602528',\n","       'mean_10.949860347181948_45.349860545707934',\n","       'mean_10.949860347181948_45.94986054380387',\n","       'mean_10.949860347181948_46.04986054348653',\n","       'mean_10.949860347181948_46.14986054316918',\n","       'mean_10.549860348782154_45.44986054539059',\n","       'mean_10.549860348782154_45.54986054507325',\n","       'mean_10.549860348782154_45.6498605447559',\n","       'mean_10.549860348782154_45.74986054443856'],\n","      dtype='object')\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.549860348782154_45.44986054539059\n","Normal starting point: \n","mean_10.649860348382102_46.14986054316918\n","Actual starting point after shuffling: \n","mean_10.949860347181948_46.14986054316918\n","Normal starting point: \n","mean_10.649860348382102_46.14986054316918\n","Actual starting point after shuffling: \n","mean_10.649860348382102_46.14986054316918\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Index(['mean_11.349860345581742_44.94986054697731',\n","       'mean_11.349860345581742_45.04986054665997',\n","       'mean_11.449860345181692_44.94986054697731',\n","       'mean_11.449860345181692_45.04986054665997',\n","       'mean_11.54986034478164_44.94986054697731',\n","       'mean_11.54986034478164_45.04986054665997',\n","       'mean_11.64986034438159_44.94986054697731',\n","       'mean_11.749860343981538_44.94986054697731',\n","       'mean_11.849860343581486_44.94986054697731',\n","       'mean_11.849860343581486_45.04986054665997',\n","       'mean_11.949860343181436_44.94986054697731',\n","       'mean_11.949860343181436_45.04986054665997',\n","       'mean_12.34986034158123_44.94986054697731',\n","       'mean_12.34986034158123_45.04986054665997',\n","       'mean_12.44986034118118_44.94986054697731',\n","       'mean_11.049860346781898_45.04986054665997',\n","       'mean_11.049860346781898_45.14986054634262',\n","       'mean_11.049860346781898_45.24986054602528',\n","       'mean_11.049860346781898_45.349860545707934',\n","       'mean_11.149860346381846_45.04986054665997',\n","       'mean_11.149860346381846_45.14986054634262',\n","       'mean_11.149860346381846_45.24986054602528',\n","       'mean_11.249860345981794_45.04986054665997',\n","       'mean_11.249860345981794_45.14986054634262',\n","       'mean_12.049860342781384_45.04986054665997',\n","       'mean_12.149860342381333_45.04986054665997',\n","       'mean_12.24986034198128_45.04986054665997',\n","       'mean_10.649860348382102_45.14986054634262',\n","       'mean_10.649860348382102_45.24986054602528',\n","       'mean_10.649860348382102_45.349860545707934',\n","       'mean_10.649860348382102_45.44986054539059',\n","       'mean_10.649860348382102_45.54986054507325',\n","       'mean_10.649860348382102_45.6498605447559',\n","       'mean_10.649860348382102_45.74986054443856',\n","       'mean_10.649860348382102_45.84986054412121',\n","       'mean_10.649860348382102_46.04986054348653',\n","       'mean_10.649860348382102_46.14986054316918',\n","       'mean_10.749860347982052_45.14986054634262',\n","       'mean_10.749860347982052_45.24986054602528',\n","       'mean_10.749860347982052_45.349860545707934',\n","       'mean_10.749860347982052_45.44986054539059',\n","       'mean_10.749860347982052_45.54986054507325',\n","       'mean_10.749860347982052_45.6498605447559',\n","       'mean_10.749860347982052_45.74986054443856',\n","       'mean_10.749860347982052_45.84986054412121',\n","       'mean_10.749860347982052_45.94986054380387',\n","       'mean_10.749860347982052_46.04986054348653',\n","       'mean_10.749860347982052_46.14986054316918',\n","       'mean_10.849860347582_45.14986054634262',\n","       'mean_10.849860347582_45.24986054602528',\n","       'mean_10.849860347582_45.349860545707934',\n","       'mean_10.849860347582_45.44986054539059',\n","       'mean_10.849860347582_45.74986054443856',\n","       'mean_10.849860347582_45.84986054412121',\n","       'mean_10.849860347582_45.94986054380387',\n","       'mean_10.849860347582_46.04986054348653',\n","       'mean_10.849860347582_46.14986054316918',\n","       'mean_10.949860347181948_45.14986054634262',\n","       'mean_10.949860347181948_45.24986054602528',\n","       'mean_10.949860347181948_45.349860545707934',\n","       'mean_10.949860347181948_45.94986054380387',\n","       'mean_10.949860347181948_46.04986054348653',\n","       'mean_10.949860347181948_46.14986054316918',\n","       'mean_10.549860348782154_45.44986054539059',\n","       'mean_10.549860348782154_45.54986054507325',\n","       'mean_10.549860348782154_45.6498605447559',\n","       'mean_10.549860348782154_45.74986054443856'],\n","      dtype='object')\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.549860348782154_45.44986054539059\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","Index(['mean_11.349860345581742_44.94986054697731',\n","       'mean_11.349860345581742_45.04986054665997',\n","       'mean_11.449860345181692_44.94986054697731',\n","       'mean_11.449860345181692_45.04986054665997',\n","       'mean_11.54986034478164_44.94986054697731',\n","       'mean_11.54986034478164_45.04986054665997',\n","       'mean_11.64986034438159_44.94986054697731',\n","       'mean_11.749860343981538_44.94986054697731',\n","       'mean_11.849860343581486_44.94986054697731',\n","       'mean_11.849860343581486_45.04986054665997',\n","       'mean_11.949860343181436_44.94986054697731',\n","       'mean_11.949860343181436_45.04986054665997',\n","       'mean_12.34986034158123_44.94986054697731',\n","       'mean_12.34986034158123_45.04986054665997',\n","       'mean_12.44986034118118_44.94986054697731',\n","       'mean_11.049860346781898_45.04986054665997',\n","       'mean_11.049860346781898_45.14986054634262',\n","       'mean_11.049860346781898_45.24986054602528',\n","       'mean_11.049860346781898_45.349860545707934',\n","       'mean_11.149860346381846_45.04986054665997',\n","       'mean_11.149860346381846_45.14986054634262',\n","       'mean_11.149860346381846_45.24986054602528',\n","       'mean_11.249860345981794_45.04986054665997',\n","       'mean_11.249860345981794_45.14986054634262',\n","       'mean_12.049860342781384_45.04986054665997',\n","       'mean_12.149860342381333_45.04986054665997',\n","       'mean_12.24986034198128_45.04986054665997',\n","       'mean_10.649860348382102_45.14986054634262',\n","       'mean_10.649860348382102_45.24986054602528',\n","       'mean_10.649860348382102_45.349860545707934',\n","       'mean_10.649860348382102_45.44986054539059',\n","       'mean_10.649860348382102_45.54986054507325',\n","       'mean_10.649860348382102_45.6498605447559',\n","       'mean_10.649860348382102_45.74986054443856',\n","       'mean_10.649860348382102_45.84986054412121',\n","       'mean_10.649860348382102_46.04986054348653',\n","       'mean_10.649860348382102_46.14986054316918',\n","       'mean_10.749860347982052_45.14986054634262',\n","       'mean_10.749860347982052_45.24986054602528',\n","       'mean_10.749860347982052_45.349860545707934',\n","       'mean_10.749860347982052_45.44986054539059',\n","       'mean_10.749860347982052_45.54986054507325',\n","       'mean_10.749860347982052_45.6498605447559',\n","       'mean_10.749860347982052_45.74986054443856',\n","       'mean_10.749860347982052_45.84986054412121',\n","       'mean_10.749860347982052_45.94986054380387',\n","       'mean_10.749860347982052_46.04986054348653',\n","       'mean_10.749860347982052_46.14986054316918',\n","       'mean_10.849860347582_45.14986054634262',\n","       'mean_10.849860347582_45.24986054602528',\n","       'mean_10.849860347582_45.349860545707934',\n","       'mean_10.849860347582_45.44986054539059',\n","       'mean_10.849860347582_45.74986054443856',\n","       'mean_10.849860347582_45.84986054412121',\n","       'mean_10.849860347582_45.94986054380387',\n","       'mean_10.849860347582_46.04986054348653',\n","       'mean_10.849860347582_46.14986054316918',\n","       'mean_10.949860347181948_45.14986054634262',\n","       'mean_10.949860347181948_45.24986054602528',\n","       'mean_10.949860347181948_45.349860545707934',\n","       'mean_10.949860347181948_45.94986054380387',\n","       'mean_10.949860347181948_46.04986054348653',\n","       'mean_10.949860347181948_46.14986054316918',\n","       'mean_10.549860348782154_45.44986054539059',\n","       'mean_10.549860348782154_45.54986054507325',\n","       'mean_10.549860348782154_45.6498605447559',\n","       'mean_10.549860348782154_45.74986054443856'],\n","      dtype='object')\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.549860348782154_45.44986054539059\n","Normal starting point: \n","mean_11.149860346381846_45.24986054602528\n","Actual starting point after shuffling: \n","mean_10.649860348382102_46.14986054316918\n","Normal starting point: \n","mean_11.149860346381846_45.24986054602528\n","Actual starting point after shuffling: \n","mean_10.849860347582_46.14986054316918\n","Normal starting point: \n","mean_11.149860346381846_45.24986054602528\n","Actual starting point after shuffling: \n","mean_11.149860346381846_45.24986054602528\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Index(['mean_11.349860345581742_44.94986054697731',\n","       'mean_11.349860345581742_45.04986054665997',\n","       'mean_11.449860345181692_44.94986054697731',\n","       'mean_11.449860345181692_45.04986054665997',\n","       'mean_11.54986034478164_44.94986054697731',\n","       'mean_11.54986034478164_45.04986054665997',\n","       'mean_11.64986034438159_44.94986054697731',\n","       'mean_11.749860343981538_44.94986054697731',\n","       'mean_11.849860343581486_44.94986054697731',\n","       'mean_11.849860343581486_45.04986054665997',\n","       'mean_11.949860343181436_44.94986054697731',\n","       'mean_11.949860343181436_45.04986054665997',\n","       'mean_12.34986034158123_44.94986054697731',\n","       'mean_12.34986034158123_45.04986054665997',\n","       'mean_12.44986034118118_44.94986054697731',\n","       'mean_11.049860346781898_45.04986054665997',\n","       'mean_11.049860346781898_45.14986054634262',\n","       'mean_11.049860346781898_45.24986054602528',\n","       'mean_11.049860346781898_45.349860545707934',\n","       'mean_11.149860346381846_45.04986054665997',\n","       'mean_11.149860346381846_45.14986054634262',\n","       'mean_11.149860346381846_45.24986054602528',\n","       'mean_11.249860345981794_45.04986054665997',\n","       'mean_11.249860345981794_45.14986054634262',\n","       'mean_12.049860342781384_45.04986054665997',\n","       'mean_12.149860342381333_45.04986054665997',\n","       'mean_12.24986034198128_45.04986054665997',\n","       'mean_10.649860348382102_45.14986054634262',\n","       'mean_10.649860348382102_45.24986054602528',\n","       'mean_10.649860348382102_45.349860545707934',\n","       'mean_10.649860348382102_45.44986054539059',\n","       'mean_10.649860348382102_45.54986054507325',\n","       'mean_10.649860348382102_45.6498605447559',\n","       'mean_10.649860348382102_45.74986054443856',\n","       'mean_10.649860348382102_45.84986054412121',\n","       'mean_10.649860348382102_46.04986054348653',\n","       'mean_10.649860348382102_46.14986054316918',\n","       'mean_10.749860347982052_45.14986054634262',\n","       'mean_10.749860347982052_45.24986054602528',\n","       'mean_10.749860347982052_45.349860545707934',\n","       'mean_10.749860347982052_45.44986054539059',\n","       'mean_10.749860347982052_45.54986054507325',\n","       'mean_10.749860347982052_45.6498605447559',\n","       'mean_10.749860347982052_45.74986054443856',\n","       'mean_10.749860347982052_45.84986054412121',\n","       'mean_10.749860347982052_45.94986054380387',\n","       'mean_10.749860347982052_46.04986054348653',\n","       'mean_10.749860347982052_46.14986054316918',\n","       'mean_10.849860347582_45.14986054634262',\n","       'mean_10.849860347582_45.24986054602528',\n","       'mean_10.849860347582_45.349860545707934',\n","       'mean_10.849860347582_45.44986054539059',\n","       'mean_10.849860347582_45.74986054443856',\n","       'mean_10.849860347582_45.84986054412121',\n","       'mean_10.849860347582_45.94986054380387',\n","       'mean_10.849860347582_46.04986054348653',\n","       'mean_10.849860347582_46.14986054316918',\n","       'mean_10.949860347181948_45.14986054634262',\n","       'mean_10.949860347181948_45.24986054602528',\n","       'mean_10.949860347181948_45.349860545707934',\n","       'mean_10.949860347181948_45.94986054380387',\n","       'mean_10.949860347181948_46.04986054348653',\n","       'mean_10.949860347181948_46.14986054316918',\n","       'mean_10.549860348782154_45.44986054539059',\n","       'mean_10.549860348782154_45.54986054507325',\n","       'mean_10.549860348782154_45.6498605447559',\n","       'mean_10.549860348782154_45.74986054443856'],\n","      dtype='object')\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.549860348782154_45.44986054539059\n","Normal starting point: \n","mean_11.049860346781898_45.349860545707934\n","Actual starting point after shuffling: \n","mean_10.849860347582_45.349860545707934\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Index(['mean_11.349860345581742_44.94986054697731',\n","       'mean_11.349860345581742_45.04986054665997',\n","       'mean_11.449860345181692_44.94986054697731',\n","       'mean_11.449860345181692_45.04986054665997',\n","       'mean_11.54986034478164_44.94986054697731',\n","       'mean_11.54986034478164_45.04986054665997',\n","       'mean_11.64986034438159_44.94986054697731',\n","       'mean_11.749860343981538_44.94986054697731',\n","       'mean_11.849860343581486_44.94986054697731',\n","       'mean_11.849860343581486_45.04986054665997',\n","       'mean_11.949860343181436_44.94986054697731',\n","       'mean_11.949860343181436_45.04986054665997',\n","       'mean_12.34986034158123_44.94986054697731',\n","       'mean_12.34986034158123_45.04986054665997',\n","       'mean_12.44986034118118_44.94986054697731',\n","       'mean_11.049860346781898_45.04986054665997',\n","       'mean_11.049860346781898_45.14986054634262',\n","       'mean_11.049860346781898_45.24986054602528',\n","       'mean_11.049860346781898_45.349860545707934',\n","       'mean_11.149860346381846_45.04986054665997',\n","       'mean_11.149860346381846_45.14986054634262',\n","       'mean_11.149860346381846_45.24986054602528',\n","       'mean_11.249860345981794_45.04986054665997',\n","       'mean_11.249860345981794_45.14986054634262',\n","       'mean_12.049860342781384_45.04986054665997',\n","       'mean_12.149860342381333_45.04986054665997',\n","       'mean_12.24986034198128_45.04986054665997',\n","       'mean_10.649860348382102_45.14986054634262',\n","       'mean_10.649860348382102_45.24986054602528',\n","       'mean_10.649860348382102_45.349860545707934',\n","       'mean_10.649860348382102_45.44986054539059',\n","       'mean_10.649860348382102_45.54986054507325',\n","       'mean_10.649860348382102_45.6498605447559',\n","       'mean_10.649860348382102_45.74986054443856',\n","       'mean_10.649860348382102_45.84986054412121',\n","       'mean_10.649860348382102_46.04986054348653',\n","       'mean_10.649860348382102_46.14986054316918',\n","       'mean_10.749860347982052_45.14986054634262',\n","       'mean_10.749860347982052_45.24986054602528',\n","       'mean_10.749860347982052_45.349860545707934',\n","       'mean_10.749860347982052_45.44986054539059',\n","       'mean_10.749860347982052_45.54986054507325',\n","       'mean_10.749860347982052_45.6498605447559',\n","       'mean_10.749860347982052_45.74986054443856',\n","       'mean_10.749860347982052_45.84986054412121',\n","       'mean_10.749860347982052_45.94986054380387',\n","       'mean_10.749860347982052_46.04986054348653',\n","       'mean_10.749860347982052_46.14986054316918',\n","       'mean_10.849860347582_45.14986054634262',\n","       'mean_10.849860347582_45.24986054602528',\n","       'mean_10.849860347582_45.349860545707934',\n","       'mean_10.849860347582_45.44986054539059',\n","       'mean_10.849860347582_45.74986054443856',\n","       'mean_10.849860347582_45.84986054412121',\n","       'mean_10.849860347582_45.94986054380387',\n","       'mean_10.849860347582_46.04986054348653',\n","       'mean_10.849860347582_46.14986054316918',\n","       'mean_10.949860347181948_45.14986054634262',\n","       'mean_10.949860347181948_45.24986054602528',\n","       'mean_10.949860347181948_45.349860545707934',\n","       'mean_10.949860347181948_45.94986054380387',\n","       'mean_10.949860347181948_46.04986054348653',\n","       'mean_10.949860347181948_46.14986054316918',\n","       'mean_10.549860348782154_45.44986054539059',\n","       'mean_10.549860348782154_45.54986054507325',\n","       'mean_10.549860348782154_45.6498605447559',\n","       'mean_10.549860348782154_45.74986054443856'],\n","      dtype='object')\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.549860348782154_45.44986054539059\n","Normal starting point: \n","mean_11.449860345181692_45.04986054665997\n","Actual starting point after shuffling: \n","mean_12.049860342781384_45.04986054665997\n","Normal starting point: \n","mean_11.449860345181692_45.04986054665997\n","Actual starting point after shuffling: \n","mean_10.849860347582_45.349860545707934\n","Normal starting point: \n","mean_11.449860345181692_45.04986054665997\n","Actual starting point after shuffling: \n","mean_11.54986034478164_45.04986054665997\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Index(['mean_11.349860345581742_44.94986054697731',\n","       'mean_11.349860345581742_45.04986054665997',\n","       'mean_11.449860345181692_44.94986054697731',\n","       'mean_11.449860345181692_45.04986054665997',\n","       'mean_11.54986034478164_44.94986054697731',\n","       'mean_11.54986034478164_45.04986054665997',\n","       'mean_11.64986034438159_44.94986054697731',\n","       'mean_11.749860343981538_44.94986054697731',\n","       'mean_11.849860343581486_44.94986054697731',\n","       'mean_11.849860343581486_45.04986054665997',\n","       'mean_11.949860343181436_44.94986054697731',\n","       'mean_11.949860343181436_45.04986054665997',\n","       'mean_12.34986034158123_44.94986054697731',\n","       'mean_12.34986034158123_45.04986054665997',\n","       'mean_12.44986034118118_44.94986054697731',\n","       'mean_11.049860346781898_45.04986054665997',\n","       'mean_11.049860346781898_45.14986054634262',\n","       'mean_11.049860346781898_45.24986054602528',\n","       'mean_11.049860346781898_45.349860545707934',\n","       'mean_11.149860346381846_45.04986054665997',\n","       'mean_11.149860346381846_45.14986054634262',\n","       'mean_11.149860346381846_45.24986054602528',\n","       'mean_11.249860345981794_45.04986054665997',\n","       'mean_11.249860345981794_45.14986054634262',\n","       'mean_12.049860342781384_45.04986054665997',\n","       'mean_12.149860342381333_45.04986054665997',\n","       'mean_12.24986034198128_45.04986054665997',\n","       'mean_10.649860348382102_45.14986054634262',\n","       'mean_10.649860348382102_45.24986054602528',\n","       'mean_10.649860348382102_45.349860545707934',\n","       'mean_10.649860348382102_45.44986054539059',\n","       'mean_10.649860348382102_45.54986054507325',\n","       'mean_10.649860348382102_45.6498605447559',\n","       'mean_10.649860348382102_45.74986054443856',\n","       'mean_10.649860348382102_45.84986054412121',\n","       'mean_10.649860348382102_46.04986054348653',\n","       'mean_10.649860348382102_46.14986054316918',\n","       'mean_10.749860347982052_45.14986054634262',\n","       'mean_10.749860347982052_45.24986054602528',\n","       'mean_10.749860347982052_45.349860545707934',\n","       'mean_10.749860347982052_45.44986054539059',\n","       'mean_10.749860347982052_45.54986054507325',\n","       'mean_10.749860347982052_45.6498605447559',\n","       'mean_10.749860347982052_45.74986054443856',\n","       'mean_10.749860347982052_45.84986054412121',\n","       'mean_10.749860347982052_45.94986054380387',\n","       'mean_10.749860347982052_46.04986054348653',\n","       'mean_10.749860347982052_46.14986054316918',\n","       'mean_10.849860347582_45.14986054634262',\n","       'mean_10.849860347582_45.24986054602528',\n","       'mean_10.849860347582_45.349860545707934',\n","       'mean_10.849860347582_45.44986054539059',\n","       'mean_10.849860347582_45.74986054443856',\n","       'mean_10.849860347582_45.84986054412121',\n","       'mean_10.849860347582_45.94986054380387',\n","       'mean_10.849860347582_46.04986054348653',\n","       'mean_10.849860347582_46.14986054316918',\n","       'mean_10.949860347181948_45.14986054634262',\n","       'mean_10.949860347181948_45.24986054602528',\n","       'mean_10.949860347181948_45.349860545707934',\n","       'mean_10.949860347181948_45.94986054380387',\n","       'mean_10.949860347181948_46.04986054348653',\n","       'mean_10.949860347181948_46.14986054316918',\n","       'mean_10.549860348782154_45.44986054539059',\n","       'mean_10.549860348782154_45.54986054507325',\n","       'mean_10.549860348782154_45.6498605447559',\n","       'mean_10.549860348782154_45.74986054443856'],\n","      dtype='object')\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.549860348782154_45.44986054539059\n","Normal starting point: \n","mean_11.349860345581742_45.04986054665997\n","Actual starting point after shuffling: \n","mean_12.149860342381333_45.04986054665997\n","Normal starting point: \n","mean_10.849860347582_45.44986054539059\n","Actual starting point after shuffling: \n","mean_10.849860347582_45.44986054539059\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Index(['mean_11.349860345581742_44.94986054697731',\n","       'mean_11.349860345581742_45.04986054665997',\n","       'mean_11.449860345181692_44.94986054697731',\n","       'mean_11.449860345181692_45.04986054665997',\n","       'mean_11.54986034478164_44.94986054697731',\n","       'mean_11.54986034478164_45.04986054665997',\n","       'mean_11.64986034438159_44.94986054697731',\n","       'mean_11.749860343981538_44.94986054697731',\n","       'mean_11.849860343581486_44.94986054697731',\n","       'mean_11.849860343581486_45.04986054665997',\n","       'mean_11.949860343181436_44.94986054697731',\n","       'mean_11.949860343181436_45.04986054665997',\n","       'mean_12.34986034158123_44.94986054697731',\n","       'mean_12.34986034158123_45.04986054665997',\n","       'mean_12.44986034118118_44.94986054697731',\n","       'mean_11.049860346781898_45.04986054665997',\n","       'mean_11.049860346781898_45.14986054634262',\n","       'mean_11.049860346781898_45.24986054602528',\n","       'mean_11.049860346781898_45.349860545707934',\n","       'mean_11.149860346381846_45.04986054665997',\n","       'mean_11.149860346381846_45.14986054634262',\n","       'mean_11.149860346381846_45.24986054602528',\n","       'mean_11.249860345981794_45.04986054665997',\n","       'mean_11.249860345981794_45.14986054634262',\n","       'mean_12.049860342781384_45.04986054665997',\n","       'mean_12.149860342381333_45.04986054665997',\n","       'mean_12.24986034198128_45.04986054665997',\n","       'mean_10.649860348382102_45.14986054634262',\n","       'mean_10.649860348382102_45.24986054602528',\n","       'mean_10.649860348382102_45.349860545707934',\n","       'mean_10.649860348382102_45.44986054539059',\n","       'mean_10.649860348382102_45.54986054507325',\n","       'mean_10.649860348382102_45.6498605447559',\n","       'mean_10.649860348382102_45.74986054443856',\n","       'mean_10.649860348382102_45.84986054412121',\n","       'mean_10.649860348382102_46.04986054348653',\n","       'mean_10.649860348382102_46.14986054316918',\n","       'mean_10.749860347982052_45.14986054634262',\n","       'mean_10.749860347982052_45.24986054602528',\n","       'mean_10.749860347982052_45.349860545707934',\n","       'mean_10.749860347982052_45.44986054539059',\n","       'mean_10.749860347982052_45.54986054507325',\n","       'mean_10.749860347982052_45.6498605447559',\n","       'mean_10.749860347982052_45.74986054443856',\n","       'mean_10.749860347982052_45.84986054412121',\n","       'mean_10.749860347982052_45.94986054380387',\n","       'mean_10.749860347982052_46.04986054348653',\n","       'mean_10.749860347982052_46.14986054316918',\n","       'mean_10.849860347582_45.14986054634262',\n","       'mean_10.849860347582_45.24986054602528',\n","       'mean_10.849860347582_45.349860545707934',\n","       'mean_10.849860347582_45.44986054539059',\n","       'mean_10.849860347582_45.74986054443856',\n","       'mean_10.849860347582_45.84986054412121',\n","       'mean_10.849860347582_45.94986054380387',\n","       'mean_10.849860347582_46.04986054348653',\n","       'mean_10.849860347582_46.14986054316918',\n","       'mean_10.949860347181948_45.14986054634262',\n","       'mean_10.949860347181948_45.24986054602528',\n","       'mean_10.949860347181948_45.349860545707934',\n","       'mean_10.949860347181948_45.94986054380387',\n","       'mean_10.949860347181948_46.04986054348653',\n","       'mean_10.949860347181948_46.14986054316918',\n","       'mean_10.549860348782154_45.44986054539059',\n","       'mean_10.549860348782154_45.54986054507325',\n","       'mean_10.549860348782154_45.6498605447559',\n","       'mean_10.549860348782154_45.74986054443856'],\n","      dtype='object')\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.549860348782154_45.44986054539059\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.649860348382102_46.14986054316918\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.949860347181948_45.24986054602528\n","Normal starting point: \n","mean_10.749860347982052_45.54986054507325\n","Actual starting point after shuffling: \n","mean_10.749860347982052_45.54986054507325\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Index(['mean_11.349860345581742_44.94986054697731',\n","       'mean_11.349860345581742_45.04986054665997',\n","       'mean_11.449860345181692_44.94986054697731',\n","       'mean_11.449860345181692_45.04986054665997',\n","       'mean_11.54986034478164_44.94986054697731',\n","       'mean_11.54986034478164_45.04986054665997',\n","       'mean_11.64986034438159_44.94986054697731',\n","       'mean_11.749860343981538_44.94986054697731',\n","       'mean_11.849860343581486_44.94986054697731',\n","       'mean_11.849860343581486_45.04986054665997',\n","       'mean_11.949860343181436_44.94986054697731',\n","       'mean_11.949860343181436_45.04986054665997',\n","       'mean_12.34986034158123_44.94986054697731',\n","       'mean_12.34986034158123_45.04986054665997',\n","       'mean_12.44986034118118_44.94986054697731',\n","       'mean_11.049860346781898_45.04986054665997',\n","       'mean_11.049860346781898_45.14986054634262',\n","       'mean_11.049860346781898_45.24986054602528',\n","       'mean_11.049860346781898_45.349860545707934',\n","       'mean_11.149860346381846_45.04986054665997',\n","       'mean_11.149860346381846_45.14986054634262',\n","       'mean_11.149860346381846_45.24986054602528',\n","       'mean_11.249860345981794_45.04986054665997',\n","       'mean_11.249860345981794_45.14986054634262',\n","       'mean_12.049860342781384_45.04986054665997',\n","       'mean_12.149860342381333_45.04986054665997',\n","       'mean_12.24986034198128_45.04986054665997',\n","       'mean_10.649860348382102_45.14986054634262',\n","       'mean_10.649860348382102_45.24986054602528',\n","       'mean_10.649860348382102_45.349860545707934',\n","       'mean_10.649860348382102_45.44986054539059',\n","       'mean_10.649860348382102_45.54986054507325',\n","       'mean_10.649860348382102_45.6498605447559',\n","       'mean_10.649860348382102_45.74986054443856',\n","       'mean_10.649860348382102_45.84986054412121',\n","       'mean_10.649860348382102_46.04986054348653',\n","       'mean_10.649860348382102_46.14986054316918',\n","       'mean_10.749860347982052_45.14986054634262',\n","       'mean_10.749860347982052_45.24986054602528',\n","       'mean_10.749860347982052_45.349860545707934',\n","       'mean_10.749860347982052_45.44986054539059',\n","       'mean_10.749860347982052_45.54986054507325',\n","       'mean_10.749860347982052_45.6498605447559',\n","       'mean_10.749860347982052_45.74986054443856',\n","       'mean_10.749860347982052_45.84986054412121',\n","       'mean_10.749860347982052_45.94986054380387',\n","       'mean_10.749860347982052_46.04986054348653',\n","       'mean_10.749860347982052_46.14986054316918',\n","       'mean_10.849860347582_45.14986054634262',\n","       'mean_10.849860347582_45.24986054602528',\n","       'mean_10.849860347582_45.349860545707934',\n","       'mean_10.849860347582_45.44986054539059',\n","       'mean_10.849860347582_45.74986054443856',\n","       'mean_10.849860347582_45.84986054412121',\n","       'mean_10.849860347582_45.94986054380387',\n","       'mean_10.849860347582_46.04986054348653',\n","       'mean_10.849860347582_46.14986054316918',\n","       'mean_10.949860347181948_45.14986054634262',\n","       'mean_10.949860347181948_45.24986054602528',\n","       'mean_10.949860347181948_45.349860545707934',\n","       'mean_10.949860347181948_45.94986054380387',\n","       'mean_10.949860347181948_46.04986054348653',\n","       'mean_10.949860347181948_46.14986054316918',\n","       'mean_10.549860348782154_45.44986054539059',\n","       'mean_10.549860348782154_45.54986054507325',\n","       'mean_10.549860348782154_45.6498605447559',\n","       'mean_10.549860348782154_45.74986054443856'],\n","      dtype='object')\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.549860348782154_45.44986054539059\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.649860348382102_46.04986054348653\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.849860347582_45.14986054634262\n","Normal starting point: \n","mean_12.44986034118118_44.94986054697731\n","Actual starting point after shuffling: \n","mean_11.049860346781898_45.04986054665997\n","Normal starting point: \n","mean_12.44986034118118_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.749860347982052_45.54986054507325\n","Normal starting point: \n","mean_12.44986034118118_44.94986054697731\n","Actual starting point after shuffling: \n","mean_12.44986034118118_44.94986054697731\n","Number of aggregated features: 6\n","\n","Number of features: 67\n","\n","Index(['mean_11.349860345581742_44.94986054697731',\n","       'mean_11.349860345581742_45.04986054665997',\n","       'mean_11.449860345181692_44.94986054697731',\n","       'mean_11.449860345181692_45.04986054665997',\n","       'mean_11.54986034478164_44.94986054697731',\n","       'mean_11.54986034478164_45.04986054665997',\n","       'mean_11.64986034438159_44.94986054697731',\n","       'mean_11.749860343981538_44.94986054697731',\n","       'mean_11.849860343581486_44.94986054697731',\n","       'mean_11.849860343581486_45.04986054665997',\n","       'mean_11.949860343181436_44.94986054697731',\n","       'mean_11.949860343181436_45.04986054665997',\n","       'mean_12.34986034158123_44.94986054697731',\n","       'mean_12.34986034158123_45.04986054665997',\n","       'mean_12.44986034118118_44.94986054697731',\n","       'mean_11.049860346781898_45.04986054665997',\n","       'mean_11.049860346781898_45.14986054634262',\n","       'mean_11.049860346781898_45.24986054602528',\n","       'mean_11.049860346781898_45.349860545707934',\n","       'mean_11.149860346381846_45.04986054665997',\n","       'mean_11.149860346381846_45.14986054634262',\n","       'mean_11.149860346381846_45.24986054602528',\n","       'mean_11.249860345981794_45.04986054665997',\n","       'mean_11.249860345981794_45.14986054634262',\n","       'mean_12.049860342781384_45.04986054665997',\n","       'mean_12.149860342381333_45.04986054665997',\n","       'mean_12.24986034198128_45.04986054665997',\n","       'mean_10.649860348382102_45.14986054634262',\n","       'mean_10.649860348382102_45.24986054602528',\n","       'mean_10.649860348382102_45.349860545707934',\n","       'mean_10.649860348382102_45.44986054539059',\n","       'mean_10.649860348382102_45.54986054507325',\n","       'mean_10.649860348382102_45.6498605447559',\n","       'mean_10.649860348382102_45.74986054443856',\n","       'mean_10.649860348382102_45.84986054412121',\n","       'mean_10.649860348382102_46.04986054348653',\n","       'mean_10.649860348382102_46.14986054316918',\n","       'mean_10.749860347982052_45.14986054634262',\n","       'mean_10.749860347982052_45.24986054602528',\n","       'mean_10.749860347982052_45.349860545707934',\n","       'mean_10.749860347982052_45.44986054539059',\n","       'mean_10.749860347982052_45.54986054507325',\n","       'mean_10.749860347982052_45.6498605447559',\n","       'mean_10.749860347982052_45.74986054443856',\n","       'mean_10.749860347982052_45.84986054412121',\n","       'mean_10.749860347982052_45.94986054380387',\n","       'mean_10.749860347982052_46.04986054348653',\n","       'mean_10.749860347982052_46.14986054316918',\n","       'mean_10.849860347582_45.14986054634262',\n","       'mean_10.849860347582_45.24986054602528',\n","       'mean_10.849860347582_45.349860545707934',\n","       'mean_10.849860347582_45.44986054539059',\n","       'mean_10.849860347582_45.74986054443856',\n","       'mean_10.849860347582_45.84986054412121',\n","       'mean_10.849860347582_45.94986054380387',\n","       'mean_10.849860347582_46.04986054348653',\n","       'mean_10.849860347582_46.14986054316918',\n","       'mean_10.949860347181948_45.14986054634262',\n","       'mean_10.949860347181948_45.24986054602528',\n","       'mean_10.949860347181948_45.349860545707934',\n","       'mean_10.949860347181948_45.94986054380387',\n","       'mean_10.949860347181948_46.04986054348653',\n","       'mean_10.949860347181948_46.14986054316918',\n","       'mean_10.549860348782154_45.44986054539059',\n","       'mean_10.549860348782154_45.54986054507325',\n","       'mean_10.549860348782154_45.6498605447559',\n","       'mean_10.549860348782154_45.74986054443856'],\n","      dtype='object')\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.549860348782154_45.44986054539059\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_11.049860346781898_45.04986054665997\n","Normal starting point: \n","mean_10.649860348382102_45.14986054634262\n","Actual starting point after shuffling: \n","mean_10.649860348382102_45.24986054602528\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Index(['mean_11.349860345581742_44.94986054697731',\n","       'mean_11.349860345581742_45.04986054665997',\n","       'mean_11.449860345181692_44.94986054697731',\n","       'mean_11.449860345181692_45.04986054665997',\n","       'mean_11.54986034478164_44.94986054697731',\n","       'mean_11.54986034478164_45.04986054665997',\n","       'mean_11.64986034438159_44.94986054697731',\n","       'mean_11.749860343981538_44.94986054697731',\n","       'mean_11.849860343581486_44.94986054697731',\n","       'mean_11.849860343581486_45.04986054665997',\n","       'mean_11.949860343181436_44.94986054697731',\n","       'mean_11.949860343181436_45.04986054665997',\n","       'mean_12.34986034158123_44.94986054697731',\n","       'mean_12.34986034158123_45.04986054665997',\n","       'mean_12.44986034118118_44.94986054697731',\n","       'mean_11.049860346781898_45.04986054665997',\n","       'mean_11.049860346781898_45.14986054634262',\n","       'mean_11.049860346781898_45.24986054602528',\n","       'mean_11.049860346781898_45.349860545707934',\n","       'mean_11.149860346381846_45.04986054665997',\n","       'mean_11.149860346381846_45.14986054634262',\n","       'mean_11.149860346381846_45.24986054602528',\n","       'mean_11.249860345981794_45.04986054665997',\n","       'mean_11.249860345981794_45.14986054634262',\n","       'mean_12.049860342781384_45.04986054665997',\n","       'mean_12.149860342381333_45.04986054665997',\n","       'mean_12.24986034198128_45.04986054665997',\n","       'mean_10.649860348382102_45.14986054634262',\n","       'mean_10.649860348382102_45.24986054602528',\n","       'mean_10.649860348382102_45.349860545707934',\n","       'mean_10.649860348382102_45.44986054539059',\n","       'mean_10.649860348382102_45.54986054507325',\n","       'mean_10.649860348382102_45.6498605447559',\n","       'mean_10.649860348382102_45.74986054443856',\n","       'mean_10.649860348382102_45.84986054412121',\n","       'mean_10.649860348382102_46.04986054348653',\n","       'mean_10.649860348382102_46.14986054316918',\n","       'mean_10.749860347982052_45.14986054634262',\n","       'mean_10.749860347982052_45.24986054602528',\n","       'mean_10.749860347982052_45.349860545707934',\n","       'mean_10.749860347982052_45.44986054539059',\n","       'mean_10.749860347982052_45.54986054507325',\n","       'mean_10.749860347982052_45.6498605447559',\n","       'mean_10.749860347982052_45.74986054443856',\n","       'mean_10.749860347982052_45.84986054412121',\n","       'mean_10.749860347982052_45.94986054380387',\n","       'mean_10.749860347982052_46.04986054348653',\n","       'mean_10.749860347982052_46.14986054316918',\n","       'mean_10.849860347582_45.14986054634262',\n","       'mean_10.849860347582_45.24986054602528',\n","       'mean_10.849860347582_45.349860545707934',\n","       'mean_10.849860347582_45.44986054539059',\n","       'mean_10.849860347582_45.74986054443856',\n","       'mean_10.849860347582_45.84986054412121',\n","       'mean_10.849860347582_45.94986054380387',\n","       'mean_10.849860347582_46.04986054348653',\n","       'mean_10.849860347582_46.14986054316918',\n","       'mean_10.949860347181948_45.14986054634262',\n","       'mean_10.949860347181948_45.24986054602528',\n","       'mean_10.949860347181948_45.349860545707934',\n","       'mean_10.949860347181948_45.94986054380387',\n","       'mean_10.949860347181948_46.04986054348653',\n","       'mean_10.949860347181948_46.14986054316918',\n","       'mean_10.549860348782154_45.44986054539059',\n","       'mean_10.549860348782154_45.54986054507325',\n","       'mean_10.549860348782154_45.6498605447559',\n","       'mean_10.549860348782154_45.74986054443856'],\n","      dtype='object')\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.549860348782154_45.44986054539059\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_11.049860346781898_45.04986054665997\n","Normal starting point: \n","mean_12.34986034158123_44.94986054697731\n","Actual starting point after shuffling: \n","mean_12.149860342381333_45.04986054665997\n","Normal starting point: \n","mean_12.34986034158123_44.94986054697731\n","Actual starting point after shuffling: \n","mean_12.24986034198128_45.04986054665997\n","Normal starting point: \n","mean_12.44986034118118_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.649860348382102_45.14986054634262\n","Normal starting point: \n","mean_12.44986034118118_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.649860348382102_45.24986054602528\n","Normal starting point: \n","mean_12.44986034118118_44.94986054697731\n","Actual starting point after shuffling: \n","mean_12.44986034118118_44.94986054697731\n","Number of aggregated features: 7\n","\n","Number of features: 67\n","\n","Index(['mean_11.349860345581742_44.94986054697731',\n","       'mean_11.349860345581742_45.04986054665997',\n","       'mean_11.449860345181692_44.94986054697731',\n","       'mean_11.449860345181692_45.04986054665997',\n","       'mean_11.54986034478164_44.94986054697731',\n","       'mean_11.54986034478164_45.04986054665997',\n","       'mean_11.64986034438159_44.94986054697731',\n","       'mean_11.749860343981538_44.94986054697731',\n","       'mean_11.849860343581486_44.94986054697731',\n","       'mean_11.849860343581486_45.04986054665997',\n","       'mean_11.949860343181436_44.94986054697731',\n","       'mean_11.949860343181436_45.04986054665997',\n","       'mean_12.34986034158123_44.94986054697731',\n","       'mean_12.34986034158123_45.04986054665997',\n","       'mean_12.44986034118118_44.94986054697731',\n","       'mean_11.049860346781898_45.04986054665997',\n","       'mean_11.049860346781898_45.14986054634262',\n","       'mean_11.049860346781898_45.24986054602528',\n","       'mean_11.049860346781898_45.349860545707934',\n","       'mean_11.149860346381846_45.04986054665997',\n","       'mean_11.149860346381846_45.14986054634262',\n","       'mean_11.149860346381846_45.24986054602528',\n","       'mean_11.249860345981794_45.04986054665997',\n","       'mean_11.249860345981794_45.14986054634262',\n","       'mean_12.049860342781384_45.04986054665997',\n","       'mean_12.149860342381333_45.04986054665997',\n","       'mean_12.24986034198128_45.04986054665997',\n","       'mean_10.649860348382102_45.14986054634262',\n","       'mean_10.649860348382102_45.24986054602528',\n","       'mean_10.649860348382102_45.349860545707934',\n","       'mean_10.649860348382102_45.44986054539059',\n","       'mean_10.649860348382102_45.54986054507325',\n","       'mean_10.649860348382102_45.6498605447559',\n","       'mean_10.649860348382102_45.74986054443856',\n","       'mean_10.649860348382102_45.84986054412121',\n","       'mean_10.649860348382102_46.04986054348653',\n","       'mean_10.649860348382102_46.14986054316918',\n","       'mean_10.749860347982052_45.14986054634262',\n","       'mean_10.749860347982052_45.24986054602528',\n","       'mean_10.749860347982052_45.349860545707934',\n","       'mean_10.749860347982052_45.44986054539059',\n","       'mean_10.749860347982052_45.54986054507325',\n","       'mean_10.749860347982052_45.6498605447559',\n","       'mean_10.749860347982052_45.74986054443856',\n","       'mean_10.749860347982052_45.84986054412121',\n","       'mean_10.749860347982052_45.94986054380387',\n","       'mean_10.749860347982052_46.04986054348653',\n","       'mean_10.749860347982052_46.14986054316918',\n","       'mean_10.849860347582_45.14986054634262',\n","       'mean_10.849860347582_45.24986054602528',\n","       'mean_10.849860347582_45.349860545707934',\n","       'mean_10.849860347582_45.44986054539059',\n","       'mean_10.849860347582_45.74986054443856',\n","       'mean_10.849860347582_45.84986054412121',\n","       'mean_10.849860347582_45.94986054380387',\n","       'mean_10.849860347582_46.04986054348653',\n","       'mean_10.849860347582_46.14986054316918',\n","       'mean_10.949860347181948_45.14986054634262',\n","       'mean_10.949860347181948_45.24986054602528',\n","       'mean_10.949860347181948_45.349860545707934',\n","       'mean_10.949860347181948_45.94986054380387',\n","       'mean_10.949860347181948_46.04986054348653',\n","       'mean_10.949860347181948_46.14986054316918',\n","       'mean_10.549860348782154_45.44986054539059',\n","       'mean_10.549860348782154_45.54986054507325',\n","       'mean_10.549860348782154_45.6498605447559',\n","       'mean_10.549860348782154_45.74986054443856'],\n","      dtype='object')\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.549860348782154_45.44986054539059\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_11.049860346781898_45.04986054665997\n","Normal starting point: \n","mean_12.44986034118118_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.649860348382102_45.14986054634262\n","Normal starting point: \n","mean_12.44986034118118_44.94986054697731\n","Actual starting point after shuffling: \n","mean_12.44986034118118_44.94986054697731\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Index(['mean_11.349860345581742_44.94986054697731',\n","       'mean_11.349860345581742_45.04986054665997',\n","       'mean_11.449860345181692_44.94986054697731',\n","       'mean_11.449860345181692_45.04986054665997',\n","       'mean_11.54986034478164_44.94986054697731',\n","       'mean_11.54986034478164_45.04986054665997',\n","       'mean_11.64986034438159_44.94986054697731',\n","       'mean_11.749860343981538_44.94986054697731',\n","       'mean_11.849860343581486_44.94986054697731',\n","       'mean_11.849860343581486_45.04986054665997',\n","       'mean_11.949860343181436_44.94986054697731',\n","       'mean_11.949860343181436_45.04986054665997',\n","       'mean_12.34986034158123_44.94986054697731',\n","       'mean_12.34986034158123_45.04986054665997',\n","       'mean_12.44986034118118_44.94986054697731',\n","       'mean_11.049860346781898_45.04986054665997',\n","       'mean_11.049860346781898_45.14986054634262',\n","       'mean_11.049860346781898_45.24986054602528',\n","       'mean_11.049860346781898_45.349860545707934',\n","       'mean_11.149860346381846_45.04986054665997',\n","       'mean_11.149860346381846_45.14986054634262',\n","       'mean_11.149860346381846_45.24986054602528',\n","       'mean_11.249860345981794_45.04986054665997',\n","       'mean_11.249860345981794_45.14986054634262',\n","       'mean_12.049860342781384_45.04986054665997',\n","       'mean_12.149860342381333_45.04986054665997',\n","       'mean_12.24986034198128_45.04986054665997',\n","       'mean_10.649860348382102_45.14986054634262',\n","       'mean_10.649860348382102_45.24986054602528',\n","       'mean_10.649860348382102_45.349860545707934',\n","       'mean_10.649860348382102_45.44986054539059',\n","       'mean_10.649860348382102_45.54986054507325',\n","       'mean_10.649860348382102_45.6498605447559',\n","       'mean_10.649860348382102_45.74986054443856',\n","       'mean_10.649860348382102_45.84986054412121',\n","       'mean_10.649860348382102_46.04986054348653',\n","       'mean_10.649860348382102_46.14986054316918',\n","       'mean_10.749860347982052_45.14986054634262',\n","       'mean_10.749860347982052_45.24986054602528',\n","       'mean_10.749860347982052_45.349860545707934',\n","       'mean_10.749860347982052_45.44986054539059',\n","       'mean_10.749860347982052_45.54986054507325',\n","       'mean_10.749860347982052_45.6498605447559',\n","       'mean_10.749860347982052_45.74986054443856',\n","       'mean_10.749860347982052_45.84986054412121',\n","       'mean_10.749860347982052_45.94986054380387',\n","       'mean_10.749860347982052_46.04986054348653',\n","       'mean_10.749860347982052_46.14986054316918',\n","       'mean_10.849860347582_45.14986054634262',\n","       'mean_10.849860347582_45.24986054602528',\n","       'mean_10.849860347582_45.349860545707934',\n","       'mean_10.849860347582_45.44986054539059',\n","       'mean_10.849860347582_45.74986054443856',\n","       'mean_10.849860347582_45.84986054412121',\n","       'mean_10.849860347582_45.94986054380387',\n","       'mean_10.849860347582_46.04986054348653',\n","       'mean_10.849860347582_46.14986054316918',\n","       'mean_10.949860347181948_45.14986054634262',\n","       'mean_10.949860347181948_45.24986054602528',\n","       'mean_10.949860347181948_45.349860545707934',\n","       'mean_10.949860347181948_45.94986054380387',\n","       'mean_10.949860347181948_46.04986054348653',\n","       'mean_10.949860347181948_46.14986054316918',\n","       'mean_10.549860348782154_45.44986054539059',\n","       'mean_10.549860348782154_45.54986054507325',\n","       'mean_10.549860348782154_45.6498605447559',\n","       'mean_10.549860348782154_45.74986054443856'],\n","      dtype='object')\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.549860348782154_45.44986054539059\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_11.049860346781898_45.04986054665997\n","Normal starting point: \n","mean_10.649860348382102_45.24986054602528\n","Actual starting point after shuffling: \n","mean_10.649860348382102_45.24986054602528\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Index(['mean_11.349860345581742_44.94986054697731',\n","       'mean_11.349860345581742_45.04986054665997',\n","       'mean_11.449860345181692_44.94986054697731',\n","       'mean_11.449860345181692_45.04986054665997',\n","       'mean_11.54986034478164_44.94986054697731',\n","       'mean_11.54986034478164_45.04986054665997',\n","       'mean_11.64986034438159_44.94986054697731',\n","       'mean_11.749860343981538_44.94986054697731',\n","       'mean_11.849860343581486_44.94986054697731',\n","       'mean_11.849860343581486_45.04986054665997',\n","       'mean_11.949860343181436_44.94986054697731',\n","       'mean_11.949860343181436_45.04986054665997',\n","       'mean_12.34986034158123_44.94986054697731',\n","       'mean_12.34986034158123_45.04986054665997',\n","       'mean_12.44986034118118_44.94986054697731',\n","       'mean_11.049860346781898_45.04986054665997',\n","       'mean_11.049860346781898_45.14986054634262',\n","       'mean_11.049860346781898_45.24986054602528',\n","       'mean_11.049860346781898_45.349860545707934',\n","       'mean_11.149860346381846_45.04986054665997',\n","       'mean_11.149860346381846_45.14986054634262',\n","       'mean_11.149860346381846_45.24986054602528',\n","       'mean_11.249860345981794_45.04986054665997',\n","       'mean_11.249860345981794_45.14986054634262',\n","       'mean_12.049860342781384_45.04986054665997',\n","       'mean_12.149860342381333_45.04986054665997',\n","       'mean_12.24986034198128_45.04986054665997',\n","       'mean_10.649860348382102_45.14986054634262',\n","       'mean_10.649860348382102_45.24986054602528',\n","       'mean_10.649860348382102_45.349860545707934',\n","       'mean_10.649860348382102_45.44986054539059',\n","       'mean_10.649860348382102_45.54986054507325',\n","       'mean_10.649860348382102_45.6498605447559',\n","       'mean_10.649860348382102_45.74986054443856',\n","       'mean_10.649860348382102_45.84986054412121',\n","       'mean_10.649860348382102_46.04986054348653',\n","       'mean_10.649860348382102_46.14986054316918',\n","       'mean_10.749860347982052_45.14986054634262',\n","       'mean_10.749860347982052_45.24986054602528',\n","       'mean_10.749860347982052_45.349860545707934',\n","       'mean_10.749860347982052_45.44986054539059',\n","       'mean_10.749860347982052_45.54986054507325',\n","       'mean_10.749860347982052_45.6498605447559',\n","       'mean_10.749860347982052_45.74986054443856',\n","       'mean_10.749860347982052_45.84986054412121',\n","       'mean_10.749860347982052_45.94986054380387',\n","       'mean_10.749860347982052_46.04986054348653',\n","       'mean_10.749860347982052_46.14986054316918',\n","       'mean_10.849860347582_45.14986054634262',\n","       'mean_10.849860347582_45.24986054602528',\n","       'mean_10.849860347582_45.349860545707934',\n","       'mean_10.849860347582_45.44986054539059',\n","       'mean_10.849860347582_45.74986054443856',\n","       'mean_10.849860347582_45.84986054412121',\n","       'mean_10.849860347582_45.94986054380387',\n","       'mean_10.849860347582_46.04986054348653',\n","       'mean_10.849860347582_46.14986054316918',\n","       'mean_10.949860347181948_45.14986054634262',\n","       'mean_10.949860347181948_45.24986054602528',\n","       'mean_10.949860347181948_45.349860545707934',\n","       'mean_10.949860347181948_45.94986054380387',\n","       'mean_10.949860347181948_46.04986054348653',\n","       'mean_10.949860347181948_46.14986054316918',\n","       'mean_10.549860348782154_45.44986054539059',\n","       'mean_10.549860348782154_45.54986054507325',\n","       'mean_10.549860348782154_45.6498605447559',\n","       'mean_10.549860348782154_45.74986054443856'],\n","      dtype='object')\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.549860348782154_45.44986054539059\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_10.849860347582_45.94986054380387\n","Normal starting point: \n","mean_11.349860345581742_44.94986054697731\n","Actual starting point after shuffling: \n","mean_11.049860346781898_45.04986054665997\n","Number of aggregated features: 3\n","\n"]}],"source":["random_seed = randomlist[0]\n","basin = \"Garda_Mincio\"\n","print('####################' + basin + '####################')\n","target_df_train, target_df_val, target_df_test, target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', \n","    path=path_target+basin+'.csv', window_size = 1)\n","eps = 0.001\n","actual_path = path_features+basin+'_aggreg.csv'\n","output, aggregate_trainVal, aggregate_test = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg', \n","                                                                              'cyclostationary_mean_tg_1w',\n","                                                                              'cyclostationary_mean_tg_4w', \n","                                                                              'cyclostationary_mean_tg_8w',\n","                                                                              'cyclostationary_mean_tg_12w', \n","                                                                              'cyclostationary_mean_tg_16w',\n","                                                                              'cyclostationary_mean_tg_24w',\n","                                                                              'cyclostationary_mean_rr', \n","                                                                              'cyclostationary_mean_rr_1w',\n","                                                                              'cyclostationary_mean_rr_4w', \n","                                                                              'cyclostationary_mean_rr_8w',\n","                                                                              'cyclostationary_mean_rr_12w', \n","                                                                              'cyclostationary_mean_rr_16w',\n","                                                                              'cyclostationary_mean_rr_24w'\n","                                                                              ],\n","                                                                        target_df_trainVal, eps=eps,\n","                                                                        max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01',\n","                                                                        curr_seed=random_seed, shuffle=False, shuffle_starting_point_only = True)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":641},"executionInfo":{"elapsed":314,"status":"ok","timestamp":1684763655214,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"IkFfTcE8vTB6","outputId":"172252a1-649a-4e06-cfe0-fa68d9a30fcf"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-fd4e88ad-22f0-4415-94ca-7d6358f18902\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003emean_11.349860345581742_44.94986054697731\u003c/th\u003e\n","      \u003cth\u003emean_11.349860345581742_45.04986054665997\u003c/th\u003e\n","      \u003cth\u003emean_11.449860345181692_44.94986054697731\u003c/th\u003e\n","      \u003cth\u003emean_11.449860345181692_45.04986054665997\u003c/th\u003e\n","      \u003cth\u003emean_11.54986034478164_44.94986054697731\u003c/th\u003e\n","      \u003cth\u003emean_11.54986034478164_45.04986054665997\u003c/th\u003e\n","      \u003cth\u003emean_11.64986034438159_44.94986054697731\u003c/th\u003e\n","      \u003cth\u003emean_11.749860343981538_44.94986054697731\u003c/th\u003e\n","      \u003cth\u003emean_11.849860343581486_44.94986054697731\u003c/th\u003e\n","      \u003cth\u003emean_11.849860343581486_45.04986054665997\u003c/th\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003cth\u003emean_10.949860347181948_45.14986054634262\u003c/th\u003e\n","      \u003cth\u003emean_10.949860347181948_45.24986054602528\u003c/th\u003e\n","      \u003cth\u003emean_10.949860347181948_45.349860545707934\u003c/th\u003e\n","      \u003cth\u003emean_10.949860347181948_45.94986054380387\u003c/th\u003e\n","      \u003cth\u003emean_10.949860347181948_46.04986054348653\u003c/th\u003e\n","      \u003cth\u003emean_10.949860347181948_46.14986054316918\u003c/th\u003e\n","      \u003cth\u003emean_10.549860348782154_45.44986054539059\u003c/th\u003e\n","      \u003cth\u003emean_10.549860348782154_45.54986054507325\u003c/th\u003e\n","      \u003cth\u003emean_10.549860348782154_45.6498605447559\u003c/th\u003e\n","      \u003cth\u003emean_10.549860348782154_45.74986054443856\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e3.207456\u003c/td\u003e\n","      \u003ctd\u003e3.297651\u003c/td\u003e\n","      \u003ctd\u003e2.783099\u003c/td\u003e\n","      \u003ctd\u003e2.821105\u003c/td\u003e\n","      \u003ctd\u003e1.258830\u003c/td\u003e\n","      \u003ctd\u003e1.422104\u003c/td\u003e\n","      \u003ctd\u003e-0.499844\u003c/td\u003e\n","      \u003ctd\u003e-0.074300\u003c/td\u003e\n","      \u003ctd\u003e1.785845\u003c/td\u003e\n","      \u003ctd\u003e1.266257\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e2.745747\u003c/td\u003e\n","      \u003ctd\u003e1.830092\u003c/td\u003e\n","      \u003ctd\u003e1.151971\u003c/td\u003e\n","      \u003ctd\u003e2.154612\u003c/td\u003e\n","      \u003ctd\u003e2.511212\u003c/td\u003e\n","      \u003ctd\u003e2.738489\u003c/td\u003e\n","      \u003ctd\u003e2.556723\u003c/td\u003e\n","      \u003ctd\u003e1.769422\u003c/td\u003e\n","      \u003ctd\u003e2.522854\u003c/td\u003e\n","      \u003ctd\u003e2.391862\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e2.309203\u003c/td\u003e\n","      \u003ctd\u003e1.855434\u003c/td\u003e\n","      \u003ctd\u003e2.368965\u003c/td\u003e\n","      \u003ctd\u003e2.147824\u003c/td\u003e\n","      \u003ctd\u003e2.803999\u003c/td\u003e\n","      \u003ctd\u003e2.371406\u003c/td\u003e\n","      \u003ctd\u003e1.036654\u003c/td\u003e\n","      \u003ctd\u003e1.602794\u003c/td\u003e\n","      \u003ctd\u003e2.134216\u003c/td\u003e\n","      \u003ctd\u003e1.754440\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e1.787778\u003c/td\u003e\n","      \u003ctd\u003e1.193085\u003c/td\u003e\n","      \u003ctd\u003e0.870551\u003c/td\u003e\n","      \u003ctd\u003e4.547085\u003c/td\u003e\n","      \u003ctd\u003e5.558760\u003c/td\u003e\n","      \u003ctd\u003e5.459724\u003c/td\u003e\n","      \u003ctd\u003e3.789723\u003c/td\u003e\n","      \u003ctd\u003e4.323750\u003c/td\u003e\n","      \u003ctd\u003e3.914084\u003c/td\u003e\n","      \u003ctd\u003e3.664721\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e1.536681\u003c/td\u003e\n","      \u003ctd\u003e1.282708\u003c/td\u003e\n","      \u003ctd\u003e1.507159\u003c/td\u003e\n","      \u003ctd\u003e0.947016\u003c/td\u003e\n","      \u003ctd\u003e1.969045\u003c/td\u003e\n","      \u003ctd\u003e1.127633\u003c/td\u003e\n","      \u003ctd\u003e1.184744\u003c/td\u003e\n","      \u003ctd\u003e1.554165\u003c/td\u003e\n","      \u003ctd\u003e1.982804\u003c/td\u003e\n","      \u003ctd\u003e1.752417\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e0.924445\u003c/td\u003e\n","      \u003ctd\u003e0.538122\u003c/td\u003e\n","      \u003ctd\u003e0.299188\u003c/td\u003e\n","      \u003ctd\u003e3.013864\u003c/td\u003e\n","      \u003ctd\u003e3.645080\u003c/td\u003e\n","      \u003ctd\u003e3.703467\u003c/td\u003e\n","      \u003ctd\u003e2.198768\u003c/td\u003e\n","      \u003ctd\u003e2.500586\u003c/td\u003e\n","      \u003ctd\u003e2.745334\u003c/td\u003e\n","      \u003ctd\u003e2.567081\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e0.838330\u003c/td\u003e\n","      \u003ctd\u003e0.681827\u003c/td\u003e\n","      \u003ctd\u003e0.853553\u003c/td\u003e\n","      \u003ctd\u003e0.413714\u003c/td\u003e\n","      \u003ctd\u003e1.445855\u003c/td\u003e\n","      \u003ctd\u003e0.568398\u003c/td\u003e\n","      \u003ctd\u003e0.744181\u003c/td\u003e\n","      \u003ctd\u003e1.034754\u003c/td\u003e\n","      \u003ctd\u003e1.349881\u003c/td\u003e\n","      \u003ctd\u003e1.167798\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e0.531169\u003c/td\u003e\n","      \u003ctd\u003e0.290419\u003c/td\u003e\n","      \u003ctd\u003e0.246256\u003c/td\u003e\n","      \u003ctd\u003e2.874078\u003c/td\u003e\n","      \u003ctd\u003e3.477684\u003c/td\u003e\n","      \u003ctd\u003e3.678456\u003c/td\u003e\n","      \u003ctd\u003e2.072628\u003c/td\u003e\n","      \u003ctd\u003e2.344124\u003c/td\u003e\n","      \u003ctd\u003e2.600717\u003c/td\u003e\n","      \u003ctd\u003e2.587748\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e1.259691\u003c/td\u003e\n","      \u003ctd\u003e0.930066\u003c/td\u003e\n","      \u003ctd\u003e1.477911\u003c/td\u003e\n","      \u003ctd\u003e1.040630\u003c/td\u003e\n","      \u003ctd\u003e1.631074\u003c/td\u003e\n","      \u003ctd\u003e0.814454\u003c/td\u003e\n","      \u003ctd\u003e1.081189\u003c/td\u003e\n","      \u003ctd\u003e1.211671\u003c/td\u003e\n","      \u003ctd\u003e1.301213\u003c/td\u003e\n","      \u003ctd\u003e1.226112\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e0.193334\u003c/td\u003e\n","      \u003ctd\u003e0.022587\u003c/td\u003e\n","      \u003ctd\u003e-0.214478\u003c/td\u003e\n","      \u003ctd\u003e2.011651\u003c/td\u003e\n","      \u003ctd\u003e2.506752\u003c/td\u003e\n","      \u003ctd\u003e2.763421\u003c/td\u003e\n","      \u003ctd\u003e1.284442\u003c/td\u003e\n","      \u003ctd\u003e1.475371\u003c/td\u003e\n","      \u003ctd\u003e1.728102\u003c/td\u003e\n","      \u003ctd\u003e1.805581\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e...\u003c/th\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e406\u003c/th\u003e\n","      \u003ctd\u003e-0.895112\u003c/td\u003e\n","      \u003ctd\u003e-0.401893\u003c/td\u003e\n","      \u003ctd\u003e-1.261234\u003c/td\u003e\n","      \u003ctd\u003e-0.964170\u003c/td\u003e\n","      \u003ctd\u003e-1.273093\u003c/td\u003e\n","      \u003ctd\u003e-1.149891\u003c/td\u003e\n","      \u003ctd\u003e-1.219059\u003c/td\u003e\n","      \u003ctd\u003e-1.055789\u003c/td\u003e\n","      \u003ctd\u003e-0.633284\u003c/td\u003e\n","      \u003ctd\u003e-0.714066\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e-0.563825\u003c/td\u003e\n","      \u003ctd\u003e-0.450454\u003c/td\u003e\n","      \u003ctd\u003e-0.366832\u003c/td\u003e\n","      \u003ctd\u003e-0.872908\u003c/td\u003e\n","      \u003ctd\u003e-0.806074\u003c/td\u003e\n","      \u003ctd\u003e-1.069294\u003c/td\u003e\n","      \u003ctd\u003e-0.990897\u003c/td\u003e\n","      \u003ctd\u003e-0.955825\u003c/td\u003e\n","      \u003ctd\u003e-1.407006\u003c/td\u003e\n","      \u003ctd\u003e-1.090589\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e407\u003c/th\u003e\n","      \u003ctd\u003e-0.321277\u003c/td\u003e\n","      \u003ctd\u003e0.198700\u003c/td\u003e\n","      \u003ctd\u003e-0.761462\u003c/td\u003e\n","      \u003ctd\u003e-0.424014\u003c/td\u003e\n","      \u003ctd\u003e-0.928823\u003c/td\u003e\n","      \u003ctd\u003e-0.731564\u003c/td\u003e\n","      \u003ctd\u003e-0.942825\u003c/td\u003e\n","      \u003ctd\u003e-0.785399\u003c/td\u003e\n","      \u003ctd\u003e-0.394359\u003c/td\u003e\n","      \u003ctd\u003e-0.438864\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e-0.166107\u003c/td\u003e\n","      \u003ctd\u003e-0.087924\u003c/td\u003e\n","      \u003ctd\u003e-0.095020\u003c/td\u003e\n","      \u003ctd\u003e-0.467096\u003c/td\u003e\n","      \u003ctd\u003e-0.393638\u003c/td\u003e\n","      \u003ctd\u003e-0.684219\u003c/td\u003e\n","      \u003ctd\u003e-0.728833\u003c/td\u003e\n","      \u003ctd\u003e-0.678092\u003c/td\u003e\n","      \u003ctd\u003e-1.305794\u003c/td\u003e\n","      \u003ctd\u003e-1.082790\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e408\u003c/th\u003e\n","      \u003ctd\u003e-0.249014\u003c/td\u003e\n","      \u003ctd\u003e0.270191\u003c/td\u003e\n","      \u003ctd\u003e-0.689507\u003c/td\u003e\n","      \u003ctd\u003e-0.344621\u003c/td\u003e\n","      \u003ctd\u003e-0.834090\u003c/td\u003e\n","      \u003ctd\u003e-0.630262\u003c/td\u003e\n","      \u003ctd\u003e-0.876407\u003c/td\u003e\n","      \u003ctd\u003e-0.718080\u003c/td\u003e\n","      \u003ctd\u003e-0.316829\u003c/td\u003e\n","      \u003ctd\u003e-0.350577\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e-0.065481\u003c/td\u003e\n","      \u003ctd\u003e0.055642\u003c/td\u003e\n","      \u003ctd\u003e0.091543\u003c/td\u003e\n","      \u003ctd\u003e-0.249248\u003c/td\u003e\n","      \u003ctd\u003e-0.232331\u003c/td\u003e\n","      \u003ctd\u003e-0.482049\u003c/td\u003e\n","      \u003ctd\u003e-0.551561\u003c/td\u003e\n","      \u003ctd\u003e-0.501721\u003c/td\u003e\n","      \u003ctd\u003e-1.174669\u003c/td\u003e\n","      \u003ctd\u003e-0.961943\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e409\u003c/th\u003e\n","      \u003ctd\u003e-0.205121\u003c/td\u003e\n","      \u003ctd\u003e0.304836\u003c/td\u003e\n","      \u003ctd\u003e-0.623757\u003c/td\u003e\n","      \u003ctd\u003e-0.288114\u003c/td\u003e\n","      \u003ctd\u003e-0.760164\u003c/td\u003e\n","      \u003ctd\u003e-0.556316\u003c/td\u003e\n","      \u003ctd\u003e-0.743453\u003c/td\u003e\n","      \u003ctd\u003e-0.599004\u003c/td\u003e\n","      \u003ctd\u003e-0.221473\u003c/td\u003e\n","      \u003ctd\u003e-0.237523\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e-0.054215\u003c/td\u003e\n","      \u003ctd\u003e0.157700\u003c/td\u003e\n","      \u003ctd\u003e0.184445\u003c/td\u003e\n","      \u003ctd\u003e-0.184850\u003c/td\u003e\n","      \u003ctd\u003e-0.176353\u003c/td\u003e\n","      \u003ctd\u003e-0.421931\u003c/td\u003e\n","      \u003ctd\u003e-0.477888\u003c/td\u003e\n","      \u003ctd\u003e-0.431335\u003c/td\u003e\n","      \u003ctd\u003e-1.130728\u003c/td\u003e\n","      \u003ctd\u003e-0.910794\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e410\u003c/th\u003e\n","      \u003ctd\u003e-0.208359\u003c/td\u003e\n","      \u003ctd\u003e0.349330\u003c/td\u003e\n","      \u003ctd\u003e-0.612521\u003c/td\u003e\n","      \u003ctd\u003e-0.248731\u003c/td\u003e\n","      \u003ctd\u003e-0.755297\u003c/td\u003e\n","      \u003ctd\u003e-0.525825\u003c/td\u003e\n","      \u003ctd\u003e-0.737321\u003c/td\u003e\n","      \u003ctd\u003e-0.623934\u003c/td\u003e\n","      \u003ctd\u003e-0.301751\u003c/td\u003e\n","      \u003ctd\u003e-0.301910\u003c/td\u003e\n","      \u003ctd\u003e...\u003c/td\u003e\n","      \u003ctd\u003e0.030733\u003c/td\u003e\n","      \u003ctd\u003e0.229483\u003c/td\u003e\n","      \u003ctd\u003e0.192987\u003c/td\u003e\n","      \u003ctd\u003e0.028905\u003c/td\u003e\n","      \u003ctd\u003e0.027148\u003c/td\u003e\n","      \u003ctd\u003e-0.238182\u003c/td\u003e\n","      \u003ctd\u003e-0.451894\u003c/td\u003e\n","      \u003ctd\u003e-0.472306\u003c/td\u003e\n","      \u003ctd\u003e-1.218718\u003c/td\u003e\n","      \u003ctd\u003e-0.951135\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003cp\u003e411 rows  67 columns\u003c/p\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd4e88ad-22f0-4415-94ca-7d6358f18902')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-fd4e88ad-22f0-4415-94ca-7d6358f18902 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fd4e88ad-22f0-4415-94ca-7d6358f18902');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["     mean_11.349860345581742_44.94986054697731  \\\n","0                                     3.207456   \n","1                                     2.309203   \n","2                                     1.536681   \n","3                                     0.838330   \n","4                                     1.259691   \n","..                                         ...   \n","406                                  -0.895112   \n","407                                  -0.321277   \n","408                                  -0.249014   \n","409                                  -0.205121   \n","410                                  -0.208359   \n","\n","     mean_11.349860345581742_45.04986054665997  \\\n","0                                     3.297651   \n","1                                     1.855434   \n","2                                     1.282708   \n","3                                     0.681827   \n","4                                     0.930066   \n","..                                         ...   \n","406                                  -0.401893   \n","407                                   0.198700   \n","408                                   0.270191   \n","409                                   0.304836   \n","410                                   0.349330   \n","\n","     mean_11.449860345181692_44.94986054697731  \\\n","0                                     2.783099   \n","1                                     2.368965   \n","2                                     1.507159   \n","3                                     0.853553   \n","4                                     1.477911   \n","..                                         ...   \n","406                                  -1.261234   \n","407                                  -0.761462   \n","408                                  -0.689507   \n","409                                  -0.623757   \n","410                                  -0.612521   \n","\n","     mean_11.449860345181692_45.04986054665997  \\\n","0                                     2.821105   \n","1                                     2.147824   \n","2                                     0.947016   \n","3                                     0.413714   \n","4                                     1.040630   \n","..                                         ...   \n","406                                  -0.964170   \n","407                                  -0.424014   \n","408                                  -0.344621   \n","409                                  -0.288114   \n","410                                  -0.248731   \n","\n","     mean_11.54986034478164_44.94986054697731  \\\n","0                                    1.258830   \n","1                                    2.803999   \n","2                                    1.969045   \n","3                                    1.445855   \n","4                                    1.631074   \n","..                                        ...   \n","406                                 -1.273093   \n","407                                 -0.928823   \n","408                                 -0.834090   \n","409                                 -0.760164   \n","410                                 -0.755297   \n","\n","     mean_11.54986034478164_45.04986054665997  \\\n","0                                    1.422104   \n","1                                    2.371406   \n","2                                    1.127633   \n","3                                    0.568398   \n","4                                    0.814454   \n","..                                        ...   \n","406                                 -1.149891   \n","407                                 -0.731564   \n","408                                 -0.630262   \n","409                                 -0.556316   \n","410                                 -0.525825   \n","\n","     mean_11.64986034438159_44.94986054697731  \\\n","0                                   -0.499844   \n","1                                    1.036654   \n","2                                    1.184744   \n","3                                    0.744181   \n","4                                    1.081189   \n","..                                        ...   \n","406                                 -1.219059   \n","407                                 -0.942825   \n","408                                 -0.876407   \n","409                                 -0.743453   \n","410                                 -0.737321   \n","\n","     mean_11.749860343981538_44.94986054697731  \\\n","0                                    -0.074300   \n","1                                     1.602794   \n","2                                     1.554165   \n","3                                     1.034754   \n","4                                     1.211671   \n","..                                         ...   \n","406                                  -1.055789   \n","407                                  -0.785399   \n","408                                  -0.718080   \n","409                                  -0.599004   \n","410                                  -0.623934   \n","\n","     mean_11.849860343581486_44.94986054697731  \\\n","0                                     1.785845   \n","1                                     2.134216   \n","2                                     1.982804   \n","3                                     1.349881   \n","4                                     1.301213   \n","..                                         ...   \n","406                                  -0.633284   \n","407                                  -0.394359   \n","408                                  -0.316829   \n","409                                  -0.221473   \n","410                                  -0.301751   \n","\n","     mean_11.849860343581486_45.04986054665997  ...  \\\n","0                                     1.266257  ...   \n","1                                     1.754440  ...   \n","2                                     1.752417  ...   \n","3                                     1.167798  ...   \n","4                                     1.226112  ...   \n","..                                         ...  ...   \n","406                                  -0.714066  ...   \n","407                                  -0.438864  ...   \n","408                                  -0.350577  ...   \n","409                                  -0.237523  ...   \n","410                                  -0.301910  ...   \n","\n","     mean_10.949860347181948_45.14986054634262  \\\n","0                                     2.745747   \n","1                                     1.787778   \n","2                                     0.924445   \n","3                                     0.531169   \n","4                                     0.193334   \n","..                                         ...   \n","406                                  -0.563825   \n","407                                  -0.166107   \n","408                                  -0.065481   \n","409                                  -0.054215   \n","410                                   0.030733   \n","\n","     mean_10.949860347181948_45.24986054602528  \\\n","0                                     1.830092   \n","1                                     1.193085   \n","2                                     0.538122   \n","3                                     0.290419   \n","4                                     0.022587   \n","..                                         ...   \n","406                                  -0.450454   \n","407                                  -0.087924   \n","408                                   0.055642   \n","409                                   0.157700   \n","410                                   0.229483   \n","\n","     mean_10.949860347181948_45.349860545707934  \\\n","0                                      1.151971   \n","1                                      0.870551   \n","2                                      0.299188   \n","3                                      0.246256   \n","4                                     -0.214478   \n","..                                          ...   \n","406                                   -0.366832   \n","407                                   -0.095020   \n","408                                    0.091543   \n","409                                    0.184445   \n","410                                    0.192987   \n","\n","     mean_10.949860347181948_45.94986054380387  \\\n","0                                     2.154612   \n","1                                     4.547085   \n","2                                     3.013864   \n","3                                     2.874078   \n","4                                     2.011651   \n","..                                         ...   \n","406                                  -0.872908   \n","407                                  -0.467096   \n","408                                  -0.249248   \n","409                                  -0.184850   \n","410                                   0.028905   \n","\n","     mean_10.949860347181948_46.04986054348653  \\\n","0                                     2.511212   \n","1                                     5.558760   \n","2                                     3.645080   \n","3                                     3.477684   \n","4                                     2.506752   \n","..                                         ...   \n","406                                  -0.806074   \n","407                                  -0.393638   \n","408                                  -0.232331   \n","409                                  -0.176353   \n","410                                   0.027148   \n","\n","     mean_10.949860347181948_46.14986054316918  \\\n","0                                     2.738489   \n","1                                     5.459724   \n","2                                     3.703467   \n","3                                     3.678456   \n","4                                     2.763421   \n","..                                         ...   \n","406                                  -1.069294   \n","407                                  -0.684219   \n","408                                  -0.482049   \n","409                                  -0.421931   \n","410                                  -0.238182   \n","\n","     mean_10.549860348782154_45.44986054539059  \\\n","0                                     2.556723   \n","1                                     3.789723   \n","2                                     2.198768   \n","3                                     2.072628   \n","4                                     1.284442   \n","..                                         ...   \n","406                                  -0.990897   \n","407                                  -0.728833   \n","408                                  -0.551561   \n","409                                  -0.477888   \n","410                                  -0.451894   \n","\n","     mean_10.549860348782154_45.54986054507325  \\\n","0                                     1.769422   \n","1                                     4.323750   \n","2                                     2.500586   \n","3                                     2.344124   \n","4                                     1.475371   \n","..                                         ...   \n","406                                  -0.955825   \n","407                                  -0.678092   \n","408                                  -0.501721   \n","409                                  -0.431335   \n","410                                  -0.472306   \n","\n","     mean_10.549860348782154_45.6498605447559  \\\n","0                                    2.522854   \n","1                                    3.914084   \n","2                                    2.745334   \n","3                                    2.600717   \n","4                                    1.728102   \n","..                                        ...   \n","406                                 -1.407006   \n","407                                 -1.305794   \n","408                                 -1.174669   \n","409                                 -1.130728   \n","410                                 -1.218718   \n","\n","     mean_10.549860348782154_45.74986054443856  \n","0                                     2.391862  \n","1                                     3.664721  \n","2                                     2.567081  \n","3                                     2.587748  \n","4                                     1.805581  \n","..                                         ...  \n","406                                  -1.090589  \n","407                                  -1.082790  \n","408                                  -0.961943  \n","409                                  -0.910794  \n","410                                  -0.951135  \n","\n","[411 rows x 67 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"},{"name":"stdout","output_type":"stream","text":["Warning: Total number of columns (67) exceeds max_columns (20) limiting to first (20) columns.\n"]}],"source":["x"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39842,"status":"ok","timestamp":1684675895385,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"Dd_c8fjYuJ9h","outputId":"832b0989-7cf8-4f13-cfbc-dab2d4f63049"},"outputs":[{"name":"stdout","output_type":"stream","text":["####################Emiliani2####################\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 9\n","\n","Number of features: 130\n","\n","Number of aggregated features: 14\n","\n","Number of features: 130\n","\n","Number of aggregated features: 11\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","----- MI Scores -----\n","[(2, 0.1417797539341001), (10, 0.13721500952563062), (8, 0.12828265634036487), (0, 0.12179110241277581), (68, 0.12131751862018479), (5, 0.11185209883590831), (11, 0.10986275099519403), (67, 0.10933154474462303), (72, 0.10910640473489472), (4, 0.1045114575243505), (71, 0.09746137816431787), (3, 0.09674503527089101), (74, 0.09054955462491504), (13, 0.09003186611152561), (40, 0.08939889585589772), (76, 0.0887785102331146), (7, 0.08840980007656025), (66, 0.08816024706287238), (57, 0.08655694030848354), (1, 0.08633953056624281), (6, 0.08600171117968501), (69, 0.08518727390993583), (43, 0.08266131741074899), (65, 0.08179196380125643), (56, 0.08079358266104533), (75, 0.078637949694317), (63, 0.07614452618739159), (54, 0.07515073162512392), (48, 0.07453154808910913), (45, 0.07300041088254008), (51, 0.0724122460457046), (9, 0.07221231675697015), (58, 0.0713705614621383), (39, 0.06990949338261673), (15, 0.0681128062203191), (32, 0.06653777766551189), (17, 0.06427469138682587), (38, 0.06384195201394072), (61, 0.06375077592342832), (49, 0.06281036758005758), (44, 0.061720810914446554), (21, 0.06062596095686573), (18, 0.0594988296754642), (37, 0.05935953452744363), (36, 0.05701935964420881), (80, 0.054705098402256264), (47, 0.05462822726817888), (55, 0.05450153113907474), (14, 0.05421868696883028), (53, 0.05388695885698442), (77, 0.05362387256451879), (46, 0.05329124766274402), (64, 0.05272715584172873), (12, 0.05260987529074913), (78, 0.051038134049028634), (50, 0.05065406938502589), (70, 0.05049155692907435), (42, 0.04874103143983202), (34, 0.04827862789610107), (73, 0.047097506874652785), (24, 0.044947963883539686), (52, 0.04488781196239462), (84, 0.044319549594830816), (20, 0.04428458759911999), (19, 0.0438202268974033), (60, 0.041211758579206226), (16, 0.04024461809293377), (59, 0.03768171944947573), (62, 0.03627480449479854), (41, 0.035603593846909636), (29, 0.03417420760169446), (81, 0.03371908153136655), (31, 0.03279882395045534), (27, 0.03091297304037759), (35, 0.03006585087319341), (82, 0.0291246591928012), (79, 0.02878024093019482), (28, 0.027466373609814694), (22, 0.025718715788767988), (30, 0.025022690464666555), (23, 0.01977566753393892), (83, 0.017990095111212343), (25, 0.017607608585779005), (33, 0.016172022555694502), (26, -0.004145623794999376)]\n","Best MI score: 0.1417797539341001\n","Adding first best original feature: 2\n","CMI: 0.009411851327375154\n","CMI: 0.005921995224084015\n","CMI: 0.01358159449648455\n","CMI: 0.0014613538802160098\n","CMI: 0.01735542054613934\n","CMI: 0.0088784609552921\n","CMI: 0.017000525833608088\n","CMI: 0.002973740395237401\n","CMI: 0.018062809415841263\n","CMI: 0.008926390966258857\n","CMI: 0.010874010411096369\n","CMI: 0.012265702290034292\n","CMI: 0.004289581310486568\n","CMI: 0.0011925383831384861\n","CMI: 0.0041398839918680985\n","CMI: 0.0030880124040162937\n","CMI: 0.025194415761086497\n","CMI: 0.0019210841817088598\n","CMI: 0.01686306636958762\n","CMI: 0.03804106438974991\n","CMI: 0.04623046183721641\n","CMI: 0.018317678084675326\n","CMI: 0.00877372113243588\n","CMI: 0.0073137291167406915\n","CMI: 0.0024771675507703483\n","CMI: 0.009449344439361906\n","CMI: 0.008660669850610425\n","CMI: 0.02446771978708076\n","CMI: 0.033456528749442604\n","CMI: 0.04852129750552894\n","CMI: 0.05944698893427197\n","CMI: 0.04162882386979275\n","CMI: 0.02036487041459209\n","CMI: 0.06160837321538096\n","CMI: 0.023518683534076545\n","CMI: 0.02085901942249213\n","CMI: 0.03342494207523833\n","CMI: 0.009665294143983788\n","Highest CMI score: 0.06160837321538096\n","Adding original feature: 71\n","CMI: 0.00044781082731470967\n","CMI: 0.0023721979356431944\n","CMI: 0.0045398866754665645\n","CMI: 0.005715532547019064\n","CMI: 0.0041934638962421444\n","CMI: 0.0052466752370231295\n","CMI: 0.010462347381183318\n","CMI: 0.005109755858011933\n","CMI: 0.000634843499583787\n","CMI: 0.008440126421508792\n","CMI: 0.01379744649646894\n","CMI: 0.0016500120619932501\n","CMI: 0.01102378361411524\n","CMI: 0.000954268498065014\n","Highest CMI score: 0.01379744649646894\n","Adding original feature: 33\n","CMI: 0.011798139222340187\n","CMI: 0.0020293544269886776\n","CMI: 0.013948125054093652\n","CMI: 0.005304951510566008\n","CMI: 0.0002626131830967271\n","CMI: 0.00016049847669266648\n","CMI: 0.0004204101617276135\n","CMI: 0.002268542884118624\n","CMI: 0.010278425011123166\n","Highest CMI score: 0.013948125054093652\n","Adding original feature: 20\n","CMI: 0.00010005463491888356\n","CMI: 0.0009210590711123123\n","CMI: 0.002994669608051226\n","CMI: 0.0034873174688561104\n","CMI: 0.0005338483879452904\n","CMI: 0.0020252914253594823\n","CMI: 0.00015154147671325724\n","CMI: 0.0036945278933021852\n","CMI: 0.0020269493068904576\n","CMI: 0.0006740068989631309\n","CMI: 0.016250543163200737\n","CMI: 0.0026700283954925186\n","CMI: 0.006951512951525102\n","CMI: 0.0015641429079600588\n","CMI: 0.014837848441241669\n","Highest CMI score: 0.016250543163200737\n","Adding original feature: 74\n","CMI: 0.0021269811500863878\n","CMI: 0.007501630588709535\n","CMI: 0.0019981780065712884\n","CMI: 0.005446924678759263\n","CMI: 0.0020433213557557173\n","CMI: 0.0012498894867415955\n","CMI: 0.014702790928975279\n","Highest CMI score: 0.014702790928975279\n","Adding original feature: 80\n","CMI: 0.004761753023259374\n","CMI: 0.003865454255216727\n","Highest CMI score: 0.004761753023259374\n","Adding original feature: 8\n","Highest CMI score: -0.0017007586696853871\n","\n","[2, 71, 33, 20, 74, 80, 8]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.47075534201332736, test score: -0.4994601351847947\n","Aggregate regression train score with FS: 0.22237264943404988, test score: 0.31024241867444835\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.47075534201332736, test score: -0.4994601351847947\n","Aggregate regression train score with FS: 0.20260081626517867, test score: 0.25838733170602435\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.203\n","Test R2 linear regression CMI best 5:  0.258 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.0:  0.701\n","Test accuracy logregr CMI best 5 for shuffle n.0:  0.75 \n","\n","####################Emiliani2####################\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 8\n","\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 5\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 9\n","\n","Number of features: 130\n","\n","Number of aggregated features: 9\n","\n","Number of features: 130\n","\n","Number of aggregated features: 9\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 2\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","----- MI Scores -----\n","[(12, 0.15246918228231238), (2, 0.1417797539341001), (11, 0.13069123294496232), (65, 0.1263818146280069), (9, 0.1231135469682487), (0, 0.11586248845462338), (3, 0.1045114575243505), (63, 0.10304206399070182), (69, 0.09843539811092092), (4, 0.09674503527089101), (60, 0.0966209825430217), (5, 0.09638910381995788), (75, 0.09207223934751455), (62, 0.09112974058257313), (61, 0.09104982381307869), (20, 0.09047532970765305), (44, 0.08939889585589772), (7, 0.08840980007656025), (6, 0.08697349987395087), (64, 0.08659024552484941), (1, 0.08633953056624281), (55, 0.08457348638491272), (70, 0.08335891158654551), (45, 0.08272066381412507), (41, 0.08167772497165847), (73, 0.08130184534173333), (59, 0.08015981151084407), (66, 0.07935783651921058), (72, 0.07608865743150646), (74, 0.07593527481570693), (47, 0.07273564035370086), (10, 0.07221231675697015), (18, 0.06896435611072183), (16, 0.0681128062203191), (71, 0.0667022030424269), (48, 0.06519639234656507), (46, 0.0651147706491816), (39, 0.06477254760606097), (17, 0.06427469138682587), (51, 0.06373165200420969), (50, 0.06281036758005758), (25, 0.06062596095686573), (21, 0.05850148040346572), (76, 0.058225689656730195), (77, 0.05791093883117723), (42, 0.05701935964420881), (54, 0.05653805308184253), (8, 0.055587005851714597), (53, 0.05450153113907474), (19, 0.054430235646067054), (57, 0.05272715584172873), (14, 0.05102007472527081), (78, 0.050575366849171265), (79, 0.050507343294060994), (68, 0.05049155692907435), (13, 0.0501310042699894), (15, 0.0485632316334752), (49, 0.04765930103366655), (67, 0.047097506874652785), (29, 0.044947963883539686), (52, 0.04488781196239462), (83, 0.044319549594830816), (24, 0.04428458759911999), (23, 0.040952307481581594), (26, 0.04070691211815687), (30, 0.04061484646912885), (58, 0.03768171944947573), (22, 0.036924379392515735), (56, 0.03627480449479854), (35, 0.03417420760169446), (37, 0.03279882395045534), (81, 0.03220695679166698), (40, 0.030224008773557843), (43, 0.02998505351765693), (80, 0.02878024093019482), (33, 0.027466373609814694), (36, 0.027357903741169944), (32, 0.024399617537454687), (27, 0.02344025889054505), (28, 0.022701818474071513), (82, 0.017990095111212343), (38, 0.016172022555694502), (31, 0.001588102169966924), (34, -0.0002453597419440218)]\n","Best MI score: 0.15246918228231238\n","Adding first best original feature: 12\n","CMI: 0.0014904131899340645\n","CMI: 0.013015892252652594\n","CMI: 0.011797715907085504\n","CMI: 0.03757846183521857\n","CMI: 0.0016309547571995986\n","CMI: 0.01787815324617162\n","CMI: 0.02823472473599603\n","CMI: 0.018462289385866276\n","CMI: 0.02670382134422558\n","CMI: 0.04798220554604385\n","CMI: 0.025015073430876666\n","CMI: 0.013650416713110014\n","CMI: 0.02897433049821574\n","CMI: 0.019027692789901768\n","CMI: 0.025655887599053268\n","CMI: 0.013958304886088013\n","CMI: 0.004028119700150767\n","CMI: 0.029008104198038814\n","CMI: 0.013287241670572852\n","CMI: 0.02548206891251545\n","CMI: 0.02357653001496854\n","CMI: 0.010677041626155098\n","CMI: 0.004896054729931237\n","CMI: 0.005905132456976769\n","Highest CMI score: 0.04798220554604385\n","Adding original feature: 63\n","CMI: 0.015302615391764501\n","CMI: 0.008650527421035753\n","CMI: 0.001330564249648697\n","CMI: 0.004436713259899333\n","CMI: 0.009431142819357752\n","CMI: 0.020077396791355506\n","CMI: 0.0004814068774238456\n","CMI: 0.015572406676912204\n","CMI: 0.020224614286399267\n","CMI: 0.01680628339662063\n","CMI: 0.02509950712407527\n","CMI: 0.010452693906802119\n","CMI: 0.006907722832130342\n","CMI: 0.0006952045332693502\n","CMI: 0.016858606328103404\n","CMI: 0.023823635364348117\n","CMI: 0.005342233701796095\n","CMI: 0.010688897827522165\n","CMI: 0.01981365932293755\n","CMI: 0.0027388495165274196\n","CMI: 0.005531473365332634\n","CMI: 0.03047292655127476\n","CMI: 0.0200574937111625\n","CMI: 0.0037750239179132616\n","CMI: 0.017012261694762137\n","CMI: 0.005792953647888538\n","CMI: 0.0110383645130461\n","CMI: 0.00034334697132909486\n","CMI: 0.004299554594471761\n","CMI: 0.0046391835264418535\n","CMI: 0.0017281927682299136\n","CMI: 0.023505571717691548\n","CMI: 0.0036528697970058532\n","CMI: 0.001025363734541207\n","CMI: 0.006168096991089833\n","CMI: 0.008271547060141993\n","CMI: 0.0066507946003794005\n","CMI: 0.006781418564358183\n","CMI: 0.010143172801081513\n","CMI: 0.0041722749838758455\n","CMI: 0.01655807281912114\n","CMI: 0.017060318215048054\n","CMI: 0.021435989195269706\n","CMI: 0.008591940308576657\n","CMI: 0.0014813409354483553\n","CMI: 0.024313992778593585\n","CMI: 0.010647691909965618\n","CMI: 0.021036331169356715\n","Highest CMI score: 0.03047292655127476\n","Adding original feature: 30\n","CMI: 0.00043120081140698985\n","CMI: 0.0027380010297073376\n","CMI: 0.00038147623496614935\n","CMI: 0.0014133608333183612\n","CMI: 0.007105544576191114\n","CMI: 0.0014730555788001476\n","CMI: 0.007175749160865164\n","CMI: 0.004823821384701693\n","CMI: 0.021539986636975678\n","CMI: 0.011616789702992403\n","CMI: 0.0015076745733570152\n","Highest CMI score: 0.021539986636975678\n","Adding original feature: 81\n","CMI: 0.0023859942108273025\n","CMI: 0.0006646346605945763\n","CMI: 0.002359835810548272\n","Highest CMI score: 0.0023859942108273025\n","Adding original feature: 11\n","Highest CMI score: -0.0011350480588480094\n","\n","[12, 63, 30, 81, 11]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.4929548038919269, test score: -0.2980923009023353\n","Aggregate regression train score with FS: 0.19487395152033693, test score: 0.26213868704172716\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.4929548038919269, test score: -0.2980923009023353\n","Aggregate regression train score with FS: 0.19487395152033693, test score: 0.26213868704172716\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.195\n","Test R2 linear regression CMI best 5:  0.262 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.1:  0.687\n","Test accuracy logregr CMI best 5 for shuffle n.1:  0.693 \n","\n","####################Emiliani2####################\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 8\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 10\n","\n","Number of features: 130\n","\n","Number of aggregated features: 13\n","\n","Number of features: 130\n","\n","Number of aggregated features: 9\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","----- MI Scores -----\n","[(9, 0.13721500952563062), (1, 0.13301823025174073), (8, 0.12712317149385993), (68, 0.12230714619074522), (0, 0.12179110241277581), (4, 0.11185209883590831), (12, 0.10986275099519403), (63, 0.10933154474462303), (64, 0.10446029715274105), (70, 0.09843539811092092), (2, 0.09837955367460148), (74, 0.09746137816431787), (5, 0.09674503527089101), (7, 0.09379158058855251), (73, 0.09054955462491504), (20, 0.09003186611152561), (40, 0.08939889585589772), (77, 0.0887785102331146), (11, 0.08840980007656025), (59, 0.08765926746917717), (3, 0.08633953056624281), (69, 0.08518727390993583), (6, 0.0843177118216153), (46, 0.08266131741074899), (62, 0.08211756606945644), (66, 0.08179196380125643), (57, 0.08079358266104533), (75, 0.07784711862990787), (43, 0.0766416995253756), (60, 0.07614452618739159), (54, 0.07515073162512392), (58, 0.07453154808910913), (37, 0.07397079829503901), (65, 0.07272607982751346), (53, 0.0724122460457046), (13, 0.07221231675697015), (78, 0.07136907917480058), (10, 0.07128216030915008), (45, 0.06990949338261673), (18, 0.0681128062203191), (35, 0.06653777766551189), (17, 0.06427469138682587), (41, 0.06405548699189753), (49, 0.06281036758005758), (47, 0.061720810914446554), (42, 0.05935953452744363), (21, 0.058354935796658736), (80, 0.054705098402256264), (56, 0.05462822726817888), (55, 0.05450153113907474), (15, 0.05421868696883028), (48, 0.05388695885698442), (76, 0.05362387256451879), (26, 0.053148177740384994), (14, 0.05110317644607735), (79, 0.051038134049028634), (72, 0.05049155692907435), (44, 0.04874103143983202), (36, 0.04827862789610107), (19, 0.04758562455990436), (71, 0.047097506874652785), (50, 0.04599544176619915), (51, 0.04488781196239462), (52, 0.04466402152975735), (83, 0.044319549594830816), (24, 0.04428458759911999), (22, 0.04309278735609501), (27, 0.04197409502721091), (67, 0.041211758579206226), (23, 0.04070691211815687), (16, 0.04024461809293377), (61, 0.0396116702618395), (30, 0.03417420760169446), (39, 0.03376859736550506), (82, 0.03371908153136655), (38, 0.033148779825756015), (34, 0.03279882395045534), (29, 0.03091297304037759), (84, 0.0291246591928012), (81, 0.02878024093019482), (31, 0.027466373609814694), (25, 0.025718715788767988), (32, 0.025022690464666555), (85, 0.017990095111212343), (33, 0.016172022555694502), (28, -0.004145623794999376)]\n","Best MI score: 0.13721500952563062\n","Adding first best original feature: 9\n","CMI: 0.0005437311250973964\n","CMI: 0.0033403690819653054\n","CMI: 0.0007229454372505439\n","CMI: 0.007525016379351129\n","CMI: 0.011609779804195697\n","CMI: 0.0008812560136682579\n","CMI: 0.011541939406410545\n","CMI: 0.017122061008201767\n","CMI: 0.0002388272513383638\n","CMI: 0.00896890948044926\n","CMI: 0.007091821299072237\n","CMI: 0.02766192367089243\n","CMI: 0.007324838411600171\n","CMI: 0.007101690740494188\n","CMI: 0.0025135741480117046\n","CMI: 0.011146266899231289\n","CMI: 0.02739494969527259\n","CMI: 0.006888052456073185\n","CMI: 0.04318041454083779\n","CMI: 0.0013198272094619434\n","CMI: 0.0044525209587841785\n","CMI: 0.007502143352531104\n","CMI: 0.04902997875423734\n","CMI: 0.03675197170407499\n","CMI: 0.029423098529384656\n","CMI: 0.015080508375508644\n","CMI: 0.002242855701132501\n","CMI: 0.057539774473253896\n","CMI: 0.0406827427900516\n","CMI: 0.016257038893598447\n","CMI: 0.029468426185157548\n","CMI: 0.028734858380781603\n","CMI: 0.03790561577145929\n","CMI: 0.0489570751835543\n","CMI: 0.020642635631114514\n","CMI: 0.009614219046355288\n","CMI: 0.027374895547514155\n","CMI: 0.03184179149888361\n","CMI: 0.004224575714541656\n","CMI: 0.009877768689602828\n","Highest CMI score: 0.057539774473253896\n","Adding original feature: 68\n","CMI: 0.008492759045567039\n","CMI: 0.02768323633161507\n","CMI: 0.010332298900229714\n","CMI: 0.0056506365415250615\n","CMI: 0.0038771805148006544\n","CMI: 0.0075269977031550694\n","CMI: 0.0012817428324555236\n","CMI: 0.0030617883541468327\n","CMI: 0.028195119359996884\n","CMI: 0.011333473137538352\n","CMI: 0.02579307537205658\n","CMI: 0.019956926251009505\n","CMI: 0.016303234738253958\n","CMI: 0.013136033160406069\n","CMI: 0.001337739075194716\n","CMI: 0.009026082357076914\n","CMI: 0.0039221364524731905\n","CMI: 0.007064445859481572\n","CMI: 0.002358239874782231\n","CMI: 0.0030496249990121516\n","CMI: 0.002871602225600872\n","CMI: 0.0021823494571670543\n","CMI: 0.010821694458737235\n","CMI: 0.0005257341251439784\n","CMI: 0.007559811520089416\n","CMI: 0.0003973381062125636\n","CMI: 0.0153671872463223\n","CMI: 0.001086521719951078\n","CMI: 0.0026018511441543435\n","CMI: 0.012096198356115084\n","CMI: 0.007158861819820256\n","CMI: 0.013117003699728708\n","CMI: 0.004315437335970396\n","CMI: 0.005940765058226022\n","CMI: 0.009999921779303811\n","CMI: 0.013925861698799447\n","CMI: 0.01577130471986371\n","CMI: 0.007171423043803249\n","Highest CMI score: 0.028195119359996884\n","Adding original feature: 14\n","CMI: 0.010787541452752764\n","CMI: 0.0007154539801031978\n","CMI: 0.0011157029616938596\n","Highest CMI score: 0.010787541452752764\n","Adding original feature: 17\n","CMI: 0.0009054193539688726\n","CMI: 0.00152019407271628\n","CMI: 0.007784763663428118\n","CMI: 0.0017812539638546732\n","Highest CMI score: 0.007784763663428118\n","Adding original feature: 75\n","CMI: 0.001374728128462066\n","Highest CMI score: 0.001374728128462066\n","Adding original feature: 82\n","CMI: 0.001289556043771567\n","CMI: 0.012921321972581001\n","Highest CMI score: 0.012921321972581001\n","Adding original feature: 73\n","CMI: 0.00018645183410820332\n","CMI: 0.0005232042687216554\n","CMI: 0.0007416676290107893\n","CMI: 0.0010056647876448555\n","Highest CMI score: 0.0010056647876448555\n","Adding original feature: 79\n","CMI: 0.002195570581957962\n","Highest CMI score: 0.002195570581957962\n","Adding original feature: 20\n","Highest CMI score: -0.0013409491416657149\n","\n","[9, 68, 14, 17, 75, 82, 73, 79, 20]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.48124791053008087, test score: -0.6807045427866554\n","Aggregate regression train score with FS: 0.24814679492861236, test score: 0.23844542492428478\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.48124791053008087, test score: -0.6807045427866554\n","Aggregate regression train score with FS: 0.2315230234898199, test score: 0.22550111494416558\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.232\n","Test R2 linear regression CMI best 5:  0.226 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.2:  0.695\n","Test accuracy logregr CMI best 5 for shuffle n.2:  0.711 \n","\n","####################Emiliani2####################\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 8\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 5\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 1\n","\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 11\n","\n","Number of features: 130\n","\n","Number of aggregated features: 8\n","\n","Number of features: 130\n","\n","Number of aggregated features: 5\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","----- MI Scores -----\n","[(5, 0.1349170730411436), (62, 0.13395572172304704), (1, 0.1322488306459369), (12, 0.13069123294496232), (8, 0.12579312385229421), (0, 0.11517243350091598), (6, 0.11185209883590831), (13, 0.10986275099519403), (2, 0.09985124999678821), (4, 0.09638910381995788), (54, 0.09522722873368694), (58, 0.09511661050849562), (71, 0.09207223934751455), (17, 0.09139628132408192), (61, 0.09133977451094433), (41, 0.08939889585589772), (9, 0.08840980007656025), (7, 0.08378591096011093), (65, 0.08325975465760076), (38, 0.08205557474531879), (67, 0.08130184534173333), (3, 0.07921842318994085), (66, 0.07608865743150646), (69, 0.07593527481570693), (37, 0.07397079829503901), (60, 0.07272607982751346), (46, 0.06927848223663591), (19, 0.0681128062203191), (53, 0.06662174497879145), (44, 0.06659945072551099), (74, 0.06620203252178232), (18, 0.06427469138682587), (48, 0.06281036758005758), (75, 0.061973557637818116), (20, 0.06173854401454857), (51, 0.0599370840593464), (57, 0.058639741159914764), (68, 0.058225689656730195), (70, 0.05791093883117723), (10, 0.05660301114055047), (22, 0.055984052269931646), (16, 0.055703209790854386), (11, 0.055587005851714597), (45, 0.0551023587005056), (21, 0.054430235646067054), (50, 0.05388695885698442), (49, 0.05329124766274402), (72, 0.050575366849171265), (64, 0.05049155692907435), (73, 0.0503967022441886), (55, 0.050174623766528904), (43, 0.050048918277901616), (14, 0.049778471953153346), (42, 0.04829202218948881), (63, 0.047097506874652785), (36, 0.04586710145277669), (15, 0.04517383305296787), (28, 0.044947963883539686), (78, 0.044319549594830816), (24, 0.04428458759911999), (23, 0.04309278735609501), (47, 0.04293666972275636), (29, 0.04061484646912885), (56, 0.03768171944947573), (59, 0.03627480449479854), (76, 0.034684498590479895), (25, 0.03438379717543677), (39, 0.03376859736550506), (52, 0.030612754597037033), (40, 0.02998505351765693), (77, 0.0291246591928012), (30, 0.028542006664438742), (32, 0.027466373609814694), (35, 0.026596125506811837), (26, 0.02500116730901378), (33, 0.024399617537454687), (27, 0.022701818474071513), (34, 0.003279000906735116), (31, 0.0005084338210195976)]\n","Best MI score: 0.1349170730411436\n","Adding first best original feature: 5\n","CMI: 0.007593587022542481\n","CMI: 0.014395902625397056\n","CMI: 0.007128027531736858\n","CMI: 0.005911314227950076\n","CMI: 0.02188213725053212\n","CMI: 0.015305430816307641\n","CMI: 0.010981329800595185\n","CMI: 0.018122359091333612\n","CMI: 0.00342179781189042\n","CMI: 0.01125976937847753\n","CMI: 0.01271845159693083\n","CMI: 0.024925663438963214\n","CMI: 0.006296912177332414\n","CMI: 0.0027770098366983464\n","CMI: 0.02583694158017741\n","CMI: 0.020923868273871882\n","CMI: 0.0004066798995099319\n","CMI: 0.013187115601697191\n","CMI: 0.007995663207404108\n","CMI: 0.012457133711518464\n","CMI: 0.003215802224951464\n","CMI: 0.008029677638094701\n","CMI: 0.018062891992101066\n","CMI: 0.010284979967722652\n","CMI: 0.02383203657380603\n","CMI: 0.007973936488195027\n","CMI: 0.0034703411070641788\n","CMI: 0.00020620384421488058\n","CMI: 0.007393765317676049\n","CMI: 0.00043137805122708817\n","CMI: 0.03704974492000487\n","CMI: 0.017481453360693955\n","CMI: 0.015773882185979082\n","CMI: 0.019082444623902184\n","CMI: 0.036764225960396246\n","CMI: 0.003029978314878251\n","CMI: 0.024475609439481766\n","CMI: 0.047480937745067064\n","CMI: 0.05721284083520509\n","CMI: 0.01714516055097315\n","CMI: 0.014920116928249655\n","CMI: 0.011534935507319516\n","CMI: 0.05605818878596022\n","CMI: 0.01648732418380458\n","CMI: 0.037489562179723074\n","CMI: 0.06370379447338967\n","CMI: 0.06600909113072762\n","CMI: 0.02917781478530082\n","CMI: 0.03150679574685242\n","CMI: 0.015287009281409275\n","CMI: 0.007423117734554285\n","CMI: 0.015443199459494683\n","CMI: 0.008902161270636366\n","CMI: 0.0037396704814351422\n","CMI: 0.013633736016325892\n","CMI: 0.026408500332325474\n","CMI: 0.00821003951645169\n","CMI: 0.0029416726565365536\n","Highest CMI score: 0.06600909113072762\n","Adding original feature: 62\n","CMI: 0.004467227372294658\n","CMI: 0.011878309397878428\n","CMI: 0.005444109649105522\n","CMI: 0.008831703473317493\n","CMI: 0.0018612351792568205\n","CMI: 0.010836152065783478\n","CMI: 0.005022212956703409\n","CMI: 0.0037259746622033962\n","Highest CMI score: 0.011878309397878428\n","Adding original feature: 14\n","CMI: 0.0007630565007560597\n","CMI: 0.0016366537888147792\n","CMI: 0.012515962596325036\n","CMI: 0.00673486942919968\n","CMI: 0.0022672852510197683\n","CMI: 0.004477051698352275\n","CMI: 0.003282103652024748\n","CMI: 0.001855515607172037\n","CMI: 0.0037510058833602478\n","CMI: 0.0004512932607748654\n","CMI: 0.0029492500847020375\n","CMI: 0.0005911237973800776\n","CMI: 0.0033606805251812644\n","CMI: 0.004299888093793253\n","CMI: 0.009980964098224687\n","CMI: 0.0014245178441484874\n","CMI: 0.003948217237193158\n","CMI: 0.0025270935039100606\n","CMI: 0.000769439131286076\n","CMI: 0.0012907466590570682\n","CMI: 0.0071928307993658624\n","Highest CMI score: 0.012515962596325036\n","Adding original feature: 7\n","CMI: 0.0003289452068613863\n","CMI: 0.0024670852962489775\n","CMI: 0.008934863422931455\n","CMI: 0.0022804160622985903\n","CMI: 0.00014438741403885458\n","CMI: 0.0016587424433436582\n","Highest CMI score: 0.008934863422931455\n","Adding original feature: 54\n","CMI: 0.0008106179533793889\n","CMI: 0.0003059491774557166\n","Highest CMI score: 0.0008106179533793889\n","Adding original feature: 20\n","CMI: 0.011666634607577497\n","Highest CMI score: 0.011666634607577497\n","Adding original feature: 71\n","Highest CMI score: -0.0008755883009942678\n","\n","[5, 62, 14, 7, 54, 20, 71]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.46753411513276766, test score: -0.020306931656428384\n","Aggregate regression train score with FS: 0.27071531774025825, test score: 0.29895970951629725\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.46753411513276766, test score: -0.020306931656428384\n","Aggregate regression train score with FS: 0.24183450044321697, test score: 0.2881765581248543\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.242\n","Test R2 linear regression CMI best 5:  0.288 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.3:  0.717\n","Test accuracy logregr CMI best 5 for shuffle n.3:  0.732 \n","\n","####################Emiliani2####################\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","Number of aggregated features: 13\n","\n","Number of features: 130\n","\n","Number of aggregated features: 10\n","\n","Number of features: 130\n","\n","Number of aggregated features: 9\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 2\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","----- MI Scores -----\n","[(9, 0.15246918228231238), (3, 0.1349170730411436), (11, 0.13069123294496232), (1, 0.13065462984779644), (7, 0.1231135469682487), (10, 0.12256467225678017), (0, 0.12182086061180196), (66, 0.12166687461546744), (68, 0.1032695949160546), (58, 0.1032310708167428), (2, 0.09837955367460148), (69, 0.09746137816431787), (5, 0.09674503527089101), (60, 0.09104982381307869), (67, 0.09054955462491504), (15, 0.09003186611152561), (38, 0.08939889585589772), (75, 0.0887785102331146), (12, 0.08840980007656025), (4, 0.08633953056624281), (57, 0.08571540481257531), (6, 0.08413534342032805), (47, 0.0809999696063312), (53, 0.08079358266104533), (76, 0.0756539453373972), (73, 0.0756116585430903), (42, 0.07370388129928994), (36, 0.07291232799503407), (59, 0.07272607982751346), (8, 0.07221231675697015), (41, 0.06990949338261673), (40, 0.06885945808877662), (46, 0.0681175128446899), (17, 0.0681128062203191), (33, 0.06653777766551189), (18, 0.06554679770153546), (71, 0.06543266244978575), (50, 0.06476007619581492), (16, 0.06427469138682587), (44, 0.06405548699189753), (64, 0.06025800996666824), (51, 0.05949934330217164), (45, 0.05935953452744363), (55, 0.05916130292386988), (48, 0.05856324305243495), (20, 0.058354935796658736), (35, 0.0577197466470289), (61, 0.05596319204538578), (78, 0.054705098402256264), (74, 0.05362387256451879), (56, 0.05329124766274402), (63, 0.05272715584172873), (13, 0.05260987529074913), (14, 0.05102007472527081), (72, 0.05049155692907435), (54, 0.04985832206533135), (77, 0.04945172109990459), (70, 0.047097506874652785), (34, 0.046401400970065065), (52, 0.04599544176619915), (26, 0.044947963883539686), (49, 0.04488781196239462), (19, 0.0448166098357237), (81, 0.044319549594830816), (23, 0.04428458759911999), (21, 0.04309278735609501), (22, 0.04070691211815687), (37, 0.03860010803242936), (65, 0.03768171944947573), (39, 0.036566437254767034), (62, 0.03627480449479854), (43, 0.035603593846909636), (28, 0.03417420760169446), (79, 0.03371908153136655), (32, 0.03279882395045534), (29, 0.03091297304037759), (80, 0.0291246591928012), (30, 0.027466373609814694), (24, 0.025718715788767988), (31, 0.0246493919988305), (25, 0.02107256144868112), (82, 0.017990095111212343), (27, -0.004145623794999376)]\n","Best MI score: 0.15246918228231238\n","Adding first best original feature: 9\n","CMI: 0.002185858509828026\n","CMI: 0.003173695655592529\n","CMI: 0.009242010891818864\n","CMI: 0.011800561253395764\n","CMI: 0.0107282052593492\n","CMI: 0.03463945992575526\n","CMI: 0.030656065862458032\n","CMI: 0.01874997708569051\n","CMI: 0.018462289385866276\n","CMI: 0.0016309547571995986\n","CMI: 0.04176020387692084\n","CMI: 0.027737577667498847\n","CMI: 0.020133922985887454\n","CMI: 0.03762661933977218\n","CMI: 0.019027692789901768\n","CMI: 0.022066154011240374\n","CMI: 0.025655887599053268\n","CMI: 0.014710054201112904\n","CMI: 0.012799170506736152\n","CMI: 0.029500787093944048\n","Highest CMI score: 0.04176020387692084\n","Adding original feature: 66\n","CMI: 0.030568639018343613\n","CMI: 0.0145319454785858\n","CMI: 0.025403364349046692\n","CMI: 0.0029561151369248972\n","CMI: 0.01372928388109304\n","CMI: 0.01130614371948227\n","CMI: 0.011680263195483598\n","CMI: 0.006807781057454609\n","CMI: 0.019012478097200636\n","CMI: 0.0025928429532232344\n","CMI: 0.005182117699902455\n","CMI: 0.001420024359657629\n","CMI: 0.004705721176203742\n","CMI: 0.004480285791057637\n","CMI: 0.002328994540688939\n","CMI: 0.012171742442267125\n","CMI: 0.00795514138473255\n","CMI: 0.0024184750964990065\n","CMI: 0.016637148211460312\n","CMI: 0.0037023402451829\n","CMI: 0.004476680094488705\n","CMI: 0.02123636573825008\n","CMI: 0.007720010036872393\n","CMI: 0.01705688510031908\n","CMI: 0.010194595262089268\n","Highest CMI score: 0.030568639018343613\n","Adding original feature: 1\n","CMI: 0.0022302893856810113\n","Highest CMI score: 0.0022302893856810113\n","Adding original feature: 78\n","CMI: 0.0076635070440145\n","CMI: 0.006392845703717204\n","CMI: 0.006731419781365017\n","CMI: 0.0022097484854975147\n","CMI: 0.0018257346774040728\n","CMI: 0.0030486916863482483\n","CMI: 0.0047218656547386995\n","CMI: 0.001342857759113275\n","CMI: 0.007935858524631523\n","Highest CMI score: 0.007935858524631523\n","Adding original feature: 77\n","CMI: 0.0035037667933783823\n","CMI: 0.0024329436941614713\n","CMI: 0.0010126524581901275\n","Highest CMI score: 0.0035037667933783823\n","Adding original feature: 3\n","CMI: 0.00072820364667181\n","CMI: 0.000911140293372803\n","Highest CMI score: 0.000911140293372803\n","Adding original feature: 67\n","CMI: 0.01602975839484283\n","CMI: 0.004885098377516495\n","CMI: 0.012521333090708187\n","CMI: 0.010333812082029104\n","CMI: 0.018378928549608986\n","CMI: 0.012422044253849629\n","CMI: 0.009287822432893\n","CMI: 0.003548511149318534\n","CMI: 0.0002364681596508933\n","CMI: 0.0003812274224871959\n","CMI: 0.0032097521673445373\n","CMI: 0.005032693943474359\n","CMI: 0.007224711940728601\n","CMI: 0.002261053721827777\n","CMI: 0.002629139081610915\n","Highest CMI score: 0.018378928549608986\n","Adding original feature: 23\n","CMI: 0.001315605114481977\n","CMI: 0.0009662907686667221\n","CMI: 0.006826644911162583\n","CMI: 0.005077224590302187\n","CMI: 0.00029847992421144776\n","CMI: 0.00466109653447061\n","CMI: 0.0034440875539678006\n","Highest CMI score: 0.006826644911162583\n","Adding original feature: 68\n","Highest CMI score: -0.00016329115310670383\n","\n","[9, 66, 1, 78, 77, 3, 67, 23, 68]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.4683407570555955, test score: -0.2866740514610535\n","Aggregate regression train score with FS: 0.2785520750922813, test score: 0.281754884338815\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.4683407570555955, test score: -0.2866740514610535\n","Aggregate regression train score with FS: 0.24018160554017765, test score: 0.05076943311561055\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.24\n","Test R2 linear regression CMI best 5:  0.051 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.4:  0.704\n","Test accuracy logregr CMI best 5 for shuffle n.4:  0.636 \n","\n","####################Emiliani2####################\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 8\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 5\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 1\n","\n","Number of features: 130\n","\n","Number of aggregated features: 8\n","\n","Number of features: 130\n","\n","Number of aggregated features: 12\n","\n","Number of features: 130\n","\n","Number of aggregated features: 8\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","----- MI Scores -----\n","[(10, 0.13721500952563062), (1, 0.13301823025174073), (8, 0.12828265634036487), (64, 0.12678550226508206), (0, 0.11633194285686282), (6, 0.09985124999678821), (5, 0.09923524916294915), (3, 0.09837955367460148), (2, 0.09638910381995788), (65, 0.09623197123570164), (63, 0.09587456364588653), (12, 0.09396973579042195), (57, 0.09323600605777407), (68, 0.09207223934751455), (61, 0.09104982381307869), (42, 0.08939889585589772), (60, 0.08873753149051027), (11, 0.08840980007656025), (4, 0.08633953056624281), (7, 0.08333026583198527), (56, 0.08305912140226565), (59, 0.08179196380125643), (69, 0.08130184534173333), (37, 0.07935995796150516), (19, 0.07819538841918847), (67, 0.07608865743150646), (72, 0.07593527481570693), (54, 0.07515073162512392), (38, 0.0736016155052639), (66, 0.0735140645695574), (62, 0.07272607982751346), (48, 0.0724122460457046), (51, 0.0699905475133246), (17, 0.06896435611072183), (41, 0.0681175128446899), (14, 0.0681128062203191), (75, 0.06620203252178232), (44, 0.06561626118641399), (35, 0.06505639083866975), (50, 0.06476007619581492), (20, 0.06427469138682587), (76, 0.061973557637818116), (23, 0.06062596095686573), (58, 0.06025800996666824), (45, 0.05893331824072426), (71, 0.058225689656730195), (70, 0.05791093883117723), (9, 0.055587005851714597), (21, 0.05450860227429629), (18, 0.054430235646067054), (15, 0.05421868696883028), (52, 0.05388695885698442), (26, 0.053148177740384994), (49, 0.05223766278849154), (73, 0.050575366849171265), (74, 0.0503967022441886), (13, 0.04925490722965137), (36, 0.04778771370564316), (28, 0.04693189552336387), (43, 0.04599544176619915), (16, 0.045872478476382754), (53, 0.04469719772368524), (46, 0.04466402152975735), (78, 0.044319549594830816), (24, 0.04070691211815687), (27, 0.04061484646912885), (22, 0.036924379392515735), (55, 0.03617542313069295), (77, 0.034684498590479895), (39, 0.03376859736550506), (47, 0.03356187213813549), (79, 0.0291246591928012), (29, 0.028542006664438742), (34, 0.026596125506811837), (25, 0.025532779646589912), (32, 0.024399617537454687), (40, 0.024391509760606597), (33, 0.008623335404627583), (31, 0.0035345946350680097), (30, -0.0017500114382319495)]\n","Best MI score: 0.13721500952563062\n","Adding first best original feature: 10\n","CMI: 0.0005437311250973964\n","CMI: 0.0033403690819653054\n","CMI: 0.0016781681617114574\n","CMI: 0.001345762746386897\n","CMI: 0.0026113762073966817\n","CMI: 0.007525016379351129\n","CMI: 0.013408985347976021\n","CMI: 0.009671108257188865\n","CMI: 0.009482781072779278\n","CMI: 0.0003284151472476293\n","CMI: 0.007700931013382539\n","CMI: 0.017354536127702574\n","CMI: 0.0014167202119841626\n","CMI: 0.003267909890492554\n","CMI: 0.007324838411600171\n","CMI: 0.007101690740494188\n","CMI: 0.00022261060006770195\n","CMI: 0.02388259012301347\n","CMI: 0.00697919411742795\n","CMI: 0.007091821299072237\n","CMI: 0.0025135741480117046\n","CMI: 0.005464394968543895\n","CMI: 0.039979712826621966\n","CMI: 0.04533509435293728\n","CMI: 0.004039316371137303\n","CMI: 0.015080508375508644\n","CMI: 0.005421197120656945\n","CMI: 0.03301468484510792\n","CMI: 0.029423098529384656\n","CMI: 0.0516191490465972\n","CMI: 0.025615135238831105\n","CMI: 0.014837594933452297\n","CMI: 0.021235948332955112\n","CMI: 0.019628031480109664\n","CMI: 0.02810146253541526\n","CMI: 0.029795305435958153\n","CMI: 0.011892147199168507\n","CMI: 0.00945606074113034\n","CMI: 0.028147738227501273\n","CMI: 0.002471896374470456\n","CMI: 0.0023002498133247173\n","CMI: 0.007320120109399447\n","CMI: 0.0040278027860420895\n","CMI: 0.009877768689602828\n","Highest CMI score: 0.0516191490465972\n","Adding original feature: 63\n","CMI: 0.00990482535308479\n","CMI: 0.017324518324972976\n","CMI: 0.0079747656422684\n","CMI: 0.020144166882456432\n","CMI: 0.01076927973357561\n","CMI: 0.017111219464270327\n","CMI: 0.0069088181389318215\n","CMI: 0.000570459656602601\n","CMI: 0.00022539419316894294\n","CMI: 0.004907156335185847\n","CMI: 0.02442809625309883\n","CMI: 0.017484435931924308\n","CMI: 0.004541774842545754\n","CMI: 0.017667861323491352\n","CMI: 0.01140417333771157\n","CMI: 0.016689728904229456\n","CMI: 0.029538064942396386\n","CMI: 0.0044158755996753785\n","CMI: 0.004861323033216264\n","CMI: 0.002059952683999111\n","CMI: 0.017211733846153765\n","CMI: 0.004923427690783383\n","CMI: 0.002686126871919603\n","CMI: 0.027581804986835184\n","CMI: 0.00993745665532289\n","CMI: 0.0027696172400529517\n","CMI: 0.002113815047269707\n","CMI: 0.007169710755265263\n","CMI: 0.016799977548442868\n","CMI: 0.00501411986283562\n","CMI: 0.01654948936676129\n","CMI: 0.008117859913750136\n","CMI: 0.0018023429417973469\n","CMI: 0.00467116480960969\n","CMI: 0.003855009356651007\n","CMI: 0.0006726944933893586\n","CMI: 0.0004386159363217179\n","CMI: 0.019532474436590175\n","CMI: 0.02120189739326228\n","CMI: 0.009542732225815864\n","CMI: 0.005997959199124048\n","CMI: 0.01364809651132648\n","CMI: 0.020398459309875466\n","CMI: 0.013453105391470516\n","CMI: 0.0012229199540416125\n","CMI: 0.009944646563665782\n","CMI: 0.03234388013207748\n","CMI: 0.009739000955862442\n","CMI: 0.0012642099941558571\n","Highest CMI score: 0.03234388013207748\n","Adding original feature: 77\n","CMI: 0.0042027286509198625\n","CMI: 0.00042181994961440483\n","CMI: 0.009618922296087073\n","CMI: 0.004175644102596465\n","CMI: 0.01655209370186958\n","CMI: 0.011048648841421982\n","CMI: 0.028659353907009244\n","CMI: 0.00195369677034099\n","CMI: 0.0003817341026987886\n","CMI: 0.005457048737768394\n","CMI: 0.0019634188510393447\n","CMI: 0.00871269900317681\n","CMI: 0.0011829315261486506\n","CMI: 0.019612072831730137\n","CMI: 0.011262453676139234\n","CMI: 0.0018136449264816723\n","CMI: 0.0031245064354678553\n","CMI: 0.008286812622007395\n","CMI: 0.0029047778854283945\n","Highest CMI score: 0.028659353907009244\n","Adding original feature: 20\n","Highest CMI score: -0.0004714415201160782\n","\n","[10, 63, 77, 20]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.4494438522409865, test score: 0.08068762575125199\n","Aggregate regression train score with FS: 0.2015692672768159, test score: 0.24326442457444675\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.4494438522409865, test score: 0.08068762575125199\n","Aggregate regression train score with FS: 0.2015692672768159, test score: 0.24326442457444675\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.202\n","Test R2 linear regression CMI best 5:  0.243 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.5:  0.679\n","Test accuracy logregr CMI best 5 for shuffle n.5:  0.719 \n","\n","####################Emiliani2####################\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 8\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 11\n","\n","Number of features: 130\n","\n","Number of aggregated features: 13\n","\n","Number of features: 130\n","\n","Number of aggregated features: 9\n","\n","Number of features: 130\n","\n","Number of aggregated features: 8\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","----- MI Scores -----\n","[(12, 0.15246918228231238), (6, 0.1349170730411436), (14, 0.13069123294496232), (1, 0.13065462984779644), (9, 0.1231135469682487), (0, 0.12179110241277581), (70, 0.12115482015646392), (3, 0.11185209883590831), (11, 0.10986275099519403), (64, 0.10771568892180332), (72, 0.1032695949160546), (4, 0.09837955367460148), (71, 0.09746137816431787), (5, 0.09674503527089101), (74, 0.09054955462491504), (76, 0.0904349847377698), (18, 0.09003186611152561), (81, 0.0887785102331146), (10, 0.08840980007656025), (61, 0.08744302312023922), (2, 0.08633953056624281), (7, 0.08374382388366132), (40, 0.08272195545924747), (67, 0.08179196380125643), (80, 0.0756539453373972), (78, 0.0756116585430903), (56, 0.07515073162512392), (55, 0.07453154808910913), (59, 0.0724122460457046), (13, 0.07221231675697015), (41, 0.07057853400969465), (51, 0.0699905475133246), (45, 0.06990949338261673), (65, 0.06957318454256288), (49, 0.06853362559267394), (47, 0.0681175128446899), (20, 0.0681128062203191), (43, 0.06773914541819946), (34, 0.06653777766551189), (73, 0.06543266244978575), (53, 0.06476007619581492), (19, 0.06427469138682587), (46, 0.06405548699189753), (48, 0.06330402915035589), (50, 0.06182758827270333), (8, 0.06097423077768163), (69, 0.06025800996666824), (22, 0.058354935796658736), (39, 0.05701935964420881), (62, 0.05648159068835168), (83, 0.054705098402256264), (52, 0.05388695885698442), (79, 0.05362387256451879), (54, 0.05282521094083604), (68, 0.05272715584172873), (60, 0.05223766278849154), (15, 0.05110317644607735), (82, 0.051038134049028634), (16, 0.05102007472527081), (75, 0.05049155692907435), (38, 0.049154951548969206), (21, 0.0485632316334752), (37, 0.048022953610647616), (17, 0.04758562455990436), (77, 0.047097506874652785), (28, 0.044947963883539686), (58, 0.04469719772368524), (87, 0.044319549594830816), (25, 0.04428458759911999), (23, 0.04309278735609501), (24, 0.04070691211815687), (63, 0.03768171944947573), (66, 0.03627480449479854), (32, 0.03417420760169446), (85, 0.03371908153136655), (57, 0.03356187213813549), (36, 0.03279882395045534), (86, 0.0291246591928012), (84, 0.02878024093019482), (42, 0.02630922513870871), (26, 0.025718715788767988), (33, 0.025022690464666555), (31, 0.024399617537454687), (27, 0.02107256144868112), (30, 0.019661600889636293), (88, 0.017990095111212343), (44, 0.017958768466419212), (35, 0.016172022555694502), (29, -0.004145623794999376)]\n","Best MI score: 0.15246918228231238\n","Adding first best original feature: 12\n","CMI: 0.002185858509828026\n","CMI: 0.003173695655592529\n","CMI: 0.0022573585671187835\n","CMI: 0.009242010891818864\n","CMI: 0.005901752730679832\n","CMI: 0.03393820061659\n","CMI: 0.03439552227501075\n","CMI: 0.0045246619782707\n","CMI: 0.0016309547571995986\n","CMI: 0.042895593366124946\n","CMI: 0.03762661933977218\n","CMI: 0.020133922985887454\n","CMI: 0.022066154011240374\n","CMI: 0.027737577667498847\n","CMI: 0.025655887599053268\n","CMI: 0.026887207837082178\n","CMI: 0.019027692789901768\n","CMI: 0.014710054201112904\n","CMI: 0.029500787093944048\n","CMI: 0.012799170506736152\n","Highest CMI score: 0.042895593366124946\n","Adding original feature: 70\n","CMI: 0.02884127267298675\n","CMI: 0.01283562356614823\n","CMI: 0.024269198235140316\n","CMI: 0.0025257743092248763\n","CMI: 0.012741147495107602\n","CMI: 0.009942899238194025\n","CMI: 0.010908586725660058\n","CMI: 0.006640677420439001\n","CMI: 0.017048333701698587\n","CMI: 0.0024816708128417575\n","CMI: 0.0038274813832525623\n","CMI: 0.00010025554840664697\n","CMI: 0.003712388006560541\n","CMI: 0.0015748192499660807\n","CMI: 0.006738501033440786\n","CMI: 0.01622410027543708\n","CMI: 0.0033125396544682606\n","CMI: 0.01968776963249863\n","CMI: 0.002079624881366482\n","CMI: 0.0071365092914630335\n","CMI: 0.01649154552911966\n","CMI: 0.009848554337829135\n","Highest CMI score: 0.02884127267298675\n","Adding original feature: 1\n","CMI: 0.0029275721043447722\n","Highest CMI score: 0.0029275721043447722\n","Adding original feature: 83\n","CMI: 0.008139996187910142\n","CMI: 0.006602436647514476\n","CMI: 0.002859203636891766\n","CMI: 0.003383677762359455\n","CMI: 0.0011951177729866147\n","CMI: 0.005364969522220875\n","CMI: 0.0012168359364402581\n","CMI: 0.007025607714027632\n","Highest CMI score: 0.008139996187910142\n","Adding original feature: 6\n","CMI: 0.0005721019122601478\n","CMI: 0.001120358092315088\n","CMI: 0.0010127535488597128\n","Highest CMI score: 0.001120358092315088\n","Adding original feature: 29\n","CMI: 0.0002912374836739895\n","CMI: 0.000955389323171324\n","CMI: 0.00459636790465992\n","CMI: 0.001613832701568535\n","CMI: 0.007916703715266177\n","CMI: 0.006888474373523662\n","CMI: 0.0035076908357984105\n","CMI: 0.001456274672640534\n","CMI: 0.0031297646346195307\n","Highest CMI score: 0.007916703715266177\n","Adding original feature: 71\n","CMI: 0.002282260678005188\n","CMI: 0.0041878040999918376\n","CMI: 0.0026166060792136847\n","CMI: 0.0001673085332374591\n","CMI: 0.0017191810279230668\n","CMI: 0.0002643607764587219\n","CMI: 0.00614270247525095\n","CMI: 0.008798155147887843\n","CMI: 0.0006430239149802786\n","CMI: 0.002767031191593966\n","CMI: 0.0019860673716391164\n","CMI: 0.00020389825410727092\n","Highest CMI score: 0.008798155147887843\n","Adding original feature: 74\n","CMI: 0.0062479949016831515\n","CMI: 0.00454418762234543\n","CMI: 0.0055178620393709354\n","CMI: 0.001040843717657891\n","CMI: 0.007296416373427372\n","CMI: 0.0011567727075850187\n","CMI: 0.0006521764824982124\n","CMI: 0.0015906830275151385\n","Highest CMI score: 0.007296416373427372\n","Adding original feature: 33\n","Highest CMI score: -0.002394655392785272\n","\n","[12, 70, 1, 83, 6, 29, 71, 74, 33]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.469904712952554, test score: -0.35920872125274506\n","Aggregate regression train score with FS: 0.2539771703692495, test score: 0.20500113727245628\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.469904712952554, test score: -0.35920872125274506\n","Aggregate regression train score with FS: 0.23230981232654258, test score: 0.11957785223871864\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.232\n","Test R2 linear regression CMI best 5:  0.12 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.6:  0.714\n","Test accuracy logregr CMI best 5 for shuffle n.6:  0.632 \n","\n","####################Emiliani2####################\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 8\n","\n","Number of features: 130\n","\n","Number of aggregated features: 5\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 8\n","\n","Number of features: 130\n","\n","Number of aggregated features: 10\n","\n","Number of features: 130\n","\n","Number of aggregated features: 12\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 2\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","----- MI Scores -----\n","[(3, 0.1349170730411436), (2, 0.1322488306459369), (9, 0.13069123294496232), (8, 0.12579312385229421), (0, 0.11586248845462338), (68, 0.1139060564002551), (69, 0.1032695949160546), (67, 0.10304206399070182), (73, 0.09746137816431787), (5, 0.09674503527089101), (1, 0.09638910381995788), (56, 0.09593284622545954), (75, 0.09207223934751455), (58, 0.0910555983077716), (43, 0.08939889585589772), (10, 0.08840980007656025), (6, 0.08697349987395087), (4, 0.08633953056624281), (45, 0.08272066381412507), (59, 0.08242460425325937), (64, 0.08196594367009552), (80, 0.08130184534173333), (66, 0.07865670616859136), (74, 0.07608865743150646), (76, 0.07593527481570693), (63, 0.07272607982751346), (11, 0.07221231675697015), (44, 0.06990949338261673), (48, 0.06988392014824574), (57, 0.06957318454256288), (14, 0.06896435611072183), (17, 0.0681128062203191), (42, 0.06694601173395667), (36, 0.06653777766551189), (37, 0.06611452826742871), (18, 0.06554679770153546), (71, 0.06543266244978575), (50, 0.06519639234656507), (61, 0.06461653565061169), (16, 0.06427469138682587), (49, 0.06281036758005758), (46, 0.06279697713330123), (54, 0.062416319640709816), (38, 0.060722129579761495), (20, 0.05841460464732814), (79, 0.058225689656730195), (27, 0.05815778989392451), (78, 0.05791093883117723), (40, 0.05701935964420881), (55, 0.05653805308184253), (7, 0.055587005851714597), (23, 0.05471305601235513), (53, 0.05450153113907474), (47, 0.05388695885698442), (62, 0.05272715584172873), (12, 0.051683662241925325), (13, 0.05102007472527081), (77, 0.050575366849171265), (81, 0.050507343294060994), (72, 0.05049155692907435), (52, 0.04989624249888793), (15, 0.04758562455990436), (70, 0.047097506874652785), (28, 0.044947963883539686), (51, 0.04488781196239462), (19, 0.0448166098357237), (84, 0.044319549594830816), (24, 0.04428458759911999), (22, 0.04309278735609501), (21, 0.04070691211815687), (65, 0.03768171944947573), (60, 0.03627480449479854), (30, 0.03417420760169446), (35, 0.03279882395045534), (83, 0.03220695679166698), (39, 0.031823912766080355), (31, 0.03091297304037759), (41, 0.02899018147052886), (82, 0.02878024093019482), (32, 0.027466373609814694), (25, 0.026387022571751025), (33, 0.025022690464666555), (26, 0.022701818474071513), (85, 0.017990095111212343), (34, 0.016172022555694502), (29, -0.004145623794999376)]\n","Best MI score: 0.1349170730411436\n","Adding first best original feature: 3\n","CMI: 0.007593587022542481\n","CMI: 0.014117812007050229\n","CMI: 0.0019296228013451766\n","CMI: 0.0014409130198974884\n","CMI: 0.005911314227950076\n","CMI: 0.015305430816307641\n","CMI: 0.02188213725053212\n","CMI: 0.012031212369960687\n","CMI: 0.018996779717484813\n","CMI: 0.00342179781189042\n","CMI: 0.01125976937847753\n","CMI: 0.006398048616245017\n","CMI: 0.007240717370946809\n","CMI: 0.0027770098366983464\n","CMI: 0.014180569644849372\n","CMI: 0.02583694158017741\n","CMI: 0.02183980344604111\n","CMI: 0.0004066798995099319\n","CMI: 0.008990825703655225\n","CMI: 0.013187115601697191\n","CMI: 0.002730402912466401\n","CMI: 0.005273629780667893\n","CMI: 0.02536740119620781\n","CMI: 0.008029677638094701\n","CMI: 0.023398036527725985\n","CMI: 0.018501776387259444\n","CMI: 0.0031667104264539725\n","CMI: 0.0166832575402594\n","CMI: 0.00358867558251455\n","CMI: 0.00229865962719486\n","CMI: 0.0005704579580946834\n","CMI: 0.01575667566102648\n","CMI: 0.016937501992915716\n","CMI: 0.032673632577748773\n","CMI: 0.036764225960396246\n","CMI: 0.01970073736664507\n","CMI: 0.015773882185979082\n","CMI: 0.0011431542153060303\n","CMI: 0.01914556039394344\n","CMI: 0.02423723697716551\n","CMI: 0.018706694789997008\n","CMI: 0.027038845150361368\n","CMI: 0.05136225223040869\n","CMI: 0.014406301164109264\n","CMI: 0.04704414211367611\n","CMI: 0.04568491112856554\n","CMI: 0.01648732418380458\n","CMI: 0.025197860256063992\n","CMI: 0.037489562179723074\n","CMI: 0.045589816812925094\n","CMI: 0.014920116928249655\n","CMI: 0.020421060856020662\n","CMI: 0.08602626663497348\n","CMI: 0.06424204457913452\n","CMI: 0.037414235024077064\n","CMI: 0.02917781478530082\n","CMI: 0.03551236560485921\n","CMI: 0.03150679574685242\n","CMI: 0.05648274713515666\n","CMI: 0.007423117734554285\n","CMI: 0.026408500332325474\n","CMI: 0.0037396704814351422\n","CMI: 0.013633736016325892\n","CMI: 0.008902161270636366\n","CMI: 0.015443199459494683\n","CMI: 0.009942336260854723\n","Highest CMI score: 0.08602626663497348\n","Adding original feature: 67\n","CMI: 0.013198036783145656\n","CMI: 0.004287000367626498\n","CMI: 0.0038504014747259563\n","Highest CMI score: 0.013198036783145656\n","Adding original feature: 10\n","Highest CMI score: -0.005005019526177545\n","\n","[3, 67, 10]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.4867047463115628, test score: -0.6504741813401906\n","Aggregate regression train score with FS: 0.1866220390439155, test score: 0.13591923135669604\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.4867047463115628, test score: -0.6504741813401906\n","Aggregate regression train score with FS: 0.1866220390439155, test score: 0.13591923135669604\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.187\n","Test R2 linear regression CMI best 5:  0.136 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.7:  0.695\n","Test accuracy logregr CMI best 5 for shuffle n.7:  0.684 \n","\n","####################Emiliani2####################\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 11\n","\n","Number of features: 130\n","\n","Number of aggregated features: 14\n","\n","Number of features: 130\n","\n","Number of aggregated features: 8\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","----- MI Scores -----\n","[(9, 0.15246918228231238), (3, 0.1349170730411436), (11, 0.13069123294496232), (1, 0.13065462984779644), (7, 0.1231135469682487), (10, 0.12256467225678017), (0, 0.12182086061180196), (68, 0.12099185973997534), (61, 0.10933154474462303), (63, 0.1039703079526966), (2, 0.09837955367460148), (71, 0.09746137816431787), (5, 0.09674503527089101), (70, 0.09623197123570164), (69, 0.09054955462491504), (60, 0.09030351781729812), (15, 0.09003186611152561), (77, 0.0887785102331146), (12, 0.08840980007656025), (4, 0.08633953056624281), (62, 0.08619817075855546), (6, 0.08413534342032805), (46, 0.08364723369492302), (66, 0.08211756606945644), (67, 0.08179196380125643), (52, 0.08079358266104533), (36, 0.08077098054324394), (78, 0.0756539453373972), (75, 0.0756116585430903), (53, 0.07515073162512392), (58, 0.07453154808910913), (42, 0.07370388129928994), (65, 0.07272607982751346), (56, 0.0724122460457046), (8, 0.07221231675697015), (39, 0.06885945808877662), (40, 0.0681175128446899), (17, 0.0681128062203191), (34, 0.06653777766551189), (18, 0.06554679770153546), (73, 0.06543266244978575), (48, 0.06476007619581492), (16, 0.06427469138682587), (44, 0.06405548699189753), (59, 0.05954726996327907), (45, 0.05935953452744363), (20, 0.058354935796658736), (80, 0.054705098402256264), (57, 0.05462822726817888), (54, 0.05450153113907474), (49, 0.053781963739039144), (76, 0.05362387256451879), (13, 0.05260987529074913), (79, 0.051038134049028634), (14, 0.05102007472527081), (74, 0.05049155692907435), (35, 0.05022617767323693), (51, 0.04985832206533135), (41, 0.04874103143983202), (72, 0.047097506874652785), (50, 0.04599544176619915), (26, 0.044947963883539686), (47, 0.04488781196239462), (19, 0.0448166098357237), (55, 0.04466402152975735), (84, 0.044319549594830816), (23, 0.04428458759911999), (21, 0.04309278735609501), (22, 0.04070691211815687), (64, 0.0396116702618395), (43, 0.035603593846909636), (28, 0.03417420760169446), (82, 0.03371908153136655), (33, 0.03279882395045534), (29, 0.03091297304037759), (37, 0.029913011849647904), (83, 0.0291246591928012), (81, 0.02878024093019482), (38, 0.028428080994467395), (30, 0.027466373609814694), (24, 0.025718715788767988), (31, 0.025022690464666555), (25, 0.02107256144868112), (85, 0.017990095111212343), (32, 0.016172022555694502), (27, -0.004145623794999376)]\n","Best MI score: 0.15246918228231238\n","Adding first best original feature: 9\n","CMI: 0.003173695655592529\n","CMI: 0.002185858509828026\n","CMI: 0.009242010891818864\n","CMI: 0.013415929250417902\n","CMI: 0.0107282052593492\n","CMI: 0.004317827344836489\n","CMI: 0.0379643242461378\n","CMI: 0.028929204805698522\n","CMI: 0.006075993852393685\n","CMI: 0.01798287404719698\n","CMI: 0.01874997708569051\n","CMI: 0.03989907735856868\n","CMI: 0.027737577667498847\n","CMI: 0.008689093606747827\n","CMI: 0.03762661933977218\n","CMI: 0.019027692789901768\n","CMI: 0.022066154011240374\n","CMI: 0.025655887599053268\n","CMI: 0.014710054201112904\n","CMI: 0.012799170506736152\n","CMI: 0.029500787093944048\n","Highest CMI score: 0.03989907735856868\n","Adding original feature: 68\n","CMI: 0.032491179680920024\n","CMI: 0.01677103598274124\n","CMI: 0.02698665935683986\n","CMI: 0.00048255465263219444\n","CMI: 0.004936416692240986\n","CMI: 0.0005084744908980809\n","CMI: 0.015284093188778825\n","CMI: 0.013138033262487858\n","CMI: 0.012616863820073598\n","CMI: 0.009514808620800785\n","CMI: 0.0009186430825001979\n","CMI: 0.0008920138242504982\n","CMI: 0.02098150087012543\n","CMI: 0.004788498709667077\n","CMI: 0.005832915046070919\n","CMI: 0.0024263378872786123\n","CMI: 0.004279123153035719\n","CMI: 0.0067309871183459935\n","CMI: 0.006956329938109795\n","CMI: 0.011255424941441161\n","CMI: 0.014157677806062474\n","CMI: 0.0020415900319354086\n","CMI: 0.004769519333667205\n","CMI: 0.013956228801949105\n","CMI: 0.009994000161608174\n","CMI: 0.004124662142960922\n","CMI: 0.01892934268917079\n","CMI: 0.0070676006123154\n","CMI: 0.006477353026468097\n","CMI: 0.022909610959979704\n","CMI: 0.008306126367316341\n","CMI: 0.01917905341192544\n","CMI: 0.01300221786146949\n","Highest CMI score: 0.032491179680920024\n","Adding original feature: 1\n","CMI: 0.002943652117456369\n","Highest CMI score: 0.002943652117456369\n","Adding original feature: 80\n","CMI: 0.006469871706503871\n","CMI: 0.00521876948759975\n","CMI: 0.005048714235316026\n","CMI: 0.0027368666914728834\n","CMI: 0.000996130680648244\n","CMI: 0.002070119926237235\n","CMI: 0.0044063289653934745\n","CMI: 0.001449196212490067\n","CMI: 0.006595968660584206\n","Highest CMI score: 0.006595968660584206\n","Adding original feature: 79\n","CMI: 0.002357616322204742\n","CMI: 0.0021109031389471566\n","CMI: 0.002020905443269466\n","Highest CMI score: 0.002357616322204742\n","Adding original feature: 3\n","CMI: 0.0027263971544551624\n","CMI: 0.0012160685229442303\n","Highest CMI score: 0.0027263971544551624\n","Adding original feature: 27\n","CMI: 0.0019487166589047256\n","CMI: 0.008233593621625734\n","CMI: 0.006458922108612847\n","CMI: 0.00012678429882193032\n","Highest CMI score: 0.008233593621625734\n","Adding original feature: 69\n","CMI: 0.0036054789508925267\n","CMI: 3.155875691468468e-05\n","CMI: 0.0025387633750089678\n","CMI: 0.00409730815682241\n","CMI: 0.00124116958047224\n","CMI: 0.006493045268268105\n","CMI: 0.003265990073075653\n","CMI: 0.002507121620703101\n","Highest CMI score: 0.006493045268268105\n","Adding original feature: 71\n","CMI: 0.006697255871683572\n","CMI: 0.006887867377284418\n","CMI: 0.006250028392892848\n","CMI: 0.001977143311221008\n","CMI: 0.0001845654468875524\n","Highest CMI score: 0.006887867377284418\n","Adding original feature: 23\n","CMI: 0.0004774894058666157\n","Highest CMI score: 0.0004774894058666157\n","Adding original feature: 24\n","CMI: 0.0015325671932845397\n","CMI: 0.0006375600346069099\n","Highest CMI score: 0.0015325671932845397\n","Adding original feature: 7\n","Highest CMI score: -0.0005758597010658839\n","\n","[9, 68, 1, 80, 79, 3, 27, 69, 71, 23, 24, 7]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.47273235819024284, test score: -0.4666634173056303\n","Aggregate regression train score with FS: 0.28738049032731205, test score: 0.26106166497182426\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.47273235819024284, test score: -0.4666634173056303\n","Aggregate regression train score with FS: 0.24057606293000244, test score: 0.05019816873597549\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.241\n","Test R2 linear regression CMI best 5:  0.05 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.8:  0.706\n","Test accuracy logregr CMI best 5 for shuffle n.8:  0.636 \n","\n","####################Emiliani2####################\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 8\n","\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 5\n","\n","Number of features: 130\n","\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","Number of aggregated features: 2\n","\n","Number of features: 130\n","\n","Number of aggregated features: 5\n","\n","Number of features: 130\n","\n","Number of aggregated features: 10\n","\n","Number of features: 130\n","\n","Number of aggregated features: 10\n","\n","Number of features: 130\n","\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","Number of aggregated features: 3\n","\n","----- MI Scores -----\n","[(2, 0.14092958845490258), (10, 0.13126063784810943), (8, 0.1268661414946071), (63, 0.12678550226508206), (0, 0.11794496702102156), (57, 0.10446029715274105), (5, 0.09923524916294915), (4, 0.09837955367460148), (53, 0.09695549203156313), (3, 0.09638910381995788), (64, 0.09623197123570164), (11, 0.09396973579042195), (56, 0.09337349145507913), (62, 0.09309424940891699), (71, 0.09207223934751455), (41, 0.08939889585589772), (9, 0.08840980007656025), (1, 0.08633953056624281), (6, 0.08610453816182828), (58, 0.08376635254572325), (69, 0.08130184534173333), (66, 0.07935783651921058), (19, 0.07819538841918847), (68, 0.07608865743150646), (70, 0.07593527481570693), (38, 0.07392562557185416), (61, 0.07272607982751346), (14, 0.06896435611072183), (16, 0.0681128062203191), (40, 0.06758303660348196), (45, 0.06659945072551099), (76, 0.06620203252178232), (43, 0.06549875175048006), (15, 0.06427469138682587), (47, 0.06281036758005758), (52, 0.06272753354065073), (77, 0.061973557637818116), (51, 0.0599370840593464), (59, 0.05980031984977003), (60, 0.05825889791770142), (72, 0.058225689656730195), (73, 0.05791093883117723), (20, 0.05759227777826015), (49, 0.057552292241895515), (17, 0.055703209790854386), (7, 0.055587005851714597), (39, 0.0548143968219707), (18, 0.054430235646067054), (50, 0.05388695885698442), (48, 0.05329124766274402), (27, 0.053148177740384994), (55, 0.05272715584172873), (74, 0.050575366849171265), (65, 0.05049155692907435), (75, 0.0503967022441886), (44, 0.050048918277901616), (12, 0.04925490722965137), (23, 0.04860658983543109), (29, 0.0478906742286079), (46, 0.04765930103366655), (42, 0.04711954763787815), (67, 0.047097506874652785), (21, 0.04654496524474467), (37, 0.045802026000329336), (80, 0.044319549594830816), (24, 0.04428458759911999), (13, 0.04335660749874698), (54, 0.037792223435905124), (78, 0.034684498590479895), (25, 0.03438379717543677), (22, 0.03176525258247889), (79, 0.0291246591928012), (28, 0.028835240519698647), (30, 0.028542006664438742), (26, 0.02592696088605072), (35, 0.02490080195843239), (32, 0.024399617537454687), (36, 0.010372578044046614), (34, 0.008623335404627583), (33, 0.0035345946350680097), (31, -0.0017500114382319495)]\n","Best MI score: 0.14092958845490258\n","Adding first best original feature: 2\n","CMI: 0.003902424309693925\n","CMI: 0.010901654514846343\n","CMI: 0.016496923326559915\n","CMI: 0.0038034629661309882\n","CMI: 0.008066820836749256\n","CMI: 0.013495074872485469\n","CMI: 0.0012342142544672918\n","CMI: 0.019826720030101497\n","CMI: 0.014168674277690474\n","CMI: 0.0029053891271553778\n","CMI: 0.022806167680892386\n","CMI: 0.0016779004775318296\n","CMI: 0.001586388199093014\n","CMI: 0.0149075044488165\n","CMI: 0.010265160477224838\n","CMI: 0.027576568047454064\n","CMI: 0.027122159302876703\n","CMI: 0.046550321284686696\n","CMI: 0.013706756754810229\n","CMI: 0.006663710740064471\n","CMI: 0.0540761229737077\n","CMI: 0.03317132748262622\n","CMI: 0.011616572431210198\n","CMI: 0.03566527716878076\n","CMI: 0.004755759001723231\n","CMI: 0.030672070990676314\n","CMI: 0.0610631487345189\n","CMI: 0.06578610988210179\n","CMI: 0.024487594008778174\n","CMI: 0.020646390901009365\n","CMI: 0.03159112630713093\n","CMI: 0.0242149652751954\n","CMI: 0.004622737714222114\n","CMI: 0.005199160484829463\n","CMI: 0.020527143401274206\n","CMI: 0.0009483921130383488\n","CMI: 0.001058565315095461\n","Highest CMI score: 0.06578610988210179\n","Adding original feature: 63\n","CMI: 0.0013332512622029336\n","CMI: 0.008708978755016222\n","CMI: 0.0034286886580670584\n","CMI: 0.0014862203814541286\n","CMI: 0.002692189206571244\n","Highest CMI score: 0.008708978755016222\n","Adding original feature: 12\n","CMI: 0.0012383271828153852\n","CMI: 1.71796500337551e-05\n","CMI: 0.0007606936174491263\n","CMI: 0.0032983620166086025\n","CMI: 0.002647571810030669\n","CMI: 0.0034586860846475553\n","CMI: 0.0023275893295282013\n","Highest CMI score: 0.0034586860846475553\n","Adding original feature: 57\n","CMI: 0.00038156611129630535\n","CMI: 0.0017580814443284853\n","CMI: 0.002114551019062577\n","CMI: 0.013315096077200633\n","CMI: 0.0054238313157236595\n","CMI: 0.0015391742809559572\n","CMI: 0.008342353483713982\n","CMI: 0.002028844512379585\n","CMI: 0.0017915799212828987\n","CMI: 0.003100278958918179\n","CMI: 0.00092086095010252\n","CMI: 0.00046820784963497175\n","CMI: 0.016589748854474035\n","Highest CMI score: 0.016589748854474035\n","Adding original feature: 71\n","CMI: 0.0003295974722059558\n","CMI: 0.005784117823496138\n","CMI: 0.0010688289747428081\n","CMI: 0.006431552748425273\n","CMI: 0.005895068052609698\n","CMI: 0.0015959736775558453\n","CMI: 0.00041088092123628406\n","CMI: 0.0008272796793814818\n","Highest CMI score: 0.006431552748425273\n","Adding original feature: 14\n","CMI: 0.0016902013472417654\n","CMI: 0.0006291336088568578\n","CMI: 0.002083399899365679\n","Highest CMI score: 0.002083399899365679\n","Adding original feature: 66\n","CMI: 6.219475702876065e-05\n","CMI: 0.0003355166914587593\n","CMI: 0.00667635942507977\n","CMI: 0.0003328651534284799\n","Highest CMI score: 0.00667635942507977\n","Adding original feature: 53\n","Highest CMI score: -0.0017339696967659246\n","\n","[2, 63, 12, 57, 71, 14, 66, 53]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.4673462438334167, test score: 0.048627224037309014\n","Aggregate regression train score with FS: 0.2650118514843557, test score: 0.25072022562949814\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.4673462438334167, test score: 0.048627224037309014\n","Aggregate regression train score with FS: 0.23822135641274056, test score: 0.22962342601895624\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.238\n","Test R2 linear regression CMI best 5:  0.23 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.9:  0.707\n","Test accuracy logregr CMI best 5 for shuffle n.9:  0.737 \n","\n","####################Garda_Mincio####################\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 6\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 7\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","----- MI Scores -----\n","[(30, 0.12594278060148018), (31, 0.10682474937409657), (33, 0.10425738764951727), (34, 0.10373793003163177), (38, 0.09218359594229039), (35, 0.0917540919388227), (1, 0.08191620029157745), (25, 0.08091983384549593), (37, 0.07541651525184066), (42, 0.0738060511945529), (26, 0.07187791689284748), (4, 0.07018343740918907), (28, 0.06993780573941064), (3, 0.06949854377801695), (0, 0.0666485193202881), (36, 0.0664173596180683), (44, 0.06461246529459347), (2, 0.06345228144852584), (48, 0.06162391566021959), (41, 0.06129265601658003), (40, 0.06069881068734619), (45, 0.05820198115615721), (29, 0.057662771675359575), (32, 0.056971518973107496), (21, 0.046260613320787076), (22, 0.04440884490232715), (18, 0.039784611088172064), (14, 0.03808271448050474), (5, 0.03675962572819817), (15, 0.0364855322280704), (39, 0.036379153488667146), (10, 0.03476323105543905), (23, 0.03434698662615107), (27, 0.03343295395737516), (9, 0.03327629421608082), (19, 0.03177675381282244), (11, 0.029374894123659026), (17, 0.02799205062247553), (43, 0.02750879480023889), (46, 0.02688298779415272), (24, 0.026867195549632104), (6, 0.02168722451446057), (12, 0.01742257237708035), (16, 0.017168651491971144), (7, 0.015540179879147315), (20, 0.015246924491615651), (13, 0.014253699687549953), (8, 0.013116855007375514), (47, -0.0004968315638450848)]\n","Best MI score: 0.12594278060148018\n","Adding first best original feature: 30\n","CMI: 0.07683849196564743\n","CMI: 0.05474967632573341\n","CMI: 0.07889589148405607\n","CMI: 0.052532819926473656\n","CMI: 0.059894623684360215\n","CMI: 0.021596364469172707\n","CMI: 0.020940237119073446\n","CMI: 0.001555064666774325\n","CMI: 0.025803104524072584\n","CMI: 0.01782214053065162\n","CMI: 0.03571251626882574\n","CMI: 0.027434084520255753\n","CMI: 0.03166114814659657\n","CMI: 0.0230400503619283\n","CMI: 0.02339702273612973\n","CMI: 0.023909903354571133\n","CMI: 0.009744347698356193\n","CMI: 0.019335898854796446\n","CMI: 0.005043293127661969\n","CMI: 0.02094409400526684\n","CMI: 0.03370659422937877\n","CMI: 0.005302772514599152\n","CMI: 0.01620235250402452\n","CMI: 0.010699021541411835\n","CMI: 0.004088806783314414\n","CMI: 0.02521495072230323\n","Highest CMI score: 0.07889589148405607\n","Adding original feature: 2\n","CMI: 0.003659282100648753\n","CMI: 0.0018695999049936074\n","Highest CMI score: 0.003659282100648753\n","Adding original feature: 42\n","CMI: 0.006439806345933108\n","CMI: 0.0021198032249596654\n","Highest CMI score: 0.006439806345933108\n","Adding original feature: 40\n","Highest CMI score: -0.002169086827289779\n","\n","[30, 2, 42, 40]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.36197388289988863, test score: 0.03434903943891243\n","Aggregate regression train score with FS: 0.19714812456654995, test score: 0.17757976918034069\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.36197388289988863, test score: 0.03434903943891243\n","Aggregate regression train score with FS: 0.19714812456654995, test score: 0.17757976918034069\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.197\n","Test R2 linear regression CMI best 5:  0.178 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.0:  0.682\n","Test accuracy logregr CMI best 5 for shuffle n.0:  0.715 \n","\n","####################Garda_Mincio####################\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 5\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 6\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","----- MI Scores -----\n","[(28, 0.12349633338976866), (29, 0.10682474937409657), (32, 0.10425738764951727), (33, 0.0956507201877715), (36, 0.09218359594229039), (30, 0.09008898361773215), (24, 0.08192046916141528), (34, 0.07541651525184066), (40, 0.0738060511945529), (3, 0.07321151138058377), (0, 0.07146980938755795), (26, 0.06993780573941064), (35, 0.0664173596180683), (2, 0.06517458758068774), (42, 0.06461246529459347), (39, 0.06129265601658003), (38, 0.06069881068734619), (45, 0.06060921560069072), (27, 0.057662771675359575), (10, 0.05730149074009724), (31, 0.056971518973107496), (43, 0.05665158122991894), (23, 0.04677405558343892), (1, 0.0453778461817217), (25, 0.04492821142446849), (20, 0.04043125112339926), (4, 0.03675962572819817), (14, 0.0364855322280704), (37, 0.036379153488667146), (9, 0.03566307541029757), (13, 0.0356238217943214), (16, 0.034069574553336965), (8, 0.03327629421608082), (21, 0.03153600369907041), (22, 0.03046708244231684), (47, 0.0274350197982691), (19, 0.026582374505384195), (41, 0.025296251306970118), (11, 0.025187022069856447), (5, 0.02168722451446057), (44, 0.018859173021802917), (18, 0.01830735114204872), (7, 0.015540179879147315), (12, 0.014253699687549953), (6, 0.013116855007375514), (15, 0.003348722415799), (17, 0.0026910136837429563), (46, -0.018724700501531796)]\n","Best MI score: 0.12349633338976866\n","Adding first best original feature: 28\n","CMI: 0.07808015107584775\n","CMI: 0.057641108404084276\n","CMI: 0.07599215948780257\n","CMI: 0.061802321350446957\n","CMI: 0.022035075508440985\n","CMI: 0.02317395098802276\n","CMI: 0.0003619003139608834\n","CMI: 0.0031019303064415\n","CMI: 0.02730406333816167\n","CMI: 0.01758542620249222\n","CMI: 0.03569272902895872\n","CMI: 0.028615338616724814\n","CMI: 0.0323132230878571\n","CMI: 0.022779964888417478\n","CMI: 0.02130453416617402\n","CMI: 0.014046403663636894\n","CMI: 0.016444566863982005\n","CMI: 0.006552024774998125\n","CMI: 0.01878222939135636\n","CMI: 0.03567451003442397\n","CMI: 0.004712649085678186\n","CMI: 0.018832118125649375\n","CMI: 0.01405280984642697\n","CMI: 0.026813873830615606\n","CMI: 0.006769464583819704\n","Highest CMI score: 0.07808015107584775\n","Adding original feature: 0\n","CMI: 0.008118487019690146\n","CMI: 0.00014487327591222732\n","CMI: 0.0089455620464379\n","CMI: 0.0077260475553829755\n","CMI: 0.0015026375045740503\n","CMI: 0.004944360045429308\n","Highest CMI score: 0.0089455620464379\n","Adding original feature: 29\n","Highest CMI score: -0.0036040707690299933\n","\n","[28, 0, 29]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3615526221454052, test score: -0.12901005342001626\n","Aggregate regression train score with FS: 0.19860605600558068, test score: 0.14382575465550307\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3615526221454052, test score: -0.12901005342001626\n","Aggregate regression train score with FS: 0.19860605600558068, test score: 0.14382575465550307\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.199\n","Test R2 linear regression CMI best 5:  0.144 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.1:  0.712\n","Test accuracy logregr CMI best 5 for shuffle n.1:  0.702 \n","\n","####################Garda_Mincio####################\n","Number of features: 67\n","\n","Number of aggregated features: 6\n","\n","Number of features: 67\n","\n","Number of aggregated features: 6\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 7\n","\n","Number of features: 67\n","\n","Number of aggregated features: 5\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 7\n","\n","----- MI Scores -----\n","[(38, 0.12798862174500839), (39, 0.11541136953245926), (36, 0.10886721673543838), (41, 0.09978228375904741), (44, 0.09218359594229039), (29, 0.08600551090942259), (5, 0.08191620029157745), (0, 0.07936116478824588), (1, 0.07494095026424288), (4, 0.07348403771303066), (30, 0.07182421363104681), (42, 0.070893679541073), (9, 0.07018343740918907), (34, 0.06993780573941064), (47, 0.06976401768047137), (10, 0.06949854377801695), (45, 0.0655824120762228), (7, 0.06554248774201991), (3, 0.06469055561355494), (8, 0.060305206506415306), (6, 0.05975235653069669), (37, 0.05947689170543129), (11, 0.059302757049079405), (49, 0.05820198115615721), (2, 0.05742919520595305), (19, 0.04981590893962883), (50, 0.049216826756414186), (12, 0.04444272020647614), (43, 0.04391011784109195), (32, 0.04364876354572815), (18, 0.03853253206013806), (14, 0.036660473508875316), (28, 0.036243414346516255), (46, 0.0358435550243809), (17, 0.03468404198828163), (25, 0.03361568229345798), (35, 0.03343295395737516), (27, 0.03300312440879623), (20, 0.032713251538484076), (13, 0.03236750143215883), (24, 0.032051603453797144), (23, 0.031990296531804956), (33, 0.02983815796949425), (15, 0.029729502793806213), (51, 0.0274350197982691), (22, 0.02646386775614294), (31, 0.025907509767764427), (55, 0.0235344479872647), (26, 0.02078847815467888), (48, 0.01603090809869696), (16, 0.015540179879147315), (21, 0.014253699687549953), (52, 0.010571625816905912), (56, 0.010230437183862962), (40, 0.009692456390089805), (54, 0.007992082523325821), (53, 0.005556183533065954)]\n","Best MI score: 0.12798862174500839\n","Adding first best original feature: 38\n","CMI: 0.05535500754632511\n","CMI: 0.06402816630937594\n","CMI: 0.06611719118469961\n","CMI: 0.07067858196822199\n","CMI: 0.05716074910268179\n","CMI: 0.043161785760693655\n","CMI: 0.04976238600933067\n","CMI: 0.06474274135927074\n","CMI: 0.044187278421889464\n","CMI: 0.05090029590721176\n","CMI: 0.05976841190716198\n","CMI: 0.05203300596801472\n","CMI: 0.002643720676927974\n","CMI: 0.01084476953530586\n","CMI: 0.021465005386468144\n","CMI: 0.007077992998859695\n","CMI: 0.023199783416859743\n","CMI: 0.004895322997027857\n","CMI: 0.015631793536354105\n","CMI: 0.006846033495190862\n","CMI: 0.010427582959723514\n","CMI: 0.0008005324700731953\n","CMI: 0.018654180768305606\n","CMI: 0.008698547102286402\n","CMI: 0.007048453969421248\n","CMI: 0.006679607181612063\n","CMI: 0.00920709166139777\n","Highest CMI score: 0.07067858196822199\n","Adding original feature: 3\n","CMI: 0.0031794331303342527\n","CMI: 0.005746462301749744\n","CMI: 0.013179777433827644\n","Highest CMI score: 0.013179777433827644\n","Adding original feature: 36\n","Highest CMI score: -0.003450246744623797\n","\n","[38, 3, 36]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.36316865783916197, test score: -0.1552337825970178\n","Aggregate regression train score with FS: 0.2048558106309526, test score: 0.16844822583432795\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.36316865783916197, test score: -0.1552337825970178\n","Aggregate regression train score with FS: 0.2048558106309526, test score: 0.16844822583432795\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.205\n","Test R2 linear regression CMI best 5:  0.168 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.2:  0.714\n","Test accuracy logregr CMI best 5 for shuffle n.2:  0.715 \n","\n","####################Garda_Mincio####################\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","Number of aggregated features: 6\n","\n","Number of features: 67\n","\n","Number of aggregated features: 9\n","\n","Number of features: 67\n","\n","Number of aggregated features: 7\n","\n","Number of features: 67\n","\n","Number of aggregated features: 6\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","----- MI Scores -----\n","[(32, 0.11541136953245926), (36, 0.10624567935468295), (30, 0.10479348909455402), (33, 0.10352808207862192), (27, 0.10309072217280478), (39, 0.09715121613433071), (38, 0.09218359594229039), (47, 0.09085602188128977), (31, 0.09008898361773215), (20, 0.08600551090942259), (1, 0.08191620029157745), (18, 0.072946183968265), (25, 0.07187791689284748), (4, 0.07018343740918907), (26, 0.06993780573941064), (3, 0.06949854377801695), (41, 0.0691171574668016), (42, 0.06764805153583617), (0, 0.0666485193202881), (37, 0.0664173596180683), (34, 0.06536003001408709), (2, 0.06345228144852584), (14, 0.056571612428761534), (22, 0.04962739425542101), (35, 0.04936397565004643), (40, 0.04866349453381294), (44, 0.04809528081224981), (10, 0.04740940777233785), (45, 0.047264057973115274), (15, 0.0445652080251868), (12, 0.03990230672793982), (23, 0.03944781121708115), (21, 0.03830059478084074), (24, 0.038110396635326386), (5, 0.03675962572819817), (17, 0.03626557030018234), (16, 0.036243414346516255), (8, 0.03405575833416289), (11, 0.032139322849033), (28, 0.03181806139517566), (19, 0.028820584544872758), (6, 0.026447124582110456), (29, 0.024259262779397828), (48, 0.0235344479872647), (9, 0.0230919491415793), (13, 0.01859609462525847), (43, 0.01603090809869696), (7, 0.015540179879147315), (46, 0.009348204146729032)]\n","Best MI score: 0.11541136953245926\n","Adding first best original feature: 32\n","CMI: 0.04337414573739928\n","CMI: 0.04977656783537587\n","CMI: 0.057596210888480825\n","CMI: 0.028818942217205712\n","CMI: 0.020554812159024466\n","CMI: 0.026011052810780616\n","CMI: 0.011243368152417166\n","CMI: 0.0006903577379858\n","CMI: 0.009885349590666143\n","CMI: 0.004101646397781877\n","CMI: 0.003368196553221958\n","CMI: 0.0072577351815664715\n","CMI: 0.002133884839885525\n","CMI: 0.01253825894364205\n","CMI: 0.003921598159506795\n","CMI: 0.001255299923409739\n","CMI: 0.00698961904418334\n","CMI: 0.003953383057268833\n","CMI: 0.0032308751334376162\n","CMI: 0.0178612429874489\n","Highest CMI score: 0.057596210888480825\n","Adding original feature: 2\n","CMI: 0.002322065148763791\n","CMI: 0.002033604545320006\n","CMI: 0.012995055584451382\n","CMI: 0.009502644273028799\n","CMI: 0.010002782152285505\n","CMI: 0.015619567005218327\n","CMI: 0.01258239126196603\n","CMI: 0.0024853924644523406\n","CMI: 0.01617242336171426\n","CMI: 0.00041695729994137287\n","Highest CMI score: 0.01617242336171426\n","Adding original feature: 45\n","CMI: 0.017155978517331055\n","CMI: 0.007886932400771318\n","CMI: 0.000598659932002088\n","CMI: 0.0002690231018771527\n","CMI: 0.004335471524908707\n","CMI: 0.006748845540183734\n","CMI: 0.002305196153664757\n","CMI: 0.0004739362020881044\n","CMI: 0.00482904947791768\n","Highest CMI score: 0.017155978517331055\n","Adding original feature: 5\n","CMI: 0.0018883045913936913\n","Highest CMI score: 0.0018883045913936913\n","Adding original feature: 25\n","Highest CMI score: -0.0032981164917474937\n","\n","[32, 2, 45, 5, 25]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3350770860910307, test score: 0.06429162989480397\n","Aggregate regression train score with FS: 0.21223063634255823, test score: 0.22564677792365262\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3350770860910307, test score: 0.06429162989480397\n","Aggregate regression train score with FS: 0.21223063634255823, test score: 0.22564677792365262\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.212\n","Test R2 linear regression CMI best 5:  0.226 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.3:  0.701\n","Test accuracy logregr CMI best 5 for shuffle n.3:  0.697 \n","\n","####################Garda_Mincio####################\n","Number of features: 67\n","\n","Number of aggregated features: 5\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 5\n","\n","Number of features: 67\n","\n","Number of aggregated features: 6\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 7\n","\n","----- MI Scores -----\n","[(28, 0.09726862101025892), (34, 0.09218359594229039), (29, 0.09008898361773215), (32, 0.08842440113466793), (3, 0.08176150293512269), (0, 0.0809926770686211), (22, 0.07989113738798505), (2, 0.07348403771303066), (4, 0.07295310960882422), (25, 0.07187791689284748), (24, 0.06993780573941064), (38, 0.06858134159461278), (35, 0.06557006580172677), (5, 0.06537013213340408), (6, 0.06279695499536699), (1, 0.06148969891183812), (36, 0.058322194113197265), (41, 0.05820198115615721), (45, 0.05502484009524533), (20, 0.051479079277542104), (19, 0.05020863394116318), (40, 0.04809528081224981), (42, 0.04781482433217149), (33, 0.04643748520445946), (43, 0.04583290250635488), (27, 0.04492821142446849), (11, 0.040538661051370994), (17, 0.03865545801794183), (23, 0.03856217230418955), (7, 0.03675962572819817), (37, 0.0358435550243809), (16, 0.032051603453797144), (15, 0.031990296531804956), (30, 0.03181806139517566), (18, 0.029607448153692918), (26, 0.02854690589624177), (13, 0.028389161596355683), (46, 0.0274350197982691), (14, 0.026102495950775913), (8, 0.02510309485256738), (31, 0.024259262779397828), (21, 0.02352173885973278), (39, 0.01603090809869696), (12, 0.01563994041804793), (9, 0.015540179879147315), (10, 0.013116855007375514), (47, 0.010571625816905912), (48, 0.010230437183862962), (44, 0.005556183533065954)]\n","Best MI score: 0.09726862101025892\n","Adding first best original feature: 28\n","CMI: 0.08739613314403653\n","CMI: 0.08144125016503619\n","CMI: 0.06739384023117119\n","CMI: 0.057205202935420627\n","CMI: 0.05944943260430756\n","CMI: 0.07819732362715116\n","CMI: 0.05051946026454156\n","CMI: 0.025983124031405097\n","CMI: 0.010689503092955382\n","CMI: 0.006734436729099472\n","CMI: 0.004080197237691624\n","CMI: 0.004826889360122016\n","CMI: 0.008878536156715827\n","CMI: 0.006863620971843787\n","CMI: 0.017283791779700644\n","CMI: 0.006207446013044626\n","CMI: 0.025287230034940433\n","CMI: 0.008693183339427854\n","CMI: 0.016574988917757008\n","CMI: 0.002344079038753888\n","CMI: 0.017493399820526653\n","CMI: 0.014535929499963948\n","CMI: 0.042957000703961204\n","CMI: 0.004118647872637604\n","CMI: 0.03238864234536844\n","CMI: 0.010268104529893143\n","CMI: 0.016942845563155548\n","CMI: 0.021777171606396847\n","CMI: 0.02564276304751789\n","CMI: 0.018802176017428826\n","CMI: 0.022640600523573542\n","CMI: 0.0005340538513379511\n","CMI: 0.029226370387437264\n","CMI: 0.011928442803504899\n","Highest CMI score: 0.08739613314403653\n","Adding original feature: 0\n","CMI: 0.0050063071759277045\n","CMI: 0.005200830898167058\n","CMI: 0.0013272755361703747\n","CMI: 0.006428579965243236\n","Highest CMI score: 0.006428579965243236\n","Adding original feature: 37\n","CMI: 0.01419952757482107\n","CMI: 0.0033185512114085325\n","CMI: 0.009573890724733913\n","CMI: 0.008827322431605222\n","CMI: 0.0019324288437687909\n","Highest CMI score: 0.01419952757482107\n","Adding original feature: 8\n","CMI: 0.005985799805465403\n","CMI: 0.01736942814073178\n","CMI: 0.007872228734328246\n","Highest CMI score: 0.01736942814073178\n","Adding original feature: 29\n","Highest CMI score: -0.0019477493031862525\n","\n","[28, 0, 37, 8, 29]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3425499979313582, test score: 0.034225580809565614\n","Aggregate regression train score with FS: 0.2243818384400461, test score: 0.15897472712501937\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3425499979313582, test score: 0.034225580809565614\n","Aggregate regression train score with FS: 0.2243818384400461, test score: 0.15897472712501937\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.224\n","Test R2 linear regression CMI best 5:  0.159 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.4:  0.707\n","Test accuracy logregr CMI best 5 for shuffle n.4:  0.732 \n","\n","####################Garda_Mincio####################\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 5\n","\n","Number of features: 67\n","\n","Number of aggregated features: 5\n","\n","Number of features: 67\n","\n","Number of aggregated features: 6\n","\n","Number of features: 67\n","\n","Number of aggregated features: 7\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","----- MI Scores -----\n","[(30, 0.12798862174500839), (32, 0.11734557649459675), (29, 0.11541136953245926), (31, 0.10682474937409657), (28, 0.100903765265325), (34, 0.09945672778564453), (39, 0.09715121613433071), (37, 0.09218359594229039), (48, 0.09085602188128977), (23, 0.07941372092450605), (35, 0.07815379736758961), (1, 0.07660994883588154), (38, 0.07541651525184066), (4, 0.07321151138058377), (2, 0.07095929666005615), (26, 0.06993780573941064), (36, 0.0664173596180683), (41, 0.06585810990142237), (3, 0.06517458758068774), (44, 0.06461246529459347), (0, 0.0625474673860017), (42, 0.06129265601658003), (27, 0.057662771675359575), (11, 0.05730149074009724), (33, 0.056971518973107496), (45, 0.05665158122991894), (47, 0.05217978234571527), (21, 0.05020863394116318), (25, 0.04492821142446849), (16, 0.041927573739403264), (18, 0.03912894225964435), (5, 0.03675962572819817), (40, 0.036379153488667146), (10, 0.03566307541029757), (19, 0.03397407155312966), (9, 0.03327629421608082), (20, 0.03153600369907041), (24, 0.03100718069175137), (14, 0.028872577575231644), (22, 0.027846461976266546), (17, 0.026889861646143008), (43, 0.025296251306970118), (49, 0.0235344479872647), (13, 0.023390209307608233), (6, 0.02168722451446057), (7, 0.015540179879147315), (15, 0.015201880872260643), (12, 0.013364630847039186), (8, 0.013116855007375514), (46, 0.008274368867226364)]\n","Best MI score: 0.12798862174500839\n","Adding first best original feature: 30\n","CMI: 0.058052023813177506\n","CMI: 0.06764447146334987\n","CMI: 0.04175761701347744\n","CMI: 0.06818253857515338\n","CMI: 0.044935183508812565\n","CMI: 0.016521518634312143\n","CMI: 0.0074933562668417775\n","CMI: 0.0027641385537720276\n","CMI: 0.023376365035073066\n","CMI: 0.00124213018897254\n","CMI: 0.005118275638481606\n","CMI: 0.011322459569607701\n","CMI: 0.0027656369641396172\n","CMI: 0.015631793536354105\n","CMI: 0.00824425554465713\n","CMI: 0.016465666382568717\n","CMI: 0.009959764054460973\n","CMI: 0.009101825779278233\n","CMI: 0.018654180768305606\n","CMI: 0.006789006002545311\n","CMI: 0.016734079074679747\n","CMI: 0.00932555086464526\n","CMI: 0.007130128701919453\n","CMI: 0.0016613611058650946\n","Highest CMI score: 0.06818253857515338\n","Adding original feature: 3\n","CMI: 0.012509175054805088\n","Highest CMI score: 0.012509175054805088\n","Adding original feature: 14\n","CMI: 0.00036491200338137353\n","CMI: 0.006486791078370857\n","CMI: 0.0027104272764301995\n","CMI: 0.00489035196575216\n","CMI: 0.00018178362882806387\n","CMI: 0.0021504668166729413\n","CMI: 0.0034317704107669766\n","CMI: 0.0010504423727361878\n","Highest CMI score: 0.006486791078370857\n","Adding original feature: 2\n","Highest CMI score: -0.004485469316222734\n","\n","[30, 3, 14, 2]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3583883916549938, test score: 0.008660512400635478\n","Aggregate regression train score with FS: 0.20364173119179307, test score: 0.20377772856932808\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3583883916549938, test score: 0.008660512400635478\n","Aggregate regression train score with FS: 0.20364173119179307, test score: 0.20377772856932808\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.204\n","Test R2 linear regression CMI best 5:  0.204 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.5:  0.714\n","Test accuracy logregr CMI best 5 for shuffle n.5:  0.737 \n","\n","####################Garda_Mincio####################\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 7\n","\n","Number of features: 67\n","\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 5\n","\n","Number of features: 67\n","\n","Number of aggregated features: 8\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","----- MI Scores -----\n","[(34, 0.09726862101025892), (10, 0.09510775225799974), (40, 0.09218359594229039), (35, 0.09008898361773215), (38, 0.08842440113466793), (26, 0.08564394037577139), (8, 0.08513632166186187), (2, 0.08176150293512269), (30, 0.07462991518804224), (1, 0.07348403771303066), (3, 0.07295310960882422), (32, 0.06993780573941064), (5, 0.06933888989919264), (44, 0.06858134159461278), (41, 0.06557006580172677), (0, 0.06323330408487439), (27, 0.06296158297322993), (9, 0.060305206506415306), (6, 0.05975235653069669), (7, 0.059302757049079405), (42, 0.058322194113197265), (46, 0.05820198115615721), (4, 0.05134428620199098), (48, 0.049216826756414186), (25, 0.0482947246449059), (47, 0.04809528081224981), (39, 0.04643748520445946), (31, 0.04492821142446849), (15, 0.040538661051370994), (11, 0.03675962572819817), (24, 0.036243414346516255), (43, 0.0358435550243809), (23, 0.03397407155312966), (21, 0.03361568229345798), (33, 0.03343295395737516), (29, 0.032110011526090325), (20, 0.032051603453797144), (19, 0.031990296531804956), (36, 0.03181806139517566), (17, 0.028389161596355683), (28, 0.027846461976266546), (18, 0.026102495950775913), (12, 0.02510309485256738), (37, 0.024259262779397828), (50, 0.024218116616519715), (22, 0.02078847815467888), (45, 0.01603090809869696), (16, 0.01563994041804793), (13, 0.015540179879147315), (14, 0.013116855007375514), (51, 0.010230437183862962), (49, -0.004968369809850813)]\n","Best MI score: 0.09726862101025892\n","Adding first best original feature: 34\n","CMI: 0.08008706218921217\n","CMI: 0.06739384023117119\n","CMI: 0.057205202935420627\n","CMI: 0.05944943260430756\n","CMI: 0.07007215594517514\n","CMI: 0.060198109489435506\n","CMI: 0.04227553800240562\n","CMI: 0.046778527224573166\n","CMI: 0.0763474934562638\n","CMI: 0.03989568596151298\n","CMI: 0.07855998321774003\n","CMI: 0.025983124031405097\n","CMI: 0.010689503092955382\n","CMI: 0.006734436729099472\n","CMI: 0.004080197237691624\n","CMI: 0.004826889360122016\n","CMI: 0.008878536156715827\n","CMI: 0.00018271395984352512\n","CMI: 0.018198563826658326\n","CMI: 0.010749697484924672\n","CMI: 0.00938718449538796\n","CMI: 0.01976599888758407\n","CMI: 0.025287230034940433\n","CMI: 0.002537450738891431\n","CMI: 0.016574988917757008\n","CMI: 0.002344079038753888\n","CMI: 0.017493399820526653\n","CMI: 0.014535929499963948\n","CMI: 0.042957000703961204\n","CMI: 0.004118647872637604\n","CMI: 0.03238864234536844\n","CMI: 0.010268104529893143\n","CMI: 0.016942845563155548\n","CMI: 0.021777171606396847\n","CMI: 0.018802176017428826\n","CMI: 0.02564276304751789\n","CMI: 0.016276043250650685\n","CMI: 0.00036380289056968385\n","Highest CMI score: 0.08008706218921217\n","Adding original feature: 0\n","CMI: 0.0023470245440128656\n","CMI: 0.001515023884083866\n","CMI: 0.006556657862577919\n","CMI: 0.015417244799374175\n","CMI: 0.0003805101634742625\n","CMI: 0.0006672618500083161\n","CMI: 0.0036523497967737018\n","Highest CMI score: 0.015417244799374175\n","Adding original feature: 38\n","CMI: 0.010813029370204397\n","Highest CMI score: 0.010813029370204397\n","Adding original feature: 43\n","CMI: 0.012900291492338706\n","CMI: 0.0008162102416908179\n","Highest CMI score: 0.012900291492338706\n","Adding original feature: 12\n","CMI: 0.00014014792231964446\n","Highest CMI score: 0.00014014792231964446\n","Adding original feature: 35\n","CMI: 0.0026324486440185146\n","CMI: 0.00459141877074673\n","CMI: 1.5377354951495725e-05\n","Highest CMI score: 0.00459141877074673\n","Adding original feature: 8\n","Highest CMI score: -6.0665587284347566e-05\n","\n","[34, 0, 38, 43, 12, 35, 8]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3457263104043724, test score: -0.032717719660812605\n","Aggregate regression train score with FS: 0.23983106554864553, test score: 0.23151343191465457\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3457263104043724, test score: -0.032717719660812605\n","Aggregate regression train score with FS: 0.21930815256082503, test score: 0.19688361981680602\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.219\n","Test R2 linear regression CMI best 5:  0.197 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.6:  0.714\n","Test accuracy logregr CMI best 5 for shuffle n.6:  0.697 \n","\n","####################Garda_Mincio####################\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 7\n","\n","Number of features: 67\n","\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 6\n","\n","Number of features: 67\n","\n","Number of aggregated features: 6\n","\n","Number of features: 67\n","\n","Number of aggregated features: 6\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 5\n","\n","----- MI Scores -----\n","[(34, 0.11734557649459675), (32, 0.11541136953245926), (31, 0.100903765265325), (37, 0.09945672778564453), (41, 0.09715121613433071), (42, 0.09218359594229039), (33, 0.0900570122030439), (25, 0.08564394037577139), (2, 0.08176150293512269), (30, 0.07462991518804224), (1, 0.07348403771303066), (3, 0.07295310960882422), (38, 0.07224923246511691), (5, 0.07164777812689885), (39, 0.07087353799508538), (9, 0.07018343740918907), (27, 0.06993780573941064), (45, 0.06976401768047137), (10, 0.06949854377801695), (43, 0.0655824120762228), (0, 0.06323330408487439), (26, 0.06180747640157667), (8, 0.060305206506415306), (6, 0.05975235653069669), (7, 0.059302757049079405), (47, 0.05820198115615721), (4, 0.05134428620199098), (49, 0.049216826756414186), (40, 0.04391011784109195), (15, 0.040538661051370994), (11, 0.03675962572819817), (23, 0.036327113336155584), (44, 0.0358435550243809), (21, 0.03361568229345798), (28, 0.03255723360151648), (20, 0.032051603453797144), (19, 0.031990296531804956), (24, 0.03153600369907041), (35, 0.031041632369108414), (17, 0.028389161596355683), (29, 0.026867195549632104), (18, 0.026102495950775913), (12, 0.02510309485256738), (52, 0.0235344479872647), (22, 0.01830735114204872), (48, 0.018253521621274665), (16, 0.01563994041804793), (13, 0.015540179879147315), (46, 0.015419848362536112), (14, 0.013116855007375514), (53, 0.010230437183862962), (36, 0.009692456390089805), (50, 0.005556183533065954), (51, -0.004968369809850813)]\n","Best MI score: 0.11734557649459675\n","Adding first best original feature: 34\n","CMI: 0.04575181700254989\n","CMI: 0.048179583122270206\n","CMI: 0.041147200488436966\n","CMI: 0.024219431325278887\n","CMI: 0.05575633118981772\n","CMI: 0.04493169591752251\n","CMI: 0.039727386540070006\n","CMI: 0.035275429515621695\n","CMI: 0.03191277088922191\n","CMI: 0.018619953796321323\n","CMI: 0.020230104193841816\n","CMI: 0.015841245208468316\n","CMI: 0.00024802940552878794\n","CMI: 0.0030427265118399965\n","CMI: 0.01719097135425486\n","CMI: 0.005438653426171405\n","CMI: 0.003294402806405486\n","CMI: 0.0031002766995841258\n","CMI: 0.013021951675520602\n","CMI: 0.02465724544680571\n","CMI: 0.012784125609444738\n","Highest CMI score: 0.05575633118981772\n","Adding original feature: 4\n","CMI: 0.001959072487719926\n","CMI: 0.007616285562534547\n","CMI: 0.005561800583663845\n","CMI: 0.013065030121030025\n","CMI: 0.0037644023956337758\n","CMI: 0.0067734974574576445\n","Highest CMI score: 0.013065030121030025\n","Adding original feature: 32\n","Highest CMI score: -0.0015797483846586857\n","\n","[34, 4, 32]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.35715539552015096, test score: 0.017518213019226847\n","Aggregate regression train score with FS: 0.18531678704488097, test score: 0.13707372479143964\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.35715539552015096, test score: 0.017518213019226847\n","Aggregate regression train score with FS: 0.18531678704488097, test score: 0.13707372479143964\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.185\n","Test R2 linear regression CMI best 5:  0.137 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.7:  0.657\n","Test accuracy logregr CMI best 5 for shuffle n.7:  0.658 \n","\n","####################Garda_Mincio####################\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 8\n","\n","Number of features: 67\n","\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 7\n","\n","Number of features: 67\n","\n","Number of aggregated features: 6\n","\n","Number of features: 67\n","\n","Number of aggregated features: 6\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","----- MI Scores -----\n","[(33, 0.11734557649459675), (35, 0.11541136953245926), (32, 0.100903765265325), (38, 0.09945672778564453), (43, 0.09715121613433071), (10, 0.09510775225799974), (39, 0.09218359594229039), (34, 0.0900570122030439), (25, 0.08564394037577139), (11, 0.08513632166186187), (2, 0.08176150293512269), (30, 0.07462991518804224), (46, 0.0738060511945529), (1, 0.07348403771303066), (7, 0.07321151138058377), (3, 0.07295310960882422), (40, 0.07224923246511691), (41, 0.07087353799508538), (5, 0.07057227338822886), (26, 0.06993780573941064), (47, 0.06976401768047137), (44, 0.066470984090926), (0, 0.06323330408487439), (27, 0.06180747640157667), (9, 0.060305206506415306), (8, 0.05975235653069669), (6, 0.059302757049079405), (49, 0.05820198115615721), (4, 0.05134428620199098), (50, 0.049216826756414186), (28, 0.04587619018356308), (42, 0.04391011784109195), (16, 0.040538661051370994), (31, 0.039548077199498766), (12, 0.03675962572819817), (45, 0.0358435550243809), (22, 0.03361568229345798), (21, 0.032051603453797144), (20, 0.031990296531804956), (36, 0.031041632369108414), (29, 0.02854690589624177), (18, 0.028389161596355683), (19, 0.026102495950775913), (13, 0.02510309485256738), (51, 0.024218116616519715), (23, 0.02287916718903644), (24, 0.019965706219790276), (48, 0.01603090809869696), (17, 0.01563994041804793), (14, 0.015540179879147315), (15, 0.013116855007375514), (53, 0.010230437183862962), (37, 0.009692456390089805), (52, -0.004968369809850813)]\n","Best MI score: 0.11734557649459675\n","Adding first best original feature: 33\n","CMI: 0.04575181700254989\n","CMI: 0.048179583122270206\n","CMI: 0.041147200488436966\n","CMI: 0.024219431325278887\n","CMI: 0.05575633118981772\n","CMI: 0.033697129304059006\n","CMI: 0.035275429515621695\n","CMI: 0.022603004598834117\n","CMI: 0.039727386540070006\n","CMI: 0.03191277088922191\n","CMI: 0.054219931617975434\n","CMI: 0.05838595284586083\n","CMI: 0.015841245208468316\n","CMI: 0.00024802940552878794\n","CMI: 0.0030427265118399965\n","CMI: 0.01719097135425486\n","CMI: 0.005438653426171405\n","CMI: 0.003294402806405486\n","CMI: 0.0031002766995841258\n","CMI: 0.011776651892721715\n","CMI: 0.013021951675520602\n","CMI: 0.02465724544680571\n","CMI: 0.012784125609444738\n","Highest CMI score: 0.05838595284586083\n","Adding original feature: 11\n","CMI: 0.006058830267933468\n","CMI: 0.013142464593354747\n","CMI: 0.0061475908710464655\n","CMI: 0.0008030292137337636\n","CMI: 0.009533588083953465\n","CMI: 0.00023637869879222784\n","CMI: 0.0018571947108242393\n","Highest CMI score: 0.013142464593354747\n","Adding original feature: 25\n","CMI: 0.004592235808220352\n","CMI: 0.0016626162059419636\n","Highest CMI score: 0.004592235808220352\n","Adding original feature: 42\n","CMI: 0.004860608435349606\n","Highest CMI score: 0.004860608435349606\n","Adding original feature: 35\n","Highest CMI score: -0.003642305876923213\n","\n","[33, 11, 25, 42, 35]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3514501943960697, test score: -0.05956024760910328\n","Aggregate regression train score with FS: 0.206755835687635, test score: 0.1870633806258012\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3514501943960697, test score: -0.05956024760910328\n","Aggregate regression train score with FS: 0.206755835687635, test score: 0.1870633806258012\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.207\n","Test R2 linear regression CMI best 5:  0.187 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.8:  0.693\n","Test accuracy logregr CMI best 5 for shuffle n.8:  0.684 \n","\n","####################Garda_Mincio####################\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 6\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 6\n","\n","Number of features: 67\n","\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","Number of aggregated features: 7\n","\n","----- MI Scores -----\n","[(29, 0.12349633338976866), (30, 0.10682474937409657), (33, 0.10425738764951727), (49, 0.09907047202240124), (34, 0.0956507201877715), (37, 0.09218359594229039), (31, 0.09008898361773215), (23, 0.08558953082118216), (1, 0.08191620029157745), (35, 0.07541651525184066), (41, 0.0738060511945529), (26, 0.07187791689284748), (51, 0.0706286467104322), (4, 0.07018343740918907), (27, 0.06993780573941064), (3, 0.06949854377801695), (0, 0.0666485193202881), (36, 0.0664173596180683), (43, 0.06461246529459347), (2, 0.06345228144852584), (40, 0.06129265601658003), (39, 0.06069881068734619), (44, 0.05820198115615721), (28, 0.057662771675359575), (11, 0.05730149074009724), (32, 0.056971518973107496), (50, 0.05502484009524533), (20, 0.04043125112339926), (48, 0.038485306658074286), (5, 0.03675962572819817), (15, 0.0364855322280704), (14, 0.0364745048110661), (38, 0.036379153488667146), (18, 0.035807738604257865), (10, 0.03566307541029757), (25, 0.03343295395737516), (22, 0.033279824036513736), (9, 0.03327629421608082), (19, 0.028923675013272452), (42, 0.02750879480023889), (46, 0.0274350197982691), (24, 0.026867195549632104), (12, 0.02564796541130629), (16, 0.022618886196568246), (45, 0.02181412221689453), (6, 0.02168722451446057), (17, 0.020040822116361733), (8, 0.015540179879147315), (21, 0.015246924491615651), (13, 0.014253699687549953), (7, 0.013116855007375514), (47, 0.010571625816905912)]\n","Best MI score: 0.12349633338976866\n","Adding first best original feature: 29\n","CMI: 0.0783819122337502\n","CMI: 0.05876924999391338\n","CMI: 0.07898920672668204\n","CMI: 0.05526405621033949\n","CMI: 0.05964569997952661\n","CMI: 0.022035075508440985\n","CMI: 0.02317395098802276\n","CMI: 0.0003619003139608834\n","CMI: 0.0031019303064415\n","CMI: 0.02730406333816167\n","CMI: 0.01758542620249222\n","CMI: 0.03569272902895872\n","CMI: 0.028615338616724814\n","CMI: 0.03143947205138618\n","CMI: 0.022779964888417478\n","CMI: 0.025623828006701502\n","CMI: 0.012866651848193258\n","CMI: 0.014046403663636894\n","CMI: 0.016444566863982005\n","CMI: 0.006552024774998125\n","CMI: 0.01878222939135636\n","CMI: 0.03567451003442397\n","CMI: 0.005394057566705732\n","CMI: 0.018832118125649375\n","CMI: 0.010560014676502152\n","CMI: 0.00036727100698555337\n","CMI: 0.006769464583819704\n","CMI: 0.020182545882805727\n","CMI: 0.03295019341580087\n","CMI: 0.021289604224657047\n","CMI: 0.022550194141086013\n","Highest CMI score: 0.07898920672668204\n","Adding original feature: 2\n","CMI: 0.0024657763093225704\n","CMI: 0.0037489747675271134\n","CMI: 0.002171617155824257\n","Highest CMI score: 0.0037489747675271134\n","Adding original feature: 41\n","CMI: 0.008882135117568385\n","CMI: 0.0016421217546502553\n","Highest CMI score: 0.008882135117568385\n","Adding original feature: 39\n","Highest CMI score: -0.0017521061264353377\n","\n","[29, 2, 41, 39]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.36786385417065337, test score: -0.012461513531621726\n","Aggregate regression train score with FS: 0.19601812162651056, test score: 0.17745146902149844\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.36786385417065337, test score: -0.012461513531621726\n","Aggregate regression train score with FS: 0.19601812162651056, test score: 0.17745146902149844\n","###### Linear Regression ######\n","Train R2 linear regression CMI best 5:  0.196\n","Test R2 linear regression CMI best 5:  0.177 \n","\n","###### Binary Classification ######\n","Train accuracy logregr CMI best 5 for shuffle n.9:  0.682\n","Test accuracy logregr CMI best 5 for shuffle n.9:  0.711 \n","\n"]}],"source":["basins = ['Emiliani2', 'Garda_Mincio']\n","\n","destination_folder = './NonLinCFA/temp_prec_shuffle_starting_points_only/'\n","plots_folder = './NonLinCFA/for_plots/starting_points_only/'\n","\n","for basin in basins:\n","  selected_colnames_CMI5 = []\n","  outputs = []\n","  for i, random_seed in enumerate(randomlist):\n","    print('####################' + basin + '####################')\n","    target_df_train, target_df_val, target_df_test, target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', \n","        path=path_target+basin+'.csv', window_size = 1)\n","    eps = 0.001\n","    actual_path = path_features+basin+'_aggreg.csv'\n","    output, aggregate_trainVal, aggregate_test = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg', \n","                                                                              'cyclostationary_mean_tg_1w',\n","                                                                              'cyclostationary_mean_tg_4w', \n","                                                                              'cyclostationary_mean_tg_8w',\n","                                                                              'cyclostationary_mean_tg_12w', \n","                                                                              'cyclostationary_mean_tg_16w',\n","                                                                              'cyclostationary_mean_tg_24w',\n","                                                                              'cyclostationary_mean_rr', \n","                                                                              'cyclostationary_mean_rr_1w',\n","                                                                              'cyclostationary_mean_rr_4w', \n","                                                                              'cyclostationary_mean_rr_8w',\n","                                                                              'cyclostationary_mean_rr_12w', \n","                                                                              'cyclostationary_mean_rr_16w',\n","                                                                              'cyclostationary_mean_rr_24w'\n","                                                                              ],\n","                                                                        target_df_trainVal, eps=eps,\n","                                                                        max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01',\n","                                                                        curr_seed=random_seed, shuffle=False, shuffle_starting_point_only = True)\n","    \n","    agg_trainVal_string = plots_folder + basin + \"_trainVal_aggreg_\" + str(i)\n","    agg_test_string = plots_folder + basin + \"_test_aggreg_\" + str(i)\n","    aggregate_trainVal.to_csv(agg_trainVal_string, index = False)\n","    aggregate_test.to_csv(agg_test_string, index = False)\n","    \n","    outputs.append(output)\n","    #starting_points.append(starting_point)\n","\n","    res = {\n","              \"delta\" : [], \n","              \"numSelected\" : [], \n","              \"selectedFeatures\" : [] \n","          }\n","    \n","    res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),np.array(target_df_trainVal.mean_std),res,10,1)\n","    \n","    selectedFeatures='selectedFeatures'\n","    print(f'\\n{res[selectedFeatures]}\\n')\n","    selected_colnames_CMI = aggregate_trainVal.columns[res['selectedFeatures']]\n","\n","    print('\\nFull model and selected features with CMI\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames_CMI)\n","\n","    print('\\nFull model and best 5 selected features with CMI\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames_CMI[0:5])\n","    \n","    selected_colnames_CMI5.append(aggregate_trainVal.loc[:,selected_colnames_CMI[0:5]].columns.values)\n","\n","    train_string = destination_folder + basin + '_' + str(i) + '_nonLinCFA_best5_CMI_train.csv'\n","    val_string = destination_folder + basin + '_' + str(i) + '_nonLinCFA_best5_CMI_val.csv'\n","    test_string = destination_folder + basin + '_' + str(i) + '_nonLinCFA_best5_CMI_test.csv'\n","\n","    X_train_CMI5 = aggregate_trainVal.loc[:410,selected_colnames_CMI[0:5]]\n","    X_validation_CMI5 = aggregate_trainVal.loc[411:,selected_colnames_CMI[0:5]]\n","    X_train_validation_CMI5 = pd.concat([X_train_CMI5, X_validation_CMI5])\n","    X_test_CMI5 = aggregate_test.loc[:,selected_colnames_CMI[0:5]]\n","            \n","    X_train_CMI5.to_csv(train_string, index=False)\n","    X_validation_CMI5.to_csv(val_string, index=False)\n","    X_test_CMI5.to_csv(test_string, index=False)\n","\n","\n","    print('###### Linear Regression ######')\n","\n","    lin_regr = LinearRegression()\n","\n","    # CMI best 5\n","    lin_regr.fit(X_train_validation_CMI5, target_df_trainVal['mean_std'])\n","    print(\"Train R2 linear regression CMI best 5: \", round(lin_regr.score(X_train_validation_CMI5, target_df_trainVal['mean_std']),3))\n","    print(\"Test R2 linear regression CMI best 5: \", round(lin_regr.score(X_test_CMI5, target_df_test['mean_std']),3), \"\\n\")\n","\n","    print('###### Binary Classification ######')\n","\n","    target_df_train = target_df_train.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_val = target_df_val.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_test = target_df_test.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_trainVal = target_df_trainVal.apply(lambda x: np.sign(x.mean_std), axis=1)\n","\n","    log_regr = LogisticRegression(solver='lbfgs', random_state = 42)\n","    log_regr.fit(X_train_validation_CMI5.values, target_df_trainVal)\n","    print(\"Train accuracy logregr CMI best 5 for shuffle n.\" + str(i) + \": \", round(log_regr.score(X_train_validation_CMI5.values, target_df_trainVal),3))\n","    print(\"Test accuracy logregr CMI best 5 for shuffle n.\" + str(i) + \": \", round(log_regr.score(X_test_CMI5.values, target_df_test),3), \"\\n\")\n","  #output_string = plots_folder + basin + '_aggregations.npy'\n","  #sel_col_string = plots_folder + basin + '_chosen_features.npy'\n","  #np.save(sel_col_string, selected_colnames_CMI5)\n","  #np.save(output_string, outputs)"]},{"cell_type":"markdown","metadata":{"id":"rYpR9P_TOe31"},"source":["# Multi task scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RJvLiezWRmUG"},"outputs":[],"source":["# for binary classification \n","\n","from sklearn.metrics import accuracy_score\n","def MTL_scores(clust_basins, df_train, df_val, df_test, targets_df_train, targets_df_val, targets_df_test):\n","    \n","    colnames = [x for x in df_train.columns if x.startswith(tuple(clust_basins))]\n","\n","    clusterdf_train_withClass = pd.DataFrame()\n","    clusterdf_val_withClass = pd.DataFrame()\n","    clusterdf_test_withClass = pd.DataFrame()\n","\n","    for i in range(len(clust_basins)):\n","        clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((df_train[colnames],pd.DataFrame(1+i*np.ones(len(df_train)),columns=['basin'])),axis=1)),axis=0)\n","        clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((df_val[colnames],pd.DataFrame(1+i*np.ones(len(df_val)),columns=['basin'])),axis=1)),axis=0)\n","        clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((df_test[colnames],pd.DataFrame(1+i*np.ones(len(df_test)),columns=['basin'])),axis=1)),axis=0)\n","    \n","    for i in range(len(clust_basins)):\n","        clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n","        clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n","        clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n","\n","    clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n","    clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n","    clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n","\n","    targets_df_train_unfolded = pd.DataFrame()\n","    targets_df_val_unfolded = pd.DataFrame()\n","    targets_df_test_unfolded = pd.DataFrame()\n","    \n","    for basin in clust_basins:\n","        targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n","        targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n","        targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n","    targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n","    targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n","    targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n","\n","    # same scores changing the solver, some differences changing penalty, some improve with l1\n","    model_ohe = LogisticRegression(max_iter = 500)\n","    model_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)).values,pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)).values.ravel())\n","    \n","    for basin in clust_basins:\n","        print(basin)\n","        res = model_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass[basin]==1].values)\n","        print(accuracy_score(targets_df_test[basin].values.ravel(), res))"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":313,"status":"ok","timestamp":1684676769453,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"U-SHWiBDOhY_"},"outputs":[],"source":["# for linear regression \n","\n","def MTL_scores(clust_basins, df_train, df_val, df_test, targets_df_train, targets_df_val, targets_df_test):\n","    \n","    colnames = [x for x in df_train.columns if x.startswith(tuple(clust_basins))]\n","\n","    clusterdf_train_withClass = pd.DataFrame()\n","    clusterdf_val_withClass = pd.DataFrame()\n","    clusterdf_test_withClass = pd.DataFrame()\n","\n","    for i in range(len(clust_basins)):\n","        clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((df_train[colnames],pd.DataFrame(1+i*np.ones(len(df_train)),columns=['basin'])),axis=1)),axis=0)\n","        clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((df_val[colnames],pd.DataFrame(1+i*np.ones(len(df_val)),columns=['basin'])),axis=1)),axis=0)\n","        clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((df_test[colnames],pd.DataFrame(1+i*np.ones(len(df_test)),columns=['basin'])),axis=1)),axis=0)\n","    \n","    for i in range(len(clust_basins)):\n","        clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n","        clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n","        clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n","\n","    clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n","    clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n","    clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n","\n","    targets_df_train_unfolded = pd.DataFrame()\n","    targets_df_val_unfolded = pd.DataFrame()\n","    targets_df_test_unfolded = pd.DataFrame()\n","    \n","    for basin in clust_basins:\n","        targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n","        targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n","        targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n","    targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n","    targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n","    targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n","\n","    # same scores changing the solver, some differences changing penalty, some improve with l1\n","    model_ohe = LinearRegression()\n","    model_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)).values,pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)).values.ravel())\n","    \n","    for basin in clust_basins:\n","        print(basin)\n","        res = model_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass[basin]==1].values)\n","        print(r2_score(targets_df_test[basin].values.ravel(), res))"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":3287,"status":"ok","timestamp":1684676777903,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"Knf0pZI5Zyf4"},"outputs":[],"source":["### continuous targets\n","basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona','Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n","path_targets = \"./csv/\"\n","targets_df_train = pd.DataFrame()\n","targets_df_val = pd.DataFrame()\n","targets_df_test = pd.DataFrame()\n","targets_df_trainVal = pd.DataFrame()\n","\n","for basin in basins:\n","    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', \n","                                                                                     max_test='2020-01-01', path=path_targets+basin+'.csv', \n","                                                                                     window_size = 1)\n","    targets_df_train[basin] = target_df_train.mean_std\n","    targets_df_val[basin] = target_df_val.mean_std\n","    targets_df_test[basin] = target_df_test.mean_std\n","    targets_df_trainVal[basin] = target_df_trainVal.mean_std"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zvHEyv7_O-nx"},"outputs":[],"source":["### binary targets\n","basins = ['Emiliani1','Emiliani2','Garda_Mincio']\n","path_targets = \"./csv/\"\n","targets_df_train = pd.DataFrame()\n","targets_df_val = pd.DataFrame()\n","targets_df_test = pd.DataFrame()\n","targets_df_trainVal = pd.DataFrame()\n","\n","for basin in basins:\n","    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target_binary('',max_train='2010-01-01', max_val='2015-01-01', \n","                                                                                            max_test='2020-01-01', path=path_targets+basin+'.csv', \n","                                                                                            threshold = None, nopeaks = False, window_size = 2)\n","    targets_df_train[basin] = target_df_train.mean_std\n","    targets_df_val[basin] = target_df_val.mean_std\n","    targets_df_test[basin] = target_df_test.mean_std\n","    targets_df_trainVal[basin] = target_df_trainVal.mean_std"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":1332,"status":"ok","timestamp":1684677054588,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"CFHwo5uJOhR1"},"outputs":[],"source":["basins = ['Emiliani1', 'Emiliani2', 'Garda_Mincio']\n","# basins = ['Dora','Piemonte_Sud', 'Piemonte_Nord']\n","# basins = ['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino']\n","\n","### CMI best5 features\n","path_features = './NonLinCFA/temp_prec_shuffle_starting_points_only/'\n","\n","best5_CMI_fulldf_train = pd.DataFrame()\n","best5_CMI_fulldf_val = pd.DataFrame()\n","best5_CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_9_nonLinCFA_best5_CMI_train.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_9_nonLinCFA_best5_CMI_val.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_9_nonLinCFA_best5_CMI_test.csv')\n","    best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1683721772973,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"65SnZBblnAG0","outputId":"38c5edbf-5dce-4d1d-efeb-7d6ecaa011e9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train R2 linear regression CMI best 5:  0.219\n"]}],"source":["lin_regr = LinearRegression()\n","train_val = pd.concat([train_temp,val_temp])\n","lin_regr.fit(train_val, targets_df_trainVal[basin])\n","print(\"Train R2 linear regression CMI best 5: \", round(lin_regr.score(train_val, targets_df_trainVal[basin]),3))\n","#print(\"Valid R2 linear regression CMI best 5: \", round(lin_regr.score(X_valid, y_valid),3))"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":411,"status":"ok","timestamp":1684677054994,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"iqbj2OxROhLu","outputId":"456b5fbf-ab29-432c-cbdd-fda3e330c6f8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Emiliani1\n","0.30987216051335964\n","Emiliani2\n","0.24794116452339032\n","Garda_Mincio\n","0.21771278883858325\n"]}],"source":["MTL_scores(clust_basins=['Emiliani1','Emiliani2','Garda_Mincio'], df_train=best5_CMI_fulldf_train, df_val=best5_CMI_fulldf_val, df_test=best5_CMI_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1682580261023,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"CjW2OS-5kMtt","outputId":"75945626-78aa-45d6-e6f2-fd610649337e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dora\n","-0.3907479850750135\n","Piemonte_Sud\n","-0.22770794082461743\n","Piemonte_Nord\n","-0.15350608126875898\n"]}],"source":["MTL_scores(clust_basins=['Dora','Piemonte_Sud', 'Piemonte_Nord'], df_train=best5_CMI_fulldf_train, df_val=best5_CMI_fulldf_val, df_test=best5_CMI_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":256,"status":"ok","timestamp":1682580417356,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"51c2grtqlZR2","outputId":"cddfba5f-c2bd-4517-93af-258b34e0b1ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Adda\n","0.14491512596906841\n","Lambro_Olona\n","0.0930532166989918\n","Oglio_Iseo\n","0.16227971468701263\n","Ticino\n","0.14327353589823855\n"]}],"source":["MTL_scores(clust_basins=['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino'], df_train=best5_CMI_fulldf_train, df_val=best5_CMI_fulldf_val, df_test=best5_CMI_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"]}],"metadata":{"colab":{"collapsed_sections":["NBYmy872-tgk","rYpR9P_TOe31"],"name":"","version":""},"kernelspec":{"display_name":"Python 3.9 (tensorflow)","language":"python","name":"tensorflow"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":5}