{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2229,"status":"ok","timestamp":1690352725052,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"_Q-9-_Ldoy_t","outputId":"8f9ce038-a70c-49ac-9ca9-f48758f262fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"id":"_Q-9-_Ldoy_t"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1690352725053,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"N4mlPbfnozfO","outputId":"7676b581-0b12-45e3-fd3d-81484de9c639"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/scripts\n"]}],"source":["cd drive/MyDrive/Colab\\ Notebooks/scripts"],"id":"N4mlPbfnozfO"},{"cell_type":"code","execution_count":3,"metadata":{"id":"87a19403","executionInfo":{"status":"ok","timestamp":1690352731277,"user_tz":-120,"elapsed":2846,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","import numpy as np\n","import sys\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import r2_score\n","import os\n","from collections import Counter"],"id":"87a19403"},{"cell_type":"code","execution_count":4,"metadata":{"id":"t4O3GfTbop-R","executionInfo":{"status":"ok","timestamp":1690352731278,"user_tz":-120,"elapsed":9,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"outputs":[],"source":["from feature_selection import forwardFeatureSelection\n","\n","from NonLinCFA import NonLinCFA\n","from aux_GenLinCFA import prepare_target_binary\n","\n","from aux_NonLinCFA import *\n","import random"],"id":"t4O3GfTbop-R"},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1690352731279,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"tkkdaNmFRP4N","outputId":"72fb3714-a84f-4e21-fa7d-11d2ad33e3d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["cd .."],"id":"tkkdaNmFRP4N"},{"cell_type":"markdown","metadata":{"id":"PqNz4kWf-tga"},"source":["# NonLinCFA aggregations standardized target\n","\n"],"id":"PqNz4kWf-tga"},{"cell_type":"markdown","source":["## Temp Prec"],"metadata":{"id":"YKM3aaqPwZJK"},"id":"YKM3aaqPwZJK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dd_c8fjYuJ9h","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690302959330,"user_tz":-120,"elapsed":2054950,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"b3b024ba-93a5-4aea-ccd2-e7b45cf3d0ce"},"outputs":[{"output_type":"stream","name":"stdout","text":["####################Emiliani1####################\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 7\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 5\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 2\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 6\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 9\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 7\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 2\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 18\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 17\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 10\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 7\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 6\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 4\n","\n","Number of features: 172\n","\n","eps value:  0.0005813953488372093\n","Number of aggregated features: 5\n","\n","\n","\n","selected columns: ['cyclostationary_mean_rr_8w_4', 'cyclostationary_mean_tg_0', 'cyclostationary_mean_rr_1w_14', 'cyclostationary_mean_rr_8w_6', 'cyclostationary_mean_rr_1w_9', 'cyclostationary_mean_rr_24w_4', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_rr_16w_2', 'cyclostationary_mean_rr_4w_5', 'cyclostationary_mean_tg_12w_1', 'cyclostationary_mean_tg_16w_4', 'cyclostationary_mean_tg_6', 'cyclostationary_mean_rr_8w_5', 'cyclostationary_mean_rr_1w_13', 'cyclostationary_mean_rr_4w_9', 'cyclostationary_mean_tg_12w_4', 'cyclostationary_mean_rr_12w_5', 'cyclostationary_mean_rr_24w_2', 'cyclostationary_mean_tg_16w_5', 'cyclostationary_mean_rr_4w_6', 'cyclostationary_mean_rr_8w_2', 'cyclostationary_mean_rr_8w_3', 'cyclostationary_mean_rr_4w_8', 'cyclostationary_mean_rr_4w_4'], \n","\n","validation score: 0.5257906536814898, \n","\n","number of selected features: 24\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.5707252550554658, test score: -0.4708630105017457\n","Aggregate regression train score with FS: 0.4141773154876721, test score: 0.22944723305396741\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.5707252550554658, test score: -0.4708630105017457\n","Aggregate regression train score with FS: 0.3709469990138181, test score: 0.23936597704485651\n","----- MI Scores -----\n","[(74, 0.18094562749442328), (87, 0.17340498318460199), (73, 0.1446472456082769), (90, 0.14230744592627162), (83, 0.1386595401482006), (67, 0.1349802515860218), (56, 0.1324763362676988), (61, 0.13105252517756258), (78, 0.12694880927643304), (59, 0.12386893890867491), (58, 0.12214661841855012), (11, 0.12039039926505574), (0, 0.11896468558725581), (6, 0.11780543033739596), (75, 0.11454039696340293), (98, 0.11453399321261738), (68, 0.11335540936270637), (79, 0.11250156550376682), (102, 0.11089194434859538), (81, 0.10958986288030156), (71, 0.10841941235654867), (103, 0.10827021126781076), (88, 0.10788925130816454), (65, 0.10711388855446481), (76, 0.10571525347787011), (72, 0.10549320327649592), (62, 0.10373775828161823), (63, 0.10314447604344332), (96, 0.10248333522007466), (85, 0.10154093994369653), (41, 0.10053531061638857), (92, 0.10027742629580787), (70, 0.10024619968928976), (57, 0.0994531008345894), (100, 0.09942519657860803), (48, 0.09861645872389999), (84, 0.09739680858665234), (64, 0.09606615344303136), (44, 0.09547994951997416), (66, 0.09511549492120479), (4, 0.09405187196915168), (60, 0.09328869047455321), (91, 0.09194927413671922), (45, 0.09187529418353856), (86, 0.09177450886801021), (47, 0.09129252386046051), (69, 0.08958437652000774), (93, 0.08957371740084549), (80, 0.08753254830123507), (55, 0.0867490107076037), (2, 0.08602415733777354), (77, 0.08558842129554048), (49, 0.08554998913576888), (82, 0.08491125367340009), (8, 0.08452172556134227), (50, 0.08436769616234886), (53, 0.08328726613632353), (94, 0.08261748872296845), (51, 0.08240828475834616), (89, 0.0821669057438252), (10, 0.08145242884051562), (38, 0.08135649298251192), (42, 0.08012035727379067), (3, 0.07957092675607583), (40, 0.07904464757539001), (1, 0.07889418652445655), (7, 0.07762334731582816), (43, 0.07660042166113477), (5, 0.07499550646953429), (95, 0.07407875416960118), (104, 0.0683177943511003), (18, 0.06515254344357825), (97, 0.06392638464827646), (54, 0.061974850020389695), (99, 0.05760941514094722), (29, 0.05691744091244044), (46, 0.055754979833963374), (32, 0.05516457579262129), (20, 0.05236052110382545), (14, 0.05149679768470331), (39, 0.047191465319022886), (22, 0.0456859679780398), (52, 0.04288722130539183), (34, 0.042091559041716374), (24, 0.04081054482914134), (25, 0.03653067536242513), (33, 0.03583447925860305), (30, 0.03515347052528275), (101, 0.03426346746416917), (37, 0.03425840629109658), (9, 0.03298367279402507), (13, 0.03262163084107232), (35, 0.030126065927809413), (26, 0.026579956385293566), (27, 0.026189293637828147), (21, 0.024968673067714865), (17, 0.022122817015110024), (16, 0.021399940888751197), (19, 0.01976606360613508), (28, 0.019504210416875823), (31, 0.018545523864962072), (12, 0.018083667996376635), (15, 0.011046690161012675), (36, 0.010706683026240862), (23, 0.009648700936972492)]\n","Best MI score: 0.18094562749442328\n","Adding first best original feature: 74\n","CMI: 0.07412444086163683\n","CMI: 0.06032274565913745\n","CMI: 0.056592818942128975\n","CMI: 0.05140483582957828\n","CMI: 0.040011607670009636\n","CMI: 0.069002942338456\n","CMI: 0.049307045019151674\n","CMI: 0.04584198960161451\n","CMI: 0.024798584577216204\n","CMI: 0.023354006236426444\n","CMI: 0.043037479315556154\n","CMI: 0.05364143276892802\n","CMI: 0.012896979514364554\n","CMI: 0.012689470075947618\n","CMI: 0.006777046053456526\n","CMI: 0.005633007174611154\n","CMI: 0.01026226008530215\n","CMI: 0.02345692521662729\n","CMI: 0.01806259417891759\n","CMI: 0.028379432104326807\n","CMI: 0.012571603020175487\n","CMI: 0.04041305183213184\n","CMI: 0.026009632784854575\n","CMI: 0.020712592626776438\n","CMI: 0.006154323988303623\n","CMI: 0.021069714236066378\n","CMI: 0.017194993139630882\n","CMI: 0.04405428204215464\n","CMI: 0.04030711349670607\n","CMI: 0.018603014385084382\n","CMI: 0.02132209514010963\n","CMI: 0.013939076501809061\n","CMI: 0.012314484001064163\n","CMI: 0.0482393163740199\n","CMI: 0.012251409011919817\n","CMI: 0.015764172681338784\n","CMI: 0.021437518298768554\n","CMI: 0.021635409446996823\n","CMI: 0.020254665890989454\n","CMI: 0.038300198886289355\n","CMI: 0.04626151160032216\n","CMI: 0.014702587507268522\n","CMI: 0.057345462481202675\n","CMI: 0.03112522180433336\n","CMI: 0.0471301198564639\n","CMI: 0.061850473956915925\n","CMI: 0.04722228931977204\n","CMI: 0.013666643755270186\n","CMI: 0.028394625707815868\n","CMI: 0.02284166748329186\n","CMI: 0.030532115456688408\n","CMI: 0.04577263314715904\n","CMI: 0.015499929285079372\n","CMI: 0.0453707134228756\n","CMI: 0.0437799219268486\n","CMI: 0.027482251531162932\n","CMI: 0.053737672440538925\n","CMI: 0.038633703922190066\n","CMI: 0.019185447236353348\n","CMI: 0.025120199026919282\n","CMI: 0.04528514780372245\n","CMI: 0.02176610875310217\n","CMI: 0.05795147623186431\n","CMI: 0.026041469011986895\n","CMI: 0.05678078263694261\n","CMI: 0.035696924206606945\n","CMI: 0.027511877134336643\n","CMI: 0.0584308301837726\n","CMI: 0.014594086434657733\n","CMI: 0.026099577850816763\n","CMI: 0.0204841916550437\n","CMI: 0.015914051090059417\n","CMI: 0.020153923032421917\n","CMI: 0.02135996057624978\n","CMI: 0.051865021842082304\n","CMI: 0.035408407333176684\n","CMI: 0.024069292401377645\n","CMI: 0.034135494516752574\n","CMI: 0.013691246296651194\n","CMI: 0.026321416533540837\n","CMI: 0.0036465594991872408\n","CMI: 0.013628260274831272\n","CMI: 0.02136459142513053\n","CMI: 0.03596541796112718\n","CMI: 0.008202699534577085\n","CMI: 0.02009757049245231\n","CMI: 0.028125831525061512\n","CMI: 0.018910949807040056\n","CMI: 0.026874455708276623\n","CMI: 0.013106860199690817\n","Highest CMI score: 0.07412444086163683\n","Adding original feature: 0\n","CMI: 0.012672849845036416\n","CMI: 0.002516445858072258\n","CMI: 0.005518401464563338\n","CMI: 0.011214749916707789\n","CMI: 0.012515911643593503\n","CMI: 0.011622460783913269\n","CMI: 0.010057509420454858\n","CMI: 0.010961251689319773\n","CMI: 0.015776189148621445\n","CMI: 0.01059538506059321\n","CMI: 0.0181633315971787\n","CMI: 0.0029484614392938924\n","CMI: 0.012987373791445378\n","CMI: 0.022514570866717543\n","CMI: 0.002629729006236481\n","CMI: 0.03339476708668615\n","CMI: 0.021215909063761973\n","CMI: 0.006814743598706485\n","CMI: 0.006054459137578794\n","CMI: 0.0052048079439960815\n","CMI: 0.01667097610917312\n","CMI: 0.007096229604498516\n","CMI: 0.006122573667732334\n","CMI: 0.0003963494075182594\n","CMI: 0.0013634957818765558\n","CMI: 0.007881949049246051\n","CMI: 0.01861046487184642\n","CMI: 0.002124661445927878\n","CMI: 0.020638085204063017\n","CMI: 0.0025584939915453964\n","CMI: 0.027771513274242376\n","CMI: 0.021066028843510276\n","CMI: 0.002417156073108384\n","CMI: 0.00465941910983475\n","CMI: 0.02411493208311788\n","CMI: 0.00832716892349572\n","CMI: 0.020254735751388586\n","CMI: 0.010518582910806484\n","CMI: 0.020466973425872503\n","CMI: 0.020257078163210818\n","CMI: 0.008725642272677137\n","CMI: 0.02292168320531296\n","CMI: 0.03176799870546981\n","CMI: 0.007090771622871417\n","CMI: 0.0174510589866671\n","CMI: 0.04550140332426966\n","CMI: 0.015587357261717949\n","CMI: 0.02363023516914564\n","CMI: 0.026705038330001207\n","CMI: 0.01934660616743794\n","CMI: 0.028366434018752773\n","CMI: 0.02446846509561873\n","CMI: 0.03141234760388906\n","CMI: 4.288283367487322e-05\n","CMI: 0.02244060036018053\n","CMI: 0.02144759170453686\n","CMI: 0.008930738228249135\n","CMI: 0.019270938091259793\n","CMI: 0.0014086258590851886\n","CMI: 0.018104625926450513\n","CMI: 0.0038681384739135405\n","CMI: 0.020781935582158184\n","CMI: 0.007515511445567391\n","CMI: 0.001134869270913219\n","CMI: 0.012518784344151268\n","CMI: 0.0019633245144958233\n","CMI: 0.004884452150290874\n","CMI: 0.009813063129635535\n","CMI: 0.00712464661356188\n","Highest CMI score: 0.04550140332426966\n","Adding original feature: 72\n","CMI: 0.000156685931037015\n","CMI: 0.0037457523065431153\n","CMI: 0.003234549271842191\n","CMI: 0.0016145400532657228\n","CMI: 0.0021669412328060855\n","CMI: 0.008684849930917615\n","CMI: 0.002245101428513363\n","CMI: 0.010488583415828645\n","Highest CMI score: 0.010488583415828645\n","Adding original feature: 102\n","Highest CMI score: -0.00016748311646386238\n","\n","[74, 0, 72, 102]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.5707252550554658, test score: -0.4708630105017457\n","Aggregate regression train score with FS: 0.3354591078929168, test score: 0.2860711267941545\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.5707252550554658, test score: -0.4708630105017457\n","Aggregate regression train score with FS: 0.3354591078929168, test score: 0.2860711267941545\n","###### Regression ######\n","Train R2 linear regression CMI:  0.335\n","Test R2 linear regression CMI:  0.286 \n","\n","Train R2 linear regression CMI best 5:  0.335\n","Test R2 linear regression CMI best 5:  0.286 \n","\n","Train R2 linear regression wrapper:  0.371\n","Test R2 linear regression wrapper:  0.239 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.723\n","Test accuracy logistic regression CMI:  0.689 \n","\n","Train accuracy logistic regression CMI best 5:  0.723\n","Test accuracy logistic regression CMI best 5:  0.689 \n","\n","Train accuracy logistic regression wrapper:  0.734\n","Test accuracy logistic regression wrapper:  0.711 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]},{"output_type":"stream","name":"stdout","text":["####################Emiliani2####################\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 5\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 3\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 2\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 4\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 8\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 7\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 6\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 1\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 1\n","\n","Number of features: 130\n","\n","eps value:  0.0007692307692307692\n","Number of aggregated features: 1\n","\n","\n","\n","selected columns: ['cyclostationary_mean_rr_8w_2', 'cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_rr_2', 'cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_rr_8w_3', 'cyclostationary_mean_rr_8w_4', 'cyclostationary_mean_rr_1w_4', 'cyclostationary_mean_tg_12w_0', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_tg_24w_0', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_tg_16w_0'], \n","\n","validation score: 0.4102548303177359, \n","\n","number of selected features: 17\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.41738843799840775, test score: 0.18984117121164246\n","Aggregate regression train score with FS: 0.26271110583249135, test score: 0.280724113177931\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.41738843799840775, test score: 0.18984117121164246\n","Aggregate regression train score with FS: 0.23017544267952383, test score: 0.27119383306211553\n","----- MI Scores -----\n","[(0, 0.12718245873910175), (44, 0.12365002928507647), (1, 0.11105606559756273), (2, 0.10936349802020918), (45, 0.10673449090636263), (7, 0.1062471319683625), (40, 0.10273933299236679), (46, 0.10064256260773037), (39, 0.10049432405580411), (42, 0.09604747481566951), (43, 0.09382355499119019), (47, 0.09367288690625802), (4, 0.09188383266583866), (10, 0.09139628132408192), (5, 0.0903872156146473), (3, 0.08633953056624281), (6, 0.0841592502455375), (38, 0.08070289709967944), (24, 0.07983106387081221), (48, 0.07821823052886995), (29, 0.07735136800386032), (35, 0.07470691093088286), (36, 0.07338922458274971), (41, 0.07272607982751346), (32, 0.07118434671187102), (28, 0.0673015030340393), (30, 0.06707238184316416), (33, 0.06676537225431443), (25, 0.06603537886373624), (27, 0.06311661834447387), (34, 0.06281036758005758), (37, 0.05972054269611112), (11, 0.057317333793792606), (31, 0.0554411323124629), (9, 0.05531454827164086), (26, 0.05494010120683826), (23, 0.05424361069941496), (49, 0.051368576889659456), (16, 0.044947963883539686), (8, 0.0448820114888473), (13, 0.04428458759911999), (12, 0.03438379717543677), (50, 0.03340482824399955), (22, 0.03279882395045534), (15, 0.029167067885804254), (14, 0.027470745872414933), (21, 0.02659309956960963), (20, 0.00906659767503522), (18, 0.005329259979075646), (19, 0.004884584872967409), (17, -0.0007162754311860124)]\n","Best MI score: 0.12718245873910175\n","Adding first best original feature: 0\n","CMI: 0.004118131521297391\n","CMI: 0.0015985346897502972\n","CMI: 0.0022687751236482034\n","CMI: 0.0015937050088789262\n","CMI: 0.012459095350232985\n","CMI: 0.0010253507920839067\n","CMI: 0.0016565834244711142\n","CMI: 0.004528282378567283\n","CMI: 0.015147962106961121\n","CMI: 0.0351089942262893\n","CMI: 0.022904012429138282\n","CMI: 0.011369964274236505\n","CMI: 0.028355894565899542\n","CMI: 0.020998001205570826\n","CMI: 0.018255747519092258\n","CMI: 0.04199462297519413\n","CMI: 0.034162197379349946\n","CMI: 0.017147886602226686\n","CMI: 0.04834231611927531\n","CMI: 0.04874820941885308\n","CMI: 0.04736768833033558\n","CMI: 0.05432336121752074\n","CMI: 0.0756377709693486\n","CMI: 0.05466590750084366\n","CMI: 0.06095827963108616\n","CMI: 0.065131417087507\n","CMI: 0.05903602156199314\n","CMI: 0.041014548492853936\n","CMI: 0.012026085890442378\n","Highest CMI score: 0.0756377709693486\n","Adding original feature: 42\n","CMI: 0.0024611538984455616\n","CMI: 0.00023201282809678925\n","CMI: 0.006963856725857642\n","CMI: 0.00044070373108348604\n","Highest CMI score: 0.006963856725857642\n","Adding original feature: 8\n","CMI: 0.005462427432577716\n","CMI: 0.0010937637212521945\n","Highest CMI score: 0.005462427432577716\n","Adding original feature: 40\n","CMI: 0.009285402109053875\n","CMI: 0.00039691019746010414\n","CMI: 0.0021394012847821275\n","Highest CMI score: 0.009285402109053875\n","Adding original feature: 45\n","CMI: 0.0031678894212580355\n","CMI: 0.006038985732591373\n","CMI: 0.0015119024256848024\n","CMI: 0.008617078499542186\n","Highest CMI score: 0.008617078499542186\n","Adding original feature: 43\n","CMI: 0.0034244951201751195\n","CMI: 0.002621856295802777\n","Highest CMI score: 0.0034244951201751195\n","Adding original feature: 10\n","Highest CMI score: -0.0002426023712893688\n","\n","[0, 42, 8, 40, 45, 43, 10]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.41738843799840775, test score: 0.18984117121164246\n","Aggregate regression train score with FS: 0.24309898108560013, test score: 0.25021413494680234\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.41738843799840775, test score: 0.18984117121164246\n","Aggregate regression train score with FS: 0.2242689434113071, test score: 0.24353431838283102\n","###### Regression ######\n","Train R2 linear regression CMI:  0.243\n","Test R2 linear regression CMI:  0.25 \n","\n","Train R2 linear regression CMI best 5:  0.224\n","Test R2 linear regression CMI best 5:  0.244 \n","\n","Train R2 linear regression wrapper:  0.23\n","Test R2 linear regression wrapper:  0.271 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.69\n","Test accuracy logistic regression CMI:  0.732 \n","\n","Train accuracy logistic regression CMI best 5:  0.693\n","Test accuracy logistic regression CMI best 5:  0.737 \n","\n","Train accuracy logistic regression wrapper:  0.695\n","Test accuracy logistic regression wrapper:  0.741 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]},{"output_type":"stream","name":"stdout","text":["####################Garda_Mincio####################\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 3\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 4\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 1\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 2\n","\n","Number of features: 67\n","\n","eps value:  0.0014925373134328358\n","Number of aggregated features: 2\n","\n","\n","\n","selected columns: ['cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_tg_0', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_rr_4w_3', 'cyclostationary_mean_rr_12w_1', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_rr_8w_0'], \n","\n","validation score: 0.1317770861727342, \n","\n","number of selected features: 8\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.2797434528685687, test score: 0.2863727351010156\n","Aggregate regression train score with FS: 0.2473270153864059, test score: 0.26798086454281433\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.2797434528685687, test score: 0.2863727351010156\n","Aggregate regression train score with FS: 0.22811183036762395, test score: 0.21027323651027596\n","----- MI Scores -----\n","[(21, 0.1148479296024176), (20, 0.1011018527501808), (22, 0.0910264749950588), (18, 0.08909215645786786), (5, 0.08796405313728445), (1, 0.08095250904817593), (16, 0.07737948936567525), (3, 0.07566615121465854), (0, 0.07066918822351013), (27, 0.07054479963457394), (23, 0.06748044644797903), (19, 0.06223232207656461), (25, 0.06196692927084208), (17, 0.059339125603890173), (13, 0.05582831070265135), (29, 0.0501804280925649), (24, 0.04532013220902157), (14, 0.04440884490232715), (15, 0.034738962582576235), (2, 0.03452763914582542), (8, 0.03405575833416289), (10, 0.032139322849033), (4, 0.030194068525732056), (12, 0.027461248315045785), (6, 0.026447124582110456), (9, 0.023972156183772624), (11, 0.022977759908177273), (7, 0.015540179879147315), (26, 0.011662453015030966), (28, 0.010951567631488732)]\n","Best MI score: 0.1148479296024176\n","Adding first best original feature: 21\n","CMI: 0.04881430327002256\n","CMI: 0.05712392627943097\n","CMI: 0.034810295785434875\n","CMI: 0.025548983302217693\n","CMI: 0.022067285605645443\n","CMI: 0.0028475758808122614\n","CMI: 0.013630466639944133\n","CMI: 0.005015217372760575\n","CMI: 0.0030516518620510164\n","CMI: 0.008289840545862029\n","CMI: 0.004924319262577567\n","CMI: 0.0019040357487106613\n","CMI: 0.013565666918247538\n","CMI: 0.004345033988144342\n","CMI: 0.02024162888294062\n","Highest CMI score: 0.05712392627943097\n","Adding original feature: 1\n","CMI: 0.008050507017215353\n","CMI: 0.005504598328577109\n","CMI: 0.021359718038998637\n","CMI: 0.002768534410179019\n","CMI: 0.005823069813941262\n","Highest CMI score: 0.021359718038998637\n","Adding original feature: 20\n","Highest CMI score: -0.00029927942257809703\n","\n","[21, 1, 20]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.2797434528685687, test score: 0.2863727351010156\n","Aggregate regression train score with FS: 0.18416277048738983, test score: 0.1713073084951655\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.2797434528685687, test score: 0.2863727351010156\n","Aggregate regression train score with FS: 0.18416277048738983, test score: 0.1713073084951655\n","###### Regression ######\n","Train R2 linear regression CMI:  0.184\n","Test R2 linear regression CMI:  0.171 \n","\n","Train R2 linear regression CMI best 5:  0.184\n","Test R2 linear regression CMI best 5:  0.171 \n","\n","Train R2 linear regression wrapper:  0.228\n","Test R2 linear regression wrapper:  0.21 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.704\n","Test accuracy logistic regression CMI:  0.689 \n","\n","Train accuracy logistic regression CMI best 5:  0.704\n","Test accuracy logistic regression CMI best 5:  0.689 \n","\n","Train accuracy logistic regression wrapper:  0.718\n","Test accuracy logistic regression wrapper:  0.697 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]},{"output_type":"stream","name":"stdout","text":["####################Dora####################\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 2\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 2\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 3\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 2\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.002272727272727273\n","Number of aggregated features: 1\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_rr_4w_0'], \n","\n","validation score: 0.12120362672359752, \n","\n","number of selected features: 8\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.14678310298801633, test score: -0.1938471538769242\n","Aggregate regression train score with FS: 0.12489216974154005, test score: -0.08503641637940706\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.14678310298801633, test score: -0.1938471538769242\n","Aggregate regression train score with FS: 0.10771937954605626, test score: -0.07008057178805926\n","----- MI Scores -----\n","[(0, 0.08453408389133756), (1, 0.08118375796210422), (4, 0.07326494853182239), (15, 0.06403914196637761), (2, 0.06260796159248551), (3, 0.062222355402884434), (17, 0.06171626575698934), (14, 0.060226353869968996), (7, 0.052316008063649506), (16, 0.04963889533470378), (5, 0.04937308101325847), (13, 0.04686527556655052), (10, 0.04038635522454774), (18, 0.03973911161712182), (6, 0.03761066783380293), (9, 0.037592468805947486), (8, 0.02862779243714999), (12, 0.026156781831893537), (11, 0.010491028158308404)]\n","Best MI score: 0.08453408389133756\n","Adding first best original feature: 0\n","CMI: 0.011123716709787818\n","CMI: 0.011013211993287225\n","CMI: 0.022577859531900835\n","CMI: 0.006776476545002574\n","CMI: 0.03773276169721293\n","CMI: 0.030463545216343826\n","CMI: 0.028960574626357594\n","CMI: 0.027024209167730545\n","CMI: 0.01519598536058843\n","CMI: 0.015988084724912643\n","CMI: 0.014502255430890898\n","CMI: 0.00475064660000063\n","CMI: 0.03671947062895098\n","CMI: 0.021757771973288986\n","CMI: 0.0067597167286714555\n","CMI: 0.011118141841177431\n","Highest CMI score: 0.03773276169721293\n","Adding original feature: 6\n","CMI: 0.0006367344860839647\n","CMI: 0.0063547674591361986\n","CMI: 0.02333013204262667\n","CMI: 0.0009687274690112352\n","CMI: 0.001549413733238747\n","CMI: 0.004951479356927871\n","CMI: 0.016824291867699723\n","CMI: 0.006126325533113\n","CMI: 0.00687791317164331\n","CMI: 0.0010977576706184822\n","CMI: 0.022569951964926213\n","Highest CMI score: 0.02333013204262667\n","Adding original feature: 7\n","CMI: 0.008383780320911582\n","CMI: 0.014440287706121185\n","CMI: 0.007516261650215683\n","CMI: 0.027614228553911102\n","CMI: 0.020068383685182795\n","CMI: 0.015529544380588095\n","Highest CMI score: 0.027614228553911102\n","Adding original feature: 16\n","CMI: 0.013716784910567659\n","CMI: 0.020118162609674556\n","CMI: 0.009551442217557188\n","CMI: 0.024922513708586863\n","CMI: 0.0017607782627851176\n","Highest CMI score: 0.024922513708586863\n","Adding original feature: 11\n","CMI: 0.005147784801502242\n","CMI: 0.0016745232069328986\n","CMI: 0.0065818574687569464\n","Highest CMI score: 0.0065818574687569464\n","Adding original feature: 9\n","CMI: 0.005275055322523509\n","CMI: 0.0007145875212098973\n","Highest CMI score: 0.005275055322523509\n","Adding original feature: 5\n","CMI: 0.002990526265643889\n","Highest CMI score: 0.002990526265643889\n","Adding original feature: 15\n","Highest CMI score: -0.004750776056196865\n","\n","[0, 6, 7, 16, 11, 9, 5, 15]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.14678310298801633, test score: -0.1938471538769242\n","Aggregate regression train score with FS: 0.13070755730799333, test score: -0.21336766425932296\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.14678310298801633, test score: -0.1938471538769242\n","Aggregate regression train score with FS: 0.12958452812394095, test score: -0.20039422688158504\n","###### Regression ######\n","Train R2 linear regression CMI:  0.131\n","Test R2 linear regression CMI:  -0.213 \n","\n","Train R2 linear regression CMI best 5:  0.13\n","Test R2 linear regression CMI best 5:  -0.2 \n","\n","Train R2 linear regression wrapper:  0.108\n","Test R2 linear regression wrapper:  -0.07 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.623\n","Test accuracy logistic regression CMI:  0.526 \n","\n","Train accuracy logistic regression CMI best 5:  0.603\n","Test accuracy logistic regression CMI best 5:  0.535 \n","\n","Train accuracy logistic regression wrapper:  0.593\n","Test accuracy logistic regression wrapper:  0.618 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]},{"output_type":"stream","name":"stdout","text":["####################Piemonte_Nord####################\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 7\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 5\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 5\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 5\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 1\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 1\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 1\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 2\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 3\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 4\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 5\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 3\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 1\n","\n","Number of features: 89\n","\n","eps value:  0.0011235955056179776\n","Number of aggregated features: 1\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_rr_4w_2', 'cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_rr_1w_2', 'cyclostationary_mean_rr_8w_2', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_rr_4w_3', 'cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_tg_8w_2', 'cyclostationary_mean_tg_8w_4', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_rr_8w_1', 'cyclostationary_mean_tg_4w_0'], \n","\n","validation score: 0.2883522364603879, \n","\n","number of selected features: 15\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.29218662473613766, test score: 0.004381126753915443\n","Aggregate regression train score with FS: 0.24051487453681708, test score: 0.003940171210031207\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.29218662473613766, test score: 0.004381126753915443\n","Aggregate regression train score with FS: 0.21441452502742198, test score: 0.042540144313780615\n","----- MI Scores -----\n","[(1, 0.12168700068472976), (0, 0.11626069499645725), (8, 0.1005417588066719), (9, 0.09546790395368582), (3, 0.09211493977806924), (4, 0.09137391410745542), (2, 0.09005082274241014), (6, 0.08989863929473699), (5, 0.08943711464600462), (11, 0.08603117649820118), (7, 0.08288525745001833), (30, 0.08244737877521952), (10, 0.08122444633504078), (31, 0.07803424702179484), (39, 0.062481518299434456), (28, 0.059656786327277604), (42, 0.05948643955324653), (15, 0.053451244777303446), (33, 0.05290722728042428), (19, 0.051533677931395405), (27, 0.04507166558778964), (41, 0.04452621314478553), (43, 0.0436171911659015), (21, 0.042931264791180306), (26, 0.04143700164301293), (37, 0.0405172143529542), (23, 0.03918432776370937), (29, 0.03769146161192057), (18, 0.037652390744019965), (38, 0.03654151368993407), (34, 0.03347223195293793), (24, 0.03241132199864097), (13, 0.031943887434652506), (17, 0.03182164040222668), (32, 0.030912845299651322), (25, 0.0306638078976564), (14, 0.02968470994868425), (16, 0.02906102085973071), (12, 0.029040460606773164), (20, 0.0261493038636724), (22, 0.021472580302876094), (35, 0.0203586677355634), (36, 0.01953403816877617), (40, 0.01804561110678342)]\n","Best MI score: 0.12168700068472976\n","Adding first best original feature: 1\n","CMI: 0.0028476621683102415\n","CMI: 0.0013335251111324803\n","CMI: 0.012578186981338335\n","CMI: 0.01443087302299692\n","CMI: 0.015467181802399255\n","CMI: 0.009952561966955209\n","CMI: 0.008054528347442691\n","CMI: 0.005531330012905317\n","CMI: 0.0053895402577660845\n","CMI: 0.01777302058340835\n","CMI: 0.004092677877480383\n","CMI: 0.01273225685490248\n","CMI: 0.02021037779197002\n","CMI: 0.010086416198517245\n","CMI: 0.04347759122129549\n","CMI: 0.048625991076134883\n","CMI: 0.021666067789728544\n","CMI: 0.025683992472710637\n","CMI: 0.028465525470484726\n","CMI: 0.051397266033576805\n","CMI: 0.02979318235959602\n","CMI: 0.03860013220335312\n","CMI: 0.024456777984095096\n","CMI: 0.0005312063888386204\n","CMI: 0.0060231888384525145\n","CMI: 0.008396750943837433\n","CMI: 0.01710832387126765\n","CMI: 0.03350051460052181\n","Highest CMI score: 0.051397266033576805\n","Adding original feature: 35\n","CMI: 0.005829637554452344\n","CMI: 0.0019024905639013212\n","Highest CMI score: 0.005829637554452344\n","Adding original feature: 30\n","CMI: 0.0042096524057951\n","CMI: 0.0039640741115035405\n","CMI: 0.0023513170193717736\n","CMI: 0.004050908816763676\n","Highest CMI score: 0.0042096524057951\n","Adding original feature: 5\n","CMI: 0.000542350317623147\n","CMI: 0.00651812172586852\n","Highest CMI score: 0.00651812172586852\n","Adding original feature: 31\n","CMI: 0.001019919499448907\n","CMI: 0.004046432895816909\n","Highest CMI score: 0.004046432895816909\n","Adding original feature: 34\n","CMI: 0.005898687901824934\n","Highest CMI score: 0.005898687901824934\n","Adding original feature: 6\n","Highest CMI score: -0.001164996989635736\n","\n","[1, 35, 30, 5, 31, 34, 6]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.29218662473613766, test score: 0.004381126753915443\n","Aggregate regression train score with FS: 0.1974967134898694, test score: 0.03978603342535758\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.29218662473613766, test score: 0.004381126753915443\n","Aggregate regression train score with FS: 0.195542991329828, test score: 0.06294698049742187\n","###### Regression ######\n","Train R2 linear regression CMI:  0.197\n","Test R2 linear regression CMI:  0.04 \n","\n","Train R2 linear regression CMI best 5:  0.196\n","Test R2 linear regression CMI best 5:  0.063 \n","\n","Train R2 linear regression wrapper:  0.214\n","Test R2 linear regression wrapper:  0.043 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.656\n","Test accuracy logistic regression CMI:  0.658 \n","\n","Train accuracy logistic regression CMI best 5:  0.662\n","Test accuracy logistic regression CMI best 5:  0.649 \n","\n","Train accuracy logistic regression wrapper:  0.667\n","Test accuracy logistic regression wrapper:  0.632 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]},{"output_type":"stream","name":"stdout","text":["####################Piemonte_Sud####################\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 2\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 4\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 2\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 3\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 3\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 3\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 2\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 3\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 7\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 2\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 2\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 2\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 3\n","\n","Number of features: 176\n","\n","eps value:  0.0005681818181818183\n","Number of aggregated features: 1\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_rr_1w_5', 'cyclostationary_mean_rr_16w_2', 'cyclostationary_mean_rr_16w_1', 'cyclostationary_mean_rr_8w_1', 'cyclostationary_mean_rr_0', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_tg_12w_0', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_tg_8w_2', 'cyclostationary_mean_tg_24w_1', 'cyclostationary_mean_tg_0', 'cyclostationary_mean_tg_24w_0'], \n","\n","validation score: 0.24360846531148939, \n","\n","number of selected features: 14\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.30063485943263435, test score: 0.19055427070527486\n","Aggregate regression train score with FS: 0.2549447820520788, test score: 0.2241156509245742\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.30063485943263435, test score: 0.19055427070527486\n","Aggregate regression train score with FS: 0.1801338355929204, test score: 0.1513702327619374\n","----- MI Scores -----\n","[(0, 0.11155358385190194), (1, 0.10181166733611813), (2, 0.09429641776714849), (31, 0.09253244647782162), (36, 0.09189326831703377), (3, 0.09077352977155391), (32, 0.08495304844794264), (34, 0.08198747090890705), (30, 0.08031486402144337), (29, 0.07946979469426162), (37, 0.07423403064202792), (38, 0.07167644132237468), (6, 0.06614999075836864), (4, 0.06577690590623299), (35, 0.0621984800701941), (22, 0.061410005665077066), (28, 0.06065550764201256), (26, 0.058028716616498534), (33, 0.056333899774922966), (27, 0.05078561883797493), (25, 0.05005300142915629), (5, 0.04395746851782731), (20, 0.04362969112580873), (7, 0.03355803544339865), (10, 0.033446378126184124), (12, 0.033381094504619305), (8, 0.032174055249928495), (13, 0.031022381894772185), (24, 0.03036897890814173), (9, 0.029216106747555988), (23, 0.0207040434871752), (17, 0.020340266808960217), (14, 0.014066504675564901), (11, 0.009340728736020057), (21, 0.0057171752537354395), (19, 0.003807000326932713), (16, 0.001198243294508687), (15, -0.0008609982739281993), (18, -0.006047268830530692)]\n","Best MI score: 0.11155358385190194\n","Adding first best original feature: 0\n","CMI: 0.007234109617527976\n","CMI: 0.0017847858924012333\n","CMI: 0.033451181958902496\n","CMI: 0.03686972092837558\n","CMI: 0.05162093053574572\n","CMI: 0.04744772292710246\n","CMI: 0.03367283670414921\n","CMI: 0.030950893940668647\n","CMI: 0.03164731978624262\n","CMI: 0.05503101914226981\n","CMI: 0.031194053712002137\n","CMI: 0.0691836240314214\n","Highest CMI score: 0.0691836240314214\n","Adding original feature: 38\n","CMI: 0.007769326975443108\n","CMI: 0.007238466008526845\n","CMI: 0.009586416555052213\n","CMI: 0.019548889682914877\n","CMI: 0.0063551270431285445\n","CMI: 0.0024453209127225095\n","CMI: 0.008607672906558977\n","CMI: 0.002513469222008291\n","Highest CMI score: 0.019548889682914877\n","Adding original feature: 32\n","CMI: 0.009754762691956909\n","CMI: 0.003091390513770498\n","CMI: 0.004461263060495324\n","CMI: 0.013020808575152004\n","CMI: 0.014842734211278075\n","CMI: 0.006730427030519348\n","CMI: 0.016000312203048456\n","CMI: 0.007559108338042714\n","Highest CMI score: 0.016000312203048456\n","Adding original feature: 36\n","CMI: 0.0027274929665901115\n","CMI: 0.006379433612723057\n","CMI: 0.004826986560800217\n","CMI: 0.0011271994760937154\n","CMI: 0.005254518044685602\n","CMI: 0.0005726973036065675\n","CMI: 0.0038132766480993008\n","CMI: 0.004914192557280428\n","CMI: 0.002272791385224321\n","CMI: 0.0007170545616446977\n","Highest CMI score: 0.006379433612723057\n","Adding original feature: 2\n","CMI: 0.003911278921154893\n","Highest CMI score: 0.003911278921154893\n","Adding original feature: 34\n","CMI: 0.002313735253566346\n","CMI: 0.0008412439636388547\n","CMI: 0.005660291400105294\n","CMI: 0.0014950628970282487\n","Highest CMI score: 0.005660291400105294\n","Adding original feature: 9\n","CMI: 0.0008451811244725993\n","CMI: 0.0001694076775520248\n","Highest CMI score: 0.0008451811244725993\n","Adding original feature: 7\n","Highest CMI score: -0.0002564523992879819\n","\n","[0, 38, 32, 36, 2, 34, 9, 7]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.30063485943263435, test score: 0.19055427070527486\n","Aggregate regression train score with FS: 0.17132631730040815, test score: 0.1541671188498166\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.30063485943263435, test score: 0.19055427070527486\n","Aggregate regression train score with FS: 0.1460945522676872, test score: 0.12281091488518436\n","###### Regression ######\n","Train R2 linear regression CMI:  0.171\n","Test R2 linear regression CMI:  0.154 \n","\n","Train R2 linear regression CMI best 5:  0.146\n","Test R2 linear regression CMI best 5:  0.123 \n","\n","Train R2 linear regression wrapper:  0.18\n","Test R2 linear regression wrapper:  0.151 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.665\n","Test accuracy logistic regression CMI:  0.667 \n","\n","Train accuracy logistic regression CMI best 5:  0.665\n","Test accuracy logistic regression CMI best 5:  0.649 \n","\n","Train accuracy logistic regression wrapper:  0.649\n","Test accuracy logistic regression wrapper:  0.654 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]}],"source":["basins = ['Emiliani1', 'Emiliani2', 'Garda_Mincio', 'Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n","\n","path_target = \"./csv/\"\n","path_features = './features_allvalues/'\n","destination_folder = './NonLinCFA/temp_prec_internal_ordering/dyn_eps_lin/' # eps = fixed_value/#basin_coord\n","plots_folder = './NonLinCFA/for_plots/internal_ordering/'\n","\n","for basin in basins:\n","  print('####################' + basin + '####################')\n","  target_df_train, target_df_val, target_df_test, target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01',\n","      path=path_target+basin+'.csv', window_size = 1)\n","  eps = 0.1\n","  actual_path = path_features+basin+'_aggreg.csv'\n","  output, aggregate_trainVal, aggregate_test = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg',\n","                                                                            'cyclostationary_mean_tg_1w',\n","                                                                            'cyclostationary_mean_tg_4w',\n","                                                                            'cyclostationary_mean_tg_8w',\n","                                                                            'cyclostationary_mean_tg_12w',\n","                                                                            'cyclostationary_mean_tg_16w',\n","                                                                            'cyclostationary_mean_tg_24w',\n","                                                                            'cyclostationary_mean_rr',\n","                                                                            'cyclostationary_mean_rr_1w',\n","                                                                            'cyclostationary_mean_rr_4w',\n","                                                                            'cyclostationary_mean_rr_8w',\n","                                                                            'cyclostationary_mean_rr_12w',\n","                                                                            'cyclostationary_mean_rr_16w',\n","                                                                            'cyclostationary_mean_rr_24w'\n","                                                                            ],\n","                                                                      target_df_trainVal, eps=eps,\n","                                                                      max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n","\n","  #agg_trainVal_string = plots_folder + basin + \"_trainVal_aggreg\"\n","  #agg_test_string = plots_folder + basin + \"_test_aggreg\"\n","  #aggregate_trainVal.to_csv(agg_trainVal_string, index = False)\n","  #aggregate_test.to_csv(agg_test_string, index = False)\n","\n","  selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, min(50,aggregate_trainVal.shape[1]-1), 228)\n","\n","  print('\\nFull model and selected features with wrapper\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","  print('\\nFull model and best 5 selected features with wrapper\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","  train_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_train.csv'\n","  val_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_val.csv'\n","  test_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_test.csv'\n","  X_train_wrapper = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","  X_validation_wrapper = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","  X_train_validation_wrapper = pd.concat([X_train_wrapper, X_validation_wrapper])\n","  X_test_wrapper = aggregate_test.loc[:,selected_colnames[0:5]]\n","  X_train_wrapper.to_csv(train_string, index=False)\n","  X_validation_wrapper.to_csv(val_string, index=False)\n","  X_test_wrapper.to_csv(test_string, index=False)\n","\n","  res = {\n","          \"delta\" : [],\n","          \"numSelected\" : [],\n","          \"selectedFeatures\" : []\n","      }\n","\n","  res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),\n","                                                    np.array(target_df_trainVal.mean_std),res,10,1)\n","\n","  selectedFeatures='selectedFeatures'\n","  print(f'\\n{res[selectedFeatures]}\\n')\n","\n","  selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n","\n","  print('\\nFull model and selected features with CMI\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","  print('\\nFull model and best 5 selected features with CMI\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","  train_string = destination_folder + basin + '_nonLinCFA_best5_CMI_train.csv'\n","  val_string = destination_folder + basin + '_nonLinCFA_best5_CMI_val.csv'\n","  test_string = destination_folder + basin + '_nonLinCFA_best5_CMI_test.csv'\n","\n","  X_train_CMI5 = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","  X_validation_CMI5 = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","  X_train_validation_CMI5 = pd.concat([X_train_CMI5, X_validation_CMI5])\n","  X_test_CMI5 = aggregate_test.loc[:,selected_colnames[0:5]]\n","\n","  selected_colnames_CMI5 = aggregate_trainVal.loc[:,selected_colnames[0:5]].columns.values\n","\n","  X_train_CMI5.to_csv(train_string, index=False)\n","  X_validation_CMI5.to_csv(val_string, index=False)\n","  X_test_CMI5.to_csv(test_string, index=False)\n","\n","  train_string = destination_folder + basin + '_nonLinCFA_CMI_train.csv'\n","  val_string = destination_folder + basin + '_nonLinCFA_CMI_val.csv'\n","  test_string = destination_folder + basin + '_nonLinCFA_CMI_test.csv'\n","\n","  X_train_CMI = aggregate_trainVal.loc[:410,selected_colnames]\n","  X_validation_CMI = aggregate_trainVal.loc[411:,selected_colnames]\n","  X_train_validation_CMI = pd.concat([X_train_CMI, X_validation_CMI])\n","  X_test_CMI = aggregate_test.loc[:,selected_colnames]\n","\n","  X_train_CMI.to_csv(train_string, index=False)\n","  X_validation_CMI.to_csv(val_string, index=False)\n","  X_test_CMI.to_csv(test_string, index=False)\n","\n","  print('###### Regression ######')\n","  lin_regr = LinearRegression()\n","\n","  # CMI\n","  lin_regr.fit(X_train_validation_CMI, target_df_trainVal.mean_std)\n","  print(\"Train R2 linear regression CMI: \", round(lin_regr.score(X_train_validation_CMI, target_df_trainVal.mean_std),3))\n","  print(\"Test R2 linear regression CMI: \", round(lin_regr.score(X_test_CMI, target_df_test.mean_std),3), \"\\n\")\n","\n","  # CMI best 5\n","  lin_regr.fit(X_train_validation_CMI5, target_df_trainVal.mean_std)\n","  print(\"Train R2 linear regression CMI best 5: \", round(lin_regr.score(X_train_validation_CMI5, target_df_trainVal.mean_std),3))\n","  print(\"Test R2 linear regression CMI best 5: \", round(lin_regr.score(X_test_CMI5, target_df_test.mean_std),3), \"\\n\")\n","\n","  # wrapper\n","  lin_regr.fit(X_train_validation_wrapper, target_df_trainVal.mean_std)\n","  print(\"Train R2 linear regression wrapper: \", round(lin_regr.score(X_train_validation_wrapper, target_df_trainVal.mean_std),3))\n","  print(\"Test R2 linear regression wrapper: \", round(lin_regr.score(X_test_wrapper, target_df_test.mean_std),3), \"\\n\")\n","\n","  print('###### Binary Classification ######')\n","\n","  target_df_train = target_df_train.apply(lambda x: np.sign(x.mean_std), axis=1)\n","  target_df_val = target_df_val.apply(lambda x: np.sign(x.mean_std), axis=1)\n","  target_df_test = target_df_test.apply(lambda x: np.sign(x.mean_std), axis=1)\n","  target_df_trainVal = target_df_trainVal.apply(lambda x: np.sign(x.mean_std), axis=1)\n","\n","  log_regr = LogisticRegression(solver='lbfgs', random_state = 42)\n","\n","  # CMI\n","  log_regr.fit(X_train_validation_CMI, target_df_trainVal)\n","  print(\"Train accuracy logistic regression CMI: \", round(log_regr.score(X_train_validation_CMI, target_df_trainVal),3))\n","  print(\"Test accuracy logistic regression CMI: \", round(log_regr.score(X_test_CMI, target_df_test),3), \"\\n\")\n","\n","  # CMI best 5\n","  log_regr.fit(X_train_validation_CMI5, target_df_trainVal)\n","  print(\"Train accuracy logistic regression CMI best 5: \", round(log_regr.score(X_train_validation_CMI5, target_df_trainVal),3))\n","  print(\"Test accuracy logistic regression CMI best 5: \", round(log_regr.score(X_test_CMI5, target_df_test),3), \"\\n\")\n","\n","  # wrapper\n","  log_regr.fit(X_train_validation_wrapper, target_df_trainVal)\n","  print(\"Train accuracy logistic regression wrapper: \", round(log_regr.score(X_train_validation_wrapper, target_df_trainVal),3))\n","  print(\"Test accuracy logistic regression wrapper: \", round(log_regr.score(X_test_wrapper, target_df_test),3), \"\\n\")\n","\n","  output_string = plots_folder + basin + '_aggregations.npy'\n","  sel_col_string = plots_folder + basin + '_chosen_features.npy'\n","  np.save(sel_col_string, selected_colnames_CMI5)\n","  np.save(output_string, output)"],"id":"Dd_c8fjYuJ9h"},{"cell_type":"code","source":["basins = ['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino']\n","\n","path_target = \"./csv/\"\n","path_features = './features_allvalues/'\n","destination_folder = './NonLinCFA/temp_prec_internal_ordering/dyn_eps_lin/' # eps = fixed_value/#basin_coord\n","plots_folder = './NonLinCFA/for_plots/internal_ordering/'\n","\n","for basin in basins:\n","  selected_colnames_CMI5 = []\n","  print('####################' + basin + '####################')\n","  target_df_train, target_df_val, target_df_test, target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01',\n","      path=path_target+basin+'.csv', window_size = 1)\n","  eps = 0.01\n","  actual_path = path_features+basin+'_aggreg.csv'\n","  output, aggregate_trainVal, aggregate_test = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg',\n","                                                                            'cyclostationary_mean_tg_1w',\n","                                                                            'cyclostationary_mean_tg_4w',\n","                                                                            'cyclostationary_mean_tg_8w',\n","                                                                            'cyclostationary_mean_tg_12w',\n","                                                                            'cyclostationary_mean_tg_16w',\n","                                                                            'cyclostationary_mean_tg_24w',\n","                                                                            'cyclostationary_mean_rr',\n","                                                                            'cyclostationary_mean_rr_1w',\n","                                                                            'cyclostationary_mean_rr_4w',\n","                                                                            'cyclostationary_mean_rr_8w',\n","                                                                            'cyclostationary_mean_rr_12w',\n","                                                                            'cyclostationary_mean_rr_16w',\n","                                                                            'cyclostationary_mean_rr_24w'\n","                                                                            ],\n","                                                                      target_df_trainVal, eps=eps,\n","                                                                      max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n","\n","  #agg_trainVal_string = plots_folder + basin + \"_trainVal_aggreg\"\n","  #agg_test_string = plots_folder + basin + \"_test_aggreg\"\n","  #aggregate_trainVal.to_csv(agg_trainVal_string, index = False)\n","  #aggregate_test.to_csv(agg_test_string, index = False)\n","  selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, min(50,aggregate_trainVal.shape[1]-1), 228)\n","\n","  print('\\nFull model and selected features with wrapper\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","  print('\\nFull model and best 5 selected features with wrapper\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","  train_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_train.csv'\n","  val_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_val.csv'\n","  test_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_test.csv'\n","  X_train_wrapper = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","  X_validation_wrapper = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","  X_train_validation_wrapper = pd.concat([X_train_wrapper, X_validation_wrapper])\n","  X_test_wrapper = aggregate_test.loc[:,selected_colnames[0:5]]\n","  X_train_wrapper.to_csv(train_string, index=False)\n","  X_validation_wrapper.to_csv(val_string, index=False)\n","  X_test_wrapper.to_csv(test_string, index=False)\n","\n","  res = {\n","          \"delta\" : [],\n","          \"numSelected\" : [],\n","          \"selectedFeatures\" : []\n","      }\n","\n","  res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),\n","                                                    np.array(target_df_trainVal.mean_std),res,10,1)\n","\n","  selectedFeatures='selectedFeatures'\n","  print(f'\\n{res[selectedFeatures]}\\n')\n","\n","  selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n","\n","  print('\\nFull model and selected features with CMI\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","  print('\\nFull model and best 5 selected features with CMI\\n')\n","  compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","  train_string = destination_folder + basin + '_nonLinCFA_best5_CMI_train.csv'\n","  val_string = destination_folder + basin + '_nonLinCFA_best5_CMI_val.csv'\n","  test_string = destination_folder + basin + '_nonLinCFA_best5_CMI_test.csv'\n","\n","  X_train_CMI5 = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","  X_validation_CMI5 = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","  X_train_validation_CMI5 = pd.concat([X_train_CMI5, X_validation_CMI5])\n","  X_test_CMI5 = aggregate_test.loc[:,selected_colnames[0:5]]\n","\n","  selected_colnames_CMI5.append(aggregate_trainVal.loc[:,selected_colnames[0:5]].columns.values)\n","\n","  X_train_CMI5.to_csv(train_string, index=False)\n","  X_validation_CMI5.to_csv(val_string, index=False)\n","  X_test_CMI5.to_csv(test_string, index=False)\n","\n","  train_string = destination_folder + basin + '_nonLinCFA_CMI_train.csv'\n","  val_string = destination_folder + basin + '_nonLinCFA_CMI_val.csv'\n","  test_string = destination_folder + basin + '_nonLinCFA_CMI_test.csv'\n","\n","  X_train_CMI = aggregate_trainVal.loc[:410,selected_colnames]\n","  X_validation_CMI = aggregate_trainVal.loc[411:,selected_colnames]\n","  X_train_validation_CMI = pd.concat([X_train_CMI, X_validation_CMI])\n","  X_test_CMI = aggregate_test.loc[:,selected_colnames]\n","\n","  X_train_CMI.to_csv(train_string, index=False)\n","  X_validation_CMI.to_csv(val_string, index=False)\n","  X_test_CMI.to_csv(test_string, index=False)\n","\n","  print('###### Regression ######')\n","  lin_regr = LinearRegression()\n","\n","  # CMI\n","  lin_regr.fit(X_train_validation_CMI, target_df_trainVal.mean_std)\n","  print(\"Train R2 linear regression CMI: \", round(lin_regr.score(X_train_validation_CMI, target_df_trainVal.mean_std),3))\n","  print(\"Test R2 linear regression CMI: \", round(lin_regr.score(X_test_CMI, target_df_test.mean_std),3), \"\\n\")\n","\n","  # CMI best 5\n","  lin_regr.fit(X_train_validation_CMI5, target_df_trainVal.mean_std)\n","  print(\"Train R2 linear regression CMI best 5: \", round(lin_regr.score(X_train_validation_CMI5, target_df_trainVal.mean_std),3))\n","  print(\"Test R2 linear regression CMI best 5: \", round(lin_regr.score(X_test_CMI5, target_df_test.mean_std),3), \"\\n\")\n","\n","  # wrapper\n","  lin_regr.fit(X_train_validation_wrapper, target_df_trainVal.mean_std)\n","  print(\"Train R2 linear regression wrapper: \", round(lin_regr.score(X_train_validation_wrapper, target_df_trainVal.mean_std),3))\n","  print(\"Test R2 linear regression wrapper: \", round(lin_regr.score(X_test_wrapper, target_df_test.mean_std),3), \"\\n\")\n","\n","  print('###### Binary Classification ######')\n","\n","  target_df_train = target_df_train.apply(lambda x: np.sign(x.mean_std), axis=1)\n","  target_df_val = target_df_val.apply(lambda x: np.sign(x.mean_std), axis=1)\n","  target_df_test = target_df_test.apply(lambda x: np.sign(x.mean_std), axis=1)\n","  target_df_trainVal = target_df_trainVal.apply(lambda x: np.sign(x.mean_std), axis=1)\n","\n","  log_regr = LogisticRegression(solver='lbfgs', random_state = 42)\n","\n","  # CMI\n","  log_regr.fit(X_train_validation_CMI, target_df_trainVal)\n","  print(\"Train accuracy logistic regression CMI: \", round(log_regr.score(X_train_validation_CMI, target_df_trainVal),3))\n","  print(\"Test accuracy logistic regression CMI: \", round(log_regr.score(X_test_CMI, target_df_test),3), \"\\n\")\n","\n","  # CMI best 5\n","  log_regr.fit(X_train_validation_CMI5, target_df_trainVal)\n","  print(\"Train accuracy logistic regression CMI best 5: \", round(log_regr.score(X_train_validation_CMI5, target_df_trainVal),3))\n","  print(\"Test accuracy logistic regression CMI best 5: \", round(log_regr.score(X_test_CMI5, target_df_test),3), \"\\n\")\n","\n","  # wrapper\n","  log_regr.fit(X_train_validation_wrapper, target_df_trainVal)\n","  print(\"Train accuracy logistic regression wrapper: \", round(log_regr.score(X_train_validation_wrapper, target_df_trainVal),3))\n","  print(\"Test accuracy logistic regression wrapper: \", round(log_regr.score(X_test_wrapper, target_df_test),3), \"\\n\")\n","\n","  output_string = plots_folder + basin + '_aggregations.npy'\n","  sel_col_string = plots_folder + basin + '_chosen_features.npy'\n","  np.save(sel_col_string, selected_colnames_CMI5)\n","  np.save(output_string, output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"myakMwWB4lj0","executionInfo":{"status":"ok","timestamp":1690204689997,"user_tz":-120,"elapsed":389614,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"9cbe85cb-40ec-4f95-f0cc-9cf5aadc8d23"},"id":"myakMwWB4lj0","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["####################Adda####################\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 4\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 5\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 4\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 3\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_tg_1w_4', 'cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_tg_24w_1', 'cyclostationary_mean_tg_4w_0'], \n","\n","validation score: 0.28569722616248694, \n","\n","number of selected features: 10\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.25045526999031575, test score: -0.22655960780677287\n","Aggregate regression train score with FS: 0.19518265250932498, test score: 0.09703508322616006\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.25045526999031575, test score: -0.22655960780677287\n","Aggregate regression train score with FS: 0.19217163500084344, test score: 0.0905659481466351\n","----- MI Scores -----\n","[(3, 0.12050703744657751), (2, 0.10817618197950427), (1, 0.10458666651828148), (6, 0.10000614962421837), (8, 0.09759609497149417), (5, 0.0958421245778713), (0, 0.09503214284536106), (4, 0.09477576732312769), (23, 0.07967156830045484), (7, 0.0687728511603872), (25, 0.05155755293289637), (29, 0.047334700475274924), (11, 0.045062184539707034), (12, 0.04490981082569118), (10, 0.034333966317883206), (14, 0.03431807492831074), (26, 0.03414181201005571), (13, 0.03279033144606338), (24, 0.0317000457510685), (20, 0.03044594915922083), (16, 0.029624969112521), (18, 0.02694337568051), (27, 0.0267973393965517), (15, 0.02266872778585513), (9, 0.02222559539519485), (17, 0.0207126706203192), (28, 0.01541299283864724), (21, 0.007419677971127319), (30, 0.0017077463269159448), (19, 0.00010044357455795209), (22, -0.0008309994106552068)]\n","Best MI score: 0.12050703744657751\n","Adding first best original feature: 3\n","CMI: 0.011988055394801994\n","CMI: 0.0037080553595621457\n","CMI: 0.016511440210771083\n","CMI: 0.01287806045105161\n","CMI: 0.0030869257926980503\n","CMI: 0.024203701243435266\n","CMI: 0.00643362640081066\n","Highest CMI score: 0.024203701243435266\n","Adding original feature: 26\n","CMI: 0.0015819581322940868\n","CMI: 0.01294950332127881\n","CMI: 0.00490846781138915\n","CMI: 0.0042710205129000145\n","CMI: 0.003169195958733634\n","CMI: 0.007733812114259442\n","CMI: 0.0005951123119307677\n","CMI: 0.0022363373854550617\n","CMI: 0.006784315477551511\n","CMI: 0.02135706382981209\n","CMI: 0.01605695422683559\n","Highest CMI score: 0.02135706382981209\n","Adding original feature: 23\n","Highest CMI score: -0.0007255027847322681\n","\n","[3, 26, 23]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.25045526999031575, test score: -0.22655960780677287\n","Aggregate regression train score with FS: 0.1544424050246367, test score: 0.09761785079534935\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.25045526999031575, test score: -0.22655960780677287\n","Aggregate regression train score with FS: 0.1544424050246367, test score: 0.09761785079534935\n","###### Regression ######\n","Train R2 linear regression CMI:  0.154\n","Test R2 linear regression CMI:  0.098 \n","\n","Train R2 linear regression CMI best 5:  0.154\n","Test R2 linear regression CMI best 5:  0.098 \n","\n","Train R2 linear regression wrapper:  0.192\n","Test R2 linear regression wrapper:  0.091 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.62\n","Test accuracy logistic regression CMI:  0.61 \n","\n","Train accuracy logistic regression CMI best 5:  0.62\n","Test accuracy logistic regression CMI best 5:  0.61 \n","\n","Train accuracy logistic regression wrapper:  0.649\n","Test accuracy logistic regression wrapper:  0.649 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]},{"output_type":"stream","name":"stdout","text":["####################Lambro_Olona####################\n","Number of features: 55\n","\n","eps value:  0.00018181818181818183\n","Number of aggregated features: 6\n","\n","Number of features: 55\n","\n","eps value:  0.00018181818181818183\n","Number of aggregated features: 6\n","\n","Number of features: 55\n","\n","eps value:  0.00018181818181818183\n","Number of aggregated features: 5\n","\n","Number of features: 55\n","\n","eps value:  0.00018181818181818183\n","Number of aggregated features: 4\n","\n","Number of features: 55\n","\n","eps value:  0.00018181818181818183\n","Number of aggregated features: 3\n","\n","Number of features: 55\n","\n","eps value:  0.00018181818181818183\n","Number of aggregated features: 3\n","\n","Number of features: 55\n","\n","eps value:  0.00018181818181818183\n","Number of aggregated features: 2\n","\n","Number of features: 55\n","\n","eps value:  0.00018181818181818183\n","Number of aggregated features: 4\n","\n","Number of features: 55\n","\n","eps value:  0.00018181818181818183\n","Number of aggregated features: 2\n","\n","Number of features: 55\n","\n","eps value:  0.00018181818181818183\n","Number of aggregated features: 2\n","\n","Number of features: 55\n","\n","eps value:  0.00018181818181818183\n","Number of aggregated features: 2\n","\n","Number of features: 55\n","\n","eps value:  0.00018181818181818183\n","Number of aggregated features: 3\n","\n","Number of features: 55\n","\n","eps value:  0.00018181818181818183\n","Number of aggregated features: 1\n","\n","Number of features: 55\n","\n","eps value:  0.00018181818181818183\n","Number of aggregated features: 1\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_tg_16w_2', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_tg_8w_2', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_tg_1w_5', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_rr_8w_1'], \n","\n","validation score: 0.3934636017272427, \n","\n","number of selected features: 15\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.34494629998417803, test score: 0.021620181305454067\n","Aggregate regression train score with FS: 0.2776009573821564, test score: 0.10473093591629179\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.34494629998417803, test score: 0.021620181305454067\n","Aggregate regression train score with FS: 0.2546067713439001, test score: 0.19477414670453563\n","----- MI Scores -----\n","[(11, 0.1367449901200517), (4, 0.12447115230519984), (0, 0.11927405522018476), (3, 0.11549821289145816), (7, 0.11467075075808103), (9, 0.11394050689991309), (6, 0.10891760351687875), (1, 0.10685440606162953), (2, 0.09391295918551328), (5, 0.08677358042463004), (8, 0.08554526166045712), (10, 0.07768901614250244), (36, 0.0756486279749692), (37, 0.06828882697894638), (39, 0.06687291998297702), (35, 0.0633971568678264), (15, 0.0629827836064298), (34, 0.05962906372936716), (42, 0.056325474599536816), (13, 0.0534192295401294), (12, 0.05273407466320824), (14, 0.04950329914198172), (33, 0.04731964113863448), (40, 0.04654457625195766), (29, 0.04149390425777942), (31, 0.04075180578705625), (43, 0.03860659087219579), (26, 0.03749788943090603), (32, 0.03682147115684433), (30, 0.03552724402074637), (19, 0.03474581287703576), (20, 0.031078073660024987), (41, 0.031012475355726755), (38, 0.0308411723910602), (16, 0.02972650248772553), (18, 0.026969098647239422), (24, 0.023566982399811514), (21, 0.02131621843639819), (23, 0.021305277572029203), (27, 0.0204074961194126), (28, 0.01836625165285871), (25, 0.017821713310729966), (22, 0.015897936783760953), (17, 0.012817919219027906)]\n","Best MI score: 0.1367449901200517\n","Adding first best original feature: 11\n","CMI: 0.008106261348548832\n","CMI: 0.0036068553991443486\n","CMI: 0.0019000942178920566\n","CMI: 0.007671289635931222\n","CMI: 0.023518193093671064\n","CMI: 0.051280266479590525\n","CMI: 0.007505008312899991\n","CMI: 0.03186328520095033\n","CMI: 0.016205186651222725\n","CMI: 0.002480819587091926\n","CMI: 0.02808588453538624\n","CMI: 0.036707926600840046\n","CMI: 0.025417617385355334\n","CMI: 0.014320124787892352\n","CMI: 0.003557241864538957\n","Highest CMI score: 0.051280266479590525\n","Adding original feature: 34\n","CMI: 0.002049759470506035\n","Highest CMI score: 0.002049759470506035\n","Adding original feature: 3\n","CMI: 0.001355637625356343\n","CMI: 0.0006741616212350976\n","CMI: 0.005855975855873247\n","CMI: 0.004439229922644561\n","CMI: 0.0008202646397110769\n","Highest CMI score: 0.005855975855873247\n","Adding original feature: 38\n","CMI: 0.0018160949251526948\n","CMI: 0.008913715071660527\n","CMI: 0.0012158936540768162\n","CMI: 0.0069796352409075\n","CMI: 0.004081061388579499\n","CMI: 0.012259438765398756\n","CMI: 0.005325583695268088\n","CMI: 0.0077442454879240175\n","CMI: 0.005143486163138894\n","CMI: 0.00825789364276211\n","CMI: 0.0011133483283042866\n","Highest CMI score: 0.012259438765398756\n","Adding original feature: 10\n","CMI: 0.0007570204529801505\n","Highest CMI score: 0.0007570204529801505\n","Adding original feature: 8\n","Highest CMI score: -0.004703245745425327\n","\n","[11, 34, 3, 38, 10, 8]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.34494629998417803, test score: 0.021620181305454067\n","Aggregate regression train score with FS: 0.23340820678798124, test score: 0.25169357528594605\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.34494629998417803, test score: 0.021620181305454067\n","Aggregate regression train score with FS: 0.2311416657195533, test score: 0.2579885937380081\n","###### Regression ######\n","Train R2 linear regression CMI:  0.233\n","Test R2 linear regression CMI:  0.252 \n","\n","Train R2 linear regression CMI best 5:  0.231\n","Test R2 linear regression CMI best 5:  0.258 \n","\n","Train R2 linear regression wrapper:  0.255\n","Test R2 linear regression wrapper:  0.195 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.692\n","Test accuracy logistic regression CMI:  0.702 \n","\n","Train accuracy logistic regression CMI best 5:  0.69\n","Test accuracy logistic regression CMI best 5:  0.702 \n","\n","Train accuracy logistic regression wrapper:  0.664\n","Test accuracy logistic regression wrapper:  0.675 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]},{"output_type":"stream","name":"stdout","text":["####################Oglio_Iseo####################\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 3\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 2\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 3\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 2\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_rr_2', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_rr_1'], \n","\n","validation score: 0.20030589173755142, \n","\n","number of selected features: 7\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.1947850798208165, test score: 0.23110613190394558\n","Aggregate regression train score with FS: 0.17384283559637848, test score: 0.2556355440269167\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.1947850798208165, test score: 0.23110613190394558\n","Aggregate regression train score with FS: 0.16242043376712645, test score: 0.2756897001667614\n","----- MI Scores -----\n","[(1, 0.11076080233409458), (3, 0.08993182369969176), (4, 0.08535352628620278), (0, 0.07386411287408363), (13, 0.06844398820510891), (2, 0.06408261327785464), (15, 0.06299091012845069), (18, 0.05651307447517284), (14, 0.05543184789542872), (6, 0.02979180239377202), (5, 0.026674163534289076), (12, 0.025426898033636097), (16, 0.024975603937788842), (10, 0.01719526554739976), (19, 0.015340572237401038), (17, 0.012741180847832224), (8, 0.00928620532801559), (11, 0.005595837322748134), (7, -0.0008272018359696276), (9, -0.0020231794309610793)]\n","Best MI score: 0.11076080233409458\n","Adding first best original feature: 1\n","CMI: 0.0013076969264405186\n","CMI: 0.004057567563985273\n","CMI: 0.017334319624676464\n","CMI: 0.02335160674909731\n","CMI: 0.0008355480876596488\n","CMI: 0.0068376192263017305\n","CMI: 4.136378956480502e-05\n","Highest CMI score: 0.02335160674909731\n","Adding original feature: 15\n","CMI: 0.00784044434828221\n","Highest CMI score: 0.00784044434828221\n","Adding original feature: 0\n","Highest CMI score: -0.015369096733601179\n","\n","[1, 15, 0]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.1947850798208165, test score: 0.23110613190394558\n","Aggregate regression train score with FS: 0.14395642022556665, test score: 0.19993206756174053\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.1947850798208165, test score: 0.23110613190394558\n","Aggregate regression train score with FS: 0.14395642022556665, test score: 0.19993206756174053\n","###### Regression ######\n","Train R2 linear regression CMI:  0.144\n","Test R2 linear regression CMI:  0.2 \n","\n","Train R2 linear regression CMI best 5:  0.144\n","Test R2 linear regression CMI best 5:  0.2 \n","\n","Train R2 linear regression wrapper:  0.162\n","Test R2 linear regression wrapper:  0.276 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.649\n","Test accuracy logistic regression CMI:  0.649 \n","\n","Train accuracy logistic regression CMI best 5:  0.649\n","Test accuracy logistic regression CMI best 5:  0.649 \n","\n","Train accuracy logistic regression wrapper:  0.646\n","Test accuracy logistic regression wrapper:  0.675 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]},{"output_type":"stream","name":"stdout","text":["####################Ticino####################\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 3\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 4\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 5\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 3\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 3\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_tg_16w_2', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_rr_8w_0'], \n","\n","validation score: 0.30143915753998707, \n","\n","number of selected features: 8\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.2596877558744367, test score: 0.17450862564759906\n","Aggregate regression train score with FS: 0.21512746746837685, test score: 0.21717527670885062\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.2596877558744367, test score: 0.17450862564759906\n","Aggregate regression train score with FS: 0.20713428493289743, test score: 0.21528805474868118\n","----- MI Scores -----\n","[(0, 0.12333236920388603), (3, 0.11043061820217501), (1, 0.09301073215020078), (6, 0.08598787349447463), (7, 0.08117728514132373), (2, 0.0792921840495771), (4, 0.07414296454034455), (5, 0.07273765839428532), (25, 0.06849890021359188), (26, 0.06842462865595438), (11, 0.06443446394377765), (24, 0.061138128729906156), (8, 0.05234511965473389), (20, 0.049513412252677226), (27, 0.04938930727611444), (9, 0.04826659946172222), (21, 0.04073485120365516), (10, 0.03888438583912336), (13, 0.033963563664343784), (22, 0.03312458188187903), (31, 0.03130985396849788), (30, 0.027672591502415116), (28, 0.02756612860711409), (14, 0.027512387888113166), (15, 0.01965200109139666), (12, 0.017469595475586026), (29, 0.015336378930915582), (19, 0.013579436658579852), (16, 0.012659997555127629), (18, 0.009042428305984665), (17, 0.007535869077497878), (23, 0.0035001628212959377)]\n","Best MI score: 0.12333236920388603\n","Adding first best original feature: 0\n","CMI: 0.0074244483499040365\n","CMI: 0.009875762928394996\n","CMI: 0.008345749084033946\n","CMI: 0.0056715699218127386\n","CMI: 0.031167288091795378\n","CMI: 0.022041052925945007\n","CMI: 0.033864833377157635\n","CMI: 0.014572471172885834\n","CMI: 0.007241468996928055\n","CMI: 0.005626105595362155\n","CMI: 0.00457555714095452\n","Highest CMI score: 0.033864833377157635\n","Adding original feature: 26\n","CMI: 0.00026017568164984906\n","CMI: 0.01630445543122097\n","CMI: 0.0050289656527783\n","Highest CMI score: 0.01630445543122097\n","Adding original feature: 2\n","Highest CMI score: -0.008304843257026101\n","\n","[0, 26, 2]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.2596877558744367, test score: 0.17450862564759906\n","Aggregate regression train score with FS: 0.17963535378242046, test score: 0.15480738872169852\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.2596877558744367, test score: 0.17450862564759906\n","Aggregate regression train score with FS: 0.17963535378242046, test score: 0.15480738872169852\n","###### Regression ######\n","Train R2 linear regression CMI:  0.18\n","Test R2 linear regression CMI:  0.155 \n","\n","Train R2 linear regression CMI best 5:  0.18\n","Test R2 linear regression CMI best 5:  0.155 \n","\n","Train R2 linear regression wrapper:  0.207\n","Test R2 linear regression wrapper:  0.215 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.657\n","Test accuracy logistic regression CMI:  0.675 \n","\n","Train accuracy logistic regression CMI best 5:  0.657\n","Test accuracy logistic regression CMI best 5:  0.675 \n","\n","Train accuracy logistic regression wrapper:  0.649\n","Test accuracy logistic regression wrapper:  0.64 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]}]},{"cell_type":"markdown","source":["## Temp Prec Snow"],"metadata":{"id":"bQPdcAp62Q1P"},"id":"bQPdcAp62Q1P"},{"cell_type":"code","source":["basins = ['Adda', 'Oglio_Iseo', 'Ticino', 'Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n","path_target = \"./csv/\"\n","path_features='./features_allvalues/'\n","path_features_snow = './features_allvalues/snow/copernicus/relevant_coords/'\n","\n","destination_folder = './NonLinCFA/temp_prec_snow_copernicus/relevant_coords/'\n","plots_folder = './NonLinCFA/for_plots/internal_ordering/snow/'\n","\n","for basin in basins:\n","\n","    print('####################' + basin + '####################')\n","\n","    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01',\n","                                                                                     path=path_target+basin+'.csv')\n","\n","    eps = 0.01\n","    actual_path = path_features+basin+'_aggreg.csv'\n","    snow_actual_path = path_features_snow+basin+'_aggreg_sd_allCoord.csv'\n","\n","\n","    output,aggregate_trainVal_temp_prec,aggregate_test_temp_prec = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg',\n","                                                                             'cyclostationary_mean_tg_1w',\n","                                                                             'cyclostationary_mean_tg_4w',\n","                                                                             'cyclostationary_mean_tg_8w',\n","                                                                             'cyclostationary_mean_tg_12w',\n","                                                                             'cyclostationary_mean_tg_16w',\n","                                                                             'cyclostationary_mean_tg_24w',\n","                                                                             'cyclostationary_mean_rr',\n","                                                                             'cyclostationary_mean_rr_1w',\n","                                                                             'cyclostationary_mean_rr_4w',\n","                                                                             'cyclostationary_mean_rr_8w',\n","                                                                             'cyclostationary_mean_rr_12w',\n","                                                                             'cyclostationary_mean_rr_16w',\n","                                                                             'cyclostationary_mean_rr_24w'\n","                                                                            ],\n","                                                                       target_df_trainVal, eps=eps,\n","                                                                       max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n","    if os.path.isfile(snow_actual_path):\n","      output_snow,aggregate_trainVal_snow,aggregate_test_snow = aggregate_unfolded_data(snow_actual_path,['cyclostationary_mean_HS',\n","                                                                              'cyclostationary_mean_HS_1w',\n","                                                                              'cyclostationary_mean_HS_4w',\n","                                                                              'cyclostationary_mean_HS_8w',\n","                                                                              'cyclostationary_mean_HS_12w',\n","                                                                              'cyclostationary_mean_HS_16w',\n","                                                                              'cyclostationary_mean_HS_24w'\n","                                                                              ],\n","                                                                        target_df_trainVal, eps=eps,\n","                                                                        max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01',\n","                                                                                        scale = 0.26)\n","\n","\n","      aggregate_trainVal = pd.concat((aggregate_trainVal_snow,aggregate_trainVal_temp_prec),axis=1)\n","      aggregate_test = pd.concat((aggregate_test_snow,aggregate_test_temp_prec),axis=1)\n","\n","    selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, min(50,aggregate_trainVal.shape[1]-1), 228)\n","\n","    print('\\nFull model and selected features with wrapper\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","    print('\\nFull model and best 5 selected features with wrapper\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","    train_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_train_withSnow.csv'\n","    val_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_val_withSnow.csv'\n","    test_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_test_withSnow.csv'\n","    X_train_wrapper = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","    X_validation_wrapper = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","    X_train_validation_wrapper = pd.concat([X_train_wrapper, X_validation_wrapper])\n","    X_test_wrapper = aggregate_test.loc[:,selected_colnames[0:5]]\n","    X_train_wrapper.to_csv(train_string, index=False)\n","    X_validation_wrapper.to_csv(val_string, index=False)\n","    X_test_wrapper.to_csv(test_string, index=False)\n","\n","    res = {\n","            \"delta\" : [],\n","            \"numSelected\" : [],\n","            \"selectedFeatures\" : []\n","        }\n","\n","    res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),\n","                                                      np.array(target_df_trainVal.mean_std),res,10,1)\n","\n","    selectedFeatures='selectedFeatures'\n","    print(f'\\n{res[selectedFeatures]}\\n')\n","\n","    selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n","\n","    print('\\nFull model and selected features with CMI\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","    print('\\nFull model and best 5 selected features with CMI\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","    train_string = destination_folder + basin + '_nonLinCFA_best5_CMI_train_withSnow.csv'\n","    val_string = destination_folder + basin + '_nonLinCFA_best5_CMI_val_withSnow.csv'\n","    test_string = destination_folder + basin + '_nonLinCFA_best5_CMI_test_withSnow.csv'\n","\n","    X_train_CMI5 = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","    X_validation_CMI5 = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","    X_train_validation_CMI5 = pd.concat([X_train_CMI5, X_validation_CMI5])\n","    X_test_CMI5 = aggregate_test.loc[:,selected_colnames[0:5]]\n","\n","    selected_colnames_CMI5 = aggregate_trainVal.loc[:,selected_colnames[0:5]].columns.values\n","\n","    X_train_CMI5.to_csv(train_string, index=False)\n","    X_validation_CMI5.to_csv(val_string, index=False)\n","    X_test_CMI5.to_csv(test_string, index=False)\n","\n","    train_string = destination_folder + basin + '_nonLinCFA_CMI_train_withSnow.csv'\n","    val_string = destination_folder + basin + '_nonLinCFA_CMI_val_withSnow.csv'\n","    test_string = destination_folder + basin + '_nonLinCFA_CMI_test_withSnow.csv'\n","\n","    X_train_CMI = aggregate_trainVal.loc[:410,selected_colnames]\n","    X_validation_CMI = aggregate_trainVal.loc[411:,selected_colnames]\n","    X_train_validation_CMI = pd.concat([X_train_CMI, X_validation_CMI])\n","    X_test_CMI = aggregate_test.loc[:,selected_colnames]\n","\n","    X_train_CMI.to_csv(train_string, index=False)\n","    X_validation_CMI.to_csv(val_string, index=False)\n","    X_test_CMI.to_csv(test_string, index=False)\n","\n","    print('###### Regression ######')\n","    lin_regr = LinearRegression()\n","\n","    # CMI\n","    lin_regr.fit(X_train_validation_CMI, target_df_trainVal.mean_std)\n","    print(\"Train R2 linear regression CMI: \", round(lin_regr.score(X_train_validation_CMI, target_df_trainVal.mean_std),3))\n","    print(\"Test R2 linear regression CMI: \", round(lin_regr.score(X_test_CMI, target_df_test.mean_std),3), \"\\n\")\n","\n","    # CMI best 5\n","    lin_regr.fit(X_train_validation_CMI5, target_df_trainVal.mean_std)\n","    print(\"Train R2 linear regression CMI best 5: \", round(lin_regr.score(X_train_validation_CMI5, target_df_trainVal.mean_std),3))\n","    print(\"Test R2 linear regression CMI best 5: \", round(lin_regr.score(X_test_CMI5, target_df_test.mean_std),3), \"\\n\")\n","\n","    # wrapper\n","    lin_regr.fit(X_train_validation_wrapper, target_df_trainVal.mean_std)\n","    print(\"Train R2 linear regression wrapper: \", round(lin_regr.score(X_train_validation_wrapper, target_df_trainVal.mean_std),3))\n","    print(\"Test R2 linear regression wrapper: \", round(lin_regr.score(X_test_wrapper, target_df_test.mean_std),3), \"\\n\")\n","\n","    print('###### Binary Classification ######')\n","\n","    target_df_train = target_df_train.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_val = target_df_val.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_test = target_df_test.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_trainVal = target_df_trainVal.apply(lambda x: np.sign(x.mean_std), axis=1)\n","\n","    log_regr = LogisticRegression(solver='lbfgs', random_state = 42)\n","\n","    # CMI\n","    log_regr.fit(X_train_validation_CMI, target_df_trainVal)\n","    print(\"Train accuracy logistic regression CMI: \", round(log_regr.score(X_train_validation_CMI, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression CMI: \", round(log_regr.score(X_test_CMI, target_df_test),3), \"\\n\")\n","\n","    # CMI best 5\n","    log_regr.fit(X_train_validation_CMI5, target_df_trainVal)\n","    print(\"Train accuracy logistic regression CMI best 5: \", round(log_regr.score(X_train_validation_CMI5, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression CMI best 5: \", round(log_regr.score(X_test_CMI5, target_df_test),3), \"\\n\")\n","\n","    # wrapper\n","    log_regr.fit(X_train_validation_wrapper, target_df_trainVal)\n","    print(\"Train accuracy logistic regression wrapper: \", round(log_regr.score(X_train_validation_wrapper, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression wrapper: \", round(log_regr.score(X_test_wrapper, target_df_test),3), \"\\n\")\n","\n","    output_string = plots_folder + basin + '_aggregations.npy'\n","    sel_col_string = plots_folder + basin + '_chosen_features.npy'\n","    np.save(sel_col_string, selected_colnames_CMI5)\n","    np.save(output_string, output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nPQCqllZ2UFr","executionInfo":{"status":"ok","timestamp":1690234201688,"user_tz":-120,"elapsed":1623950,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"72e4d7f7-43f6-46f6-f824-beafb8234966"},"id":"nPQCqllZ2UFr","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["####################Adda####################\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 4\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 5\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 4\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 3\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 7\n","\n","eps value:  0.0014285714285714286\n","Number of aggregated features: 1\n","\n","Number of features: 7\n","\n","eps value:  0.0014285714285714286\n","Number of aggregated features: 1\n","\n","Number of features: 7\n","\n","eps value:  0.0014285714285714286\n","Number of aggregated features: 1\n","\n","Number of features: 7\n","\n","eps value:  0.0014285714285714286\n","Number of aggregated features: 1\n","\n","Number of features: 7\n","\n","eps value:  0.0014285714285714286\n","Number of aggregated features: 1\n","\n","Number of features: 7\n","\n","eps value:  0.0014285714285714286\n","Number of aggregated features: 1\n","\n","Number of features: 7\n","\n","eps value:  0.0014285714285714286\n","Number of aggregated features: 1\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_tg_1w_4', 'cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_tg_24w_1', 'cyclostationary_mean_tg_4w_0'], \n","\n","validation score: 0.28569722616248694, \n","\n","number of selected features: 10\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.2585699719492094, test score: -0.19564286704512046\n","Aggregate regression train score with FS: 0.19518265250932498, test score: 0.09703508322616006\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.2585699719492094, test score: -0.19564286704512046\n","Aggregate regression train score with FS: 0.19217163500084344, test score: 0.0905659481466351\n","----- MI Scores -----\n","[(10, 0.12050703744657751), (9, 0.10817618197950427), (8, 0.10458666651828148), (13, 0.10000614962421837), (15, 0.09759609497149417), (12, 0.0958421245778713), (7, 0.09503214284536106), (11, 0.09477576732312769), (2, 0.09158264060286317), (30, 0.07967156830045484), (0, 0.076574499875435), (1, 0.07510183877352265), (14, 0.0687728511603872), (32, 0.05155755293289637), (36, 0.047334700475274924), (18, 0.045062184539707034), (19, 0.04490981082569118), (6, 0.039933102800045694), (3, 0.036082882269987064), (17, 0.034333966317883206), (21, 0.03431807492831074), (33, 0.03414181201005571), (20, 0.03279033144606338), (31, 0.0317000457510685), (27, 0.03044594915922083), (23, 0.029624969112521), (25, 0.02694337568051), (34, 0.0267973393965517), (22, 0.02266872778585513), (16, 0.02222559539519485), (24, 0.0207126706203192), (35, 0.01541299283864724), (4, 0.014788839905335536), (5, 0.008030934330607703), (28, 0.007419677971127319), (37, 0.0017077463269159448), (26, 0.00010044357455795209), (29, -0.0008309994106552068)]\n","Best MI score: 0.12050703744657751\n","Adding first best original feature: 10\n","CMI: 0.022609641524625246\n","CMI: 0.026511429044607182\n","CMI: 0.029083297663191426\n","CMI: 0.038592786657139555\n","CMI: 0.011988055394801994\n","CMI: 0.0037080553595621457\n","CMI: 0.016511440210771083\n","CMI: 0.01287806045105161\n","CMI: 0.0030869257926980503\n","CMI: 0.024203701243435266\n","CMI: 0.00643362640081066\n","Highest CMI score: 0.038592786657139555\n","Adding original feature: 6\n","CMI: 0.016441969822364677\n","CMI: 0.028656537661921416\n","CMI: 0.028256831039025765\n","CMI: 0.01861044906237158\n","CMI: 0.0050625718408665865\n","CMI: 0.007487184927908064\n","CMI: 0.011532580507605389\n","CMI: 0.010483381417751847\n","CMI: 0.004951926732833067\n","Highest CMI score: 0.028656537661921416\n","Adding original feature: 1\n","CMI: 0.00636250080983608\n","CMI: 0.011354647744183738\n","Highest CMI score: 0.011354647744183738\n","Adding original feature: 32\n","CMI: 0.005699211966643053\n","CMI: 0.004640201937169186\n","CMI: 0.0008842962283595601\n","Highest CMI score: 0.005699211966643053\n","Adding original feature: 2\n","CMI: 0.0005228503481362612\n","CMI: 4.982766847561049e-05\n","Highest CMI score: 0.0005228503481362612\n","Adding original feature: 0\n","CMI: 0.0021580552444452894\n","Highest CMI score: 0.0021580552444452894\n","Adding original feature: 7\n","Highest CMI score: -0.00047981653729625706\n","\n","[10, 6, 1, 32, 2, 0, 7]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.2585699719492094, test score: -0.19564286704512046\n","Aggregate regression train score with FS: 0.15447047830426608, test score: 0.01828308070325535\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.2585699719492094, test score: -0.19564286704512046\n","Aggregate regression train score with FS: 0.14762444245918604, test score: 0.0950295241590291\n","###### Regression ######\n","Train R2 linear regression CMI:  0.154\n","Test R2 linear regression CMI:  0.018 \n","\n","Train R2 linear regression CMI best 5:  0.148\n","Test R2 linear regression CMI best 5:  0.095 \n","\n","Train R2 linear regression wrapper:  0.192\n","Test R2 linear regression wrapper:  0.091 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.648\n","Test accuracy logistic regression CMI:  0.583 \n","\n","Train accuracy logistic regression CMI best 5:  0.629\n","Test accuracy logistic regression CMI best 5:  0.632 \n","\n","Train accuracy logistic regression wrapper:  0.649\n","Test accuracy logistic regression wrapper:  0.649 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]},{"output_type":"stream","name":"stdout","text":["####################Oglio_Iseo####################\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 3\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 2\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 3\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 2\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 2\n","\n","eps value:  0.005\n","Number of aggregated features: 1\n","\n","Number of features: 2\n","\n","eps value:  0.005\n","Number of aggregated features: 1\n","\n","Number of features: 2\n","\n","eps value:  0.005\n","Number of aggregated features: 1\n","\n","Number of features: 2\n","\n","eps value:  0.005\n","Number of aggregated features: 1\n","\n","Number of features: 2\n","\n","eps value:  0.005\n","Number of aggregated features: 1\n","\n","Number of features: 2\n","\n","eps value:  0.005\n","Number of aggregated features: 1\n","\n","Number of features: 2\n","\n","eps value:  0.005\n","Number of aggregated features: 1\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_HS_1w_0', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_HS_24w_0', 'cyclostationary_mean_HS_12w_0', 'cyclostationary_mean_rr_2', 'cyclostationary_mean_rr_1', 'cyclostationary_mean_tg_1w_0'], \n","\n","validation score: 0.24011256042532736, \n","\n","number of selected features: 11\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.21569484431458574, test score: 0.19234240239149014\n","Aggregate regression train score with FS: 0.19144933374219664, test score: 0.2253178785530423\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.21569484431458574, test score: 0.19234240239149014\n","Aggregate regression train score with FS: 0.17484245450473102, test score: 0.2555246483481647\n","----- MI Scores -----\n","[(8, 0.11076080233409458), (10, 0.08993182369969176), (2, 0.08626688629568093), (11, 0.08535352628620278), (7, 0.07386411287408363), (20, 0.06844398820510891), (9, 0.06408261327785464), (6, 0.06369286613492495), (22, 0.06299091012845069), (1, 0.06252184552186248), (3, 0.05830943358172954), (25, 0.05651307447517284), (0, 0.056286546013846146), (21, 0.05543184789542872), (5, 0.043859034866708314), (4, 0.03929968857194144), (13, 0.02979180239377202), (12, 0.026674163534289076), (19, 0.025426898033636097), (23, 0.024975603937788842), (17, 0.01719526554739976), (26, 0.015340572237401038), (24, 0.012741180847832224), (15, 0.00928620532801559), (18, 0.005595837322748134), (14, -0.0008272018359696276), (16, -0.0020231794309610793)]\n","Best MI score: 0.11076080233409458\n","Adding first best original feature: 8\n","CMI: 0.02396596560268352\n","CMI: 0.03814681054212907\n","CMI: 0.05617832813007542\n","CMI: 0.038176391182563996\n","CMI: 0.006673095147119737\n","CMI: 0.014154850061812982\n","CMI: 0.0013076969264405186\n","CMI: 0.004057567563985273\n","CMI: 0.017334319624676464\n","CMI: 0.02335160674909731\n","CMI: 0.0008355480876596488\n","CMI: 0.0068376192263017305\n","CMI: 4.136378956480502e-05\n","Highest CMI score: 0.05617832813007542\n","Adding original feature: 2\n","CMI: 0.005031875550787407\n","CMI: 0.010242815399036986\n","CMI: 0.0024566860963901316\n","CMI: 0.018892927942283116\n","CMI: 0.006374468866217731\n","CMI: 0.0002211600731731045\n","CMI: 0.023935475007741264\n","CMI: 0.0013439926764021726\n","Highest CMI score: 0.023935475007741264\n","Adding original feature: 22\n","CMI: 0.005040446999584419\n","CMI: 0.010703989035948464\n","CMI: 0.000249776602309959\n","CMI: 0.03165186369689746\n","Highest CMI score: 0.03165186369689746\n","Adding original feature: 6\n","CMI: 0.0014264882346131935\n","CMI: 0.009338473443923606\n","CMI: 0.0037096918311022298\n","Highest CMI score: 0.009338473443923606\n","Adding original feature: 3\n","Highest CMI score: -0.00404978055441077\n","\n","[8, 2, 22, 6, 3]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.21569484431458574, test score: 0.19234240239149014\n","Aggregate regression train score with FS: 0.1620322438328351, test score: 0.1777650111540069\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.21569484431458574, test score: 0.19234240239149014\n","Aggregate regression train score with FS: 0.1620322438328351, test score: 0.1777650111540069\n","###### Regression ######\n","Train R2 linear regression CMI:  0.162\n","Test R2 linear regression CMI:  0.178 \n","\n","Train R2 linear regression CMI best 5:  0.162\n","Test R2 linear regression CMI best 5:  0.178 \n","\n","Train R2 linear regression wrapper:  0.175\n","Test R2 linear regression wrapper:  0.256 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.651\n","Test accuracy logistic regression CMI:  0.658 \n","\n","Train accuracy logistic regression CMI best 5:  0.651\n","Test accuracy logistic regression CMI best 5:  0.658 \n","\n","Train accuracy logistic regression wrapper:  0.657\n","Test accuracy logistic regression wrapper:  0.684 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]},{"output_type":"stream","name":"stdout","text":["####################Ticino####################\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 3\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 4\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 5\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 3\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 3\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 11\n","\n","eps value:  0.0009090909090909091\n","Number of aggregated features: 1\n","\n","Number of features: 11\n","\n","eps value:  0.0009090909090909091\n","Number of aggregated features: 1\n","\n","Number of features: 11\n","\n","eps value:  0.0009090909090909091\n","Number of aggregated features: 1\n","\n","Number of features: 11\n","\n","eps value:  0.0009090909090909091\n","Number of aggregated features: 1\n","\n","Number of features: 11\n","\n","eps value:  0.0009090909090909091\n","Number of aggregated features: 1\n","\n","Number of features: 11\n","\n","eps value:  0.0009090909090909091\n","Number of aggregated features: 1\n","\n","Number of features: 11\n","\n","eps value:  0.0009090909090909091\n","Number of aggregated features: 1\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_tg_16w_2', 'cyclostationary_mean_HS_1w_0', 'cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_tg_4w_3', 'cyclostationary_mean_HS_16w_0', 'cyclostationary_mean_HS_4w_0', 'cyclostationary_mean_HS_0', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_tg_12w_1', 'cyclostationary_mean_tg_8w_2'], \n","\n","validation score: 0.317586984214582, \n","\n","number of selected features: 13\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.27026664134560907, test score: 0.15361338931170454\n","Aggregate regression train score with FS: 0.22240618356794162, test score: 0.2087150485298963\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.27026664134560907, test score: 0.15361338931170454\n","Aggregate regression train score with FS: 0.20805396525837627, test score: 0.20342987505165433\n","----- MI Scores -----\n","[(7, 0.12333236920388603), (10, 0.11043061820217501), (8, 0.09301073215020078), (13, 0.08598787349447463), (14, 0.08117728514132373), (9, 0.0792921840495771), (11, 0.07414296454034455), (12, 0.07273765839428532), (32, 0.06849890021359188), (33, 0.06842462865595438), (18, 0.06443446394377765), (31, 0.061138128729906156), (15, 0.05234511965473389), (1, 0.051578216552934666), (2, 0.05111941419748541), (27, 0.049513412252677226), (34, 0.04938930727611444), (16, 0.04826659946172222), (3, 0.043648734949412724), (0, 0.04124124157381396), (28, 0.04073485120365516), (17, 0.03888438583912336), (20, 0.033963563664343784), (29, 0.03312458188187903), (4, 0.03271879859735801), (38, 0.03130985396849788), (37, 0.027672591502415116), (35, 0.02756612860711409), (21, 0.027512387888113166), (5, 0.020055709616829186), (22, 0.01965200109139666), (19, 0.017469595475586026), (36, 0.015336378930915582), (26, 0.013579436658579852), (23, 0.012659997555127629), (25, 0.009042428305984665), (24, 0.007535869077497878), (30, 0.0035001628212959377), (6, -0.03298322086102608)]\n","Best MI score: 0.12333236920388603\n","Adding first best original feature: 7\n","CMI: 0.05177423970200952\n","CMI: 0.041623775772589536\n","CMI: 0.040219874103650036\n","CMI: 0.022159759148305272\n","CMI: 0.010906862912105117\n","CMI: 0.0074244483499040365\n","CMI: 0.009875762928394996\n","CMI: 0.008345749084033946\n","CMI: 0.0056715699218127386\n","CMI: 0.031167288091795378\n","CMI: 0.022041052925945007\n","CMI: 0.033864833377157635\n","CMI: 0.014572471172885834\n","CMI: 0.007241468996928055\n","CMI: 0.005626105595362155\n","CMI: 0.00457555714095452\n","Highest CMI score: 0.05177423970200952\n","Adding original feature: 0\n","CMI: 0.0020327880850429525\n","CMI: 0.004266472262677401\n","CMI: 0.00044614232501272166\n","CMI: 0.005158821713223738\n","CMI: 0.015657956852221766\n","Highest CMI score: 0.015657956852221766\n","Adding original feature: 33\n","CMI: 0.002118286989682666\n","CMI: 0.0015127847730379562\n","CMI: 0.004665758189775326\n","CMI: 0.0002617922910101711\n","Highest CMI score: 0.004665758189775326\n","Adding original feature: 9\n","CMI: 0.0011014470758108907\n","CMI: 0.008221560415558382\n","CMI: 0.0009614247695529654\n","Highest CMI score: 0.008221560415558382\n","Adding original feature: 31\n","Highest CMI score: -7.346791636003713e-05\n","\n","[7, 0, 33, 9, 31]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.27026664134560907, test score: 0.15361338931170454\n","Aggregate regression train score with FS: 0.19204585587733025, test score: 0.12553208635435087\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.27026664134560907, test score: 0.15361338931170454\n","Aggregate regression train score with FS: 0.19204585587733025, test score: 0.12553208635435087\n","###### Regression ######\n","Train R2 linear regression CMI:  0.192\n","Test R2 linear regression CMI:  0.126 \n","\n","Train R2 linear regression CMI best 5:  0.192\n","Test R2 linear regression CMI best 5:  0.126 \n","\n","Train R2 linear regression wrapper:  0.208\n","Test R2 linear regression wrapper:  0.203 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.662\n","Test accuracy logistic regression CMI:  0.654 \n","\n","Train accuracy logistic regression CMI best 5:  0.662\n","Test accuracy logistic regression CMI best 5:  0.654 \n","\n","Train accuracy logistic regression wrapper:  0.665\n","Test accuracy logistic regression wrapper:  0.632 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]},{"output_type":"stream","name":"stdout","text":["####################Dora####################\n","Number of features: 44\n","\n","eps value:  0.00022727272727272727\n","Number of aggregated features: 3\n","\n","Number of features: 44\n","\n","eps value:  0.00022727272727272727\n","Number of aggregated features: 2\n","\n","Number of features: 44\n","\n","eps value:  0.00022727272727272727\n","Number of aggregated features: 2\n","\n","Number of features: 44\n","\n","eps value:  0.00022727272727272727\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.00022727272727272727\n","Number of aggregated features: 3\n","\n","Number of features: 44\n","\n","eps value:  0.00022727272727272727\n","Number of aggregated features: 2\n","\n","Number of features: 44\n","\n","eps value:  0.00022727272727272727\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.00022727272727272727\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.00022727272727272727\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.00022727272727272727\n","Number of aggregated features: 2\n","\n","Number of features: 44\n","\n","eps value:  0.00022727272727272727\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.00022727272727272727\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.00022727272727272727\n","Number of aggregated features: 1\n","\n","Number of features: 44\n","\n","eps value:  0.00022727272727272727\n","Number of aggregated features: 1\n","\n","Number of features: 6\n","\n","eps value:  0.0016666666666666668\n","Number of aggregated features: 1\n","\n","Number of features: 6\n","\n","eps value:  0.0016666666666666668\n","Number of aggregated features: 1\n","\n","Number of features: 6\n","\n","eps value:  0.0016666666666666668\n","Number of aggregated features: 1\n","\n","Number of features: 6\n","\n","eps value:  0.0016666666666666668\n","Number of aggregated features: 1\n","\n","Number of features: 6\n","\n","eps value:  0.0016666666666666668\n","Number of aggregated features: 1\n","\n","Number of features: 6\n","\n","eps value:  0.0016666666666666668\n","Number of aggregated features: 1\n","\n","Number of features: 6\n","\n","eps value:  0.0016666666666666668\n","Number of aggregated features: 1\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_HS_12w_0', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_tg_4w_1', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_rr_1w_0'], \n","\n","validation score: 0.15210126315860495, \n","\n","number of selected features: 11\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.17090087203800164, test score: -0.4511790053315161\n","Aggregate regression train score with FS: 0.13635392680071035, test score: -0.48474368858344974\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.17090087203800164, test score: -0.4511790053315161\n","Aggregate regression train score with FS: 0.11070139680216984, test score: -0.02678652789905156\n","----- MI Scores -----\n","[(1, 0.19214335134358082), (0, 0.16203473707050145), (2, 0.15686833209913056), (6, 0.14106932429594027), (3, 0.12716342245692397), (4, 0.11401036632459863), (5, 0.10360214749979169), (7, 0.08258555990998045), (13, 0.08231364151511239), (8, 0.07403302765412884), (23, 0.07022127758881887), (25, 0.06403914196637761), (10, 0.06260796159248551), (11, 0.062222355402884434), (27, 0.06171626575698934), (9, 0.06012408478874562), (12, 0.051223278267829624), (26, 0.04963889533470378), (14, 0.04937308101325847), (22, 0.04686527556655052), (16, 0.04675241648453176), (19, 0.04038635522454774), (28, 0.03973911161712182), (15, 0.03799132047640648), (18, 0.037592468805947486), (24, 0.035031209346705096), (17, 0.02862779243714999), (21, 0.026156781831893537), (20, 0.010491028158308404)]\n","Best MI score: 0.19214335134358082\n","Adding first best original feature: 1\n","CMI: 0.004300365990993288\n","CMI: 0.03496287189679867\n","CMI: 0.08524303638791877\n","CMI: 0.11145532838512298\n","CMI: 0.11486426965649146\n","CMI: 0.04369278468770235\n","CMI: 0.027914501725020274\n","CMI: 0.01547161141653755\n","CMI: 0.02183184612200842\n","CMI: 0.01566966390247937\n","CMI: 0.022211899357344883\n","CMI: 0.0317464537075427\n","CMI: 0.017722302816722657\n","CMI: 0.04958489800303251\n","CMI: 0.021220421506892656\n","CMI: 0.015704014773991776\n","CMI: 0.005127153480743107\n","CMI: 0.003274900156732069\n","CMI: 0.01167232728911713\n","CMI: 0.007526554970341659\n","CMI: 0.043894279422611066\n","CMI: 0.04683672863780766\n","CMI: 0.052385322919464655\n","CMI: 0.03098099396766213\n","Highest CMI score: 0.11486426965649146\n","Adding original feature: 6\n","CMI: 0.003503302157855104\n","CMI: 0.002532556279691567\n","CMI: 0.009707543309320665\n","CMI: 0.02217221490294241\n","CMI: 0.0014137691559354404\n","CMI: 0.002487258671236614\n","CMI: 0.009189663317643149\n","CMI: 0.016924066284258188\n","CMI: 0.012850324712600336\n","Highest CMI score: 0.02217221490294241\n","Adding original feature: 5\n","CMI: 0.0044705670345080994\n","CMI: 0.007608085074405357\n","Highest CMI score: 0.007608085074405357\n","Adding original feature: 4\n","CMI: 0.0013582309018924654\n","Highest CMI score: 0.0013582309018924654\n","Adding original feature: 2\n","Highest CMI score: -0.006123677215474299\n","\n","[1, 6, 5, 4, 2]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.17090087203800164, test score: -0.4511790053315161\n","Aggregate regression train score with FS: 0.010857251201310758, test score: -0.06518324012872978\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.17090087203800164, test score: -0.4511790053315161\n","Aggregate regression train score with FS: 0.010857251201310758, test score: -0.06518324012872978\n","###### Regression ######\n","Train R2 linear regression CMI:  0.011\n","Test R2 linear regression CMI:  -0.065 \n","\n","Train R2 linear regression CMI best 5:  0.011\n","Test R2 linear regression CMI best 5:  -0.065 \n","\n","Train R2 linear regression wrapper:  0.111\n","Test R2 linear regression wrapper:  -0.027 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.554\n","Test accuracy logistic regression CMI:  0.412 \n","\n","Train accuracy logistic regression CMI best 5:  0.554\n","Test accuracy logistic regression CMI best 5:  0.412 \n","\n","Train accuracy logistic regression wrapper:  0.587\n","Test accuracy logistic regression wrapper:  0.632 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]},{"output_type":"stream","name":"stdout","text":["####################Piemonte_Nord####################\n","Number of features: 89\n","\n","eps value:  0.00011235955056179776\n","Number of aggregated features: 8\n","\n","Number of features: 89\n","\n","eps value:  0.00011235955056179776\n","Number of aggregated features: 5\n","\n","Number of features: 89\n","\n","eps value:  0.00011235955056179776\n","Number of aggregated features: 5\n","\n","Number of features: 89\n","\n","eps value:  0.00011235955056179776\n","Number of aggregated features: 5\n","\n","Number of features: 89\n","\n","eps value:  0.00011235955056179776\n","Number of aggregated features: 1\n","\n","Number of features: 89\n","\n","eps value:  0.00011235955056179776\n","Number of aggregated features: 1\n","\n","Number of features: 89\n","\n","eps value:  0.00011235955056179776\n","Number of aggregated features: 1\n","\n","Number of features: 89\n","\n","eps value:  0.00011235955056179776\n","Number of aggregated features: 5\n","\n","Number of features: 89\n","\n","eps value:  0.00011235955056179776\n","Number of aggregated features: 6\n","\n","Number of features: 89\n","\n","eps value:  0.00011235955056179776\n","Number of aggregated features: 4\n","\n","Number of features: 89\n","\n","eps value:  0.00011235955056179776\n","Number of aggregated features: 3\n","\n","Number of features: 89\n","\n","eps value:  0.00011235955056179776\n","Number of aggregated features: 3\n","\n","Number of features: 89\n","\n","eps value:  0.00011235955056179776\n","Number of aggregated features: 1\n","\n","Number of features: 89\n","\n","eps value:  0.00011235955056179776\n","Number of aggregated features: 1\n","\n","Number of features: 5\n","\n","eps value:  0.002\n","Number of aggregated features: 2\n","\n","Number of features: 5\n","\n","eps value:  0.002\n","Number of aggregated features: 2\n","\n","Number of features: 5\n","\n","eps value:  0.002\n","Number of aggregated features: 2\n","\n","Number of features: 5\n","\n","eps value:  0.002\n","Number of aggregated features: 2\n","\n","Number of features: 5\n","\n","eps value:  0.002\n","Number of aggregated features: 2\n","\n","Number of features: 5\n","\n","eps value:  0.002\n","Number of aggregated features: 2\n","\n","Number of features: 5\n","\n","eps value:  0.002\n","Number of aggregated features: 2\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_rr_4w_2', 'cyclostationary_mean_HS_8w_1', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_rr_1w_4', 'cyclostationary_mean_rr_1w_5', 'cyclostationary_mean_HS_24w_1', 'cyclostationary_mean_tg_24w_0', 'cyclostationary_mean_tg_8w_4', 'cyclostationary_mean_tg_8w_3', 'cyclostationary_mean_HS_4w_0', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_rr_8w_1', 'cyclostationary_mean_tg_1w_4', 'cyclostationary_mean_tg_4w_4', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_tg_4w_1', 'cyclostationary_mean_HS_24w_0'], \n","\n","validation score: 0.31763548193187585, \n","\n","number of selected features: 20\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.34726129170072406, test score: 0.00979804924506178\n","Aggregate regression train score with FS: 0.26255695111993704, test score: 0.00128849863682734\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.34726129170072406, test score: 0.00979804924506178\n","Aggregate regression train score with FS: 0.23411921889853993, test score: 0.06589227107364559\n","----- MI Scores -----\n","[(15, 0.1272083141734311), (23, 0.11304505150806433), (18, 0.09639054922214828), (24, 0.09546790395368582), (17, 0.09137391410745542), (16, 0.09005082274241014), (20, 0.08989863929473699), (14, 0.08653560998148224), (21, 0.08633648652787185), (26, 0.08603117649820118), (51, 0.08244737877521952), (25, 0.08122444633504078), (19, 0.079348618109436), (22, 0.07887312055534308), (52, 0.07803424702179484), (9, 0.07716189144018644), (11, 0.07200832609455955), (5, 0.06930957392750184), (1, 0.06227247000553843), (13, 0.06173195277405632), (3, 0.061319493448305014), (49, 0.06088020750825367), (40, 0.06023694289404412), (46, 0.059656786327277604), (61, 0.05948643955324653), (2, 0.05717441543687977), (7, 0.05479542727303205), (29, 0.053451244777303446), (54, 0.05290722728042428), (34, 0.051533677931395405), (44, 0.050330399692301776), (41, 0.049146346081314546), (0, 0.04890055065355474), (8, 0.048193564563850814), (6, 0.04767275280756928), (10, 0.04746276853465832), (50, 0.04607727693109591), (62, 0.0436171911659015), (58, 0.04302557106493591), (36, 0.042931264791180306), (42, 0.04143700164301293), (60, 0.04104026126722697), (38, 0.03918432776370937), (59, 0.038027658584827054), (47, 0.03769146161192057), (33, 0.037652390744019965), (31, 0.03709746216566798), (45, 0.037008712211307665), (30, 0.033662970974681676), (12, 0.033391249330365), (39, 0.03241132199864097), (32, 0.03182164040222668), (53, 0.030912845299651322), (28, 0.02968470994868425), (48, 0.029216144069336064), (27, 0.028103476289163022), (35, 0.0261493038636724), (57, 0.022818617837319484), (4, 0.022653327371813903), (37, 0.021472580302876094), (55, 0.02090859799665261), (56, 0.0203586677355634), (43, -0.005111403837293355)]\n","Best MI score: 0.1272083141734311\n","Adding first best original feature: 15\n","CMI: 0.01425126410958219\n","CMI: 0.023678306183629372\n","CMI: 0.016428752946072406\n","CMI: 0.01641753715894559\n","CMI: 0.024237001054734364\n","CMI: 0.01160669163032857\n","CMI: 0.00581412365677636\n","CMI: 0.0020175339771924816\n","CMI: 0.0069912294510176\n","CMI: 0.016620625713956616\n","CMI: 0.041597675549213065\n","CMI: 0.009193549695883874\n","CMI: 0.000537454877511917\n","CMI: 0.007461046013438166\n","CMI: 0.006973841174661433\n","CMI: 0.003713225328506986\n","CMI: 0.005589688061598985\n","CMI: 0.00039355975886176675\n","CMI: 0.0030850387609556162\n","CMI: 0.007905710394489174\n","CMI: 0.004540876745400685\n","CMI: 0.025307064272140134\n","CMI: 0.013719607031754344\n","CMI: 0.007491487867379937\n","CMI: 0.006390192455863503\n","CMI: 0.013409460265993906\n","CMI: 0.019230030678086707\n","CMI: 0.006815177935888234\n","CMI: 0.038967714646118284\n","CMI: 0.038591950223530874\n","CMI: 0.013581947160608149\n","CMI: 0.02463212432466716\n","CMI: 0.024644235719706725\n","CMI: 0.04279588316012822\n","CMI: 0.03269798626176218\n","CMI: 0.014030639343244361\n","CMI: 0.014095773248165522\n","CMI: 0.025005521149043003\n","Highest CMI score: 0.04279588316012822\n","Adding original feature: 56\n","CMI: 0.0002166186533471559\n","CMI: 0.008005194063813198\n","CMI: 0.006946334282194211\n","CMI: 0.0019969032263188746\n","CMI: 0.010611297107712386\n","Highest CMI score: 0.010611297107712386\n","Adding original feature: 57\n","CMI: 0.0021142576546099856\n","CMI: 0.0021227013798423566\n","CMI: 0.0025108728703722993\n","CMI: 0.008183544263124148\n","CMI: 0.009052615812738668\n","CMI: 0.0006433865976283593\n","Highest CMI score: 0.009052615812738668\n","Adding original feature: 48\n","CMI: 0.002014278230565353\n","CMI: 0.0018146143158284667\n","Highest CMI score: 0.002014278230565353\n","Adding original feature: 2\n","CMI: 0.0011616192582533935\n","CMI: 0.00015342689439190593\n","CMI: 0.00021617115174812906\n","CMI: 0.0006675480018767943\n","Highest CMI score: 0.0011616192582533935\n","Adding original feature: 14\n","CMI: 0.0032544829414860033\n","Highest CMI score: 0.0032544829414860033\n","Adding original feature: 55\n","Highest CMI score: -0.0009778227668538475\n","\n","[15, 56, 57, 48, 2, 14, 55]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.34726129170072406, test score: 0.00979804924506178\n","Aggregate regression train score with FS: 0.21658288888991994, test score: 0.05948521116347849\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.34726129170072406, test score: 0.00979804924506178\n","Aggregate regression train score with FS: 0.207008477483267, test score: 0.03715220670063546\n","###### Regression ######\n","Train R2 linear regression CMI:  0.217\n","Test R2 linear regression CMI:  0.059 \n","\n","Train R2 linear regression CMI best 5:  0.207\n","Test R2 linear regression CMI best 5:  0.037 \n","\n","Train R2 linear regression wrapper:  0.234\n","Test R2 linear regression wrapper:  0.066 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.674\n","Test accuracy logistic regression CMI:  0.649 \n","\n","Train accuracy logistic regression CMI best 5:  0.664\n","Test accuracy logistic regression CMI best 5:  0.636 \n","\n","Train accuracy logistic regression wrapper:  0.674\n","Test accuracy logistic regression wrapper:  0.654 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]},{"output_type":"stream","name":"stdout","text":["####################Piemonte_Sud####################\n","Number of features: 176\n","\n","eps value:  5.681818181818182e-05\n","Number of aggregated features: 3\n","\n","Number of features: 176\n","\n","eps value:  5.681818181818182e-05\n","Number of aggregated features: 4\n","\n","Number of features: 176\n","\n","eps value:  5.681818181818182e-05\n","Number of aggregated features: 2\n","\n","Number of features: 176\n","\n","eps value:  5.681818181818182e-05\n","Number of aggregated features: 4\n","\n","Number of features: 176\n","\n","eps value:  5.681818181818182e-05\n","Number of aggregated features: 6\n","\n","Number of features: 176\n","\n","eps value:  5.681818181818182e-05\n","Number of aggregated features: 5\n","\n","Number of features: 176\n","\n","eps value:  5.681818181818182e-05\n","Number of aggregated features: 2\n","\n","Number of features: 176\n","\n","eps value:  5.681818181818182e-05\n","Number of aggregated features: 7\n","\n","Number of features: 176\n","\n","eps value:  5.681818181818182e-05\n","Number of aggregated features: 5\n","\n","Number of features: 176\n","\n","eps value:  5.681818181818182e-05\n","Number of aggregated features: 4\n","\n","Number of features: 176\n","\n","eps value:  5.681818181818182e-05\n","Number of aggregated features: 3\n","\n","Number of features: 176\n","\n","eps value:  5.681818181818182e-05\n","Number of aggregated features: 4\n","\n","Number of features: 176\n","\n","eps value:  5.681818181818182e-05\n","Number of aggregated features: 3\n","\n","Number of features: 176\n","\n","eps value:  5.681818181818182e-05\n","Number of aggregated features: 1\n","\n","Number of features: 3\n","\n","eps value:  0.0033333333333333335\n","Number of aggregated features: 1\n","\n","Number of features: 3\n","\n","eps value:  0.0033333333333333335\n","Number of aggregated features: 1\n","\n","Number of features: 3\n","\n","eps value:  0.0033333333333333335\n","Number of aggregated features: 1\n","\n","Number of features: 3\n","\n","eps value:  0.0033333333333333335\n","Number of aggregated features: 1\n","\n","Number of features: 3\n","\n","eps value:  0.0033333333333333335\n","Number of aggregated features: 1\n","\n","Number of features: 3\n","\n","eps value:  0.0033333333333333335\n","Number of aggregated features: 1\n","\n","Number of features: 3\n","\n","eps value:  0.0033333333333333335\n","Number of aggregated features: 1\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1', 'cyclostationary_mean_rr_12w_2', 'cyclostationary_mean_HS_8w_0', 'cyclostationary_mean_rr_12w_3', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_rr_1', 'cyclostationary_mean_rr_5', 'cyclostationary_mean_rr_8w_1', 'cyclostationary_mean_rr_0', 'cyclostationary_mean_rr_4w_2', 'cyclostationary_mean_HS_12w_0', 'cyclostationary_mean_tg_2', 'cyclostationary_mean_tg_8w_3', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_tg_8w_2', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_tg_0', 'cyclostationary_mean_tg_12w_0', 'cyclostationary_mean_tg_4w_1', 'cyclostationary_mean_rr_12w_0', 'cyclostationary_mean_tg_12w_4', 'cyclostationary_mean_tg_12w_5', 'cyclostationary_mean_tg_12w_1', 'cyclostationary_mean_tg_16w_4', 'cyclostationary_mean_tg_16w_2', 'cyclostationary_mean_tg_12w_2'], \n","\n","validation score: 0.2871437776630591, \n","\n","number of selected features: 28\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.3796318995078204, test score: -0.39482774339206483\n","Aggregate regression train score with FS: 0.3032578634091594, test score: -0.15561982826024812\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.3796318995078204, test score: -0.39482774339206483\n","Aggregate regression train score with FS: 0.20505950356251168, test score: 0.2675696223036095\n","----- MI Scores -----\n","[(7, 0.11678375300175307), (0, 0.10316226066042487), (49, 0.09746536965410076), (11, 0.09599629995264444), (10, 0.09388611048674152), (57, 0.09189326831703377), (8, 0.08931532980528292), (51, 0.08787369911435106), (46, 0.08202135600214848), (55, 0.08198747090890705), (9, 0.07720122513843419), (45, 0.0764840680640028), (2, 0.0759654203779618), (58, 0.07423403064202792), (59, 0.07167644132237468), (54, 0.07028360506414186), (14, 0.06896465121930961), (40, 0.06710747949727099), (1, 0.06573651193083838), (13, 0.06439324885251883), (56, 0.0621984800701941), (4, 0.06115420736153006), (44, 0.06065550764201256), (5, 0.05976115225943994), (48, 0.05369555684047585), (12, 0.05278709114075169), (52, 0.051771581395081055), (3, 0.05145748426190894), (47, 0.0505690944753633), (50, 0.048383868976238746), (53, 0.047783343856843304), (41, 0.04447532521600801), (38, 0.04362969112580873), (28, 0.04095324509959275), (15, 0.04036780000216598), (16, 0.03410580387562576), (18, 0.033446378126184124), (21, 0.033381094504619305), (43, 0.031119264399123204), (24, 0.031022381894772185), (42, 0.03036897890814173), (17, 0.029216106747555988), (26, 0.023032052840485012), (19, 0.021172189749865622), (31, 0.020340266808960217), (36, 0.01871054174955448), (37, 0.015541054770613594), (22, 0.012950448953233423), (25, 0.011748515531599063), (20, 0.008543021901746498), (6, 0.007470174375119532), (39, 0.0057171752537354395), (30, 0.005625908198894942), (34, 0.0040054811257983925), (33, 0.0017925711254218072), (29, 0.001198243294508687), (27, -0.0008609982739281993), (23, -0.0009593492323403657), (35, -0.0026518315077107015), (32, -0.006047268830530692)]\n","Best MI score: 0.11678375300175307\n","Adding first best original feature: 7\n","CMI: 0.04635427703098584\n","CMI: 0.04503260572017202\n","CMI: 0.03659628538673167\n","CMI: 0.0033958278366102573\n","CMI: 0.006644802796868493\n","CMI: 0.02682525737279247\n","CMI: 0.030293733706405493\n","CMI: 0.03205817496293713\n","CMI: 0.005267190200672067\n","CMI: 0.04561044759388645\n","CMI: 0.028591088290316438\n","CMI: 0.03600901986778708\n","CMI: 0.034691301977610375\n","CMI: 0.01982493559664346\n","CMI: 0.03178265751593541\n","CMI: 0.030665285864108563\n","CMI: 0.027228654943761962\n","CMI: 0.053404342659235285\n","CMI: 0.03236360999396577\n","CMI: 0.0675860745260194\n","Highest CMI score: 0.0675860745260194\n","Adding original feature: 59\n","CMI: 0.007366271191750623\n","CMI: 0.006179867712999665\n","CMI: 0.002611335117873592\n","CMI: 0.008817509479109975\n","CMI: 0.0023164722498724977\n","CMI: 0.0013458763303393073\n","CMI: 0.010099476958420284\n","CMI: 0.01583512777489604\n","CMI: 0.0027210567097186444\n","CMI: 0.0009973418868351458\n","Highest CMI score: 0.01583512777489604\n","Adding original feature: 50\n","CMI: 0.027872397620985617\n","CMI: 0.031321415219679766\n","CMI: 0.021440584883111263\n","CMI: 0.010210779998513692\n","CMI: 0.004479242476468054\n","CMI: 0.0020659026603702946\n","CMI: 0.006534433292219838\n","CMI: 0.011046073234133619\n","CMI: 0.008487565312565781\n","CMI: 0.008818042465006976\n","CMI: 0.01944199636577615\n","CMI: 0.010996544965223676\n","CMI: 0.0134398283887808\n","Highest CMI score: 0.031321415219679766\n","Adding original feature: 1\n","CMI: 0.0040394363267511335\n","CMI: 0.010798023283242392\n","CMI: 0.005719576988821196\n","CMI: 0.0005700680789554602\n","CMI: 0.01030398455335177\n","CMI: 0.0033976839325993713\n","CMI: 0.0033248065715337505\n","CMI: 0.00044462982018739217\n","CMI: 0.0023543288627877468\n","Highest CMI score: 0.010798023283242392\n","Adding original feature: 16\n","CMI: 0.00045292308762112654\n","CMI: 0.0010535563880208765\n","CMI: 0.00399641610626858\n","CMI: 0.0014301517595871893\n","CMI: 0.0024984457773805646\n","CMI: 0.005074859415487909\n","CMI: 0.002880255151157418\n","Highest CMI score: 0.005074859415487909\n","Adding original feature: 56\n","CMI: 0.0005176069985242393\n","CMI: 0.002562639709761505\n","CMI: 0.000642217096694403\n","CMI: 0.0010651647297358346\n","CMI: 0.0007679957569295681\n","CMI: 0.001929005394924549\n","Highest CMI score: 0.002562639709761505\n","Adding original feature: 19\n","CMI: 0.00019346360055783052\n","Highest CMI score: 0.00019346360055783052\n","Adding original feature: 0\n","CMI: 0.001688275687616203\n","Highest CMI score: 0.001688275687616203\n","Adding original feature: 51\n","CMI: 0.00031949148234494684\n","Highest CMI score: 0.00031949148234494684\n","Adding original feature: 15\n","CMI: 0.0002809436452023695\n","Highest CMI score: 0.0002809436452023695\n","Adding original feature: 55\n","Highest CMI score: -0.0004562675387944082\n","\n","[7, 59, 50, 1, 16, 56, 19, 0, 51, 15, 55]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3796318995078204, test score: -0.39482774339206483\n","Aggregate regression train score with FS: 0.1870397304047946, test score: 0.17685151854014913\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3796318995078204, test score: -0.39482774339206483\n","Aggregate regression train score with FS: 0.15997311584734475, test score: 0.14575387942461615\n","###### Regression ######\n","Train R2 linear regression CMI:  0.187\n","Test R2 linear regression CMI:  0.177 \n","\n","Train R2 linear regression CMI best 5:  0.16\n","Test R2 linear regression CMI best 5:  0.146 \n","\n","Train R2 linear regression wrapper:  0.205\n","Test R2 linear regression wrapper:  0.268 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.668\n","Test accuracy logistic regression CMI:  0.645 \n","\n","Train accuracy logistic regression CMI best 5:  0.651\n","Test accuracy logistic regression CMI best 5:  0.671 \n","\n","Train accuracy logistic regression wrapper:  0.67\n","Test accuracy logistic regression wrapper:  0.706 \n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = np.asanyarray(arr)\n"]}]},{"cell_type":"markdown","metadata":{"id":"NHQGqoo7z-9g"},"source":["## Temp Prec Snow Lakes"],"id":"NHQGqoo7z-9g"},{"cell_type":"code","execution_count":null,"metadata":{"id":"rXj02rbS0BL4"},"outputs":[],"source":["basins = ['Ticino', 'Oglio_Iseo', 'Adda', 'Lambro_Olona']\n","\n","path_target = \"./csv/\"\n","path_features_snow = './features_allvalues/snow/copernicus/relevant_coords/'\n","path_features='./features_allvalues/'\n","path_features_lakes='./lakes/'\n","\n","destination_folder = './NonLinCFA/temp_prec_snow_lakes_copernicus/'\n","\n","for basin in basins:\n","    print('####################' + basin + '####################')\n","\n","    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01',\n","                                                                                     path=path_target+basin+'.csv')\n","\n","    eps = 0.01\n","    actual_path = path_features+basin+'_aggreg.csv'\n","    snow_actual_path = path_features_snow+basin+'_aggreg_sd_allCoord.csv'\n","    lakes_actual_path = path_features_lakes + 'lakes_' + basin + '_with_aggreg.csv'\n","\n","    output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg',\n","                                                                             'cyclostationary_mean_tg_1w',\n","                                                                             'cyclostationary_mean_tg_4w',\n","                                                                             'cyclostationary_mean_tg_8w',\n","                                                                             'cyclostationary_mean_tg_12w',\n","                                                                             'cyclostationary_mean_tg_16w',\n","                                                                             'cyclostationary_mean_tg_24w',\n","                                                                             'cyclostationary_mean_rr',\n","                                                                             'cyclostationary_mean_rr_1w',\n","                                                                             'cyclostationary_mean_rr_4w',\n","                                                                             'cyclostationary_mean_rr_8w',\n","                                                                             'cyclostationary_mean_rr_12w',\n","                                                                             'cyclostationary_mean_rr_16w',\n","                                                                             'cyclostationary_mean_rr_24w'\n","                                                                            ],\n","                                                                       target_df_trainVal, eps=eps,\n","                                                                       max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n","\n","    if os.path.isfile(snow_actual_path):\n","      output_snow,aggregate_trainVal_snow,aggregate_test_snow = aggregate_unfolded_data(snow_actual_path,['cyclostationary_mean_HS',\n","                                                                              'cyclostationary_mean_HS_1w',\n","                                                                              'cyclostationary_mean_HS_4w',\n","                                                                              'cyclostationary_mean_HS_8w',\n","                                                                              'cyclostationary_mean_HS_12w',\n","                                                                              'cyclostationary_mean_HS_16w',\n","                                                                              'cyclostationary_mean_HS_24w'\n","                                                                              ],\n","                                                                        target_df_trainVal, eps=eps,\n","                                                                        max_train='2010-01-01', max_val='2015-01-01',\n","                                                                                        max_test='2020-01-01', scale = 0.26)\n","\n","      aggregate_trainVal = pd.concat((aggregate_trainVal_snow,aggregate_trainVal),axis=1)\n","      aggregate_test = pd.concat((aggregate_test_snow,aggregate_test),axis=1)\n","\n","    if os.path.isfile(lakes_actual_path):\n","      df_lakes = pd.read_csv(lakes_actual_path)\n","      df_lakes = df_lakes.drop(\"Unnamed: 0\", axis='columns')\n","\n","      df_lakes_trainVal = df_lakes.loc[(df_lakes['date'] > '2001-01-01') & (df_lakes['date'] <= '2015-01-01'),:]\n","      df_lakes_trainVal.reset_index(inplace = True, drop = True)\n","      df_lakes_trainVal = df_lakes_trainVal.iloc[:,3:]\n","      df_lakes_test = df_lakes.loc[(df_lakes['date'] > '2015-01-01') & (df_lakes['date'] <= '2020-01-01'),:]\n","      df_lakes_test.reset_index(inplace = True, drop = True)\n","      df_lakes_test = df_lakes_test.iloc[:,3:]\n","\n","      aggregate_trainVal = pd.concat((aggregate_trainVal, df_lakes_trainVal),axis=1)\n","      aggregate_test = pd.concat((aggregate_test, df_lakes_test),axis=1)\n","\n","    selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, min(50,aggregate_trainVal.shape[1]-1), 228)\n","\n","    print('\\nFull model and selected features with wrapper\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","    print('\\nFull model and best 5 selected features with wrapper\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","    train_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_train_withSnowLakes.csv'\n","    val_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_val_withSnowLakes.csv'\n","    test_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_test_withSnowLakes.csv'\n","    X_train_wrapper = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","    X_validation_wrapper = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","    X_train_validation_wrapper = pd.concat([X_train_wrapper, X_validation_wrapper])\n","    X_test_wrapper = aggregate_test.loc[:,selected_colnames[0:5]]\n","    X_train_wrapper.to_csv(train_string, index=False)\n","    X_validation_wrapper.to_csv(val_string, index=False)\n","    X_test_wrapper.to_csv(test_string, index=False)\n","\n","    res = {\n","            \"delta\" : [],\n","            \"numSelected\" : [],\n","            \"selectedFeatures\" : []\n","        }\n","\n","    res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),\n","                                                      np.array(target_df_trainVal.mean_std),res,10,1)\n","\n","    selectedFeatures='selectedFeatures'\n","    print(f'\\n{res[selectedFeatures]}\\n')\n","\n","    selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n","\n","    print('\\nFull model and selected features with CMI\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","    print('\\nFull model and best 5 selected features with CMI\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","    train_string = destination_folder + basin + '_nonLinCFA_best5_CMI_train_withSnowLakes.csv'\n","    val_string = destination_folder + basin + '_nonLinCFA_best5_CMI_val_withSnowLakes.csv'\n","    test_string = destination_folder + basin + '_nonLinCFA_best5_CMI_test_withSnowLakes.csv'\n","\n","    X_train_CMI5 = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","    X_validation_CMI5 = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","    X_train_validation_CMI5 = pd.concat([X_train_CMI5, X_validation_CMI5])\n","    X_test_CMI5 = aggregate_test.loc[:,selected_colnames[0:5]]\n","\n","    selected_colnames_CMI5 = aggregate_trainVal.loc[:,selected_colnames[0:5]].columns.values\n","\n","    X_train_CMI5.to_csv(train_string, index=False)\n","    X_validation_CMI5.to_csv(val_string, index=False)\n","    X_test_CMI5.to_csv(test_string, index=False)\n","\n","    train_string = destination_folder + basin + '_nonLinCFA_CMI_train_withSnowLakes.csv'\n","    val_string = destination_folder + basin + '_nonLinCFA_CMI_val_withSnowLakes.csv'\n","    test_string = destination_folder + basin + '_nonLinCFA_CMI_test_withSnowLakes.csv'\n","\n","    X_train_CMI = aggregate_trainVal.loc[:410,selected_colnames]\n","    X_validation_CMI = aggregate_trainVal.loc[411:,selected_colnames]\n","    X_train_validation_CMI = pd.concat([X_train_CMI, X_validation_CMI])\n","    X_test_CMI = aggregate_test.loc[:,selected_colnames]\n","\n","    X_train_CMI.to_csv(train_string, index=False)\n","    X_validation_CMI.to_csv(val_string, index=False)\n","    X_test_CMI.to_csv(test_string, index=False)\n","\n","    print('###### Regression ######')\n","    lin_regr = LinearRegression()\n","\n","    # CMI\n","    lin_regr.fit(X_train_validation_CMI, target_df_trainVal.mean_std)\n","    print(\"Train R2 linear regression CMI: \", round(lin_regr.score(X_train_validation_CMI, target_df_trainVal.mean_std),3))\n","    print(\"Test R2 linear regression CMI: \", round(lin_regr.score(X_test_CMI, target_df_test.mean_std),3), \"\\n\")\n","\n","    # CMI best 5\n","    lin_regr.fit(X_train_validation_CMI5, target_df_trainVal.mean_std)\n","    print(\"Train R2 linear regression CMI best 5: \", round(lin_regr.score(X_train_validation_CMI5, target_df_trainVal.mean_std),3))\n","    print(\"Test R2 linear regression CMI best 5: \", round(lin_regr.score(X_test_CMI5, target_df_test.mean_std),3), \"\\n\")\n","\n","    # wrapper\n","    lin_regr.fit(X_train_validation_wrapper, target_df_trainVal.mean_std)\n","    print(\"Train R2 linear regression wrapper: \", round(lin_regr.score(X_train_validation_wrapper, target_df_trainVal.mean_std),3))\n","    print(\"Test R2 linear regression wrapper: \", round(lin_regr.score(X_test_wrapper, target_df_test.mean_std),3), \"\\n\")\n","\n","    print('###### Binary Classification ######')\n","\n","    target_df_train = target_df_train.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_val = target_df_val.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_test = target_df_test.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_trainVal = target_df_trainVal.apply(lambda x: np.sign(x.mean_std), axis=1)\n","\n","    log_regr = LogisticRegression(solver='lbfgs', random_state = 42)\n","\n","    # CMI\n","    log_regr.fit(X_train_validation_CMI, target_df_trainVal)\n","    print(\"Train accuracy logistic regression CMI: \", round(log_regr.score(X_train_validation_CMI, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression CMI: \", round(log_regr.score(X_test_CMI, target_df_test),3), \"\\n\")\n","\n","    # CMI best 5\n","    log_regr.fit(X_train_validation_CMI5, target_df_trainVal)\n","    print(\"Train accuracy logistic regression CMI best 5: \", round(log_regr.score(X_train_validation_CMI5, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression CMI best 5: \", round(log_regr.score(X_test_CMI5, target_df_test),3), \"\\n\")\n","\n","    # wrapper\n","    log_regr.fit(X_train_validation_wrapper, target_df_trainVal)\n","    print(\"Train accuracy logistic regression wrapper: \", round(log_regr.score(X_train_validation_wrapper, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression wrapper: \", round(log_regr.score(X_test_wrapper, target_df_test),3), \"\\n\")"],"id":"rXj02rbS0BL4"},{"cell_type":"markdown","metadata":{"id":"c3WXxyk95Vyk"},"source":["## Temp Prec Lakes"],"id":"c3WXxyk95Vyk"},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SpEton0e55Ev","executionInfo":{"status":"ok","timestamp":1690235626621,"user_tz":-120,"elapsed":619376,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"6d4c7a95-3459-4c13-8540-d01c15ae6321"},"outputs":[{"output_type":"stream","name":"stdout","text":["####################Adda####################\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 4\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 5\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 4\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 3\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_tg_1w_4', 'cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_tg_8w_0', 'cyclostat_level_Como_8w', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_tg_24w_1', 'cyclostat_release_Como_8w', 'cyclostat_inflow_Como_8w'], \n","\n","validation score: 0.30005434967781763, \n","\n","number of selected features: 12\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.28572941307779975, test score: -0.22742736261923335\n","Aggregate regression train score with FS: 0.2049208853512553, test score: 0.1431557717376526\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.28572941307779975, test score: -0.22742736261923335\n","Aggregate regression train score with FS: 0.19217163500084344, test score: 0.0905659481466351\n","----- MI Scores -----\n","[(24, 0.12050703744657751), (23, 0.10817618197950427), (22, 0.10458666651828148), (27, 0.10000614962421837), (29, 0.09759609497149417), (26, 0.0958421245778713), (21, 0.09503214284536106), (25, 0.09477576732312769), (44, 0.07967156830045484), (28, 0.0687728511603872), (46, 0.05155755293289637), (50, 0.047334700475274924), (32, 0.045062184539707034), (33, 0.04490981082569118), (6, 0.04316537072220728), (19, 0.0377202074188002), (31, 0.034333966317883206), (35, 0.03431807492831074), (47, 0.03414181201005571), (14, 0.03369016292903339), (34, 0.03279033144606338), (45, 0.0317000457510685), (41, 0.03044594915922083), (37, 0.029624969112521), (11, 0.029073851808119867), (39, 0.02694337568051), (48, 0.0267973393965517), (18, 0.02621617706663386), (13, 0.025000665964151257), (16, 0.023976248085649556), (5, 0.023488365216029025), (36, 0.02266872778585513), (30, 0.02222559539519485), (20, 0.021412543682473775), (38, 0.0207126706203192), (7, 0.019324748093329652), (12, 0.01745629978658138), (8, 0.016198013346771074), (4, 0.01581791892093346), (49, 0.01541299283864724), (17, 0.011543383357071963), (42, 0.007419677971127319), (2, 0.002697878809520353), (51, 0.0017077463269159448), (40, 0.00010044357455795209), (1, -0.00016759223392961325), (43, -0.0008309994106552068), (15, -0.004191326807827526), (10, -0.006035566490142361), (3, -0.0077005596866281355), (9, -0.008932884633970913), (0, -0.015002522107927406)]\n","Best MI score: 0.12050703744657751\n","Adding first best original feature: 24\n","CMI: 0.011813708728229372\n","CMI: 0.008908410233554376\n","CMI: 0.0034317376290815688\n","CMI: 0.011988055394801994\n","CMI: 0.0037080553595621457\n","CMI: 0.016511440210771083\n","CMI: 0.01287806045105161\n","CMI: 0.0030869257926980503\n","CMI: 0.024203701243435266\n","CMI: 0.00643362640081066\n","Highest CMI score: 0.024203701243435266\n","Adding original feature: 47\n","CMI: 0.005884157740854518\n","CMI: 0.006905076590937587\n","CMI: 0.0039253222200795745\n","CMI: 0.005211212771411372\n","CMI: 0.006662204094629504\n","CMI: 0.008006529334076973\n","CMI: 0.006884469963014006\n","CMI: 0.0015819581322940868\n","CMI: 0.01294950332127881\n","CMI: 0.00490846781138915\n","CMI: 0.0042710205129000145\n","CMI: 0.003169195958733634\n","CMI: 0.007733812114259442\n","CMI: 0.0005951123119307677\n","CMI: 0.0022363373854550617\n","CMI: 0.006784315477551511\n","CMI: 0.02135706382981209\n","CMI: 0.01605695422683559\n","Highest CMI score: 0.02135706382981209\n","Adding original feature: 44\n","CMI: 0.0006073943199813581\n","Highest CMI score: 0.0006073943199813581\n","Adding original feature: 3\n","CMI: 0.002726643370053322\n","CMI: 0.000537699337567088\n","CMI: 0.0003669252301613801\n","Highest CMI score: 0.002726643370053322\n","Adding original feature: 4\n","CMI: 0.0005145730453991748\n","CMI: 0.00039843695247082644\n","Highest CMI score: 0.0005145730453991748\n","Adding original feature: 0\n","Highest CMI score: -0.00018799546375525278\n","\n","[24, 47, 44, 3, 4, 0]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.28572941307779975, test score: -0.22742736261923335\n","Aggregate regression train score with FS: 0.1585722188663813, test score: 0.08959533012690957\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.28572941307779975, test score: -0.22742736261923335\n","Aggregate regression train score with FS: 0.157949536830022, test score: 0.09624036223372345\n","###### Regression ######\n","Train R2 linear regression CMI:  0.159\n","Test R2 linear regression CMI:  0.09 \n","\n","Train R2 linear regression CMI best 5:  0.158\n","Test R2 linear regression CMI best 5:  0.096 \n","\n","Train R2 linear regression wrapper:  0.192\n","Test R2 linear regression wrapper:  0.091 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.628\n","Test accuracy logistic regression CMI:  0.61 \n","\n","Train accuracy logistic regression CMI best 5:  0.623\n","Test accuracy logistic regression CMI best 5:  0.614 \n","\n","Train accuracy logistic regression wrapper:  0.649\n","Test accuracy logistic regression wrapper:  0.649 \n","\n","####################Ticino####################\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 3\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 4\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 5\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 3\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 3\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 1\n","\n","Number of features: 92\n","\n","eps value:  0.00010869565217391305\n","Number of aggregated features: 2\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_rr_1w_1', 'cyclostat_level_Maggiore_16w', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_tg_16w_2', 'cyclostat_release_Maggiore', 'cyclostat_release_Lugano_24w', 'cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_rr_8w_0', 'cyclostat_release_Maggiore_4w', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_tg_1w_2', 'cyclostat_inflow_Lugano_4w', 'cyclostat_release_Maggiore_1w', 'cyclostat_inflow_Lugano', 'cyclostat_inflow_Lugano_24w', 'cyclostat_release_Lugano_4w', 'cyclostationary_mean_tg_12w_0', 'cyclostationary_mean_tg_4w_3', 'cyclostationary_mean_tg_4w_2'], \n","\n","validation score: 0.3761561283720378, \n","\n","number of selected features: 21\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.3355436477302004, test score: -0.16305062584343122\n","Aggregate regression train score with FS: 0.25811297127730004, test score: -0.004205340737247987\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.3355436477302004, test score: -0.16305062584343122\n","Aggregate regression train score with FS: 0.20813248314885502, test score: 0.21440078939841845\n","----- MI Scores -----\n","[(42, 0.12333236920388603), (45, 0.11043061820217501), (43, 0.09301073215020078), (48, 0.08598787349447463), (49, 0.08117728514132373), (44, 0.0792921840495771), (46, 0.07414296454034455), (47, 0.07273765839428532), (67, 0.06849890021359188), (68, 0.06842462865595438), (53, 0.06443446394377765), (18, 0.06184797162703089), (66, 0.061138128729906156), (13, 0.053577691156415), (50, 0.05234511965473389), (62, 0.049513412252677226), (69, 0.04938930727611444), (51, 0.04826659946172222), (19, 0.04364098057909389), (29, 0.040809628895743605), (63, 0.04073485120365516), (25, 0.04069335370791208), (20, 0.03926344530783084), (52, 0.03888438583912336), (17, 0.037283160282428215), (28, 0.03550989203356637), (27, 0.03485461756185672), (55, 0.033963563664343784), (24, 0.03382027585182155), (14, 0.03327839446370728), (64, 0.03312458188187903), (10, 0.03290128137418164), (73, 0.03130985396849788), (12, 0.03069097990316162), (8, 0.028115445603095725), (26, 0.027803684700859865), (72, 0.027672591502415116), (11, 0.027627615346643635), (0, 0.02757448569316106), (70, 0.02756612860711409), (56, 0.027512387888113166), (35, 0.026073634227453846), (15, 0.022299320489896492), (7, 0.02203128452691925), (21, 0.02011684688620335), (57, 0.01965200109139666), (2, 0.017546793819884544), (54, 0.017469595475586026), (3, 0.01572980768362217), (1, 0.015578251454588112), (71, 0.015336378930915582), (61, 0.013579436658579852), (6, 0.013408519478414259), (58, 0.012659997555127629), (16, 0.009915107556890602), (60, 0.009042428305984665), (39, 0.008499367005721717), (40, 0.00799093388470823), (59, 0.007535869077497878), (33, 0.007494798257367092), (38, 0.005880891494174583), (31, 0.005144395995900352), (37, 0.0045430970084845935), (5, 0.00407310524310762), (41, 0.003815244698354896), (65, 0.0035001628212959377), (32, 0.0028954496097208468), (4, 0.0016883176844555783), (9, 0.0010365404494602699), (34, 0.0003716609681883357), (36, -0.006684512626610416), (23, -0.008527922368286428), (30, -0.010906781607438548), (22, -0.017375161372504853)]\n","Best MI score: 0.12333236920388603\n","Adding first best original feature: 42\n","CMI: 0.013370496043136879\n","CMI: 0.009115224676631936\n","CMI: 3.9393583136718147e-05\n","CMI: 0.02258199918243449\n","CMI: 0.003727761761269252\n","CMI: 0.013566120938100487\n","CMI: 0.011536999061692907\n","CMI: 0.00891090577700264\n","CMI: 0.00269456934512792\n","CMI: 0.003915297508432766\n","CMI: 0.0074244483499040365\n","CMI: 0.009875762928394996\n","CMI: 0.008345749084033946\n","CMI: 0.0056715699218127386\n","CMI: 0.031167288091795378\n","CMI: 0.022041052925945007\n","CMI: 0.033864833377157635\n","CMI: 0.014572471172885834\n","CMI: 0.007241468996928055\n","CMI: 0.005626105595362155\n","CMI: 0.00457555714095452\n","Highest CMI score: 0.033864833377157635\n","Adding original feature: 68\n","CMI: 0.0021420490149900717\n","CMI: 0.0003974688419258743\n","CMI: 0.00010909473937642522\n","CMI: 0.001603963980776224\n","CMI: 0.007462678243016274\n","CMI: 0.004798959315415824\n","CMI: 0.005988560065941978\n","CMI: 0.00026017568164984906\n","CMI: 0.01630445543122097\n","CMI: 0.0050289656527783\n","Highest CMI score: 0.01630445543122097\n","Adding original feature: 44\n","CMI: 0.0024453162673578055\n","CMI: 0.0008979870519092714\n","CMI: 4.4707289490492075e-05\n","CMI: 0.00010432968179446833\n","CMI: 0.00010432968179446833\n","Highest CMI score: 0.0024453162673578055\n","Adding original feature: 0\n","CMI: 7.981215956173737e-05\n","CMI: 0.00012038040207051903\n","Highest CMI score: 0.00012038040207051903\n","Adding original feature: 7\n","CMI: 7.981215956173737e-05\n","Highest CMI score: 7.981215956173737e-05\n","Adding original feature: 3\n","Highest CMI score: 0.0\n","\n","[42, 68, 44, 0, 7, 3]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.3355436477302004, test score: -0.16305062584343122\n","Aggregate regression train score with FS: 0.18400612336302413, test score: 0.12628486988167842\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.3355436477302004, test score: -0.16305062584343122\n","Aggregate regression train score with FS: 0.18109803030894, test score: 0.15030796612094244\n","###### Regression ######\n","Train R2 linear regression CMI:  0.184\n","Test R2 linear regression CMI:  0.126 \n","\n","Train R2 linear regression CMI best 5:  0.181\n","Test R2 linear regression CMI best 5:  0.15 \n","\n","Train R2 linear regression wrapper:  0.208\n","Test R2 linear regression wrapper:  0.214 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.653\n","Test accuracy logistic regression CMI:  0.658 \n","\n","Train accuracy logistic regression CMI best 5:  0.654\n","Test accuracy logistic regression CMI best 5:  0.667 \n","\n","Train accuracy logistic regression wrapper:  0.671\n","Test accuracy logistic regression wrapper:  0.627 \n","\n","####################Oglio_Iseo####################\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 3\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 2\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 3\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 2\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","Number of features: 74\n","\n","eps value:  0.00013513513513513514\n","Number of aggregated features: 1\n","\n","\n","\n","selected columns: ['cyclostationary_mean_tg_1w_1', 'cyclostat_level_Iseo_4w', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_rr_1w_0', 'cyclostat_level_Iseo', 'cyclostationary_mean_tg_1w_0', 'cyclostat_inflow_Iseo_12w', 'cyclostat_release_Iseo_8w', 'cyclostat_level_Iseo_12w', 'cyclostationary_mean_rr_12w_0', 'cyclostat_inflow_Iseo_8w', 'cyclostationary_mean_rr_2', 'cyclostat_level_Iseo_8w', 'cyclostationary_mean_tg_8w_0'], \n","\n","validation score: 0.3345468741174783, \n","\n","number of selected features: 14\n","\n","Full model and selected features with wrapper\n","\n","Full aggregate regression train score: 0.2582438054063898, test score: 0.17222999443393794\n","Aggregate regression train score with FS: 0.22915131755866058, test score: 0.18637564110543858\n","\n","Full model and best 5 selected features with wrapper\n","\n","Full aggregate regression train score: 0.2582438054063898, test score: 0.17222999443393794\n","Aggregate regression train score with FS: 0.20895673055607833, test score: 0.21101851407257155\n","----- MI Scores -----\n","[(22, 0.11076080233409458), (24, 0.08993182369969176), (25, 0.08535352628620278), (21, 0.07386411287408363), (34, 0.06844398820510891), (23, 0.06408261327785464), (36, 0.06299091012845069), (17, 0.05968732320210273), (39, 0.05651307447517284), (35, 0.05543184789542872), (12, 0.04372805132684975), (11, 0.039471396440316206), (18, 0.03711942965571348), (19, 0.03691882835251606), (13, 0.03483459143211405), (10, 0.031873197720609356), (27, 0.02979180239377202), (26, 0.026674163534289076), (20, 0.02664367807831303), (33, 0.025426898033636097), (5, 0.025109580112678557), (37, 0.024975603937788842), (7, 0.023989378841521084), (15, 0.02381538748472473), (16, 0.021209988210563694), (31, 0.01719526554739976), (6, 0.017192586093223473), (40, 0.015340572237401038), (14, 0.01364174766339926), (8, 0.012905671124772457), (38, 0.012741180847832224), (0, 0.010014735062162055), (29, 0.00928620532801559), (32, 0.005595837322748134), (1, 0.0044229062886479206), (28, -0.0008272018359696276), (9, -0.0011342245589047988), (4, -0.0019741396983703834), (30, -0.0020231794309610793), (3, -0.005006423360942694), (2, -0.007477247469657561)]\n","Best MI score: 0.11076080233409458\n","Adding first best original feature: 22\n","CMI: 0.0013076969264405186\n","CMI: 0.004057567563985273\n","CMI: 0.017334319624676464\n","CMI: 0.02335160674909731\n","CMI: 0.0008355480876596488\n","CMI: 0.0068376192263017305\n","CMI: 4.136378956480502e-05\n","Highest CMI score: 0.02335160674909731\n","Adding original feature: 36\n","CMI: 0.00784044434828221\n","Highest CMI score: 0.00784044434828221\n","Adding original feature: 21\n","Highest CMI score: -0.015369096733601179\n","\n","[22, 36, 21]\n","\n","\n","Full model and selected features with CMI\n","\n","Full aggregate regression train score: 0.2582438054063898, test score: 0.17222999443393794\n","Aggregate regression train score with FS: 0.14395642022556665, test score: 0.19993206756174053\n","\n","Full model and best 5 selected features with CMI\n","\n","Full aggregate regression train score: 0.2582438054063898, test score: 0.17222999443393794\n","Aggregate regression train score with FS: 0.14395642022556665, test score: 0.19993206756174053\n","###### Regression ######\n","Train R2 linear regression CMI:  0.144\n","Test R2 linear regression CMI:  0.2 \n","\n","Train R2 linear regression CMI best 5:  0.144\n","Test R2 linear regression CMI best 5:  0.2 \n","\n","Train R2 linear regression wrapper:  0.209\n","Test R2 linear regression wrapper:  0.211 \n","\n","###### Binary Classification ######\n","Train accuracy logistic regression CMI:  0.649\n","Test accuracy logistic regression CMI:  0.649 \n","\n","Train accuracy logistic regression CMI best 5:  0.649\n","Test accuracy logistic regression CMI best 5:  0.649 \n","\n","Train accuracy logistic regression wrapper:  0.64\n","Test accuracy logistic regression wrapper:  0.636 \n","\n"]}],"source":["basins = ['Adda', 'Ticino', 'Oglio_Iseo']\n","path_target = \"./csv/\"\n","path_features='./features_allvalues/'\n","path_features_lakes='./lakes/'\n","destination_folder = './NonLinCFA/temp_prec_lakes/internal_ordering/'\n","\n","for basin in basins:\n","    print('####################' + basin + '####################')\n","\n","    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', path=path_target+basin+'.csv')\n","\n","    eps = 0.01\n","    actual_path = path_features+basin+'_aggreg.csv'\n","    lakes_actual_path = path_features_lakes + 'lakes_' + basin + '_with_aggreg.csv'\n","\n","    output,aggregate_trainVal_temp_prec,aggregate_test_temp_prec = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg',\n","                                                                             'cyclostationary_mean_tg_1w',\n","                                                                             'cyclostationary_mean_tg_4w',\n","                                                                             'cyclostationary_mean_tg_8w',\n","                                                                             'cyclostationary_mean_tg_12w',\n","                                                                             'cyclostationary_mean_tg_16w',\n","                                                                             'cyclostationary_mean_tg_24w',\n","                                                                             'cyclostationary_mean_rr',\n","                                                                             'cyclostationary_mean_rr_1w',\n","                                                                             'cyclostationary_mean_rr_4w',\n","                                                                             'cyclostationary_mean_rr_8w',\n","                                                                             'cyclostationary_mean_rr_12w',\n","                                                                             'cyclostationary_mean_rr_16w',\n","                                                                             'cyclostationary_mean_rr_24w'\n","                                                                            ],\n","                                                                       target_df_trainVal, eps=eps,\n","                                                                       max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n","\n","    if os.path.isfile(lakes_actual_path):\n","      df_lakes = pd.read_csv(lakes_actual_path)\n","\n","      df_lakes = df_lakes.drop(\"Unnamed: 0\", axis='columns')\n","\n","      df_lakes_trainVal = df_lakes.loc[(df_lakes['date'] > '2001-01-01') & (df_lakes['date'] <= '2015-01-01'),:]\n","      df_lakes_trainVal.reset_index(inplace = True, drop = True)\n","      df_lakes_trainVal = df_lakes_trainVal.iloc[:,3:]\n","      df_lakes_test = df_lakes.loc[(df_lakes['date'] > '2015-01-01') & (df_lakes['date'] <= '2020-01-01'),:]\n","      df_lakes_test.reset_index(inplace = True, drop = True)\n","      df_lakes_test = df_lakes_test.iloc[:,3:]\n","\n","      aggregate_trainVal = pd.concat((df_lakes_trainVal,aggregate_trainVal_temp_prec),axis=1)\n","      aggregate_test = pd.concat((df_lakes_test,aggregate_test_temp_prec),axis=1)\n","\n","    selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, min(50,aggregate_trainVal.shape[1]-1), 228)\n","\n","    print('\\nFull model and selected features with wrapper\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","    print('\\nFull model and best 5 selected features with wrapper\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","    train_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_train_withLakes.csv'\n","    val_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_val_withLakes.csv'\n","    test_string = destination_folder + basin + '_nonLinCFA_wrapper_best5_test_withLakes.csv'\n","    X_train_wrapper = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","    X_validation_wrapper = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","    X_train_validation_wrapper = pd.concat([X_train_wrapper, X_validation_wrapper])\n","    X_test_wrapper = aggregate_test.loc[:,selected_colnames[0:5]]\n","    X_train_wrapper.to_csv(train_string, index=False)\n","    X_validation_wrapper.to_csv(val_string, index=False)\n","    X_test_wrapper.to_csv(test_string, index=False)\n","\n","    res = {\n","            \"delta\" : [],\n","            \"numSelected\" : [],\n","            \"selectedFeatures\" : []\n","        }\n","\n","    res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),\n","                                                      np.array(target_df_trainVal.mean_std),res,10,1)\n","\n","    selectedFeatures='selectedFeatures'\n","    print(f'\\n{res[selectedFeatures]}\\n')\n","\n","    selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n","\n","    print('\\nFull model and selected features with CMI\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n","\n","    print('\\nFull model and best 5 selected features with CMI\\n')\n","    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n","\n","    train_string = destination_folder + basin + '_nonLinCFA_best5_CMI_train_withLakes.csv'\n","    val_string = destination_folder + basin + '_nonLinCFA_best5_CMI_val_withLakes.csv'\n","    test_string = destination_folder + basin + '_nonLinCFA_best5_CMI_test_withLakes.csv'\n","\n","    X_train_CMI5 = aggregate_trainVal.loc[:410,selected_colnames[0:5]]\n","    X_validation_CMI5 = aggregate_trainVal.loc[411:,selected_colnames[0:5]]\n","    X_train_validation_CMI5 = pd.concat([X_train_CMI5, X_validation_CMI5])\n","    X_test_CMI5 = aggregate_test.loc[:,selected_colnames[0:5]]\n","\n","    selected_colnames_CMI5 = aggregate_trainVal.loc[:,selected_colnames[0:5]].columns.values\n","\n","    X_train_CMI5.to_csv(train_string, index=False)\n","    X_validation_CMI5.to_csv(val_string, index=False)\n","    X_test_CMI5.to_csv(test_string, index=False)\n","\n","    train_string = destination_folder + basin + '_nonLinCFA_CMI_train_withLakes.csv'\n","    val_string = destination_folder + basin + '_nonLinCFA_CMI_val_withLakes.csv'\n","    test_string = destination_folder + basin + '_nonLinCFA_CMI_test_withLakes.csv'\n","\n","    X_train_CMI = aggregate_trainVal.loc[:410,selected_colnames]\n","    X_validation_CMI = aggregate_trainVal.loc[411:,selected_colnames]\n","    X_train_validation_CMI = pd.concat([X_train_CMI, X_validation_CMI])\n","    X_test_CMI = aggregate_test.loc[:,selected_colnames]\n","\n","    X_train_CMI.to_csv(train_string, index=False)\n","    X_validation_CMI.to_csv(val_string, index=False)\n","    X_test_CMI.to_csv(test_string, index=False)\n","\n","    print('###### Regression ######')\n","    lin_regr = LinearRegression()\n","\n","    # CMI\n","    lin_regr.fit(X_train_validation_CMI, target_df_trainVal.mean_std)\n","    print(\"Train R2 linear regression CMI: \", round(lin_regr.score(X_train_validation_CMI, target_df_trainVal.mean_std),3))\n","    print(\"Test R2 linear regression CMI: \", round(lin_regr.score(X_test_CMI, target_df_test.mean_std),3), \"\\n\")\n","\n","    # CMI best 5\n","    lin_regr.fit(X_train_validation_CMI5, target_df_trainVal.mean_std)\n","    print(\"Train R2 linear regression CMI best 5: \", round(lin_regr.score(X_train_validation_CMI5, target_df_trainVal.mean_std),3))\n","    print(\"Test R2 linear regression CMI best 5: \", round(lin_regr.score(X_test_CMI5, target_df_test.mean_std),3), \"\\n\")\n","\n","    # wrapper\n","    lin_regr.fit(X_train_validation_wrapper, target_df_trainVal.mean_std)\n","    print(\"Train R2 linear regression wrapper: \", round(lin_regr.score(X_train_validation_wrapper, target_df_trainVal.mean_std),3))\n","    print(\"Test R2 linear regression wrapper: \", round(lin_regr.score(X_test_wrapper, target_df_test.mean_std),3), \"\\n\")\n","\n","    print('###### Binary Classification ######')\n","\n","    target_df_train = target_df_train.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_val = target_df_val.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_test = target_df_test.apply(lambda x: np.sign(x.mean_std), axis=1)\n","    target_df_trainVal = target_df_trainVal.apply(lambda x: np.sign(x.mean_std), axis=1)\n","\n","    log_regr = LogisticRegression(solver='lbfgs', random_state = 42)\n","\n","    # CMI\n","    log_regr.fit(X_train_validation_CMI, target_df_trainVal)\n","    print(\"Train accuracy logistic regression CMI: \", round(log_regr.score(X_train_validation_CMI, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression CMI: \", round(log_regr.score(X_test_CMI, target_df_test),3), \"\\n\")\n","\n","    # CMI best 5\n","    log_regr.fit(X_train_validation_CMI5, target_df_trainVal)\n","    print(\"Train accuracy logistic regression CMI best 5: \", round(log_regr.score(X_train_validation_CMI5, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression CMI best 5: \", round(log_regr.score(X_test_CMI5, target_df_test),3), \"\\n\")\n","\n","    # wrapper\n","    log_regr.fit(X_train_validation_wrapper, target_df_trainVal)\n","    print(\"Train accuracy logistic regression wrapper: \", round(log_regr.score(X_train_validation_wrapper, target_df_trainVal),3))\n","    print(\"Test accuracy logistic regression wrapper: \", round(log_regr.score(X_test_wrapper, target_df_test),3), \"\\n\")"],"id":"SpEton0e55Ev"},{"cell_type":"markdown","metadata":{"id":"rYpR9P_TOe31"},"source":["## Multi task scores"],"id":"rYpR9P_TOe31"},{"cell_type":"code","execution_count":null,"metadata":{"id":"RJvLiezWRmUG"},"outputs":[],"source":["# for binary classification\n","\n","from sklearn.metrics import accuracy_score\n","def MTL_scores(clust_basins, df_train, df_val, df_test, targets_df_train, targets_df_val, targets_df_test):\n","\n","    colnames = [x for x in df_train.columns if x.startswith(tuple(clust_basins))]\n","\n","    clusterdf_train_withClass = pd.DataFrame()\n","    clusterdf_val_withClass = pd.DataFrame()\n","    clusterdf_test_withClass = pd.DataFrame()\n","\n","    for i in range(len(clust_basins)):\n","        clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((df_train[colnames],pd.DataFrame(1+i*np.ones(len(df_train)),columns=['basin'])),axis=1)),axis=0)\n","        clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((df_val[colnames],pd.DataFrame(1+i*np.ones(len(df_val)),columns=['basin'])),axis=1)),axis=0)\n","        clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((df_test[colnames],pd.DataFrame(1+i*np.ones(len(df_test)),columns=['basin'])),axis=1)),axis=0)\n","\n","    for i in range(len(clust_basins)):\n","        clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n","        clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n","        clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n","\n","    clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n","    clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n","    clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n","\n","    targets_df_train_unfolded = pd.DataFrame()\n","    targets_df_val_unfolded = pd.DataFrame()\n","    targets_df_test_unfolded = pd.DataFrame()\n","\n","    for basin in clust_basins:\n","        targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n","        targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n","        targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n","    targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n","    targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n","    targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n","\n","    # same scores changing the solver, some differences changing penalty, some improve with l1\n","    model_ohe = LogisticRegression(max_iter = 500)\n","    model_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)).values,pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)).values.ravel())\n","\n","    for basin in clust_basins:\n","        print(basin)\n","        res = model_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass[basin]==1].values)\n","        print(accuracy_score(targets_df_test[basin].values.ravel(), res))"],"id":"RJvLiezWRmUG"},{"cell_type":"code","execution_count":7,"metadata":{"id":"U-SHWiBDOhY_","executionInfo":{"status":"ok","timestamp":1690352755616,"user_tz":-120,"elapsed":275,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"outputs":[],"source":["# for linear regression\n","\n","def MTL_scores(clust_basins, df_train, df_val, df_test, targets_df_train, targets_df_val, targets_df_test):\n","\n","    colnames = [x for x in df_train.columns if x.startswith(tuple(clust_basins))]\n","\n","    clusterdf_train_withClass = pd.DataFrame()\n","    clusterdf_val_withClass = pd.DataFrame()\n","    clusterdf_test_withClass = pd.DataFrame()\n","\n","    for i in range(len(clust_basins)):\n","        clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((df_train[colnames],pd.DataFrame(1+i*np.ones(len(df_train)),columns=['basin'])),axis=1)),axis=0)\n","        clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((df_val[colnames],pd.DataFrame(1+i*np.ones(len(df_val)),columns=['basin'])),axis=1)),axis=0)\n","        clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((df_test[colnames],pd.DataFrame(1+i*np.ones(len(df_test)),columns=['basin'])),axis=1)),axis=0)\n","\n","    for i in range(len(clust_basins)):\n","        clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n","        clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n","        clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n","\n","    clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n","    clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n","    clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n","\n","    targets_df_train_unfolded = pd.DataFrame()\n","    targets_df_val_unfolded = pd.DataFrame()\n","    targets_df_test_unfolded = pd.DataFrame()\n","\n","    for basin in clust_basins:\n","        targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n","        targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n","        targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n","    targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n","    targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n","    targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n","\n","    # same scores changing the solver, some differences changing penalty, some improve with l1\n","    model_ohe = LinearRegression()\n","    model_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)).values,pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)).values.ravel())\n","\n","    for basin in clust_basins:\n","        print(basin)\n","        res = model_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass[basin]==1].values)\n","        print(r2_score(targets_df_test[basin].values.ravel(), res))"],"id":"U-SHWiBDOhY_"},{"cell_type":"code","execution_count":8,"metadata":{"id":"Knf0pZI5Zyf4","executionInfo":{"status":"ok","timestamp":1690352758718,"user_tz":-120,"elapsed":542,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"outputs":[],"source":["### continuous targets\n","basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona','Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n","path_targets = \"./csv/\"\n","targets_df_train = pd.DataFrame()\n","targets_df_val = pd.DataFrame()\n","targets_df_test = pd.DataFrame()\n","targets_df_trainVal = pd.DataFrame()\n","\n","for basin in basins:\n","    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01',\n","                                                                                     max_test='2020-01-01', path=path_targets+basin+'.csv',\n","                                                                                     window_size = 1)\n","    targets_df_train[basin] = target_df_train.mean_std\n","    targets_df_val[basin] = target_df_val.mean_std\n","    targets_df_test[basin] = target_df_test.mean_std\n","    targets_df_trainVal[basin] = target_df_trainVal.mean_std"],"id":"Knf0pZI5Zyf4"},{"cell_type":"code","execution_count":null,"metadata":{"id":"zvHEyv7_O-nx"},"outputs":[],"source":["### binary targets\n","basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona','Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n","path_targets = \"./csv/\"\n","targets_df_train = pd.DataFrame()\n","targets_df_val = pd.DataFrame()\n","targets_df_test = pd.DataFrame()\n","targets_df_trainVal = pd.DataFrame()\n","\n","for basin in basins:\n","    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target_binary('',max_train='2010-01-01', max_val='2015-01-01',\n","                                                                                            max_test='2020-01-01', path=path_targets+basin+'.csv',\n","                                                                                            threshold = None, nopeaks = False,\n","                                                                                            window_size = 1)\n","    targets_df_train[basin] = target_df_train.mean_std\n","    targets_df_val[basin] = target_df_val.mean_std\n","    targets_df_test[basin] = target_df_test.mean_std\n","    targets_df_trainVal[basin] = target_df_trainVal.mean_std"],"id":"zvHEyv7_O-nx"},{"cell_type":"markdown","source":["# Chosen Features analysis"],"metadata":{"id":"S8UREqvlGqSI"},"id":"S8UREqvlGqSI"},{"cell_type":"code","source":["basin = 'Oglio_Iseo'\n","path_features = './NonLinCFA/temp_prec_snow_lakes_copernicus/'\n","train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_train_withSnowLakes.csv')\n","\n","print(\"Features chosen by CMI for \", basin, \" \\ntaken temp, prec, snow, lakes now: \")\n","idx_dic = {}\n","for col in train_temp.columns:\n","    idx_dic[col] = train_temp.columns.get_loc(col)\n","print('\\n'.join(f'{value}: {key}' for key, value in idx_dic.items()))"],"metadata":{"id":"EmfUF-jbGtRW"},"id":"EmfUF-jbGtRW","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Temp Prec"],"metadata":{"id":"RNVfpQiZCBLm"},"id":"RNVfpQiZCBLm"},{"cell_type":"code","source":["basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona',\n","          'Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n","\n","### CMI best5 features\n","path_features = './NonLinCFA/temp_prec_internal_ordering/dyn_eps_lin/'\n","\n","best5_CMI_fulldf_train = pd.DataFrame()\n","best5_CMI_fulldf_val = pd.DataFrame()\n","best5_CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_train.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_val.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_test.csv')\n","    best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"Xj5e7hEjCIDw"},"id":"Xj5e7hEjCIDw","execution_count":null,"outputs":[]},{"cell_type":"code","source":["basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona',\n","          'Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n","\n","### CMI features\n","path_features = './NonLinCFA/temp_prec_internal_ordering/dyn_eps_lin/'\n","\n","CMI_fulldf_train = pd.DataFrame()\n","CMI_fulldf_val = pd.DataFrame()\n","CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_train.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_val.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_test.csv')\n","    CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"khp5J7YHCvdo"},"id":"khp5J7YHCvdo","execution_count":null,"outputs":[]},{"cell_type":"code","source":["basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona',\n","          'Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n","\n","### wrapper best5 features\n","path_features = './NonLinCFA/temp_prec_internal_ordering/dyn_eps_lin/'\n","\n","best5_wrapper_fulldf_train = pd.DataFrame()\n","best5_wrapper_fulldf_val = pd.DataFrame()\n","best5_wrapper_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_train.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_val.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_test.csv')\n","    best5_wrapper_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_wrapper_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_wrapper_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"miLfnNeKCvDx"},"id":"miLfnNeKCvDx","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Temp Prec Snow"],"metadata":{"id":"kve2cBhjCC-A"},"id":"kve2cBhjCC-A"},{"cell_type":"code","source":["basins = ['Adda', 'Oglio_Iseo', 'Ticino', 'Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n","\n","### CMI best5 features\n","path_features = './NonLinCFA/temp_prec_snow_copernicus/relevant_coords/'\n","\n","best5_CMI_fulldf_train = pd.DataFrame()\n","best5_CMI_fulldf_val = pd.DataFrame()\n","best5_CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_train_withSnow.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_val_withSnow.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_test_withSnow.csv')\n","    best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n","\n","basin = 'Lambro_Olona'\n","path_features = './NonLinCFA/temp_prec_internal_ordering/dyn_eps_lin/'\n","\n","train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_train.csv')\n","val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_val.csv')\n","test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_test.csv')\n","best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"E_uHxe7dG7Qt","executionInfo":{"status":"ok","timestamp":1690352763818,"user_tz":-120,"elapsed":316,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"E_uHxe7dG7Qt","execution_count":9,"outputs":[]},{"cell_type":"code","source":["basins = ['Adda', 'Oglio_Iseo', 'Ticino', 'Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n","\n","### CMI features\n","path_features = './NonLinCFA/temp_prec_snow_copernicus/relevant_coords/'\n","\n","CMI_fulldf_train = pd.DataFrame()\n","CMI_fulldf_val = pd.DataFrame()\n","CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_train_withSnow.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_val_withSnow.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_test_withSnow.csv')\n","    CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n","\n","basin = 'Lambro_Olona'\n","path_features = './NonLinCFA/temp_prec_internal_ordering/dyn_eps_lin/'\n","\n","train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_train.csv')\n","val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_val.csv')\n","test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_test.csv')\n","CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"Wk_qcjB-G7BB","executionInfo":{"status":"ok","timestamp":1690352764240,"user_tz":-120,"elapsed":6,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"Wk_qcjB-G7BB","execution_count":10,"outputs":[]},{"cell_type":"code","source":["basins = ['Adda', 'Oglio_Iseo', 'Ticino', 'Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n","\n","### wrapper best5 features\n","path_features = './NonLinCFA/temp_prec_snow_copernicus/relevant_coords/'\n","\n","best5_wrapper_fulldf_train = pd.DataFrame()\n","best5_wrapper_fulldf_val = pd.DataFrame()\n","best5_wrapper_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_train_withSnow.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_val_withSnow.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_test_withSnow.csv')\n","    best5_wrapper_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_wrapper_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_wrapper_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n","\n","basin = 'Lambro_Olona'\n","path_features = './NonLinCFA/temp_prec_internal_ordering/dyn_eps_lin/'\n","\n","train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_train.csv')\n","val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_val.csv')\n","test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_test.csv')\n","best5_wrapper_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","best5_wrapper_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","best5_wrapper_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"dvBuVDulG62M","executionInfo":{"status":"ok","timestamp":1690352764609,"user_tz":-120,"elapsed":374,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"dvBuVDulG62M","execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Temp Prec Snow Lakes"],"metadata":{"id":"N1bBu9FICE0w"},"id":"N1bBu9FICE0w"},{"cell_type":"code","source":["basins = ['Ticino', 'Oglio_Iseo', 'Adda', 'Lambro_Olona']\n","\n","### CMI best5 features\n","path_features = './NonLinCFA/temp_prec_snow_lakes_copernicus/'\n","\n","best5_CMI_fulldf_train = pd.DataFrame()\n","best5_CMI_fulldf_val = pd.DataFrame()\n","best5_CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_train_withSnowLakes.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_val_withSnowLakes.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_test_withSnowLakes.csv')\n","    best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"BuZc92DgtalV","executionInfo":{"status":"ok","timestamp":1690316794519,"user_tz":-120,"elapsed":6700,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"BuZc92DgtalV","execution_count":8,"outputs":[]},{"cell_type":"code","source":["basins = ['Ticino', 'Oglio_Iseo', 'Adda', 'Lambro_Olona']\n","\n","### CMI features\n","path_features = './NonLinCFA/temp_prec_snow_lakes_copernicus/'\n","\n","CMI_fulldf_train = pd.DataFrame()\n","CMI_fulldf_val = pd.DataFrame()\n","CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_train_withSnowLakes.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_val_withSnowLakes.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_test_withSnowLakes.csv')\n","    CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"APyv_LTJtaad","executionInfo":{"status":"ok","timestamp":1690316802447,"user_tz":-120,"elapsed":5616,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"APyv_LTJtaad","execution_count":9,"outputs":[]},{"cell_type":"code","source":["basins = ['Ticino', 'Oglio_Iseo', 'Adda', 'Lambro_Olona']\n","\n","### wrapper best5 features\n","path_features = './NonLinCFA/temp_prec_snow_lakes_copernicus/'\n","\n","best5_wrapper_fulldf_train = pd.DataFrame()\n","best5_wrapper_fulldf_val = pd.DataFrame()\n","best5_wrapper_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_train_withSnowLakes.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_val_withSnowLakes.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_test_withSnowLakes.csv')\n","    best5_wrapper_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_wrapper_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_wrapper_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"gKUod4Q0taS6","executionInfo":{"status":"ok","timestamp":1690316808610,"user_tz":-120,"elapsed":6170,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"gKUod4Q0taS6","execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Temp Prec Lakes"],"metadata":{"id":"UNfmcUZMG9Tb"},"id":"UNfmcUZMG9Tb"},{"cell_type":"code","source":["basins = ['Ticino', 'Oglio_Iseo', 'Adda']\n","\n","### CMI best5 features\n","path_features = './NonLinCFA/temp_prec_lakes/internal_ordering/'\n","\n","best5_CMI_fulldf_train = pd.DataFrame()\n","best5_CMI_fulldf_val = pd.DataFrame()\n","best5_CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_train_withLakes.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_val_withLakes.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_test_withLakes.csv')\n","    best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n","\n","basin = 'Lambro_Olona'\n","path_features = './NonLinCFA/temp_prec_internal_ordering/dyn_eps_lin/'\n","\n","train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_train.csv')\n","val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_val.csv')\n","test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_test.csv')\n","best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"_iQOLN1F-SBQ","executionInfo":{"status":"ok","timestamp":1690317669006,"user_tz":-120,"elapsed":3025,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"_iQOLN1F-SBQ","execution_count":27,"outputs":[]},{"cell_type":"code","source":["basins = ['Ticino', 'Oglio_Iseo', 'Adda']\n","\n","### CMI features\n","path_features = './NonLinCFA/temp_prec_lakes/internal_ordering/'\n","\n","CMI_fulldf_train = pd.DataFrame()\n","CMI_fulldf_val = pd.DataFrame()\n","CMI_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_train_withLakes.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_val_withLakes.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_test_withLakes.csv')\n","    CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n","\n","basin = 'Lambro_Olona'\n","path_features = './NonLinCFA/temp_prec_internal_ordering/dyn_eps_lin/'\n","\n","train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_train.csv')\n","val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_val.csv')\n","test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_test.csv')\n","CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"BiPl1ztNwYxf","executionInfo":{"status":"ok","timestamp":1690317697714,"user_tz":-120,"elapsed":1515,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"BiPl1ztNwYxf","execution_count":29,"outputs":[]},{"cell_type":"code","source":["basins = ['Ticino', 'Oglio_Iseo', 'Adda']\n","\n","### wrapper best5 features\n","path_features = './NonLinCFA/temp_prec_lakes/internal_ordering/'\n","\n","best5_wrapper_fulldf_train = pd.DataFrame()\n","best5_wrapper_fulldf_val = pd.DataFrame()\n","best5_wrapper_fulldf_test = pd.DataFrame()\n","\n","for basin in basins:\n","    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_train_withLakes.csv')\n","    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_val_withLakes.csv')\n","    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_test_withLakes.csv')\n","    best5_wrapper_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","    best5_wrapper_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","    best5_wrapper_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n","\n","basin = 'Lambro_Olona'\n","path_features = './NonLinCFA/temp_prec_internal_ordering/dyn_eps_lin/'\n","\n","train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_train.csv')\n","val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_val.csv')\n","test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_test.csv')\n","best5_wrapper_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n","best5_wrapper_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n","best5_wrapper_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp"],"metadata":{"id":"ZU0-P47swYgH","executionInfo":{"status":"ok","timestamp":1690317715981,"user_tz":-120,"elapsed":1938,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}}},"id":"ZU0-P47swYgH","execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["# MTL scores"],"metadata":{"id":"L9MRKI0cDZG0"},"id":"L9MRKI0cDZG0"},{"cell_type":"markdown","source":["## CMI best 5"],"metadata":{"id":"tsacTVIvDgiT"},"id":"tsacTVIvDgiT"},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":318,"status":"ok","timestamp":1690352258282,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"iqbj2OxROhLu","outputId":"7b385d93-cbe8-48fc-8c46-96a1ca979419"},"outputs":[{"output_type":"stream","name":"stdout","text":["Emiliani1\n","-0.014517744669723553\n","Emiliani2\n","-0.010037458448500791\n","Garda_Mincio\n","-0.07339744154500183\n"]}],"source":["MTL_scores(clust_basins=['Emiliani1','Emiliani2','Garda_Mincio'], df_train=best5_CMI_fulldf_train, df_val=best5_CMI_fulldf_val, df_test=best5_CMI_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"id":"iqbj2OxROhLu"},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1690352258690,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"CjW2OS-5kMtt","outputId":"5eef0dc6-3cf7-4908-a5ec-41c448fcd38c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dora\n","-0.29205489910850146\n","Piemonte_Sud\n","-0.05206902691266557\n","Piemonte_Nord\n","0.0585558916397908\n"]}],"source":["MTL_scores(clust_basins=['Dora','Piemonte_Sud', 'Piemonte_Nord'], df_train=best5_CMI_fulldf_train, df_val=best5_CMI_fulldf_val, df_test=best5_CMI_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"id":"CjW2OS-5kMtt"},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":325,"status":"ok","timestamp":1690352259012,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"},"user_tz":-120},"id":"51c2grtqlZR2","outputId":"a90958dc-0b6d-45a2-a6a1-30eda93eddd6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Adda\n","0.1804925042258657\n","Lambro_Olona\n","0.14283102959093497\n","Oglio_Iseo\n","0.18119239504163553\n","Ticino\n","0.12752723907741315\n"]}],"source":["MTL_scores(clust_basins=['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino'], df_train=best5_CMI_fulldf_train, df_val=best5_CMI_fulldf_val, df_test=best5_CMI_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"id":"51c2grtqlZR2"},{"cell_type":"markdown","source":["## CMI"],"metadata":{"id":"FvBZWM65Diqq"},"id":"FvBZWM65Diqq"},{"cell_type":"code","source":["MTL_scores(clust_basins=['Emiliani1','Emiliani2','Garda_Mincio'], df_train=CMI_fulldf_train, df_val=CMI_fulldf_val, df_test=CMI_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1lANVDBoDnO3","executionInfo":{"status":"ok","timestamp":1690352259317,"user_tz":-120,"elapsed":309,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"ba32f406-dcdc-4d8f-e725-ddb6289ade40"},"id":"1lANVDBoDnO3","execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Emiliani1\n","-0.014517744669723553\n","Emiliani2\n","-0.010037458448500791\n","Garda_Mincio\n","-0.07339744154500183\n"]}]},{"cell_type":"code","source":["MTL_scores(clust_basins=['Dora','Piemonte_Sud', 'Piemonte_Nord'], df_train=CMI_fulldf_train, df_val=CMI_fulldf_val, df_test=CMI_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lS0aCDnpDpEM","executionInfo":{"status":"ok","timestamp":1690352259318,"user_tz":-120,"elapsed":7,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"b46404bf-6b96-42cc-9387-908891e12725"},"id":"lS0aCDnpDpEM","execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Dora\n","-0.1587187138885835\n","Piemonte_Sud\n","0.06443333124880335\n","Piemonte_Nord\n","0.13530625148562625\n"]}]},{"cell_type":"code","source":["MTL_scores(clust_basins=['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino'], df_train=CMI_fulldf_train, df_val=CMI_fulldf_val, df_test=CMI_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MA_X4oRxDpmX","executionInfo":{"status":"ok","timestamp":1690352259593,"user_tz":-120,"elapsed":280,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"2f39c562-7873-421e-ce4d-4d2da7f80ab7"},"id":"MA_X4oRxDpmX","execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Adda\n","0.16683530072841646\n","Lambro_Olona\n","0.11399602240924211\n","Oglio_Iseo\n","0.18608333775983354\n","Ticino\n","0.10370336968912319\n"]}]},{"cell_type":"markdown","source":["## Wrapper best 5"],"metadata":{"id":"pdAXlODEDkDq"},"id":"pdAXlODEDkDq"},{"cell_type":"code","source":["MTL_scores(clust_basins=['Emiliani1','Emiliani2','Garda_Mincio'], df_train=best5_wrapper_fulldf_train, df_val=best5_wrapper_fulldf_val, df_test=best5_wrapper_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TFX9evJEDsow","executionInfo":{"status":"ok","timestamp":1690352787856,"user_tz":-120,"elapsed":272,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"1731f19e-cc50-4962-ddad-566f71341b3e"},"id":"TFX9evJEDsow","execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Emiliani1\n","-0.014517744669723553\n","Emiliani2\n","-0.010037458448500791\n","Garda_Mincio\n","-0.07339744154500183\n"]}]},{"cell_type":"code","source":["MTL_scores(clust_basins=['Dora','Piemonte_Sud', 'Piemonte_Nord'], df_train=best5_wrapper_fulldf_train, df_val=best5_wrapper_fulldf_val, df_test=best5_wrapper_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"InM-oOvNDse9","executionInfo":{"status":"ok","timestamp":1690352788288,"user_tz":-120,"elapsed":7,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"618ebd83-af7d-4140-b9d4-ea873f187946"},"id":"InM-oOvNDse9","execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Dora\n","-0.06083194307625717\n","Piemonte_Sud\n","0.11328609927901678\n","Piemonte_Nord\n","0.11238616192636108\n"]}]},{"cell_type":"code","source":["MTL_scores(clust_basins=['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino'], df_train=best5_wrapper_fulldf_train, df_val=best5_wrapper_fulldf_val, df_test=best5_wrapper_fulldf_test, targets_df_train=targets_df_train, targets_df_val=targets_df_val, targets_df_test=targets_df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nazncmDYDsS0","executionInfo":{"status":"ok","timestamp":1690352788576,"user_tz":-120,"elapsed":292,"user":{"displayName":"Veronica Cardigliano","userId":"10831561450934369351"}},"outputId":"a05a0250-9cef-42d6-cae5-3ecbfcde97f2"},"id":"nazncmDYDsS0","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Adda\n","0.05382670758417063\n","Lambro_Olona\n","-0.024199259090986303\n","Oglio_Iseo\n","0.034961311535131046\n","Ticino\n","0.015471835019220337\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.9 (tensorflow)","language":"python","name":"tensorflow"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":5}