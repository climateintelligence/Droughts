{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288de91a",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4f3825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/methods/CMI_FS\")\n",
    "from feature_selection import forwardFeatureSelection\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/methods/LinCFA\")\n",
    "from LinCFA import LinCFA\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/Droughts/Paolo/regression_LinCFA\")\n",
    "from aux import standardize,unfold_dataset,compute_r2,prepare_target,prepare_features,aggregate_unfolded_data,FS_with_linearWrapper,compare_methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b525256e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cells(output,selected_colnames, xmin=9, xmax=11, ymin=44, ymax=45.5):\n",
    "    x = []\n",
    "    y = []\n",
    "    colors = cm.rainbow(np.linspace(0,1,len(output)))\n",
    "    fig, ax = plt.subplots(2)\n",
    "    ax[0].set_xlim(xmin,xmax)\n",
    "    ax[1].set_xlim(xmin,xmax)\n",
    "    ax[0].set_ylim(ymin,ymax)\n",
    "    ax[1].set_ylim(ymin,ymax)\n",
    "    for i in range(len(output)): \n",
    "        #print(len(output[i]))\n",
    "        x = []\n",
    "        y = []\n",
    "        \n",
    "        for datum in output[i]:\n",
    "            x.append(float(datum.split('_')[1]))\n",
    "            y.append(float(datum.split('_')[2]))\n",
    "        ax[0].scatter(x,y,color=colors[i])\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    col = cm.rainbow(np.linspace(0,1,len(selected_colnames)))\n",
    "    for i in range(len(selected_colnames)): \n",
    "        idx = int(selected_colnames[i].split('_')[-1])\n",
    "        for datum in output[idx]:\n",
    "            x.append(float(datum.split('_')[1]))\n",
    "            y.append(float(datum.split('_')[2]))\n",
    "        ax[1].scatter(x,y,color=col[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7236826f",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d989b0",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x14520a460>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "plt.plot(target_df_trainVal.loc[:,'mean'], color='blue')\n",
    "plt.plot(target_df_trainVal.loc[:,'mean_std'], color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f32f540",
   "metadata": {},
   "source": [
    "# 1) Aggregations: temperature, precipitation, both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0924a07d",
   "metadata": {},
   "source": [
    "## temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70116fc8",
   "metadata": {},
   "source": [
    "### full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be1ea497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.649860364384157 12.949860339180924 43.74986055078544 46.54986054189981\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>cyclostationary_mean_tg</th>\n",
       "      <th>cyclostationary_mean_rr</th>\n",
       "      <th>cyclostationary_mean_tg_1w</th>\n",
       "      <th>cyclostationary_mean_tg_4w</th>\n",
       "      <th>cyclostationary_mean_tg_8w</th>\n",
       "      <th>cyclostationary_mean_tg_12w</th>\n",
       "      <th>cyclostationary_mean_tg_16w</th>\n",
       "      <th>cyclostationary_mean_tg_24w</th>\n",
       "      <th>cyclostationary_mean_rr_1w</th>\n",
       "      <th>cyclostationary_mean_rr_4w</th>\n",
       "      <th>cyclostationary_mean_rr_8w</th>\n",
       "      <th>cyclostationary_mean_rr_12w</th>\n",
       "      <th>cyclostationary_mean_rr_16w</th>\n",
       "      <th>cyclostationary_mean_rr_24w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-05</td>\n",
       "      <td>43.749861</td>\n",
       "      <td>12.14986</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>2.009904</td>\n",
       "      <td>3.832692</td>\n",
       "      <td>2.009904</td>\n",
       "      <td>2.009904</td>\n",
       "      <td>2.009904</td>\n",
       "      <td>2.009904</td>\n",
       "      <td>2.009904</td>\n",
       "      <td>2.009904</td>\n",
       "      <td>3.832692</td>\n",
       "      <td>3.832692</td>\n",
       "      <td>3.832692</td>\n",
       "      <td>3.832692</td>\n",
       "      <td>3.832692</td>\n",
       "      <td>3.832692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-05</td>\n",
       "      <td>43.749861</td>\n",
       "      <td>12.24986</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>2.067019</td>\n",
       "      <td>5.870192</td>\n",
       "      <td>2.067019</td>\n",
       "      <td>2.067019</td>\n",
       "      <td>2.067019</td>\n",
       "      <td>2.067019</td>\n",
       "      <td>2.067019</td>\n",
       "      <td>2.067019</td>\n",
       "      <td>5.870192</td>\n",
       "      <td>5.870192</td>\n",
       "      <td>5.870192</td>\n",
       "      <td>5.870192</td>\n",
       "      <td>5.870192</td>\n",
       "      <td>5.870192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-05</td>\n",
       "      <td>43.749861</td>\n",
       "      <td>12.34986</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>1.852115</td>\n",
       "      <td>6.747115</td>\n",
       "      <td>1.852115</td>\n",
       "      <td>1.852115</td>\n",
       "      <td>1.852115</td>\n",
       "      <td>1.852115</td>\n",
       "      <td>1.852115</td>\n",
       "      <td>1.852115</td>\n",
       "      <td>6.747115</td>\n",
       "      <td>6.747115</td>\n",
       "      <td>6.747115</td>\n",
       "      <td>6.747115</td>\n",
       "      <td>6.747115</td>\n",
       "      <td>6.747115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-05</td>\n",
       "      <td>43.749861</td>\n",
       "      <td>12.44986</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>1.326058</td>\n",
       "      <td>6.315385</td>\n",
       "      <td>1.326058</td>\n",
       "      <td>1.326058</td>\n",
       "      <td>1.326058</td>\n",
       "      <td>1.326058</td>\n",
       "      <td>1.326058</td>\n",
       "      <td>1.326058</td>\n",
       "      <td>6.315385</td>\n",
       "      <td>6.315385</td>\n",
       "      <td>6.315385</td>\n",
       "      <td>6.315385</td>\n",
       "      <td>6.315385</td>\n",
       "      <td>6.315385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-01-05</td>\n",
       "      <td>43.749861</td>\n",
       "      <td>12.54986</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.919712</td>\n",
       "      <td>5.876923</td>\n",
       "      <td>0.919712</td>\n",
       "      <td>0.919712</td>\n",
       "      <td>0.919712</td>\n",
       "      <td>0.919712</td>\n",
       "      <td>0.919712</td>\n",
       "      <td>0.919712</td>\n",
       "      <td>5.876923</td>\n",
       "      <td>5.876923</td>\n",
       "      <td>5.876923</td>\n",
       "      <td>5.876923</td>\n",
       "      <td>5.876923</td>\n",
       "      <td>5.876923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972166</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>45.149861</td>\n",
       "      <td>9.94986</td>\n",
       "      <td>2022</td>\n",
       "      <td>25</td>\n",
       "      <td>2.690385</td>\n",
       "      <td>-2.800962</td>\n",
       "      <td>2.272010</td>\n",
       "      <td>2.329204</td>\n",
       "      <td>1.385630</td>\n",
       "      <td>0.870501</td>\n",
       "      <td>1.147244</td>\n",
       "      <td>0.936656</td>\n",
       "      <td>-1.272072</td>\n",
       "      <td>-1.413951</td>\n",
       "      <td>-1.272724</td>\n",
       "      <td>-1.360520</td>\n",
       "      <td>-1.324643</td>\n",
       "      <td>-1.008920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972167</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>45.149861</td>\n",
       "      <td>10.04986</td>\n",
       "      <td>2022</td>\n",
       "      <td>25</td>\n",
       "      <td>3.044231</td>\n",
       "      <td>-2.908654</td>\n",
       "      <td>2.598934</td>\n",
       "      <td>2.706495</td>\n",
       "      <td>1.759349</td>\n",
       "      <td>1.269219</td>\n",
       "      <td>1.527790</td>\n",
       "      <td>1.217671</td>\n",
       "      <td>-1.620804</td>\n",
       "      <td>-1.550787</td>\n",
       "      <td>-1.354406</td>\n",
       "      <td>-1.371571</td>\n",
       "      <td>-1.327258</td>\n",
       "      <td>-1.002166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972168</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>45.249861</td>\n",
       "      <td>9.54986</td>\n",
       "      <td>2022</td>\n",
       "      <td>25</td>\n",
       "      <td>3.776635</td>\n",
       "      <td>-1.676923</td>\n",
       "      <td>3.400022</td>\n",
       "      <td>3.327979</td>\n",
       "      <td>2.531039</td>\n",
       "      <td>1.964117</td>\n",
       "      <td>2.186415</td>\n",
       "      <td>1.916099</td>\n",
       "      <td>-0.938462</td>\n",
       "      <td>-1.116958</td>\n",
       "      <td>-1.169462</td>\n",
       "      <td>-1.253882</td>\n",
       "      <td>-1.240283</td>\n",
       "      <td>-1.040775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972169</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>45.249861</td>\n",
       "      <td>9.84986</td>\n",
       "      <td>2022</td>\n",
       "      <td>25</td>\n",
       "      <td>3.044519</td>\n",
       "      <td>-2.306731</td>\n",
       "      <td>2.604873</td>\n",
       "      <td>2.643358</td>\n",
       "      <td>1.767176</td>\n",
       "      <td>1.255820</td>\n",
       "      <td>1.511847</td>\n",
       "      <td>1.283886</td>\n",
       "      <td>-1.231774</td>\n",
       "      <td>-1.335385</td>\n",
       "      <td>-1.283196</td>\n",
       "      <td>-1.366569</td>\n",
       "      <td>-1.330153</td>\n",
       "      <td>-1.049503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972170</th>\n",
       "      <td>2022-06-24</td>\n",
       "      <td>45.249861</td>\n",
       "      <td>9.94986</td>\n",
       "      <td>2022</td>\n",
       "      <td>25</td>\n",
       "      <td>3.190865</td>\n",
       "      <td>-2.568269</td>\n",
       "      <td>2.704524</td>\n",
       "      <td>2.760435</td>\n",
       "      <td>1.833568</td>\n",
       "      <td>1.338008</td>\n",
       "      <td>1.597108</td>\n",
       "      <td>1.332762</td>\n",
       "      <td>-1.342657</td>\n",
       "      <td>-1.406626</td>\n",
       "      <td>-1.259100</td>\n",
       "      <td>-1.360855</td>\n",
       "      <td>-1.320688</td>\n",
       "      <td>-1.021798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>972171 rows  19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date          y         x  year  week  cyclostationary_mean_tg  \\\n",
       "0       2001-01-05  43.749861  12.14986  2001     1                 2.009904   \n",
       "1       2001-01-05  43.749861  12.24986  2001     1                 2.067019   \n",
       "2       2001-01-05  43.749861  12.34986  2001     1                 1.852115   \n",
       "3       2001-01-05  43.749861  12.44986  2001     1                 1.326058   \n",
       "4       2001-01-05  43.749861  12.54986  2001     1                 0.919712   \n",
       "...            ...        ...       ...   ...   ...                      ...   \n",
       "972166  2022-06-24  45.149861   9.94986  2022    25                 2.690385   \n",
       "972167  2022-06-24  45.149861  10.04986  2022    25                 3.044231   \n",
       "972168  2022-06-24  45.249861   9.54986  2022    25                 3.776635   \n",
       "972169  2022-06-24  45.249861   9.84986  2022    25                 3.044519   \n",
       "972170  2022-06-24  45.249861   9.94986  2022    25                 3.190865   \n",
       "\n",
       "        cyclostationary_mean_rr  cyclostationary_mean_tg_1w  \\\n",
       "0                      3.832692                    2.009904   \n",
       "1                      5.870192                    2.067019   \n",
       "2                      6.747115                    1.852115   \n",
       "3                      6.315385                    1.326058   \n",
       "4                      5.876923                    0.919712   \n",
       "...                         ...                         ...   \n",
       "972166                -2.800962                    2.272010   \n",
       "972167                -2.908654                    2.598934   \n",
       "972168                -1.676923                    3.400022   \n",
       "972169                -2.306731                    2.604873   \n",
       "972170                -2.568269                    2.704524   \n",
       "\n",
       "        cyclostationary_mean_tg_4w  cyclostationary_mean_tg_8w  \\\n",
       "0                         2.009904                    2.009904   \n",
       "1                         2.067019                    2.067019   \n",
       "2                         1.852115                    1.852115   \n",
       "3                         1.326058                    1.326058   \n",
       "4                         0.919712                    0.919712   \n",
       "...                            ...                         ...   \n",
       "972166                    2.329204                    1.385630   \n",
       "972167                    2.706495                    1.759349   \n",
       "972168                    3.327979                    2.531039   \n",
       "972169                    2.643358                    1.767176   \n",
       "972170                    2.760435                    1.833568   \n",
       "\n",
       "        cyclostationary_mean_tg_12w  cyclostationary_mean_tg_16w  \\\n",
       "0                          2.009904                     2.009904   \n",
       "1                          2.067019                     2.067019   \n",
       "2                          1.852115                     1.852115   \n",
       "3                          1.326058                     1.326058   \n",
       "4                          0.919712                     0.919712   \n",
       "...                             ...                          ...   \n",
       "972166                     0.870501                     1.147244   \n",
       "972167                     1.269219                     1.527790   \n",
       "972168                     1.964117                     2.186415   \n",
       "972169                     1.255820                     1.511847   \n",
       "972170                     1.338008                     1.597108   \n",
       "\n",
       "        cyclostationary_mean_tg_24w  cyclostationary_mean_rr_1w  \\\n",
       "0                          2.009904                    3.832692   \n",
       "1                          2.067019                    5.870192   \n",
       "2                          1.852115                    6.747115   \n",
       "3                          1.326058                    6.315385   \n",
       "4                          0.919712                    5.876923   \n",
       "...                             ...                         ...   \n",
       "972166                     0.936656                   -1.272072   \n",
       "972167                     1.217671                   -1.620804   \n",
       "972168                     1.916099                   -0.938462   \n",
       "972169                     1.283886                   -1.231774   \n",
       "972170                     1.332762                   -1.342657   \n",
       "\n",
       "        cyclostationary_mean_rr_4w  cyclostationary_mean_rr_8w  \\\n",
       "0                         3.832692                    3.832692   \n",
       "1                         5.870192                    5.870192   \n",
       "2                         6.747115                    6.747115   \n",
       "3                         6.315385                    6.315385   \n",
       "4                         5.876923                    5.876923   \n",
       "...                            ...                         ...   \n",
       "972166                   -1.413951                   -1.272724   \n",
       "972167                   -1.550787                   -1.354406   \n",
       "972168                   -1.116958                   -1.169462   \n",
       "972169                   -1.335385                   -1.283196   \n",
       "972170                   -1.406626                   -1.259100   \n",
       "\n",
       "        cyclostationary_mean_rr_12w  cyclostationary_mean_rr_16w  \\\n",
       "0                          3.832692                     3.832692   \n",
       "1                          5.870192                     5.870192   \n",
       "2                          6.747115                     6.747115   \n",
       "3                          6.315385                     6.315385   \n",
       "4                          5.876923                     5.876923   \n",
       "...                             ...                          ...   \n",
       "972166                    -1.360520                    -1.324643   \n",
       "972167                    -1.371571                    -1.327258   \n",
       "972168                    -1.253882                    -1.240283   \n",
       "972169                    -1.366569                    -1.330153   \n",
       "972170                    -1.360855                    -1.320688   \n",
       "\n",
       "        cyclostationary_mean_rr_24w  \n",
       "0                          3.832692  \n",
       "1                          5.870192  \n",
       "2                          6.747115  \n",
       "3                          6.315385  \n",
       "4                          5.876923  \n",
       "...                             ...  \n",
       "972166                    -1.008920  \n",
       "972167                    -1.002166  \n",
       "972168                    -1.040775  \n",
       "972169                    -1.049503  \n",
       "972170                    -1.021798  \n",
       "\n",
       "[972171 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg'\n",
    "filenames = glob.glob(path + \"/*.csv\")\n",
    "\n",
    "df = []\n",
    "for file in filenames:\n",
    "    df.append(pd.read_csv(file))\n",
    "    \n",
    "df = pd.concat(df, ignore_index=True)\n",
    "print(min(df.x),max(df.x),min(df.y),max(df.y))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cee64d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'y', 'x', 'year', 'week', 'cyclostationary_mean_tg',\n",
       "       'cyclostationary_mean_rr', 'cyclostationary_mean_tg_1w',\n",
       "       'cyclostationary_mean_tg_4w', 'cyclostationary_mean_tg_8w',\n",
       "       'cyclostationary_mean_tg_12w', 'cyclostationary_mean_tg_16w',\n",
       "       'cyclostationary_mean_tg_24w', 'cyclostationary_mean_rr_1w',\n",
       "       'cyclostationary_mean_rr_4w', 'cyclostationary_mean_rr_8w',\n",
       "       'cyclostationary_mean_rr_12w', 'cyclostationary_mean_rr_16w',\n",
       "       'cyclostationary_mean_rr_24w'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e691ea0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 17\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 18\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 18\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 14\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 17\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 18\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "actual training score: 0.1612100921061187\n",
      "actual validation score: 0.31578707677259565, number of remaining columns: 115\n",
      "\n",
      "actual training score: 0.18183865047666192\n",
      "actual validation score: 0.33730844201957577, number of remaining columns: 114\n",
      "\n",
      "actual training score: 0.1955684519394042\n",
      "actual validation score: 0.3445604324555459, number of remaining columns: 113\n",
      "\n",
      "actual training score: 0.19952446837265192\n",
      "actual validation score: 0.354517514890599, number of remaining columns: 112\n",
      "\n",
      "actual training score: 0.20179997556579776\n",
      "actual validation score: 0.36482271853121684, number of remaining columns: 111\n",
      "\n",
      "actual training score: 0.2045150170928799\n",
      "actual validation score: 0.36979253162651593, number of remaining columns: 110\n",
      "\n",
      "actual training score: 0.20601688550613895\n",
      "actual validation score: 0.38049863498185243, number of remaining columns: 109\n",
      "\n",
      "actual training score: 0.20628461708615575\n",
      "actual validation score: 0.38439372652739323, number of remaining columns: 108\n",
      "\n",
      "actual training score: 0.2083331045946034\n",
      "actual validation score: 0.39227653419960773, number of remaining columns: 107\n",
      "\n",
      "actual training score: 0.21097521084881032\n",
      "actual validation score: 0.39747211053101283, number of remaining columns: 106\n",
      "\n",
      "actual training score: 0.2115006645658778\n",
      "actual validation score: 0.3984799076915071, number of remaining columns: 105\n",
      "\n",
      "actual training score: 0.21188027530024633\n",
      "actual validation score: 0.3990245575148248, number of remaining columns: 104\n",
      "\n",
      "actual training score: 0.21207697668222603\n",
      "actual validation score: 0.39989509761716335, number of remaining columns: 103\n",
      "\n",
      "actual training score: 0.21207989880929712\n",
      "actual validation score: 0.399998199068902, number of remaining columns: 102\n",
      "\n",
      "actual training score: 0.21208280572300453\n",
      "actual validation score: 0.40004365963977906, number of remaining columns: 101\n",
      "\n",
      "actual training score: 0.21318531805628482\n",
      "actual validation score: 0.39907538334475867, number of remaining columns: 100\n",
      "\n",
      "actual training score: 0.21320828363310873\n",
      "actual validation score: 0.39866449061693876, number of remaining columns: 99\n",
      "\n",
      "actual training score: 0.21791586691450038\n",
      "actual validation score: 0.3977721793864698, number of remaining columns: 98\n",
      "\n",
      "actual training score: 0.21850438185858767\n",
      "actual validation score: 0.3975165702366772, number of remaining columns: 97\n",
      "\n",
      "actual training score: 0.21858691057349589\n",
      "actual validation score: 0.39665339131360966, number of remaining columns: 96\n",
      "\n",
      "actual training score: 0.2189323223849805\n",
      "actual validation score: 0.3940370223760695, number of remaining columns: 95\n",
      "\n",
      "actual training score: 0.22009508183641413\n",
      "actual validation score: 0.3904908769118607, number of remaining columns: 94\n",
      "\n",
      "actual training score: 0.2206604355626176\n",
      "actual validation score: 0.3832796034537356, number of remaining columns: 93\n",
      "\n",
      "actual training score: 0.2215482106802782\n",
      "actual validation score: 0.3697802226045219, number of remaining columns: 92\n",
      "\n",
      "actual training score: 0.23046953750863364\n",
      "actual validation score: 0.3569268262651065, number of remaining columns: 91\n",
      "\n",
      "actual training score: 0.2305690434026335\n",
      "actual validation score: 0.35277204093022385, number of remaining columns: 90\n",
      "\n",
      "actual training score: 0.2317830125713678\n",
      "actual validation score: 0.35946672005350544, number of remaining columns: 89\n",
      "\n",
      "actual training score: 0.2318562498059603\n",
      "actual validation score: 0.3561366750519822, number of remaining columns: 88\n",
      "\n",
      "actual training score: 0.23317248311200178\n",
      "actual validation score: 0.3617760152393211, number of remaining columns: 87\n",
      "\n",
      "actual training score: 0.23524974546813715\n",
      "actual validation score: 0.36362822838143327, number of remaining columns: 86\n",
      "\n",
      "actual training score: 0.23558508082087204\n",
      "actual validation score: 0.35931544529994586, number of remaining columns: 85\n",
      "\n",
      "actual training score: 0.24275801429893196\n",
      "actual validation score: 0.35331269398524223, number of remaining columns: 84\n",
      "\n",
      "actual training score: 0.24721569416170075\n",
      "actual validation score: 0.336036982877138, number of remaining columns: 83\n",
      "\n",
      "actual training score: 0.24819628568427232\n",
      "actual validation score: 0.32655985888454353, number of remaining columns: 82\n",
      "\n",
      "actual training score: 0.2689042916136335\n",
      "actual validation score: 0.32072550590983784, number of remaining columns: 81\n",
      "\n",
      "actual training score: 0.26891563245089634\n",
      "actual validation score: 0.3233226974212824, number of remaining columns: 80\n",
      "\n",
      "actual training score: 0.32397132274290485\n",
      "actual validation score: 0.32947298606684006, number of remaining columns: 79\n",
      "\n",
      "actual training score: 0.32428231866585044\n",
      "actual validation score: 0.3367510524696675, number of remaining columns: 78\n",
      "\n",
      "actual training score: 0.32842792209981253\n",
      "actual validation score: 0.34154691880776367, number of remaining columns: 77\n",
      "\n",
      "actual training score: 0.3285340421420194\n",
      "actual validation score: 0.3482161091413738, number of remaining columns: 76\n",
      "\n",
      "actual training score: 0.3608849944047928\n",
      "actual validation score: 0.382857436962171, number of remaining columns: 75\n",
      "\n",
      "actual training score: 0.3655249792501315\n",
      "actual validation score: 0.388336457261081, number of remaining columns: 74\n",
      "\n",
      "actual training score: 0.3657352919017265\n",
      "actual validation score: 0.38933968955748766, number of remaining columns: 73\n",
      "\n",
      "actual training score: 0.365735448706935\n",
      "actual validation score: 0.3893594277232393, number of remaining columns: 72\n",
      "\n",
      "actual training score: 0.3659322281468498\n",
      "actual validation score: 0.3889798118926776, number of remaining columns: 71\n",
      "\n",
      "actual training score: 0.3660215420211581\n",
      "actual validation score: 0.3880928253421353, number of remaining columns: 70\n",
      "\n",
      "actual training score: 0.3682467754328489\n",
      "actual validation score: 0.3865065269700363, number of remaining columns: 69\n",
      "\n",
      "actual training score: 0.3691959541403942\n",
      "actual validation score: 0.3865148382513772, number of remaining columns: 68\n",
      "\n",
      "actual training score: 0.3693103645721242\n",
      "actual validation score: 0.3846844621499841, number of remaining columns: 67\n",
      "\n",
      "actual training score: 0.3703256248893988\n",
      "actual validation score: 0.3787549437619139, number of remaining columns: 66\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_8', 'cyclostationary_mean_tg_24w_7', 'cyclostationary_mean_tg_1w_17', 'cyclostationary_mean_tg_9', 'cyclostationary_mean_tg_5', 'cyclostationary_mean_tg_24w_8', 'cyclostationary_mean_tg_1w_6', 'cyclostationary_mean_tg_1w_5', 'cyclostationary_mean_tg_3', 'cyclostationary_mean_tg_1', 'cyclostationary_mean_tg_2', 'cyclostationary_mean_tg_8w_10', 'cyclostationary_mean_tg_10', 'cyclostationary_mean_tg_7', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_tg_14'], \n",
      "\n",
      "validation score: 0.40004365963977906, \n",
      "\n",
      "number of selected features: 16\n",
      "Full aggregate regression train score: 0.5699186964999685, test score: -1.1247306018153829\n",
      "Aggregate regression train score with FS: 0.25909425773930994, test score: -0.0676221809937787\n"
     ]
    }
   ],
   "source": [
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_tg', \n",
    "                                                                         'cyclostationary_mean_tg_1w',\n",
    "                                                                         'cyclostationary_mean_tg_4w', \n",
    "                                                                         'cyclostationary_mean_tg_8w',\n",
    "                                                                         'cyclostationary_mean_tg_12w', \n",
    "                                                                         'cyclostationary_mean_tg_16w',\n",
    "                                                                         'cyclostationary_mean_tg_24w' \n",
    "                                                                         ],\n",
    "                                                                   target_df_trainVal,multiple=True, neigh=0)\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 50)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f71ec89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full aggregate regression train score: 0.5699186964999685, test score: -1.1247306018153829\n",
      "Aggregate regression train score with FS: 0.23736954151959888, test score: -0.048168562357097544\n",
      "Full aggregate regression train score: 0.5699186964999685, test score: -1.1247306018153829\n",
      "Aggregate regression train score with FS: 0.2544565220527384, test score: -0.09091229520568933\n"
     ]
    }
   ],
   "source": [
    "### forcing a low number of features\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa17c125",
   "metadata": {},
   "source": [
    "### not considering last years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb42af2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 12\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 13\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 14\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 16\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 17\n",
      "\n",
      "actual training score: 0.13155707697698882\n",
      "actual validation score: 0.2850820218081317, number of remaining columns: 100\n",
      "\n",
      "actual training score: 0.13865702052924522\n",
      "actual validation score: 0.31246555488104244, number of remaining columns: 99\n",
      "\n",
      "actual training score: 0.14164808133441242\n",
      "actual validation score: 0.3335598399547165, number of remaining columns: 98\n",
      "\n",
      "actual training score: 0.1459467547498271\n",
      "actual validation score: 0.356665397849122, number of remaining columns: 97\n",
      "\n",
      "actual training score: 0.15428869073847729\n",
      "actual validation score: 0.3675228559429847, number of remaining columns: 96\n",
      "\n",
      "actual training score: 0.17892013910788906\n",
      "actual validation score: 0.4029760997222258, number of remaining columns: 95\n",
      "\n",
      "actual training score: 0.17913950251133526\n",
      "actual validation score: 0.41201176999931277, number of remaining columns: 94\n",
      "\n",
      "actual training score: 0.18289191985195996\n",
      "actual validation score: 0.4169826808080519, number of remaining columns: 93\n",
      "\n",
      "actual training score: 0.18334225964241413\n",
      "actual validation score: 0.4217086452678621, number of remaining columns: 92\n",
      "\n",
      "actual training score: 0.21113825902533867\n",
      "actual validation score: 0.43676756260636007, number of remaining columns: 91\n",
      "\n",
      "actual training score: 0.21287616453241187\n",
      "actual validation score: 0.4394402661185106, number of remaining columns: 90\n",
      "\n",
      "actual training score: 0.21699181477645701\n",
      "actual validation score: 0.4429413723082962, number of remaining columns: 89\n",
      "\n",
      "actual training score: 0.2218199299981155\n",
      "actual validation score: 0.4486512051100209, number of remaining columns: 88\n",
      "\n",
      "actual training score: 0.22188918963620663\n",
      "actual validation score: 0.4508727313073144, number of remaining columns: 87\n",
      "\n",
      "actual training score: 0.22558678982034397\n",
      "actual validation score: 0.46053797299905574, number of remaining columns: 86\n",
      "\n",
      "actual training score: 0.22582177264848668\n",
      "actual validation score: 0.46075805377459744, number of remaining columns: 85\n",
      "\n",
      "actual training score: 0.2260530251253764\n",
      "actual validation score: 0.46077864053204887, number of remaining columns: 84\n",
      "\n",
      "actual training score: 0.22664623339784373\n",
      "actual validation score: 0.4619120141613441, number of remaining columns: 83\n",
      "\n",
      "actual training score: 0.2266481212197644\n",
      "actual validation score: 0.4620505145863254, number of remaining columns: 82\n",
      "\n",
      "actual training score: 0.22667338429185724\n",
      "actual validation score: 0.4620959153852984, number of remaining columns: 81\n",
      "\n",
      "actual training score: 0.23479085217474116\n",
      "actual validation score: 0.45574390757442396, number of remaining columns: 80\n",
      "\n",
      "actual training score: 0.24433987396150258\n",
      "actual validation score: 0.4587459187584457, number of remaining columns: 79\n",
      "\n",
      "actual training score: 0.24471473102206853\n",
      "actual validation score: 0.46467027607433997, number of remaining columns: 78\n",
      "\n",
      "actual training score: 0.2449227674658262\n",
      "actual validation score: 0.4637624527615042, number of remaining columns: 77\n",
      "\n",
      "actual training score: 0.24501025325162695\n",
      "actual validation score: 0.46057246746039726, number of remaining columns: 76\n",
      "\n",
      "actual training score: 0.24705427188314744\n",
      "actual validation score: 0.45594409782618106, number of remaining columns: 75\n",
      "\n",
      "actual training score: 0.2680173495805287\n",
      "actual validation score: 0.441812292224959, number of remaining columns: 74\n",
      "\n",
      "actual training score: 0.273791355652091\n",
      "actual validation score: 0.4321999198896187, number of remaining columns: 73\n",
      "\n",
      "actual training score: 0.2837853896091178\n",
      "actual validation score: 0.4509480672509537, number of remaining columns: 72\n",
      "\n",
      "actual training score: 0.2839476078288736\n",
      "actual validation score: 0.45415915466582135, number of remaining columns: 71\n",
      "\n",
      "actual training score: 0.28631092377627765\n",
      "actual validation score: 0.46001827628637537, number of remaining columns: 70\n",
      "\n",
      "actual training score: 0.2903696313308165\n",
      "actual validation score: 0.4568966614558102, number of remaining columns: 69\n",
      "\n",
      "actual training score: 0.29435309168533097\n",
      "actual validation score: 0.45492540406449167, number of remaining columns: 68\n",
      "\n",
      "actual training score: 0.2944191361838011\n",
      "actual validation score: 0.4563219191302351, number of remaining columns: 67\n",
      "\n",
      "actual training score: 0.29579975951672877\n",
      "actual validation score: 0.4506981225989033, number of remaining columns: 66\n",
      "\n",
      "actual training score: 0.2958221901273539\n",
      "actual validation score: 0.44906715393348473, number of remaining columns: 65\n",
      "\n",
      "actual training score: 0.29710298809412294\n",
      "actual validation score: 0.4403862719417304, number of remaining columns: 64\n",
      "\n",
      "actual training score: 0.2991940287664824\n",
      "actual validation score: 0.43681698696344473, number of remaining columns: 63\n",
      "\n",
      "actual training score: 0.29925511514653136\n",
      "actual validation score: 0.4396186586667127, number of remaining columns: 62\n",
      "\n",
      "actual training score: 0.2995517074977123\n",
      "actual validation score: 0.42942385691295304, number of remaining columns: 61\n",
      "\n",
      "actual training score: 0.3002815373784834\n",
      "actual validation score: 0.40596025056008267, number of remaining columns: 60\n",
      "\n",
      "actual training score: 0.30796884575281447\n",
      "actual validation score: 0.38006947649166667, number of remaining columns: 59\n",
      "\n",
      "actual training score: 0.308305587429731\n",
      "actual validation score: 0.3803049521890878, number of remaining columns: 58\n",
      "\n",
      "actual training score: 0.30971565941177903\n",
      "actual validation score: 0.3628477451801403, number of remaining columns: 57\n",
      "\n",
      "actual training score: 0.3134952721525359\n",
      "actual validation score: 0.3604546576722537, number of remaining columns: 56\n",
      "\n",
      "actual training score: 0.3199803252944826\n",
      "actual validation score: 0.31030258253130505, number of remaining columns: 55\n",
      "\n",
      "actual training score: 0.32440028002268684\n",
      "actual validation score: 0.3067929365547658, number of remaining columns: 54\n",
      "\n",
      "actual training score: 0.3554262464925717\n",
      "actual validation score: 0.2317493328613076, number of remaining columns: 53\n",
      "\n",
      "actual training score: 0.3758760899815261\n",
      "actual validation score: 0.2218474229626044, number of remaining columns: 52\n",
      "\n",
      "actual training score: 0.37660368849754355\n",
      "actual validation score: 0.22558707595602479, number of remaining columns: 51\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_6', 'cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_tg_24w_6', 'cyclostationary_mean_tg_1w_5', 'cyclostationary_mean_tg_1w_4', 'cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_tg_24w_5', 'cyclostationary_mean_tg_24w_7', 'cyclostationary_mean_tg_1w_12', 'cyclostationary_mean_tg_1w_10', 'cyclostationary_mean_tg_1w_8', 'cyclostationary_mean_tg_12w_15', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_tg_12w_6', 'cyclostationary_mean_tg_1w_14', 'cyclostationary_mean_tg_1w_11', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_tg_16w_6', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_tg_1w_7', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_tg_12w_12', 'cyclostationary_mean_tg_1w_9', 'cyclostationary_mean_tg_24w_10'], \n",
      "\n",
      "validation score: 0.46467027607433997, \n",
      "\n",
      "number of selected features: 24\n",
      "Full aggregate regression train score: 0.5864475531050841, test score: -2.3383063002914315\n",
      "Aggregate regression train score with FS: 0.34397720202491333, test score: -0.09395535972374125\n"
     ]
    }
   ],
   "source": [
    "### what happens without considering the last years?\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_tg', \n",
    "                                                                         'cyclostationary_mean_tg_1w',\n",
    "                                                                         'cyclostationary_mean_tg_4w', \n",
    "                                                                         'cyclostationary_mean_tg_8w',\n",
    "                                                                         'cyclostationary_mean_tg_12w', \n",
    "                                                                         'cyclostationary_mean_tg_16w',\n",
    "                                                                         'cyclostationary_mean_tg_24w' \n",
    "                                                                         ],target_df_trainVal, max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', multiple=True, neigh=0)\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 50, 228)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82e29a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full aggregate regression train score: 0.5864475531050841, test score: -2.3383063002914315\n",
      "Aggregate regression train score with FS: 0.2444965908298533, test score: 0.24215527161276673\n",
      "Full aggregate regression train score: 0.5864475531050841, test score: -2.3383063002914315\n",
      "Aggregate regression train score with FS: 0.29323947528640826, test score: 0.04956965490170584\n"
     ]
    }
   ],
   "source": [
    "### forcing a low number of features\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee0ba13",
   "metadata": {},
   "source": [
    "### repeat both with CMI FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "089f1b28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 17\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 18\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 18\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 14\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 17\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 18\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "----- MI Scores -----\n",
      "[(27, 0.1439722646141268), (26, 0.1360472396786752), (25, 0.1347427100799344), (9, 0.13299944616370707), (11, 0.12667077251898273), (8, 0.1239784192555458), (0, 0.12119797711621165), (13, 0.1208388498144807), (12, 0.11510289985911792), (10, 0.11452114544721473), (33, 0.11120687971595292), (6, 0.10719250797235592), (14, 0.10615843116992614), (3, 0.10562450015321188), (15, 0.10397644285946407), (5, 0.10354545031889083), (17, 0.10316481420585151), (46, 0.10236256367816471), (30, 0.10234883298211124), (29, 0.101488926370048), (1, 0.09911265751331305), (18, 0.0964363567095726), (35, 0.09605544027702308), (24, 0.09554071503861339), (2, 0.09474388619658705), (31, 0.09205990758542161), (28, 0.0908871741567157), (19, 0.0907533645140252), (45, 0.08963792121595135), (16, 0.08692201750779102), (42, 0.08685455366657095), (41, 0.08539595988460894), (34, 0.08479756748598985), (20, 0.08362709911530376), (32, 0.08155345776067136), (23, 0.0769602540128976), (48, 0.0756458504464153), (43, 0.07421704876399535), (44, 0.07413518985602219), (49, 0.07147406214152206), (21, 0.0672697931344359), (109, 0.05390082410325679), (47, 0.053741992456797505), (7, 0.05335917634241299), (51, 0.053026263206131484), (64, 0.0515125754022996), (36, 0.04973903351463897), (107, 0.04846688093207356), (50, 0.04354633471074945), (37, 0.0432279339942226), (60, 0.04290447340669872), (38, 0.04247263771537549), (58, 0.042414462118925605), (61, 0.041375945179070735), (106, 0.041339765721979935), (59, 0.03811241307903142), (104, 0.03807143698382983), (54, 0.03512925570509804), (66, 0.03499459941010782), (55, 0.03461402992374586), (103, 0.03318719902824042), (22, 0.0326046175966815), (80, 0.03238169549992179), (63, 0.03194367283519243), (56, 0.03113592420395238), (112, 0.029272262149398667), (74, 0.027819659814809133), (79, 0.027396812430592332), (70, 0.02735433232129675), (88, 0.02585747481350367), (89, 0.02568544424842855), (40, 0.02538559252068743), (73, 0.02536234866956596), (81, 0.025103263802681547), (65, 0.025088060558252787), (4, 0.02508295692700377), (110, 0.024085927925889018), (97, 0.02405885103138065), (99, 0.02370807339524839), (82, 0.023610349113012935), (52, 0.0233368548656305), (62, 0.022847083493602628), (111, 0.022824376360072302), (77, 0.022624668111128544), (105, 0.022577592588759708), (57, 0.021433699976182205), (75, 0.021323941420173582), (72, 0.02088315619626716), (76, 0.02011840750698962), (71, 0.019073747077748008), (90, 0.01885228523573545), (94, 0.018722510731579274), (116, 0.017290792311275664), (102, 0.01665255836138098), (67, 0.016089842378116934), (93, 0.015438420275233455), (100, 0.014903270700434271), (83, 0.01418086560881614), (98, 0.014104014907003219), (84, 0.013639087404152395), (68, 0.012610669442195794), (101, 0.011469300839532204), (78, 0.010652989109429186), (53, 0.009220014249916435), (87, 0.008298358559248814), (95, 0.006779553936738279), (39, 0.006087600494341288), (114, 0.005373694371839016), (113, 0.005024274853296952), (108, 0.004473619810655455), (96, 0.0042770478015881), (92, 0.000893603768996364), (115, -0.000882047297465393), (69, -0.0015546024218577887), (91, -0.0020219043259659857), (86, -0.00556443435540109), (85, -0.010911370030080036)]\n",
      "Best MI score: 0.1439722646141268\n",
      "Adding first best original feature: 27\n",
      "CMI: 0.008842411947401985\n",
      "CMI: 0.004369301295375272\n",
      "CMI: 0.009160117318351951\n",
      "CMI: 0.0060819458003040505\n",
      "CMI: 0.00833291162652866\n",
      "CMI: 0.009329949760962325\n",
      "CMI: 0.005637553532733264\n",
      "CMI: 0.0011789053542591021\n",
      "CMI: 0.012336932285531732\n",
      "CMI: 0.006979060880866472\n",
      "CMI: 0.00796112416304437\n",
      "CMI: 0.003357482000926587\n",
      "CMI: 0.008003011067636845\n",
      "CMI: 0.023028028301713216\n",
      "CMI: 0.030126090634769342\n",
      "CMI: 0.04504321378703546\n",
      "CMI: 0.009737528886056307\n",
      "CMI: 0.02311547353527324\n",
      "CMI: 0.022939522823535896\n",
      "CMI: 0.015182044101394093\n",
      "CMI: 0.01355581945454179\n",
      "CMI: 0.000127927990729082\n",
      "CMI: 0.0010081726309507932\n",
      "CMI: 0.013172596305828566\n",
      "CMI: 0.001719132586912142\n",
      "CMI: 0.008911528695776078\n",
      "CMI: 0.006453787286667373\n",
      "CMI: 0.0012680680941882516\n",
      "CMI: 0.020148708347701327\n",
      "CMI: 0.026431914719140553\n",
      "CMI: 0.0063722137243434895\n",
      "CMI: 0.00801663845228831\n",
      "CMI: 0.011907579321133704\n",
      "CMI: 0.016404930061980766\n",
      "CMI: 0.0158565128055575\n",
      "CMI: 0.0021341151745246645\n",
      "CMI: 0.0025361785560750194\n",
      "CMI: 0.023038301993062116\n",
      "CMI: 0.020716096384933463\n",
      "CMI: 0.010982272990621267\n",
      "CMI: 0.0052220540281111005\n",
      "CMI: 0.011381059876287347\n",
      "CMI: 0.003868374240820621\n",
      "CMI: 0.013908485057963577\n",
      "CMI: 0.026682111777709128\n",
      "CMI: 0.002813884709490816\n",
      "CMI: 0.00855894310550856\n",
      "CMI: 0.003279405743324998\n",
      "CMI: 0.02124392954175444\n",
      "CMI: 0.00673271070957801\n",
      "CMI: 0.0013091047225269048\n",
      "CMI: 0.03156889601803939\n",
      "CMI: 0.029405689526375622\n",
      "CMI: 0.020209892396930246\n",
      "CMI: 0.002371181500667341\n",
      "CMI: 0.002457711156322734\n",
      "CMI: 0.017431107466892914\n",
      "CMI: 0.007583226801924553\n",
      "CMI: 0.021507617885075186\n",
      "CMI: 0.03019048944167857\n",
      "CMI: 0.00543192368748896\n",
      "CMI: 0.0336376567980578\n",
      "CMI: 0.009820128498118696\n",
      "CMI: 0.012487992991706387\n",
      "CMI: 0.01978238330977447\n",
      "Highest CMI score: 0.04504321378703546\n",
      "Adding original feature: 40\n",
      "CMI: 0.0019573028829184547\n",
      "CMI: 0.004592804920434762\n",
      "CMI: 0.0007246162517096921\n",
      "CMI: 0.004496756053647966\n",
      "CMI: 0.0023340672550924424\n",
      "CMI: 0.008505233533055878\n",
      "CMI: 0.004195657801413372\n",
      "CMI: 0.003515923889528816\n",
      "CMI: 0.00457812695691498\n",
      "CMI: 0.016316244185350215\n",
      "CMI: 0.001289556492023225\n",
      "Highest CMI score: 0.016316244185350215\n",
      "Adding original feature: 109\n",
      "CMI: 0.0019406008743997893\n",
      "CMI: 0.00020160665723559235\n",
      "CMI: 0.0030473560226097207\n",
      "CMI: 0.0007015701871051772\n",
      "CMI: 0.006896401394769686\n",
      "CMI: 0.010280976972633166\n",
      "CMI: 0.0036844800248661824\n",
      "Highest CMI score: 0.010280976972633166\n",
      "Adding original feature: 89\n",
      "CMI: 0.0001886878443237705\n",
      "CMI: 0.0007062406340873906\n",
      "CMI: 0.004907153752665816\n",
      "CMI: 0.002602558530611143\n",
      "CMI: 0.002010401888501323\n",
      "CMI: 0.0061076786691879326\n",
      "CMI: 0.003450478361428838\n",
      "CMI: 0.00429175445906857\n",
      "CMI: 0.004462388788233712\n",
      "CMI: 0.0017588807797523087\n",
      "CMI: 0.0029562822245051412\n",
      "CMI: 0.001895162709938919\n",
      "CMI: 0.002144623102101506\n",
      "CMI: 0.006620869658222089\n",
      "CMI: 0.0001235491768371011\n",
      "CMI: 0.002816343441271185\n",
      "Highest CMI score: 0.006620869658222089\n",
      "Adding original feature: 112\n",
      "CMI: 0.006195841766827359\n",
      "CMI: 0.0014015274801838784\n",
      "CMI: 0.0020980063078768485\n",
      "CMI: 0.0012265147785696928\n",
      "CMI: 0.00370778057989235\n",
      "Highest CMI score: 0.006195841766827359\n",
      "Adding original feature: 85\n",
      "CMI: 0.0005276154900675789\n",
      "Highest CMI score: 0.0005276154900675789\n",
      "Adding original feature: 102\n",
      "Highest CMI score: -0.001644048575056678\n",
      "\n",
      "[27, 40, 109, 89, 112, 85, 102]\n",
      "\n",
      "Full aggregate regression train score: 0.5699186964999685, test score: -1.1247306018153829\n",
      "Aggregate regression train score with FS: 0.2527915103466589, test score: -0.044328705443731575\n"
     ]
    }
   ],
   "source": [
    "### all data\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_tg', \n",
    "                                                                         'cyclostationary_mean_tg_1w',\n",
    "                                                                         'cyclostationary_mean_tg_4w', \n",
    "                                                                         'cyclostationary_mean_tg_8w',\n",
    "                                                                         'cyclostationary_mean_tg_12w', \n",
    "                                                                         'cyclostationary_mean_tg_16w',\n",
    "                                                                         'cyclostationary_mean_tg_24w' \n",
    "                                                                         ],target_df_trainVal,multiple=True, neigh=0)\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1df889cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 12\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 13\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 14\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 16\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 17\n",
      "\n",
      "----- MI Scores -----\n",
      "[(7, 0.1286787791673458), (0, 0.12374369750902679), (5, 0.1237203268683318), (18, 0.12336536931319297), (11, 0.12187086949476401), (6, 0.12174013030552368), (3, 0.11859433507678267), (21, 0.11577905754372864), (20, 0.1122602436761078), (19, 0.10999168599163632), (9, 0.10770221065310064), (1, 0.1050763244597484), (2, 0.09874399377609192), (8, 0.09779179707348827), (10, 0.0946657003811646), (13, 0.09403535625215567), (24, 0.09299819006005038), (22, 0.08715696949460078), (15, 0.0863988695840408), (12, 0.08498832851672089), (31, 0.0765693287429937), (25, 0.07071454250748856), (27, 0.07029979946542761), (42, 0.06865034085371216), (26, 0.06788241276823238), (23, 0.0676616327423252), (33, 0.06701783092393991), (41, 0.06381530102637038), (36, 0.06238377786135037), (14, 0.06022979432406476), (4, 0.058232711160856696), (53, 0.0581741563964403), (89, 0.05756490460328236), (39, 0.055703209790854386), (52, 0.05373669351232221), (34, 0.05248964360310635), (30, 0.05205689066100469), (38, 0.0515677706177128), (37, 0.051315422489554736), (16, 0.05060157974805213), (48, 0.04985087907120727), (95, 0.04949486861853071), (40, 0.04946873568368696), (32, 0.04805678471755705), (45, 0.04764593560694752), (92, 0.044705574416161575), (88, 0.044504560200822135), (87, 0.043940516159519084), (43, 0.04338931174812443), (29, 0.042684707973634696), (17, 0.04252439749259397), (78, 0.042331977929834216), (28, 0.04081356826424111), (93, 0.040480481880029104), (47, 0.03873541184551873), (77, 0.03856344065542209), (46, 0.03800467039505655), (51, 0.03793704600933267), (60, 0.03714789224948342), (58, 0.034989901340466784), (35, 0.03345984305801358), (44, 0.03295085256293885), (50, 0.032897557373887415), (49, 0.03285474669174279), (98, 0.032157592205031074), (64, 0.03193117837298337), (63, 0.031307103166881824), (65, 0.03130312206351015), (100, 0.03062461397958284), (68, 0.029552154687657577), (76, 0.029222887130755937), (94, 0.029182132189701674), (84, 0.0290231132825773), (55, 0.02766998539791411), (91, 0.027152674862359952), (54, 0.025427957306889192), (96, 0.025413185114473196), (86, 0.024626800309625555), (62, 0.024002597682001033), (80, 0.021937804163694827), (59, 0.021554928182712447), (73, 0.02123072479158509), (61, 0.020844115488792885), (72, 0.020742145285632105), (56, 0.020594433839239305), (67, 0.019442081356848693), (57, 0.01822812321279784), (71, 0.018175852408074282), (85, 0.017205546183484455), (82, 0.01477907034782731), (79, 0.013201622103443136), (97, 0.012538771781410947), (99, 0.011327502693749804), (69, 0.010124880339942983), (66, 0.008940675939939123), (75, 0.007020172274815932), (90, 0.006117176106820127), (70, 0.005034260280979602), (74, 0.0015859064817030834), (83, 0.0012357371651062709), (101, -0.003936314016123794), (81, -0.005444637316576286)]\n",
      "Best MI score: 0.1286787791673458\n",
      "Adding first best original feature: 7\n",
      "CMI: 0.016787917268191677\n",
      "CMI: 0.015246737432746654\n",
      "CMI: 0.0165345842049352\n",
      "CMI: 0.01858626362419294\n",
      "CMI: 0.0008358780495181795\n",
      "CMI: 0.0035417292218047902\n",
      "CMI: 0.01472739475919263\n",
      "CMI: 0.016461012587663443\n",
      "CMI: 0.018816081410312158\n",
      "CMI: 0.002066549917260435\n",
      "CMI: 0.006681480654146005\n",
      "CMI: 0.0017841735405732528\n",
      "CMI: 0.00607265347495764\n",
      "CMI: 0.010993217282552203\n",
      "CMI: 0.010198255978421555\n",
      "CMI: 0.03892351317709436\n",
      "CMI: 0.003914651352361909\n",
      "CMI: 0.0049910332169171845\n",
      "CMI: 0.010011245717393036\n",
      "CMI: 0.0747370044128057\n",
      "CMI: 0.01593450787923209\n",
      "CMI: 0.005652261976556439\n",
      "CMI: 0.006016248092465065\n",
      "CMI: 0.013982640974121746\n",
      "CMI: 0.010114614865114169\n",
      "CMI: 0.0034226824359226415\n",
      "CMI: 0.0039977602296003\n",
      "CMI: 0.0019419438706255454\n",
      "CMI: 0.017730515869085223\n",
      "CMI: 4.6942314938513974e-05\n",
      "CMI: 0.022531571018315655\n",
      "CMI: 0.004194859878414059\n",
      "CMI: 0.0020964238951318437\n",
      "CMI: 0.007960959300653686\n",
      "CMI: 0.008182863473271185\n",
      "CMI: 0.005930959660337881\n",
      "CMI: 0.001619476106204304\n",
      "CMI: 0.013676377155579261\n",
      "CMI: 0.027590417800815642\n",
      "CMI: 0.010327295025267774\n",
      "CMI: 0.021293810144531605\n",
      "CMI: 0.046753955926967794\n",
      "CMI: 0.013988510447591085\n",
      "CMI: 0.03576578484152465\n",
      "CMI: 0.05045463920105561\n",
      "CMI: 0.02536856065881221\n",
      "CMI: 0.007417684356235438\n",
      "CMI: 0.03294061165652948\n",
      "CMI: 0.0003764138608204348\n",
      "CMI: 0.005761589936179257\n",
      "CMI: 0.010798207461970799\n",
      "CMI: 0.028975266280371087\n",
      "CMI: 0.0015742928904738107\n",
      "Highest CMI score: 0.0747370044128057\n",
      "Adding original feature: 36\n",
      "Highest CMI score: -0.003104014881980449\n",
      "\n",
      "[7, 36]\n",
      "\n",
      "Full aggregate regression train score: 0.5864475531050841, test score: -2.3383063002914315\n",
      "Aggregate regression train score with FS: 0.16261160235963357, test score: 0.15018906297510315\n"
     ]
    }
   ],
   "source": [
    "### what happens without considering the last years?\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_tg', \n",
    "                                                                         'cyclostationary_mean_tg_1w',\n",
    "                                                                         'cyclostationary_mean_tg_4w', \n",
    "                                                                         'cyclostationary_mean_tg_8w',\n",
    "                                                                         'cyclostationary_mean_tg_12w', \n",
    "                                                                         'cyclostationary_mean_tg_16w',\n",
    "                                                                         'cyclostationary_mean_tg_24w' \n",
    "                                                                         ],target_df_trainVal, max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', multiple=True, neigh=0)\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba64e53",
   "metadata": {},
   "source": [
    "## precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303817db",
   "metadata": {},
   "source": [
    "### full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "981b2fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 23\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 40\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 42\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 42\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 31\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 21\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 16\n",
      "\n",
      "actual training score: 0.16945309220923632\n",
      "actual validation score: 0.3346338049293508, number of remaining columns: 213\n",
      "\n",
      "actual training score: 0.17385251305841065\n",
      "actual validation score: 0.3462669117092593, number of remaining columns: 212\n",
      "\n",
      "actual training score: 0.17993329735262265\n",
      "actual validation score: 0.38612421976082667, number of remaining columns: 211\n",
      "\n",
      "actual training score: 0.18053685096254557\n",
      "actual validation score: 0.3948652469549684, number of remaining columns: 210\n",
      "\n",
      "actual training score: 0.1820594563917659\n",
      "actual validation score: 0.4033686131811757, number of remaining columns: 209\n",
      "\n",
      "actual training score: 0.18427105612316197\n",
      "actual validation score: 0.41232547872515846, number of remaining columns: 208\n",
      "\n",
      "actual training score: 0.18987734760952568\n",
      "actual validation score: 0.43154142387363204, number of remaining columns: 207\n",
      "\n",
      "actual training score: 0.19337503650796106\n",
      "actual validation score: 0.4506769402884042, number of remaining columns: 206\n",
      "\n",
      "actual training score: 0.19528304685011766\n",
      "actual validation score: 0.463714728095012, number of remaining columns: 205\n",
      "\n",
      "actual training score: 0.1983349867886779\n",
      "actual validation score: 0.4698163715402607, number of remaining columns: 204\n",
      "\n",
      "actual training score: 0.20048620550661256\n",
      "actual validation score: 0.47531932533197585, number of remaining columns: 203\n",
      "\n",
      "actual training score: 0.20082335468794255\n",
      "actual validation score: 0.481387360911972, number of remaining columns: 202\n",
      "\n",
      "actual training score: 0.20140028402335897\n",
      "actual validation score: 0.4884268201914772, number of remaining columns: 201\n",
      "\n",
      "actual training score: 0.20180532139743934\n",
      "actual validation score: 0.49539391412678546, number of remaining columns: 200\n",
      "\n",
      "actual training score: 0.2024162581686647\n",
      "actual validation score: 0.4995407983915362, number of remaining columns: 199\n",
      "\n",
      "actual training score: 0.2026859709446177\n",
      "actual validation score: 0.5013381413945592, number of remaining columns: 198\n",
      "\n",
      "actual training score: 0.20280280344846902\n",
      "actual validation score: 0.5029647073025584, number of remaining columns: 197\n",
      "\n",
      "actual training score: 0.20284851499803624\n",
      "actual validation score: 0.5041275814896219, number of remaining columns: 196\n",
      "\n",
      "actual training score: 0.20370740832712542\n",
      "actual validation score: 0.5054066420038239, number of remaining columns: 195\n",
      "\n",
      "actual training score: 0.20376781644336928\n",
      "actual validation score: 0.5082453100098325, number of remaining columns: 194\n",
      "\n",
      "actual training score: 0.20391606606267343\n",
      "actual validation score: 0.509579462536152, number of remaining columns: 193\n",
      "\n",
      "actual training score: 0.20538961856828408\n",
      "actual validation score: 0.5107569283170053, number of remaining columns: 192\n",
      "\n",
      "actual training score: 0.20546198108335578\n",
      "actual validation score: 0.5115628934424792, number of remaining columns: 191\n",
      "\n",
      "actual training score: 0.20546974817346553\n",
      "actual validation score: 0.5123241442243639, number of remaining columns: 190\n",
      "\n",
      "actual training score: 0.20588540246372788\n",
      "actual validation score: 0.513008825601528, number of remaining columns: 189\n",
      "\n",
      "actual training score: 0.20603332693848775\n",
      "actual validation score: 0.5155636160646775, number of remaining columns: 188\n",
      "\n",
      "actual training score: 0.20605059467500597\n",
      "actual validation score: 0.5158284158547387, number of remaining columns: 187\n",
      "\n",
      "actual training score: 0.20605286184204297\n",
      "actual validation score: 0.5159854133923651, number of remaining columns: 186\n",
      "\n",
      "actual training score: 0.20605454054743233\n",
      "actual validation score: 0.5158370982896663, number of remaining columns: 185\n",
      "\n",
      "actual training score: 0.20666037945176308\n",
      "actual validation score: 0.515734446175528, number of remaining columns: 184\n",
      "\n",
      "actual training score: 0.20673502125286403\n",
      "actual validation score: 0.5167337354723384, number of remaining columns: 183\n",
      "\n",
      "actual training score: 0.20770245654376496\n",
      "actual validation score: 0.5178184730453366, number of remaining columns: 182\n",
      "\n",
      "actual training score: 0.20770790671513673\n",
      "actual validation score: 0.5171588475521001, number of remaining columns: 181\n",
      "\n",
      "actual training score: 0.20788791834545273\n",
      "actual validation score: 0.5160312249394803, number of remaining columns: 180\n",
      "\n",
      "actual training score: 0.2078975977623495\n",
      "actual validation score: 0.5150618520231754, number of remaining columns: 179\n",
      "\n",
      "actual training score: 0.21123276609373332\n",
      "actual validation score: 0.5154406591636365, number of remaining columns: 178\n",
      "\n",
      "actual training score: 0.21124054167330208\n",
      "actual validation score: 0.5146903598688815, number of remaining columns: 177\n",
      "\n",
      "actual training score: 0.22864751168154152\n",
      "actual validation score: 0.5246565459020074, number of remaining columns: 176\n",
      "\n",
      "actual training score: 0.2315222880311859\n",
      "actual validation score: 0.5469565307831679, number of remaining columns: 175\n",
      "\n",
      "actual training score: 0.234559124987467\n",
      "actual validation score: 0.5489710337090763, number of remaining columns: 174\n",
      "\n",
      "actual training score: 0.23835291123893776\n",
      "actual validation score: 0.5507025406194801, number of remaining columns: 173\n",
      "\n",
      "actual training score: 0.23855914058254102\n",
      "actual validation score: 0.5485944760245912, number of remaining columns: 172\n",
      "\n",
      "actual training score: 0.23886329231648118\n",
      "actual validation score: 0.546167551360228, number of remaining columns: 171\n",
      "\n",
      "actual training score: 0.24120231763580346\n",
      "actual validation score: 0.5437578580126476, number of remaining columns: 170\n",
      "\n",
      "actual training score: 0.24120276748521696\n",
      "actual validation score: 0.5439547959998445, number of remaining columns: 169\n",
      "\n",
      "actual training score: 0.2454548021565468\n",
      "actual validation score: 0.549481546125759, number of remaining columns: 168\n",
      "\n",
      "actual training score: 0.24547395498988245\n",
      "actual validation score: 0.5500027963840879, number of remaining columns: 167\n",
      "\n",
      "actual training score: 0.24547996049479748\n",
      "actual validation score: 0.5496070516694533, number of remaining columns: 166\n",
      "\n",
      "actual training score: 0.24608796164351143\n",
      "actual validation score: 0.5505018820418042, number of remaining columns: 165\n",
      "\n",
      "actual training score: 0.24608860552187006\n",
      "actual validation score: 0.5505220553234826, number of remaining columns: 164\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_rr_8w_8', 'cyclostationary_mean_rr_1w_10', 'cyclostationary_mean_rr_8w_41', 'cyclostationary_mean_rr_8w_37', 'cyclostationary_mean_rr_8w_20', 'cyclostationary_mean_rr_24w_2', 'cyclostationary_mean_rr_12w_17', 'cyclostationary_mean_rr_16w_18', 'cyclostationary_mean_rr_12w_16', 'cyclostationary_mean_rr_12w_9', 'cyclostationary_mean_rr_4w_2', 'cyclostationary_mean_rr_8w_39', 'cyclostationary_mean_rr_8w_19', 'cyclostationary_mean_rr_16w_20', 'cyclostationary_mean_rr_4w_11', 'cyclostationary_mean_rr_12w_26', 'cyclostationary_mean_rr_16w_9', 'cyclostationary_mean_rr_4w_41', 'cyclostationary_mean_rr_24w_1', 'cyclostationary_mean_rr_4w_16', 'cyclostationary_mean_rr_8w_14', 'cyclostationary_mean_rr_12w_25', 'cyclostationary_mean_rr_16w_8', 'cyclostationary_mean_rr_8w_21', 'cyclostationary_mean_rr_12w_27', 'cyclostationary_mean_rr_4w_4', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_rr_1w_11', 'cyclostationary_mean_rr_12w_5', 'cyclostationary_mean_rr_8w_17', 'cyclostationary_mean_rr_8w_2', 'cyclostationary_mean_rr_8w_13', 'cyclostationary_mean_rr_4w_8', 'cyclostationary_mean_rr_8w_18', 'cyclostationary_mean_rr_12w_7', 'cyclostationary_mean_rr_12w_21', 'cyclostationary_mean_rr_8w_38', 'cyclostationary_mean_rr_20', 'cyclostationary_mean_rr_1w_25', 'cyclostationary_mean_rr_1w_34', 'cyclostationary_mean_rr_1w_29', 'cyclostationary_mean_rr_1w_33'], \n",
      "\n",
      "validation score: 0.5507025406194801, \n",
      "\n",
      "number of selected features: 42\n",
      "Full aggregate regression train score: 0.570143860193246, test score: -0.1900682280131989\n",
      "Aggregate regression train score with FS: 0.31412797704475226, test score: 0.04608389219958886\n"
     ]
    }
   ],
   "source": [
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w' \n",
    "                                                                         ],\n",
    "                                                                   target_df_trainVal,multiple=True, neigh=0)\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 50)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4abb17cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full aggregate regression train score: 0.570143860193246, test score: -0.1900682280131989\n",
      "Aggregate regression train score with FS: 0.23287565970012902, test score: 0.19911503062903702\n",
      "Full aggregate regression train score: 0.570143860193246, test score: -0.1900682280131989\n",
      "Aggregate regression train score with FS: 0.25839961387297816, test score: 0.14619797028550519\n"
     ]
    }
   ],
   "source": [
    "### forcing a low number of features\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a560a",
   "metadata": {},
   "source": [
    "### not considering last years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd4ef9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 26\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 21\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 16\n",
      "\n",
      "actual training score: 0.10592060253294022\n",
      "actual validation score: 0.25957410500826994, number of remaining columns: 172\n",
      "\n",
      "actual training score: 0.11434965499578342\n",
      "actual validation score: 0.28891625651690056, number of remaining columns: 171\n",
      "\n",
      "actual training score: 0.12743913232825554\n",
      "actual validation score: 0.30933926471792816, number of remaining columns: 170\n",
      "\n",
      "actual training score: 0.13420963230613614\n",
      "actual validation score: 0.32537767591211997, number of remaining columns: 169\n",
      "\n",
      "actual training score: 0.13771236967585265\n",
      "actual validation score: 0.34574757654766897, number of remaining columns: 168\n",
      "\n",
      "actual training score: 0.1424519662231496\n",
      "actual validation score: 0.36719615289618, number of remaining columns: 167\n",
      "\n",
      "actual training score: 0.1471697960573548\n",
      "actual validation score: 0.3841290769212863, number of remaining columns: 166\n",
      "\n",
      "actual training score: 0.1473237006174135\n",
      "actual validation score: 0.3905985581663578, number of remaining columns: 165\n",
      "\n",
      "actual training score: 0.14810344464492553\n",
      "actual validation score: 0.3972962185934593, number of remaining columns: 164\n",
      "\n",
      "actual training score: 0.1577381202615964\n",
      "actual validation score: 0.4008694113438721, number of remaining columns: 163\n",
      "\n",
      "actual training score: 0.1582436666690139\n",
      "actual validation score: 0.4029003832570399, number of remaining columns: 162\n",
      "\n",
      "actual training score: 0.1589626192896969\n",
      "actual validation score: 0.40485033918215985, number of remaining columns: 161\n",
      "\n",
      "actual training score: 0.15945034272223535\n",
      "actual validation score: 0.40636854254177046, number of remaining columns: 160\n",
      "\n",
      "actual training score: 0.1618183574191726\n",
      "actual validation score: 0.4079586941780604, number of remaining columns: 159\n",
      "\n",
      "actual training score: 0.16265553252701792\n",
      "actual validation score: 0.41478602903992956, number of remaining columns: 158\n",
      "\n",
      "actual training score: 0.16274599897845066\n",
      "actual validation score: 0.4160702010381102, number of remaining columns: 157\n",
      "\n",
      "actual training score: 0.1645302154566446\n",
      "actual validation score: 0.41697080387797225, number of remaining columns: 156\n",
      "\n",
      "actual training score: 0.1650054695515616\n",
      "actual validation score: 0.41767450064544054, number of remaining columns: 155\n",
      "\n",
      "actual training score: 0.16569705198939555\n",
      "actual validation score: 0.42111489610728814, number of remaining columns: 154\n",
      "\n",
      "actual training score: 0.16586685180252214\n",
      "actual validation score: 0.42160834245194967, number of remaining columns: 153\n",
      "\n",
      "actual training score: 0.16596426949094156\n",
      "actual validation score: 0.421881543051581, number of remaining columns: 152\n",
      "\n",
      "actual training score: 0.16598004570571578\n",
      "actual validation score: 0.4220264340888944, number of remaining columns: 151\n",
      "\n",
      "actual training score: 0.16598141407924505\n",
      "actual validation score: 0.4219450977760547, number of remaining columns: 150\n",
      "\n",
      "actual training score: 0.16606572693337696\n",
      "actual validation score: 0.4212797372390281, number of remaining columns: 149\n",
      "\n",
      "actual training score: 0.16610478766261694\n",
      "actual validation score: 0.42051001282325706, number of remaining columns: 148\n",
      "\n",
      "actual training score: 0.1683738449141119\n",
      "actual validation score: 0.41968401088421625, number of remaining columns: 147\n",
      "\n",
      "actual training score: 0.1683882588442953\n",
      "actual validation score: 0.41880825962631396, number of remaining columns: 146\n",
      "\n",
      "actual training score: 0.1684826319526399\n",
      "actual validation score: 0.4197708248433547, number of remaining columns: 145\n",
      "\n",
      "actual training score: 0.16873774621648008\n",
      "actual validation score: 0.41924239844386857, number of remaining columns: 144\n",
      "\n",
      "actual training score: 0.17070462415267795\n",
      "actual validation score: 0.41610861123543663, number of remaining columns: 143\n",
      "\n",
      "actual training score: 0.19206067027712426\n",
      "actual validation score: 0.4138470852509102, number of remaining columns: 142\n",
      "\n",
      "actual training score: 0.19376076899887773\n",
      "actual validation score: 0.40761381445003975, number of remaining columns: 141\n",
      "\n",
      "actual training score: 0.19487694142363898\n",
      "actual validation score: 0.4026330673640658, number of remaining columns: 140\n",
      "\n",
      "actual training score: 0.1956519958188243\n",
      "actual validation score: 0.4002080445181081, number of remaining columns: 139\n",
      "\n",
      "actual training score: 0.19682648987171913\n",
      "actual validation score: 0.39786955916953315, number of remaining columns: 138\n",
      "\n",
      "actual training score: 0.1975094938703431\n",
      "actual validation score: 0.39112538895954807, number of remaining columns: 137\n",
      "\n",
      "actual training score: 0.19893064032444185\n",
      "actual validation score: 0.3888708431460258, number of remaining columns: 136\n",
      "\n",
      "actual training score: 0.20036622243317204\n",
      "actual validation score: 0.38243793595820896, number of remaining columns: 135\n",
      "\n",
      "actual training score: 0.2051600686446884\n",
      "actual validation score: 0.3735849045280447, number of remaining columns: 134\n",
      "\n",
      "actual training score: 0.2081274079197254\n",
      "actual validation score: 0.3673457987644607, number of remaining columns: 133\n",
      "\n",
      "actual training score: 0.20856413939722518\n",
      "actual validation score: 0.363129581885441, number of remaining columns: 132\n",
      "\n",
      "actual training score: 0.2119894115323796\n",
      "actual validation score: 0.3563510736511838, number of remaining columns: 131\n",
      "\n",
      "actual training score: 0.2144261885926596\n",
      "actual validation score: 0.3504656564522943, number of remaining columns: 130\n",
      "\n",
      "actual training score: 0.215603601891872\n",
      "actual validation score: 0.3454014298969813, number of remaining columns: 129\n",
      "\n",
      "actual training score: 0.21779036259815465\n",
      "actual validation score: 0.33520805735059567, number of remaining columns: 128\n",
      "\n",
      "actual training score: 0.2190518102033442\n",
      "actual validation score: 0.3265877626216319, number of remaining columns: 127\n",
      "\n",
      "actual training score: 0.22018901320290551\n",
      "actual validation score: 0.31916951350312484, number of remaining columns: 126\n",
      "\n",
      "actual training score: 0.22351155761014607\n",
      "actual validation score: 0.31606267801244425, number of remaining columns: 125\n",
      "\n",
      "actual training score: 0.24466686961629558\n",
      "actual validation score: 0.3065084047525427, number of remaining columns: 124\n",
      "\n",
      "actual training score: 0.2566934728364969\n",
      "actual validation score: 0.3293817566426013, number of remaining columns: 123\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_rr_8w_3', 'cyclostationary_mean_rr_1w_19', 'cyclostationary_mean_rr_16w_14', 'cyclostationary_mean_rr_1w_34', 'cyclostationary_mean_rr_4w_17', 'cyclostationary_mean_rr_8w_14', 'cyclostationary_mean_rr_8w_12', 'cyclostationary_mean_rr_8w_17', 'cyclostationary_mean_rr_8w_13', 'cyclostationary_mean_rr_8w_5', 'cyclostationary_mean_rr_1w_18', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_rr_16w_5', 'cyclostationary_mean_rr_16w_3', 'cyclostationary_mean_rr_4w_7', 'cyclostationary_mean_rr_4w_16', 'cyclostationary_mean_rr_23', 'cyclostationary_mean_rr_25', 'cyclostationary_mean_rr_12w_17', 'cyclostationary_mean_rr_12w_20', 'cyclostationary_mean_rr_24w_8', 'cyclostationary_mean_rr_12w_7', 'cyclostationary_mean_rr_8w_6'], \n",
      "\n",
      "validation score: 0.4220264340888944, \n",
      "\n",
      "number of selected features: 23\n",
      "Full aggregate regression train score: 0.5638525597047267, test score: -0.5792186202726086\n",
      "Aggregate regression train score with FS: 0.28035767051211546, test score: -0.10821251018249534\n"
     ]
    }
   ],
   "source": [
    "### what happens without considering the last years?\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w' \n",
    "                                                                         ],target_df_trainVal, max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', multiple=True, neigh=0)\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 50, 228)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16f4bf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full aggregate regression train score: 0.5638525597047267, test score: -0.5792186202726086\n",
      "Aggregate regression train score with FS: 0.22609829034309015, test score: -0.036331161288709835\n",
      "Full aggregate regression train score: 0.5638525597047267, test score: -0.5792186202726086\n",
      "Aggregate regression train score with FS: 0.2594291140694712, test score: -0.16224153744622516\n"
     ]
    }
   ],
   "source": [
    "### forcing a low number of features\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb343ca6",
   "metadata": {},
   "source": [
    "### repeat both with CMI FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "001f427d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 23\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 40\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 42\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 42\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 31\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 21\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 16\n",
      "\n",
      "----- MI Scores -----\n",
      "[(74, 0.15463009196465674), (75, 0.1392151588916966), (72, 0.1357169943897039), (63, 0.135341465602925), (65, 0.13385298682848135), (122, 0.13330553263800363), (108, 0.1313951123569826), (66, 0.12993577169373366), (78, 0.12978711539451457), (76, 0.1277167333117068), (113, 0.1268652944987288), (31, 0.1259093311394222), (109, 0.123153340059872), (107, 0.12289474292204057), (71, 0.1206564913482002), (110, 0.11943756107974703), (26, 0.11843183257242193), (67, 0.1184024043519813), (70, 0.11815923909731171), (79, 0.11745662108949503), (160, 0.11681941433644995), (23, 0.11669842957919958), (86, 0.11665563165232691), (105, 0.11593597266665183), (112, 0.11547794176591138), (73, 0.11392221336159328), (83, 0.11390380080389086), (82, 0.1132467784690766), (80, 0.11226017023847307), (116, 0.11076817691435498), (68, 0.1098145002871088), (120, 0.10891426535325176), (32, 0.1074136572804673), (37, 0.10668507463685901), (106, 0.10630682284388752), (85, 0.10590170072133323), (43, 0.10571712611859822), (77, 0.10541373531094701), (42, 0.10519447468000323), (28, 0.1047374869344548), (39, 0.1043298333763684), (35, 0.10393761891384183), (118, 0.10369954679192567), (64, 0.10362387250437666), (24, 0.10306563629774144), (111, 0.10292861851750235), (152, 0.10269911285406089), (29, 0.10240080582714721), (121, 0.10122932991771404), (33, 0.10066471923655905), (40, 0.10026974636196617), (87, 0.09977270374931287), (128, 0.09955050794662812), (84, 0.09811195381178954), (69, 0.09787655044075268), (129, 0.09713020346933512), (41, 0.09659348569560508), (159, 0.09658554530744003), (147, 0.096399351647077), (115, 0.09596000527873873), (27, 0.09594113746925195), (126, 0.0956849919532064), (36, 0.09552801324285416), (49, 0.09544196612496783), (104, 0.09543568376333755), (153, 0.09243592584503393), (88, 0.09190769127429747), (81, 0.09141291789432866), (148, 0.09124374118646401), (194, 0.09095409561035661), (30, 0.09044579824851881), (119, 0.08993322580650172), (38, 0.08976104029271358), (123, 0.08958884252605243), (124, 0.0891454400270655), (125, 0.0878928062892166), (114, 0.08670280324561734), (127, 0.08650408972939432), (34, 0.08615621063916047), (161, 0.08595591792652443), (155, 0.08525013843148743), (156, 0.08474960231097273), (154, 0.08453871138440591), (176, 0.08345306850263189), (149, 0.08311109864206963), (44, 0.0822351123209511), (25, 0.08099583060299725), (193, 0.08043189086197061), (117, 0.08025364618559573), (162, 0.07994662175457201), (171, 0.07973284201041114), (167, 0.07966507728762483), (174, 0.07914876981795883), (150, 0.07892945993077997), (165, 0.07846475371001466), (166, 0.078358788033854), (175, 0.07800012585806144), (164, 0.0774794586358655), (102, 0.0770069773784504), (163, 0.07613089267400168), (180, 0.07420566126341957), (46, 0.07391402658240702), (45, 0.07369738667581126), (179, 0.07358666184885036), (195, 0.07339183827400256), (173, 0.07313983161536178), (201, 0.0728500279913484), (178, 0.0723271758393678), (158, 0.07204587467288769), (198, 0.07138356535377582), (137, 0.07034639128071232), (181, 0.07028710324419814), (146, 0.07022591280107687), (168, 0.069565884981515), (131, 0.0692549301923944), (89, 0.06857396899625873), (5, 0.06823215681560615), (177, 0.06819233097525136), (172, 0.06787161933378771), (170, 0.06742774337235224), (97, 0.06716764995461601), (157, 0.0670312162990861), (132, 0.06685559177881356), (135, 0.0668365953586702), (136, 0.06617703974926681), (1, 0.06560255279111699), (197, 0.0655761360767079), (103, 0.06555834514129534), (50, 0.06502687652512058), (0, 0.06398068957143602), (196, 0.06381726548322998), (169, 0.06371701204604703), (12, 0.06369840313960955), (134, 0.06312976508645063), (138, 0.06273974455027156), (144, 0.06254205429337824), (100, 0.06229642166952258), (133, 0.0622670233081979), (101, 0.06193278332408393), (10, 0.06167814060167946), (151, 0.06132156758567073), (58, 0.06128819433456677), (11, 0.06071012146762079), (199, 0.06064093527052284), (51, 0.05967226350504323), (142, 0.05959082899158622), (3, 0.05905332156818296), (60, 0.05884804892807206), (48, 0.05842989975122522), (96, 0.05831905990052018), (130, 0.05792224491106944), (91, 0.05754186509145912), (2, 0.05693558821663704), (207, 0.05613993838797728), (4, 0.056119848013967195), (192, 0.05605962110767706), (15, 0.05596119638681848), (143, 0.055575328930264976), (145, 0.05508723826793659), (7, 0.0550474603306312), (185, 0.05392171002300684), (182, 0.053595530679055245), (90, 0.05351782674782046), (16, 0.0529728123941893), (8, 0.05271966378665267), (139, 0.052501248527335474), (99, 0.05173079339038569), (6, 0.051175489430968155), (94, 0.051072702852412076), (9, 0.05016301501992545), (92, 0.04995991345161359), (53, 0.04988844452898464), (200, 0.04842084564963361), (183, 0.046461174286176805), (190, 0.046351163306507855), (47, 0.04573900827464221), (202, 0.044255032695352046), (13, 0.04353018314288297), (52, 0.04348393856811117), (186, 0.0428612782840835), (95, 0.042858024195323384), (59, 0.04262487155747792), (98, 0.04188545039675412), (189, 0.04080462161313447), (191, 0.04069003160902762), (141, 0.039999400847212825), (61, 0.03946249025410933), (62, 0.039209763512226846), (140, 0.039082601318725915), (187, 0.035514942993646915), (211, 0.034216174262358935), (57, 0.0340417081535564), (22, 0.033971791235641306), (93, 0.03238433397870408), (206, 0.03218211827294878), (188, 0.0319603125397588), (214, 0.031253426537302786), (184, 0.029525390775470353), (205, 0.029427560463259686), (212, 0.02903110111067159), (203, 0.02790887539974222), (210, 0.026889205406195594), (209, 0.025558959382657277), (54, 0.021619936937950463), (56, 0.021569519141887455), (204, 0.02139718216292766), (213, 0.021046393705901036), (208, 0.020596844104832795), (55, 0.015719990289564056), (20, 0.015627290681037128), (19, 0.011699603225898674), (21, 0.002071393783716905), (14, 0.0006394158367289899), (18, -0.0006706892242102154), (17, -0.00994323745191566)]\n",
      "Best MI score: 0.15463009196465674\n",
      "Adding first best original feature: 74\n",
      "CMI: 0.021980973118774366\n",
      "CMI: 0.021365568770378623\n",
      "CMI: 0.009794419275739735\n",
      "CMI: 0.017183230915662984\n",
      "CMI: 0.018882463316829745\n",
      "CMI: 0.015800295596205938\n",
      "CMI: 0.005656819507116301\n",
      "CMI: 0.008317350276735774\n",
      "CMI: 0.02818221960032899\n",
      "CMI: 0.010093753126111021\n",
      "CMI: 0.0031334490227397926\n",
      "CMI: 0.021898381978498443\n",
      "CMI: 0.019021030527279548\n",
      "CMI: 0.0075880229314499725\n",
      "CMI: 0.016785441481980856\n",
      "CMI: 0.015699758709935063\n",
      "CMI: 0.006972212826743651\n",
      "CMI: 0.02312428049389023\n",
      "CMI: 0.004609654763419346\n",
      "CMI: 0.010747165595465374\n",
      "CMI: 0.008187888604023419\n",
      "CMI: 0.015855535760616546\n",
      "CMI: 0.0066077298640057625\n",
      "CMI: 0.0016863517356727198\n",
      "CMI: 0.01658243368894627\n",
      "CMI: 0.013093901705611977\n",
      "CMI: 0.013918785359377212\n",
      "CMI: 0.007698166996806061\n",
      "CMI: 0.0018061786689761994\n",
      "CMI: 0.0022120624342514272\n",
      "CMI: 0.011222626651787915\n",
      "CMI: 0.006273167827107545\n",
      "CMI: 0.009841645316588488\n",
      "CMI: 0.013066126516128318\n",
      "CMI: 0.013671613240694325\n",
      "CMI: 0.012026085764172995\n",
      "CMI: 0.012657334957513505\n",
      "CMI: 0.009407218684359592\n",
      "CMI: 0.011437281358169876\n",
      "CMI: 0.0066553832983646255\n",
      "CMI: 0.01816121674500648\n",
      "CMI: 0.010881741101957582\n",
      "CMI: 0.009788390092499766\n",
      "CMI: 0.010562179626494694\n",
      "CMI: 0.024738997615140423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.0162086271422808\n",
      "CMI: 0.02030907698636955\n",
      "CMI: 0.024367653443057663\n",
      "CMI: 0.008431352469206288\n",
      "CMI: 0.023320703433699602\n",
      "CMI: 0.022952568254644812\n",
      "CMI: 0.011693563881413988\n",
      "CMI: 0.013464965382827848\n",
      "CMI: 0.01303937868153951\n",
      "CMI: 0.01805718860403019\n",
      "CMI: 0.01373735765514808\n",
      "CMI: 0.022976856722381145\n",
      "CMI: 0.004797482087527033\n",
      "CMI: 0.009453256920418318\n",
      "CMI: 0.01463575555597954\n",
      "CMI: 0.0013831452148353185\n",
      "Highest CMI score: 0.02818221960032899\n",
      "Adding original feature: 31\n",
      "CMI: 0.007555077864882881\n",
      "CMI: 0.005145428377029138\n",
      "CMI: 0.008767515909695128\n",
      "CMI: 0.0021291930994051522\n",
      "CMI: 0.0042485856933613675\n",
      "CMI: 0.003165458889068079\n",
      "CMI: 0.0012281885664826853\n",
      "CMI: 0.009363186553400266\n",
      "CMI: 0.011385595948458282\n",
      "CMI: 0.010710989114736835\n",
      "CMI: 0.006875518816054554\n",
      "CMI: 0.008656587767850915\n",
      "CMI: 0.015870314102978483\n",
      "CMI: 0.005697809205579829\n",
      "CMI: 0.0044998498491196914\n",
      "CMI: 0.004467769982752334\n",
      "CMI: 0.0033174485360002726\n",
      "CMI: 0.005028560574135921\n",
      "CMI: 0.020894998536248016\n",
      "CMI: 0.021512151851664857\n",
      "CMI: 0.014749660150328747\n",
      "CMI: 0.015086835128164694\n",
      "CMI: 0.010765931851576094\n",
      "CMI: 0.015617872032479718\n",
      "CMI: 0.007730657142322128\n",
      "CMI: 0.0067820023236329074\n",
      "CMI: 0.00031519388144335414\n",
      "CMI: 0.010594286028554445\n",
      "CMI: 0.01494930696248109\n",
      "CMI: 0.014326117771078728\n",
      "CMI: 0.020897968764276326\n",
      "CMI: 0.018897207397913507\n",
      "CMI: 0.01926714382682576\n",
      "CMI: 0.011085399415695418\n",
      "CMI: 0.0230945004948426\n",
      "CMI: 0.005760578616498341\n",
      "CMI: 0.0024154106686241905\n",
      "CMI: 0.003463504301123188\n",
      "CMI: 0.001880414456037316\n",
      "CMI: 0.00012534826154386725\n",
      "CMI: 0.005795487247953229\n",
      "CMI: 0.022098399823650028\n",
      "CMI: 0.015711144130150678\n",
      "CMI: 0.017178950740970783\n",
      "CMI: 0.01969825496559216\n",
      "CMI: 0.019085803817800256\n",
      "CMI: 0.021849908862061868\n",
      "CMI: 0.02889380753996529\n",
      "CMI: 0.01146256944666782\n",
      "CMI: 0.005444272435061709\n",
      "CMI: 0.005986576437581326\n",
      "CMI: 0.000516430512490007\n",
      "CMI: 0.0009227782340180679\n",
      "CMI: 0.004369919212763945\n",
      "CMI: 0.004459313681320881\n",
      "CMI: 0.007727753470808368\n",
      "CMI: 0.006103769541469489\n",
      "CMI: 0.002146462301202856\n",
      "CMI: 6.31485661168052e-05\n",
      "CMI: 0.0060079443187805726\n",
      "CMI: 0.007119897937305997\n",
      "CMI: 0.013037101201900408\n",
      "CMI: 0.017167824169533996\n",
      "CMI: 0.01765123559727952\n",
      "CMI: 0.0017450595798979562\n",
      "CMI: 0.01797277923042148\n",
      "CMI: 0.002904823314071714\n",
      "CMI: 0.009449531663525218\n",
      "CMI: 0.00222363505967349\n",
      "CMI: 0.01076549361486262\n",
      "CMI: 0.011015535906356622\n",
      "CMI: 0.010039882775142533\n",
      "Highest CMI score: 0.02889380753996529\n",
      "Adding original feature: 170\n",
      "CMI: 0.006404003751719428\n",
      "CMI: 0.007076042705368102\n",
      "CMI: 0.0037778599171594818\n",
      "CMI: 0.000805527184430832\n",
      "CMI: 0.0010364608183906499\n",
      "CMI: 0.004998349204687835\n",
      "CMI: 0.006705325824925973\n",
      "CMI: 0.0022381695619264896\n",
      "CMI: 6.76473527540522e-05\n",
      "CMI: 0.0001568321021608865\n",
      "CMI: 0.00010547277237815678\n",
      "CMI: 0.0025315667228967\n",
      "CMI: 0.00045846184878711727\n",
      "CMI: 0.0004643231177007823\n",
      "CMI: 0.00046280592393749265\n",
      "CMI: 0.00688192284988795\n",
      "CMI: 0.0060258140434969465\n",
      "CMI: 0.0016703929952668894\n",
      "CMI: 0.0006614370969861838\n",
      "CMI: 0.0029780385497392425\n",
      "CMI: 0.002117449877475225\n",
      "CMI: 0.006596717394895785\n",
      "CMI: 0.009272301900215274\n",
      "CMI: 0.009199663723143209\n",
      "CMI: 0.00811460878997805\n",
      "CMI: 0.007162783767712844\n",
      "CMI: 0.006097374397631972\n",
      "CMI: 0.00027658090198706686\n",
      "CMI: 0.0003407313512685528\n",
      "CMI: 8.192791337238714e-05\n",
      "CMI: 0.00429023131389461\n",
      "CMI: 2.4488895679908307e-06\n",
      "Highest CMI score: 0.009272301900215274\n",
      "Adding original feature: 142\n",
      "CMI: 0.0009872649448464388\n",
      "CMI: 0.0027335487164521777\n",
      "CMI: 0.003303521520508085\n",
      "CMI: 0.004207558426772562\n",
      "CMI: 0.0027121885529804157\n",
      "CMI: 0.0016646079495234722\n",
      "CMI: 0.004997565523122638\n",
      "CMI: 0.006852670853723292\n",
      "CMI: 0.003505151385333277\n",
      "CMI: 0.006132634878005139\n",
      "CMI: 0.002916347580955464\n",
      "CMI: 0.005203677672645929\n",
      "CMI: 0.0030502949866586804\n",
      "CMI: 0.0019401478166407027\n",
      "CMI: 0.006552535752908706\n",
      "CMI: 0.002464599515364513\n",
      "CMI: 0.0015157306421589023\n",
      "CMI: 0.00455912154327498\n",
      "CMI: 0.005304165831883034\n",
      "CMI: 0.005830411194715529\n",
      "CMI: 0.0029262106987727743\n",
      "CMI: 0.005879458316004699\n",
      "CMI: 0.007823374314260195\n",
      "CMI: 0.0049429612020150115\n",
      "CMI: 0.0021726710408415673\n",
      "CMI: 0.0014953358891861557\n",
      "CMI: 0.0019673551259922484\n",
      "CMI: 0.000542446968664595\n",
      "CMI: 0.003027946836247547\n",
      "CMI: 0.002032211918336607\n",
      "CMI: 0.002608241564896918\n",
      "CMI: 0.0030166050406786604\n",
      "CMI: 0.004790443190644339\n",
      "CMI: 0.0034986022304216158\n",
      "Highest CMI score: 0.007823374314260195\n",
      "Adding original feature: 120\n",
      "CMI: 0.002723513335224942\n",
      "CMI: 0.0003544647324963124\n",
      "CMI: 0.00028051013675653436\n",
      "CMI: 0.00017840493845483474\n",
      "CMI: 0.000579414592625338\n",
      "CMI: 0.0007988501268098025\n",
      "CMI: 0.0007970617838385652\n",
      "CMI: 0.0019525840428416819\n",
      "Highest CMI score: 0.002723513335224942\n",
      "Adding original feature: 73\n",
      "CMI: 9.016560280461494e-05\n",
      "Highest CMI score: 9.016560280461494e-05\n",
      "Adding original feature: 111\n",
      "CMI: 0.001318132337106176\n",
      "Highest CMI score: 0.001318132337106176\n",
      "Adding original feature: 144\n",
      "Highest CMI score: -0.0009897529974984831\n",
      "\n",
      "[74, 31, 170, 142, 120, 73, 111, 144]\n",
      "\n",
      "Full aggregate regression train score: 0.570143860193246, test score: -0.1900682280131989\n",
      "Aggregate regression train score with FS: 0.23596834178513937, test score: 0.17959964680879825\n"
     ]
    }
   ],
   "source": [
    "### all data\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w' \n",
    "                                                                         ],target_df_trainVal,multiple=True, neigh=0)\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90ba8f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 26\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 21\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 16\n",
      "\n",
      "----- MI Scores -----\n",
      "[(101, 0.14355837775756955), (71, 0.13768140198491086), (72, 0.13631856652553526), (95, 0.13513961185319756), (62, 0.13314748811318639), (77, 0.13133916425325634), (99, 0.13077215637224784), (108, 0.12940937077645107), (69, 0.12800303924902318), (40, 0.12776157435205412), (92, 0.12773768285015272), (73, 0.12589313998629875), (74, 0.12581966451285354), (65, 0.12322133486841645), (36, 0.12261245758049465), (93, 0.12259646278618203), (64, 0.12247561578204438), (103, 0.12190367248356769), (102, 0.12131731402791014), (94, 0.1195466277847605), (104, 0.11935459557517307), (75, 0.11863013144173605), (100, 0.116316281664481), (34, 0.11577335968657665), (70, 0.11572919380605058), (97, 0.11500464062877018), (105, 0.1149532106544037), (127, 0.11397915203550381), (35, 0.11373749145800978), (26, 0.11363223689263681), (107, 0.11311314301417705), (30, 0.11215634643910154), (66, 0.11139134112669105), (38, 0.11110177375212067), (68, 0.11094609892506647), (27, 0.11047003177135338), (141, 0.11002993252556946), (32, 0.10980008890621286), (29, 0.10961698506481543), (76, 0.10952880477659725), (63, 0.10915090860445041), (128, 0.10887729066184709), (122, 0.10854986739176381), (96, 0.10842109370077785), (67, 0.10773788087664628), (33, 0.10587611045595118), (130, 0.1044016996746289), (129, 0.10413780200273227), (98, 0.1020698701738791), (134, 0.1020265124535254), (0, 0.10194430319429787), (106, 0.10069367714903134), (91, 0.09977330759904632), (139, 0.09902441152547063), (28, 0.09772263150344872), (125, 0.09768017693113938), (37, 0.09745711036293309), (131, 0.09730112144194526), (123, 0.09572845401960096), (39, 0.09422985392702304), (52, 0.09319334116992599), (136, 0.09268049693371382), (133, 0.09218329814251448), (156, 0.09215578993034604), (135, 0.08918334467139254), (111, 0.08912960202552749), (42, 0.0873634985099328), (41, 0.08659593744214443), (144, 0.08624592249189425), (155, 0.08617356256809444), (113, 0.08582031160305832), (140, 0.08535050386355976), (31, 0.08488082023727597), (126, 0.08384475209920172), (7, 0.08350349827058232), (79, 0.0835027641083921), (3, 0.08274029747752781), (110, 0.08263412532320004), (124, 0.08244670911682571), (1, 0.08233081542811345), (83, 0.08151108340944214), (109, 0.08129215084292556), (2, 0.0812638036768999), (117, 0.08055610686235969), (114, 0.08034126364411728), (116, 0.07964691902253347), (84, 0.07954846634223894), (137, 0.07922496088131074), (138, 0.07827625691624385), (4, 0.07812853841300374), (5, 0.07809985136145359), (12, 0.07809602128133689), (88, 0.0778133663495202), (80, 0.07778342993531409), (8, 0.07743919599614255), (47, 0.07732253147526302), (160, 0.07646322063546719), (132, 0.07643493985941578), (89, 0.0760896232864488), (90, 0.07538612178216325), (82, 0.07531600016323282), (121, 0.07517384353492652), (143, 0.07402541320179462), (6, 0.0730802305726844), (112, 0.07198837029942018), (86, 0.07048609699992324), (81, 0.07023164308104615), (18, 0.07000142194521591), (154, 0.06976735121603825), (9, 0.0691025480517386), (148, 0.06891183335119605), (145, 0.06882787301797477), (142, 0.0683769258029135), (78, 0.06796725354591977), (54, 0.06769674134768101), (119, 0.06711816131914451), (87, 0.0659842873848529), (161, 0.06563474004763162), (53, 0.06547152361623924), (164, 0.06423086899290766), (118, 0.06346396421036402), (13, 0.0627809222053309), (157, 0.06236370405371424), (146, 0.062261570348160315), (147, 0.06161752152005982), (44, 0.0604918936542499), (58, 0.06012333330044267), (115, 0.05970105597397844), (153, 0.0590328555827733), (46, 0.05897262422930583), (43, 0.0588240847733125), (45, 0.05863647477718676), (11, 0.05838305278312624), (158, 0.055838286805899424), (85, 0.05568856880074352), (10, 0.055575950836459116), (159, 0.052697798611538754), (120, 0.05246711871533758), (163, 0.05062787355801183), (165, 0.05058217332421378), (162, 0.048409961933339365), (48, 0.04826807931778649), (57, 0.04777766713787423), (49, 0.04455385156469544), (61, 0.04454066464627824), (149, 0.044410241663400796), (151, 0.04345337900952832), (173, 0.04048637089050686), (59, 0.040426793183453956), (150, 0.03991244299519263), (152, 0.03959551390531029), (56, 0.039518011396490416), (172, 0.03825899078277536), (169, 0.03658165616385244), (60, 0.0356893733065745), (14, 0.03432495017777366), (166, 0.03273618030565395), (21, 0.030282826067192226), (50, 0.029750199540781657), (24, 0.02414370605294078), (167, 0.0205743832586117), (51, 0.019634142980389298), (55, 0.0191941298203265), (171, 0.016861860242097963), (20, 0.016736980901624326), (168, 0.016021337766796925), (23, 0.011100927000344788), (19, 0.003485104946823075), (170, -0.0012968733903822728), (22, -0.004800250683501454), (25, -0.007319040533698376), (15, -0.008378746513857218), (16, -0.018062055661859172), (17, -0.02324881386697934)]\n",
      "Best MI score: 0.14355837775756955\n",
      "Adding first best original feature: 101\n",
      "CMI: 0.005600787448859251\n",
      "CMI: 0.004028937508749303\n",
      "CMI: 0.004766082430778584\n",
      "CMI: 0.008430836778387185\n",
      "CMI: 0.0009388299253688392\n",
      "CMI: 0.012611455976585945\n",
      "CMI: 0.0021057047063558765\n",
      "CMI: 0.005300827933198304\n",
      "CMI: 0.007826639817621911\n",
      "CMI: 0.02592549684949902\n",
      "CMI: 0.01545230562931893\n",
      "CMI: 0.0017219609859342733\n",
      "CMI: 0.015891368929779603\n",
      "CMI: 0.013089094634827575\n",
      "CMI: 0.02277474058687809\n",
      "CMI: 0.019746016874345657\n",
      "CMI: 0.011674537852056938\n",
      "CMI: 0.013096229464576031\n",
      "CMI: 0.014093601365289421\n",
      "CMI: 0.002302731099091959\n",
      "CMI: 0.002986443069904754\n",
      "CMI: 0.009013369511790686\n",
      "CMI: 0.0008570542526449842\n",
      "CMI: 0.009075917884910967\n",
      "CMI: 0.010453168798459811\n",
      "CMI: 0.010790796916926387\n",
      "CMI: 0.014827652296081267\n",
      "CMI: 0.010103668943505895\n",
      "CMI: 0.009535737328546956\n",
      "CMI: 0.0017901347908161058\n",
      "CMI: 0.01262281384880598\n",
      "CMI: 0.015134186246724385\n",
      "CMI: 0.01642412698152612\n",
      "CMI: 0.02112494035212692\n",
      "CMI: 0.02957636487886034\n",
      "CMI: 0.020434500266516692\n",
      "CMI: 0.024846552021263707\n",
      "CMI: 0.027414095955679507\n",
      "CMI: 0.020548982391023873\n",
      "CMI: 0.009033112792450726\n",
      "CMI: 0.022898955484991435\n",
      "CMI: 0.02363382075240661\n",
      "CMI: 0.02533992922056935\n",
      "CMI: 0.035363194637746315\n",
      "CMI: 0.0287842013520212\n",
      "CMI: 0.03806384644887917\n",
      "CMI: 0.006117685288830638\n",
      "CMI: 0.005515861669712213\n",
      "CMI: 0.006251424408710682\n",
      "CMI: 0.00801522777423505\n",
      "CMI: 0.007467964778863939\n",
      "CMI: 0.004786682860404762\n",
      "CMI: 0.024654237253254913\n",
      "CMI: 0.01839586203968313\n",
      "CMI: 0.015136273038408532\n",
      "Highest CMI score: 0.03806384644887917\n",
      "Adding original feature: 138\n",
      "CMI: 0.01670994434855666\n",
      "CMI: 0.015712032997746622\n",
      "CMI: 0.016953104179279255\n",
      "CMI: 0.019404107587871644\n",
      "CMI: 0.01893324861579121\n",
      "CMI: 0.008350008904517842\n",
      "CMI: 0.014492476912980584\n",
      "CMI: 0.01364834408563001\n",
      "CMI: 0.009691502029502724\n",
      "CMI: 0.009500946835022478\n",
      "CMI: 0.041031662380613954\n",
      "CMI: 0.0384041769417158\n",
      "CMI: 0.039778451519872055\n",
      "CMI: 0.03862114373545364\n",
      "CMI: 0.044698638584700606\n",
      "CMI: 0.053373285493844486\n",
      "CMI: 0.042272146376014785\n",
      "CMI: 0.03960802099781277\n",
      "CMI: 0.04783385078958885\n",
      "CMI: 0.044497849651531696\n",
      "CMI: 0.04681462627383012\n",
      "CMI: 0.04327445621690973\n",
      "CMI: 0.02865133158717542\n",
      "CMI: 0.020576690434251976\n",
      "CMI: 0.021857811178821962\n",
      "CMI: 0.024268607249971597\n",
      "CMI: 0.023926436039582416\n",
      "CMI: 0.011909920503368115\n",
      "CMI: 0.00718537454908888\n",
      "CMI: 0.0017849244350367777\n",
      "CMI: 0.007862632464277791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.006810676911874841\n",
      "CMI: 0.0003894815917769856\n",
      "CMI: 0.006351969276642722\n",
      "CMI: 0.002449190532476969\n",
      "CMI: 0.012064889418532038\n",
      "CMI: 0.007945307895464604\n",
      "CMI: 0.0022072840200793864\n",
      "CMI: 0.0018014024579652566\n",
      "CMI: 0.024012728131077965\n",
      "CMI: 0.03346232254720807\n",
      "CMI: 0.007717053308487237\n",
      "CMI: 0.006301800816117559\n",
      "CMI: 0.006761302777913453\n",
      "CMI: 0.001763515234163543\n",
      "CMI: 0.0010612247011268228\n",
      "CMI: 0.003821024474682244\n",
      "CMI: 0.011096144849710748\n",
      "CMI: 0.008330975028102344\n",
      "CMI: 0.010191782025033819\n",
      "CMI: 0.001401013303171439\n",
      "CMI: 0.006135055751648716\n",
      "CMI: 0.001747243688729333\n",
      "CMI: 0.004219734192394686\n",
      "CMI: 0.008004362965051443\n",
      "CMI: 0.013658813240005896\n",
      "CMI: 0.029099591408473208\n",
      "CMI: 0.0185843400452608\n",
      "CMI: 0.01989552944463871\n",
      "CMI: 0.013829367495038686\n",
      "CMI: 0.004226034810538876\n",
      "CMI: 0.024930617010961664\n",
      "CMI: 0.0010519853484278474\n",
      "CMI: 0.007057236941759221\n",
      "CMI: 0.0003617081529760924\n",
      "CMI: 0.004294906922996555\n",
      "CMI: 0.02293501857033997\n",
      "CMI: 0.021144311352036232\n",
      "CMI: 0.01335770095741487\n",
      "CMI: 0.01823280398590263\n",
      "CMI: 0.019627842611362273\n",
      "CMI: 0.011068146594575806\n",
      "CMI: 0.01339191870436962\n",
      "CMI: 0.019935631960975142\n",
      "CMI: 0.01860508911101602\n",
      "CMI: 0.023255666062741542\n",
      "CMI: 0.0153530754418571\n",
      "CMI: 0.018217759539453676\n",
      "CMI: 0.015155460525892034\n",
      "CMI: 0.030985241528301233\n",
      "CMI: 0.004665125630919614\n",
      "CMI: 0.0017667863134133988\n",
      "CMI: 0.005879984908587987\n",
      "CMI: 0.010688702211057416\n",
      "CMI: 0.004574773129837922\n",
      "CMI: 0.011776272019478728\n",
      "CMI: 0.012770195931777223\n",
      "CMI: 0.010898179955107556\n",
      "CMI: 0.0032332351400183312\n",
      "CMI: 0.0018233459394891016\n",
      "CMI: 0.006811529627425789\n",
      "CMI: 0.002107218072184447\n",
      "CMI: 0.005718888450568199\n",
      "CMI: 0.004748149617930353\n",
      "CMI: 0.01196597022519913\n",
      "CMI: 0.00574083919639648\n",
      "CMI: 0.003478055150868714\n",
      "CMI: 0.002654930980940745\n",
      "CMI: 0.0036899345509657233\n",
      "CMI: 0.00450835421084303\n",
      "CMI: 0.004742023955333741\n",
      "Highest CMI score: 0.053373285493844486\n",
      "Adding original feature: 31\n",
      "CMI: 0.00036200195010094305\n",
      "CMI: 0.008979250519111998\n",
      "CMI: 0.0013886564211209873\n",
      "CMI: 0.00274971328510476\n",
      "CMI: 0.003088086978102339\n",
      "CMI: 0.0002523158583921381\n",
      "CMI: 0.003615789885036802\n",
      "CMI: 0.0038522250186539264\n",
      "CMI: 0.002045525985734431\n",
      "CMI: 0.004218915503222204\n",
      "CMI: 0.006356745115261131\n",
      "Highest CMI score: 0.008979250519111998\n",
      "Adding original feature: 72\n",
      "CMI: 0.0007714316605275939\n",
      "CMI: 0.004799041710709134\n",
      "CMI: 0.0006907480139558275\n",
      "CMI: 0.008100404901353137\n",
      "Highest CMI score: 0.008100404901353137\n",
      "Adding original feature: 137\n",
      "Highest CMI score: -0.002344817466662097\n",
      "\n",
      "[101, 138, 31, 72, 137]\n",
      "\n",
      "Full aggregate regression train score: 0.5638525597047267, test score: -0.5792186202726086\n",
      "Aggregate regression train score with FS: 0.2151914257157881, test score: 0.17754931783232586\n"
     ]
    }
   ],
   "source": [
    "### what happens without considering the last years?\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w' \n",
    "                                                                         ],target_df_trainVal, max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', multiple=True, neigh=0)\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac92b9fa",
   "metadata": {},
   "source": [
    "## both"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57470209",
   "metadata": {},
   "source": [
    "### full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4332dd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 17\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 18\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 18\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 14\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 17\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 18\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 23\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 40\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 42\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 42\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 31\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 21\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 16\n",
      "\n",
      "actual training score: 0.1911888490947128\n",
      "actual validation score: 0.4337463751959604, number of remaining columns: 330\n",
      "\n",
      "actual training score: 0.20830221324950493\n",
      "actual validation score: 0.46459284384984156, number of remaining columns: 329\n",
      "\n",
      "actual training score: 0.21514902393059343\n",
      "actual validation score: 0.4776587694053882, number of remaining columns: 328\n",
      "\n",
      "actual training score: 0.23225205377098568\n",
      "actual validation score: 0.48719078785158776, number of remaining columns: 327\n",
      "\n",
      "actual training score: 0.23720405963854896\n",
      "actual validation score: 0.5108252910372613, number of remaining columns: 326\n",
      "\n",
      "actual training score: 0.23901491268633235\n",
      "actual validation score: 0.522475731283175, number of remaining columns: 325\n",
      "\n",
      "actual training score: 0.24403766258308235\n",
      "actual validation score: 0.5349765063362263, number of remaining columns: 324\n",
      "\n",
      "actual training score: 0.2549645596307837\n",
      "actual validation score: 0.543736306640503, number of remaining columns: 323\n",
      "\n",
      "actual training score: 0.27379767673099353\n",
      "actual validation score: 0.5485367159218917, number of remaining columns: 322\n",
      "\n",
      "actual training score: 0.2744867763711488\n",
      "actual validation score: 0.5531362016805264, number of remaining columns: 321\n",
      "\n",
      "actual training score: 0.2762856965596461\n",
      "actual validation score: 0.5567055572872078, number of remaining columns: 320\n",
      "\n",
      "actual training score: 0.2769708395248843\n",
      "actual validation score: 0.5603412213978571, number of remaining columns: 319\n",
      "\n",
      "actual training score: 0.27730859690181764\n",
      "actual validation score: 0.5634889648203539, number of remaining columns: 318\n",
      "\n",
      "actual training score: 0.27775242906240505\n",
      "actual validation score: 0.5657002878060715, number of remaining columns: 317\n",
      "\n",
      "actual training score: 0.2778998104170114\n",
      "actual validation score: 0.5686365280200822, number of remaining columns: 316\n",
      "\n",
      "actual training score: 0.2784259971566968\n",
      "actual validation score: 0.5707011088941936, number of remaining columns: 315\n",
      "\n",
      "actual training score: 0.28031733026442307\n",
      "actual validation score: 0.5722808326525656, number of remaining columns: 314\n",
      "\n",
      "actual training score: 0.2808727646000089\n",
      "actual validation score: 0.5742369767877449, number of remaining columns: 313\n",
      "\n",
      "actual training score: 0.2837178128031478\n",
      "actual validation score: 0.5849357520610491, number of remaining columns: 312\n",
      "\n",
      "actual training score: 0.28375611100502385\n",
      "actual validation score: 0.5876253330954988, number of remaining columns: 311\n",
      "\n",
      "actual training score: 0.28707631745940976\n",
      "actual validation score: 0.5916407051847399, number of remaining columns: 310\n",
      "\n",
      "actual training score: 0.28720483078487424\n",
      "actual validation score: 0.5971435832031834, number of remaining columns: 309\n",
      "\n",
      "actual training score: 0.28760459195958465\n",
      "actual validation score: 0.6009073463340183, number of remaining columns: 308\n",
      "\n",
      "actual training score: 0.29014556564244776\n",
      "actual validation score: 0.6059772564506523, number of remaining columns: 307\n",
      "\n",
      "actual training score: 0.29146442690886\n",
      "actual validation score: 0.6084012899535758, number of remaining columns: 306\n",
      "\n",
      "actual training score: 0.29204185801192384\n",
      "actual validation score: 0.6112034423248455, number of remaining columns: 305\n",
      "\n",
      "actual training score: 0.29401935282694547\n",
      "actual validation score: 0.6147351104249543, number of remaining columns: 304\n",
      "\n",
      "actual training score: 0.29457221192985417\n",
      "actual validation score: 0.6175688672682247, number of remaining columns: 303\n",
      "\n",
      "actual training score: 0.29689701278608605\n",
      "actual validation score: 0.6192503018134923, number of remaining columns: 302\n",
      "\n",
      "actual training score: 0.29824024489312495\n",
      "actual validation score: 0.621767801315801, number of remaining columns: 301\n",
      "\n",
      "actual training score: 0.29886563732686566\n",
      "actual validation score: 0.6238041077202385, number of remaining columns: 300\n",
      "\n",
      "actual training score: 0.30551851222645576\n",
      "actual validation score: 0.627357277443187, number of remaining columns: 299\n",
      "\n",
      "actual training score: 0.3102343676090934\n",
      "actual validation score: 0.6334000301975646, number of remaining columns: 298\n",
      "\n",
      "actual training score: 0.3103328437923236\n",
      "actual validation score: 0.6366959492501423, number of remaining columns: 297\n",
      "\n",
      "actual training score: 0.31097655293393534\n",
      "actual validation score: 0.6410165038581352, number of remaining columns: 296\n",
      "\n",
      "actual training score: 0.3117754218069009\n",
      "actual validation score: 0.6444715571577807, number of remaining columns: 295\n",
      "\n",
      "actual training score: 0.3125031058815838\n",
      "actual validation score: 0.6486313817746164, number of remaining columns: 294\n",
      "\n",
      "actual training score: 0.31859295656886155\n",
      "actual validation score: 0.6502535679744601, number of remaining columns: 293\n",
      "\n",
      "actual training score: 0.31864888566497096\n",
      "actual validation score: 0.6520339210365564, number of remaining columns: 292\n",
      "\n",
      "actual training score: 0.3196021741592605\n",
      "actual validation score: 0.6553808065389086, number of remaining columns: 291\n",
      "\n",
      "actual training score: 0.3196931259423731\n",
      "actual validation score: 0.6565581813822634, number of remaining columns: 290\n",
      "\n",
      "actual training score: 0.3206128853039495\n",
      "actual validation score: 0.6572357186218887, number of remaining columns: 289\n",
      "\n",
      "actual training score: 0.3209642722241163\n",
      "actual validation score: 0.6581861256075523, number of remaining columns: 288\n",
      "\n",
      "actual training score: 0.3211332178621551\n",
      "actual validation score: 0.6588498303980868, number of remaining columns: 287\n",
      "\n",
      "actual training score: 0.32116626038339646\n",
      "actual validation score: 0.6594337607534435, number of remaining columns: 286\n",
      "\n",
      "actual training score: 0.32126134485611424\n",
      "actual validation score: 0.6596762656532993, number of remaining columns: 285\n",
      "\n",
      "actual training score: 0.3214479161544004\n",
      "actual validation score: 0.6599927174393496, number of remaining columns: 284\n",
      "\n",
      "actual training score: 0.3219836834051121\n",
      "actual validation score: 0.6603711510842117, number of remaining columns: 283\n",
      "\n",
      "actual training score: 0.3219941498222345\n",
      "actual validation score: 0.6604080076223866, number of remaining columns: 282\n",
      "\n",
      "actual training score: 0.32234692454859726\n",
      "actual validation score: 0.6602853745381468, number of remaining columns: 281\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_rr_8w_8', 'cyclostationary_mean_tg_1w_9', 'cyclostationary_mean_tg_8w_10', 'cyclostationary_mean_rr_16w_12', 'cyclostationary_mean_rr_4w_27', 'cyclostationary_mean_rr_4w_35', 'cyclostationary_mean_rr_8w_18', 'cyclostationary_mean_rr_12w_9', 'cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_tg_9', 'cyclostationary_mean_rr_12w_12', 'cyclostationary_mean_tg_1w_6', 'cyclostationary_mean_rr_24w_3', 'cyclostationary_mean_rr_8w_7', 'cyclostationary_mean_rr_4w_3', 'cyclostationary_mean_rr_4w_26', 'cyclostationary_mean_tg_4', 'cyclostationary_mean_tg_7', 'cyclostationary_mean_rr_8w_41', 'cyclostationary_mean_rr_8w_37', 'cyclostationary_mean_rr_24w_4', 'cyclostationary_mean_rr_24w_15', 'cyclostationary_mean_rr_8w_14', 'cyclostationary_mean_rr_12w_27', 'cyclostationary_mean_rr_16w_18', 'cyclostationary_mean_tg_24w_10', 'cyclostationary_mean_tg_12w_16', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_tg_24w_8', 'cyclostationary_mean_rr_12w_15', 'cyclostationary_mean_rr_8w_39', 'cyclostationary_mean_tg_12w_1', 'cyclostationary_mean_tg_12w_11', 'cyclostationary_mean_tg_16w_11', 'cyclostationary_mean_rr_16w_11', 'cyclostationary_mean_rr_12w_17', 'cyclostationary_mean_rr_12w_21', 'cyclostationary_mean_rr_12w_22', 'cyclostationary_mean_rr_1w_11', 'cyclostationary_mean_rr_12w_8', 'cyclostationary_mean_rr_12w_4', 'cyclostationary_mean_tg_4w_4', 'cyclostationary_mean_tg_16w_8', 'cyclostationary_mean_tg_16w_14', 'cyclostationary_mean_rr_20', 'cyclostationary_mean_rr_16w_7', 'cyclostationary_mean_tg_16', 'cyclostationary_mean_rr_24w_11', 'cyclostationary_mean_rr_1w_36', 'cyclostationary_mean_tg_1w_5'], \n",
      "\n",
      "validation score: 0.6604080076223866, \n",
      "\n",
      "number of selected features: 50\n",
      "Full aggregate regression train score: 0.7301615350510935, test score: -2.802119948552454\n",
      "Aggregate regression train score with FS: 0.4022099361812336, test score: 0.16785896281726176\n"
     ]
    }
   ],
   "source": [
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_tg', \n",
    "                                                                         'cyclostationary_mean_tg_1w',\n",
    "                                                                         'cyclostationary_mean_tg_4w', \n",
    "                                                                         'cyclostationary_mean_tg_8w',\n",
    "                                                                         'cyclostationary_mean_tg_12w', \n",
    "                                                                         'cyclostationary_mean_tg_16w',\n",
    "                                                                         'cyclostationary_mean_tg_24w', \n",
    "                                                                         'cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w'  \n",
    "                                                                         ],\n",
    "                                                                   target_df_trainVal,multiple=True, neigh=0)\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 50)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b39c6102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full aggregate regression train score: 0.7301615350510935, test score: -2.802119948552454\n",
      "Aggregate regression train score with FS: 0.2927067757084586, test score: 0.10411290696815523\n",
      "Full aggregate regression train score: 0.7301615350510935, test score: -2.802119948552454\n",
      "Aggregate regression train score with FS: 0.338257291869802, test score: 0.03859658473698746\n"
     ]
    }
   ],
   "source": [
    "### forcing a low number of features\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa42320c",
   "metadata": {},
   "source": [
    "### not considering last years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bce13569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 12\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 13\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 14\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 16\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 17\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 26\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 21\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 16\n",
      "\n",
      "actual training score: 0.11430312750515548\n",
      "actual validation score: 0.3501854546182006, number of remaining columns: 274\n",
      "\n",
      "actual training score: 0.1349366317036208\n",
      "actual validation score: 0.3872238559177743, number of remaining columns: 273\n",
      "\n",
      "actual training score: 0.14097094613291106\n",
      "actual validation score: 0.41616094171259266, number of remaining columns: 272\n",
      "\n",
      "actual training score: 0.1575159101719913\n",
      "actual validation score: 0.44593803047161384, number of remaining columns: 271\n",
      "\n",
      "actual training score: 0.1637698114493713\n",
      "actual validation score: 0.4715763898809989, number of remaining columns: 270\n",
      "\n",
      "actual training score: 0.16713821492171776\n",
      "actual validation score: 0.4839378274043935, number of remaining columns: 269\n",
      "\n",
      "actual training score: 0.17280939772541404\n",
      "actual validation score: 0.4976381460944691, number of remaining columns: 268\n",
      "\n",
      "actual training score: 0.17448814360407205\n",
      "actual validation score: 0.5093958590136256, number of remaining columns: 267\n",
      "\n",
      "actual training score: 0.17594658073472602\n",
      "actual validation score: 0.5180989551850306, number of remaining columns: 266\n",
      "\n",
      "actual training score: 0.17702012871249684\n",
      "actual validation score: 0.5237095073085495, number of remaining columns: 265\n",
      "\n",
      "actual training score: 0.17737789360871536\n",
      "actual validation score: 0.5283131584741623, number of remaining columns: 264\n",
      "\n",
      "actual training score: 0.17853165961434803\n",
      "actual validation score: 0.5335848163110366, number of remaining columns: 263\n",
      "\n",
      "actual training score: 0.17952949912708593\n",
      "actual validation score: 0.5378141714610978, number of remaining columns: 262\n",
      "\n",
      "actual training score: 0.1798053299690222\n",
      "actual validation score: 0.540070557059136, number of remaining columns: 261\n",
      "\n",
      "actual training score: 0.18860105575164232\n",
      "actual validation score: 0.5531775367454397, number of remaining columns: 260\n",
      "\n",
      "actual training score: 0.19114126578362511\n",
      "actual validation score: 0.5566742529583943, number of remaining columns: 259\n",
      "\n",
      "actual training score: 0.19354371963415062\n",
      "actual validation score: 0.5581368476031706, number of remaining columns: 258\n",
      "\n",
      "actual training score: 0.1938944244944334\n",
      "actual validation score: 0.5591533293751687, number of remaining columns: 257\n",
      "\n",
      "actual training score: 0.19400853231734583\n",
      "actual validation score: 0.5597533028617996, number of remaining columns: 256\n",
      "\n",
      "actual training score: 0.19445776727719866\n",
      "actual validation score: 0.5617468447195131, number of remaining columns: 255\n",
      "\n",
      "actual training score: 0.1949632494223753\n",
      "actual validation score: 0.5626360865409694, number of remaining columns: 254\n",
      "\n",
      "actual training score: 0.19501274229835963\n",
      "actual validation score: 0.5640005606861572, number of remaining columns: 253\n",
      "\n",
      "actual training score: 0.19613685895197375\n",
      "actual validation score: 0.565338438175232, number of remaining columns: 252\n",
      "\n",
      "actual training score: 0.1966425680524546\n",
      "actual validation score: 0.568786471839944, number of remaining columns: 251\n",
      "\n",
      "actual training score: 0.19797961156514332\n",
      "actual validation score: 0.5727991448493123, number of remaining columns: 250\n",
      "\n",
      "actual training score: 0.19915601055242116\n",
      "actual validation score: 0.5762902760712746, number of remaining columns: 249\n",
      "\n",
      "actual training score: 0.19920004693600135\n",
      "actual validation score: 0.5768956620996616, number of remaining columns: 248\n",
      "\n",
      "actual training score: 0.19924197321590953\n",
      "actual validation score: 0.5770535133184418, number of remaining columns: 247\n",
      "\n",
      "actual training score: 0.19924225076764668\n",
      "actual validation score: 0.5770203069577176, number of remaining columns: 246\n",
      "\n",
      "actual training score: 0.19939012361848507\n",
      "actual validation score: 0.5771582442087491, number of remaining columns: 245\n",
      "\n",
      "actual training score: 0.19982160603642563\n",
      "actual validation score: 0.5778511683018863, number of remaining columns: 244\n",
      "\n",
      "actual training score: 0.20056394566259683\n",
      "actual validation score: 0.5800667411872023, number of remaining columns: 243\n",
      "\n",
      "actual training score: 0.20065885004731532\n",
      "actual validation score: 0.5803096209082963, number of remaining columns: 242\n",
      "\n",
      "actual training score: 0.20085122498920627\n",
      "actual validation score: 0.5802762562582386, number of remaining columns: 241\n",
      "\n",
      "actual training score: 0.20085276789316775\n",
      "actual validation score: 0.5806029197454818, number of remaining columns: 240\n",
      "\n",
      "actual training score: 0.20097267045684997\n",
      "actual validation score: 0.5805414248709098, number of remaining columns: 239\n",
      "\n",
      "actual training score: 0.20122657646771325\n",
      "actual validation score: 0.5804286804677299, number of remaining columns: 238\n",
      "\n",
      "actual training score: 0.20147145358431207\n",
      "actual validation score: 0.5785261679615481, number of remaining columns: 237\n",
      "\n",
      "actual training score: 0.20319946758550178\n",
      "actual validation score: 0.5767144238119974, number of remaining columns: 236\n",
      "\n",
      "actual training score: 0.2036283001603909\n",
      "actual validation score: 0.5806620192985865, number of remaining columns: 235\n",
      "\n",
      "actual training score: 0.20459934850072925\n",
      "actual validation score: 0.5797533438732897, number of remaining columns: 234\n",
      "\n",
      "actual training score: 0.2048677938601252\n",
      "actual validation score: 0.5806649903523997, number of remaining columns: 233\n",
      "\n",
      "actual training score: 0.20544846344622236\n",
      "actual validation score: 0.5751245010867951, number of remaining columns: 232\n",
      "\n",
      "actual training score: 0.20755786069109572\n",
      "actual validation score: 0.5722715426777798, number of remaining columns: 231\n",
      "\n",
      "actual training score: 0.2079540727385829\n",
      "actual validation score: 0.5696642193030588, number of remaining columns: 230\n",
      "\n",
      "actual training score: 0.20795731688883223\n",
      "actual validation score: 0.5699711576038807, number of remaining columns: 229\n",
      "\n",
      "actual training score: 0.20849222496012498\n",
      "actual validation score: 0.5676892336253796, number of remaining columns: 228\n",
      "\n",
      "actual training score: 0.20906038208023103\n",
      "actual validation score: 0.5611554956298825, number of remaining columns: 227\n",
      "\n",
      "actual training score: 0.21328368195752034\n",
      "actual validation score: 0.5551388275915043, number of remaining columns: 226\n",
      "\n",
      "actual training score: 0.21988024535547834\n",
      "actual validation score: 0.551614425250458, number of remaining columns: 225\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_rr_8w_3', 'cyclostationary_mean_tg_1w_6', 'cyclostationary_mean_tg_8w_12', 'cyclostationary_mean_tg_8w_13', 'cyclostationary_mean_rr_4w_18', 'cyclostationary_mean_rr_8w_14', 'cyclostationary_mean_rr_16w_14', 'cyclostationary_mean_rr_8w_17', 'cyclostationary_mean_rr_8w_12', 'cyclostationary_mean_rr_8w_6', 'cyclostationary_mean_tg_24w_13', 'cyclostationary_mean_rr_8w_8', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_tg_24w_0', 'cyclostationary_mean_rr_1w_35', 'cyclostationary_mean_rr_1w_23', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_rr_12w_5', 'cyclostationary_mean_rr_16w_4', 'cyclostationary_mean_rr_16w_3', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_rr_12w_15', 'cyclostationary_mean_rr_12w_17', 'cyclostationary_mean_rr_12w_16', 'cyclostationary_mean_tg_16w_13', 'cyclostationary_mean_tg_12w_14', 'cyclostationary_mean_rr_1w_33', 'cyclostationary_mean_rr_12w_20', 'cyclostationary_mean_rr_24w_15', 'cyclostationary_mean_rr_24w_14', 'cyclostationary_mean_rr_24w_9', 'cyclostationary_mean_tg_16w_5', 'cyclostationary_mean_rr_16w_7', 'cyclostationary_mean_rr_8w_5', 'cyclostationary_mean_rr_16w_2', 'cyclostationary_mean_rr_12w_7', 'cyclostationary_mean_rr_1w_24', 'cyclostationary_mean_tg_4w_5', 'cyclostationary_mean_tg_8w_6', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_rr_16w_5', 'cyclostationary_mean_tg_16w_11'], \n",
      "\n",
      "validation score: 0.5806649903523997, \n",
      "\n",
      "number of selected features: 43\n",
      "Full aggregate regression train score: 0.7424846328561507, test score: -7.973731717396019\n",
      "Aggregate regression train score with FS: 0.36236466165933834, test score: -0.48845880230162564\n"
     ]
    }
   ],
   "source": [
    "### what happens without considering the last years?\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_tg', \n",
    "                                                                         'cyclostationary_mean_tg_1w',\n",
    "                                                                         'cyclostationary_mean_tg_4w', \n",
    "                                                                         'cyclostationary_mean_tg_8w',\n",
    "                                                                         'cyclostationary_mean_tg_12w', \n",
    "                                                                         'cyclostationary_mean_tg_16w',\n",
    "                                                                         'cyclostationary_mean_tg_24w', \n",
    "                                                                         'cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w'  \n",
    "                                                                         ],target_df_trainVal, max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', multiple=True, neigh=0)\n",
    "\n",
    "selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, 50, 228)\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6902cb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full aggregate regression train score: 0.7424846328561507, test score: -7.973731717396019\n",
      "Aggregate regression train score with FS: 0.2889853263379385, test score: 0.2903491316660253\n",
      "Full aggregate regression train score: 0.7424846328561507, test score: -7.973731717396019\n",
      "Aggregate regression train score with FS: 0.3213508358535988, test score: 0.16924990864684009\n"
     ]
    }
   ],
   "source": [
    "### forcing a low number of features\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n",
    "\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e0778e",
   "metadata": {},
   "source": [
    "### repeat both with CMI FS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb7e909e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.402730\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.347916\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.227090\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.087501\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.396235\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "584  2013-10-21  0.739946    0.79  2013    43  1.999865\n",
      "585  2013-10-29  0.447691    0.46  2013    44  0.108118\n",
      "586  2013-11-06  0.541628    0.56  2013    45  0.716163\n",
      "587  2013-11-14  0.493719    0.53  2013    46  0.406051\n",
      "588  2013-11-22  0.527436    0.57  2013    47  0.624301\n",
      "\n",
      "[589 rows x 6 columns]\n",
      " target shapes: ((589, 6), (200, 6), (789, 6), (192, 6))\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 17\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 18\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 18\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 14\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 17\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 18\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 23\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 40\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 42\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 42\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 31\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 21\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 16\n",
      "\n",
      "----- MI Scores -----\n",
      "[(191, 0.15463009196465674), (27, 0.1439722646141268), (192, 0.1392151588916966), (26, 0.1360472396786752), (189, 0.1357169943897039), (180, 0.135341465602925), (25, 0.1347427100799344), (182, 0.13385298682848135), (239, 0.13330553263800363), (9, 0.13299944616370707), (225, 0.1313951123569826), (183, 0.12993577169373366), (195, 0.12978711539451457), (193, 0.1277167333117068), (230, 0.1268652944987288), (11, 0.12667077251898273), (148, 0.1259093311394222), (8, 0.1239784192555458), (226, 0.123153340059872), (224, 0.12289474292204057), (0, 0.12119797711621165), (13, 0.1208388498144807), (188, 0.1206564913482002), (227, 0.11943756107974703), (143, 0.11843183257242193), (184, 0.1184024043519813), (187, 0.11815923909731171), (196, 0.11745662108949503), (277, 0.11681941433644995), (140, 0.11669842957919958), (203, 0.11665563165232691), (222, 0.11593597266665183), (229, 0.11547794176591138), (12, 0.11510289985911792), (10, 0.11452114544721473), (190, 0.11392221336159328), (200, 0.11390380080389086), (199, 0.1132467784690766), (197, 0.11226017023847307), (33, 0.11120687971595292), (233, 0.11076817691435498), (185, 0.1098145002871088), (237, 0.10891426535325176), (149, 0.1074136572804673), (6, 0.10719250797235592), (154, 0.10668507463685901), (223, 0.10630682284388752), (14, 0.10615843116992614), (202, 0.10590170072133323), (160, 0.10571712611859822), (3, 0.10562450015321188), (194, 0.10541373531094701), (159, 0.10519447468000323), (145, 0.1047374869344548), (156, 0.1043298333763684), (15, 0.10397644285946407), (152, 0.10393761891384183), (235, 0.10369954679192567), (181, 0.10362387250437666), (5, 0.10354545031889083), (17, 0.10316481420585151), (141, 0.10306563629774144), (228, 0.10292861851750235), (269, 0.10269911285406089), (146, 0.10240080582714721), (46, 0.10236256367816471), (30, 0.10234883298211124), (29, 0.101488926370048), (238, 0.10122932991771404), (150, 0.10066471923655905), (157, 0.10026974636196617), (204, 0.09977270374931287), (245, 0.09955050794662812), (1, 0.09911265751331305), (201, 0.09811195381178954), (186, 0.09787655044075268), (246, 0.09713020346933512), (158, 0.09659348569560508), (276, 0.09658554530744003), (18, 0.0964363567095726), (264, 0.096399351647077), (35, 0.09605544027702308), (232, 0.09596000527873873), (144, 0.09594113746925195), (243, 0.0956849919532064), (24, 0.09554071503861339), (153, 0.09552801324285416), (166, 0.09544196612496783), (221, 0.09543568376333755), (2, 0.09474388619658705), (270, 0.09243592584503393), (31, 0.09205990758542161), (205, 0.09190769127429747), (198, 0.09141291789432866), (265, 0.09124374118646401), (311, 0.09095409561035661), (28, 0.0908871741567157), (19, 0.0907533645140252), (147, 0.09044579824851881), (236, 0.08993322580650172), (155, 0.08976104029271358), (45, 0.08963792121595135), (240, 0.08958884252605243), (241, 0.0891454400270655), (242, 0.0878928062892166), (16, 0.08692201750779102), (42, 0.08685455366657095), (231, 0.08670280324561734), (244, 0.08650408972939432), (151, 0.08615621063916047), (278, 0.08595591792652443), (41, 0.08539595988460894), (272, 0.08525013843148743), (34, 0.08479756748598985), (273, 0.08474960231097273), (271, 0.08453871138440591), (20, 0.08362709911530376), (293, 0.08345306850263189), (266, 0.08311109864206963), (161, 0.0822351123209511), (32, 0.08155345776067136), (142, 0.08099583060299725), (310, 0.08043189086197061), (234, 0.08025364618559573), (279, 0.07994662175457201), (288, 0.07973284201041114), (284, 0.07966507728762483), (291, 0.07914876981795883), (267, 0.07892945993077997), (282, 0.07846475371001466), (283, 0.078358788033854), (292, 0.07800012585806144), (281, 0.0774794586358655), (219, 0.0770069773784504), (23, 0.0769602540128976), (280, 0.07613089267400168), (48, 0.0756458504464153), (43, 0.07421704876399535), (297, 0.07420566126341957), (44, 0.07413518985602219), (163, 0.07391402658240702), (162, 0.07369738667581126), (296, 0.07358666184885036), (312, 0.07339183827400256), (290, 0.07313983161536178), (318, 0.0728500279913484), (295, 0.0723271758393678), (275, 0.07204587467288769), (49, 0.07147406214152206), (315, 0.07138356535377582), (254, 0.07034639128071232), (298, 0.07028710324419814), (263, 0.07022591280107687), (285, 0.069565884981515), (248, 0.0692549301923944), (206, 0.06857396899625873), (122, 0.06823215681560615), (294, 0.06819233097525136), (289, 0.06787161933378771), (287, 0.06742774337235224), (21, 0.0672697931344359), (214, 0.06716764995461601), (274, 0.0670312162990861), (249, 0.06685559177881356), (252, 0.0668365953586702), (253, 0.06617703974926681), (118, 0.06560255279111699), (314, 0.0655761360767079), (220, 0.06555834514129534), (167, 0.06502687652512058), (117, 0.06398068957143602), (313, 0.06381726548322998), (286, 0.06371701204604703), (129, 0.06369840313960955), (251, 0.06312976508645063), (255, 0.06273974455027156), (261, 0.06254205429337824), (217, 0.06229642166952258), (250, 0.0622670233081979), (218, 0.06193278332408393), (127, 0.06167814060167946), (268, 0.06132156758567073), (175, 0.06128819433456677), (128, 0.06071012146762079), (316, 0.06064093527052284), (168, 0.05967226350504323), (259, 0.05959082899158622), (120, 0.05905332156818296), (177, 0.05884804892807206), (165, 0.05842989975122522), (213, 0.05831905990052018), (247, 0.05792224491106944), (208, 0.05754186509145912), (119, 0.05693558821663704), (324, 0.05613993838797728), (121, 0.056119848013967195), (309, 0.05605962110767706), (132, 0.05596119638681848), (260, 0.055575328930264976), (262, 0.05508723826793659), (124, 0.0550474603306312), (302, 0.05392171002300684), (109, 0.05390082410325679), (47, 0.053741992456797505), (299, 0.053595530679055245), (207, 0.05351782674782046), (7, 0.05335917634241299), (51, 0.053026263206131484), (133, 0.0529728123941893), (125, 0.05271966378665267), (256, 0.052501248527335474), (216, 0.05173079339038569), (64, 0.0515125754022996), (123, 0.051175489430968155), (211, 0.051072702852412076), (126, 0.05016301501992545), (209, 0.04995991345161359), (170, 0.04988844452898464), (36, 0.04973903351463897), (107, 0.04846688093207356), (317, 0.04842084564963361), (300, 0.046461174286176805), (307, 0.046351163306507855), (164, 0.04573900827464221), (319, 0.044255032695352046), (50, 0.04354633471074945), (130, 0.04353018314288297), (169, 0.04348393856811117), (37, 0.0432279339942226), (60, 0.04290447340669872), (303, 0.0428612782840835), (212, 0.042858024195323384), (176, 0.04262487155747792), (38, 0.04247263771537549), (58, 0.042414462118925605), (215, 0.04188545039675412), (61, 0.041375945179070735), (106, 0.041339765721979935), (306, 0.04080462161313447), (308, 0.04069003160902762), (258, 0.039999400847212825), (178, 0.03946249025410933), (179, 0.039209763512226846), (257, 0.039082601318725915), (59, 0.03811241307903142), (104, 0.03807143698382983), (304, 0.035514942993646915), (54, 0.03512925570509804), (66, 0.03499459941010782), (55, 0.03461402992374586), (328, 0.034216174262358935), (174, 0.0340417081535564), (139, 0.033971791235641306), (103, 0.03318719902824042), (22, 0.0326046175966815), (210, 0.03238433397870408), (80, 0.03238169549992179), (323, 0.03218211827294878), (305, 0.0319603125397588), (63, 0.03194367283519243), (331, 0.031253426537302786), (56, 0.03113592420395238), (301, 0.029525390775470353), (322, 0.029427560463259686), (112, 0.029272262149398667), (329, 0.02903110111067159), (320, 0.02790887539974222), (74, 0.027819659814809133), (79, 0.027396812430592332), (70, 0.02735433232129675), (327, 0.026889205406195594), (88, 0.02585747481350367), (89, 0.02568544424842855), (326, 0.025558959382657277), (40, 0.02538559252068743), (73, 0.02536234866956596), (81, 0.025103263802681547), (65, 0.025088060558252787), (4, 0.02508295692700377), (110, 0.024085927925889018), (97, 0.02405885103138065), (99, 0.02370807339524839), (82, 0.023610349113012935), (52, 0.0233368548656305), (62, 0.022847083493602628), (111, 0.022824376360072302), (77, 0.022624668111128544), (105, 0.022577592588759708), (171, 0.021619936937950463), (173, 0.021569519141887455), (57, 0.021433699976182205), (321, 0.02139718216292766), (75, 0.021323941420173582), (330, 0.021046393705901036), (72, 0.02088315619626716), (325, 0.020596844104832795), (76, 0.02011840750698962), (71, 0.019073747077748008), (90, 0.01885228523573545), (94, 0.018722510731579274), (116, 0.017290792311275664), (102, 0.01665255836138098), (67, 0.016089842378116934), (172, 0.015719990289564056), (137, 0.015627290681037128), (93, 0.015438420275233455), (100, 0.014903270700434271), (83, 0.01418086560881614), (98, 0.014104014907003219), (84, 0.013639087404152395), (68, 0.012610669442195794), (136, 0.011699603225898674), (101, 0.011469300839532204), (78, 0.010652989109429186), (53, 0.009220014249916435), (87, 0.008298358559248814), (95, 0.006779553936738279), (39, 0.006087600494341288), (114, 0.005373694371839016), (113, 0.005024274853296952), (108, 0.004473619810655455), (96, 0.0042770478015881), (138, 0.002071393783716905), (92, 0.000893603768996364), (131, 0.0006394158367289899), (135, -0.0006706892242102154), (115, -0.000882047297465393), (69, -0.0015546024218577887), (91, -0.0020219043259659857), (86, -0.00556443435540109), (134, -0.00994323745191566), (85, -0.010911370030080036)]\n",
      "Best MI score: 0.15463009196465674\n",
      "Adding first best original feature: 191\n",
      "CMI: 0.03668782989289282\n",
      "CMI: 0.03584424523078905\n",
      "CMI: 0.03824556900643486\n",
      "CMI: 0.03334096117186039\n",
      "CMI: 0.040182430781013884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.03512162928773693\n",
      "CMI: 0.04061494421671022\n",
      "CMI: 0.04876287221969067\n",
      "CMI: 0.032653161059468555\n",
      "CMI: 0.050560599847544435\n",
      "CMI: 0.03816301461793706\n",
      "CMI: 0.044056884484047876\n",
      "CMI: 0.035586843918382766\n",
      "CMI: 0.034952516623584756\n",
      "CMI: 0.020321508583642983\n",
      "CMI: 0.029896598255072127\n",
      "CMI: 0.02891753829186275\n",
      "CMI: 0.023935787329248503\n",
      "CMI: 0.014100165716202262\n",
      "CMI: 0.016050524602320093\n",
      "CMI: 0.02095656399018478\n",
      "CMI: 0.05361132696086013\n",
      "CMI: 0.04623068904763411\n",
      "CMI: 0.042685597226635896\n",
      "CMI: 0.0235879764269952\n",
      "CMI: 0.024245862756648195\n",
      "CMI: 0.02691659435448565\n",
      "CMI: 0.03744137786731097\n",
      "CMI: 0.025212043794982847\n",
      "CMI: 0.03219610824238184\n",
      "CMI: 0.021136833147002793\n",
      "CMI: 0.001252788303960306\n",
      "CMI: 0.003196264322254283\n",
      "CMI: 0.00044818709337174356\n",
      "CMI: 0.0005216173288185855\n",
      "CMI: 0.004723394508068635\n",
      "CMI: 0.0003836303321697043\n",
      "CMI: 0.006818932607107253\n",
      "CMI: 0.007315782195443904\n",
      "CMI: 0.01260480058245489\n",
      "CMI: 0.010960327389626379\n",
      "CMI: 0.013262036363522411\n",
      "CMI: 0.021980973118774366\n",
      "CMI: 0.021365568770378623\n",
      "CMI: 0.009794419275739735\n",
      "CMI: 0.017183230915662984\n",
      "CMI: 0.018882463316829745\n",
      "CMI: 0.015800295596205938\n",
      "CMI: 0.005656819507116301\n",
      "CMI: 0.008317350276735774\n",
      "CMI: 0.02818221960032899\n",
      "CMI: 0.010093753126111021\n",
      "CMI: 0.0031334490227397926\n",
      "CMI: 0.021898381978498443\n",
      "CMI: 0.019021030527279548\n",
      "CMI: 0.0075880229314499725\n",
      "CMI: 0.016785441481980856\n",
      "CMI: 0.015699758709935063\n",
      "CMI: 0.006972212826743651\n",
      "CMI: 0.02312428049389023\n",
      "CMI: 0.004609654763419346\n",
      "CMI: 0.010747165595465374\n",
      "CMI: 0.008187888604023419\n",
      "CMI: 0.015855535760616546\n",
      "CMI: 0.0066077298640057625\n",
      "CMI: 0.0016863517356727198\n",
      "CMI: 0.01658243368894627\n",
      "CMI: 0.013093901705611977\n",
      "CMI: 0.013918785359377212\n",
      "CMI: 0.007698166996806061\n",
      "CMI: 0.0018061786689761994\n",
      "CMI: 0.0022120624342514272\n",
      "CMI: 0.011222626651787915\n",
      "CMI: 0.006273167827107545\n",
      "CMI: 0.009841645316588488\n",
      "CMI: 0.013066126516128318\n",
      "CMI: 0.013671613240694325\n",
      "CMI: 0.012026085764172995\n",
      "CMI: 0.012657334957513505\n",
      "CMI: 0.009407218684359592\n",
      "CMI: 0.011437281358169876\n",
      "CMI: 0.0066553832983646255\n",
      "CMI: 0.01816121674500648\n",
      "CMI: 0.010881741101957582\n",
      "CMI: 0.009788390092499766\n",
      "CMI: 0.010562179626494694\n",
      "CMI: 0.024738997615140423\n",
      "CMI: 0.0162086271422808\n",
      "CMI: 0.02030907698636955\n",
      "CMI: 0.024367653443057663\n",
      "CMI: 0.008431352469206288\n",
      "CMI: 0.023320703433699602\n",
      "CMI: 0.022952568254644812\n",
      "CMI: 0.011693563881413988\n",
      "CMI: 0.013464965382827848\n",
      "CMI: 0.01303937868153951\n",
      "CMI: 0.01805718860403019\n",
      "CMI: 0.01373735765514808\n",
      "CMI: 0.022976856722381145\n",
      "CMI: 0.004797482087527033\n",
      "CMI: 0.009453256920418318\n",
      "CMI: 0.01463575555597954\n",
      "CMI: 0.0013831452148353185\n",
      "Highest CMI score: 0.05361132696086013\n",
      "Adding original feature: 25\n",
      "CMI: 0.0007047630078156897\n",
      "CMI: 0.0005375155659717579\n",
      "CMI: 0.0030488291912635357\n",
      "CMI: 0.01134066096569214\n",
      "CMI: 0.0005627204881869519\n",
      "CMI: 0.009677322951281292\n",
      "CMI: 0.0008004473570804582\n",
      "CMI: 0.00701215095754118\n",
      "CMI: 0.00030772617210858555\n",
      "CMI: 0.003425465765277802\n",
      "CMI: 0.0034566318939299456\n",
      "CMI: 0.008042398668364537\n",
      "CMI: 0.015253663715115412\n",
      "CMI: 0.009683620266843468\n",
      "CMI: 0.019022587799977092\n",
      "CMI: 0.029588760429211325\n",
      "CMI: 0.022378123091825214\n",
      "CMI: 0.0013251590678950154\n",
      "CMI: 0.008482594532072563\n",
      "CMI: 0.011270268439107223\n",
      "CMI: 0.01767156142280632\n",
      "CMI: 0.014204681131080671\n",
      "CMI: 0.014068426483317742\n",
      "CMI: 0.005995908012660978\n",
      "CMI: 0.0011119340459641303\n",
      "CMI: 0.004049552987425098\n",
      "CMI: 0.0035554818562376633\n",
      "CMI: 0.005166271351243562\n",
      "CMI: 0.008626817573726409\n",
      "CMI: 0.005597769384920209\n",
      "CMI: 0.0016238452489577282\n",
      "CMI: 0.0051276153253513035\n",
      "CMI: 0.003174017455483319\n",
      "CMI: 6.933659783062152e-05\n",
      "CMI: 0.00861743736570969\n",
      "CMI: 0.001832614976519542\n",
      "CMI: 0.00023853077098529019\n",
      "CMI: 0.00783762442695124\n",
      "CMI: 0.0006075439484515\n",
      "CMI: 0.001225379454561304\n",
      "CMI: 0.01113367201320617\n",
      "CMI: 0.002676602489179558\n",
      "CMI: 0.015972154845965564\n",
      "CMI: 0.009841591273898082\n",
      "CMI: 0.007969269750072117\n",
      "CMI: 0.0007156455345541934\n",
      "CMI: 0.0017835501970955292\n",
      "CMI: 0.00596907808861788\n",
      "CMI: 0.000934315448988976\n",
      "CMI: 0.00010461251608409605\n",
      "CMI: 0.0033724395337163815\n",
      "CMI: 0.0010238072573232893\n",
      "CMI: 0.002992727205346546\n",
      "CMI: 0.006855379043325394\n",
      "CMI: 0.0001842009837322578\n",
      "CMI: 0.0041559577021539895\n",
      "CMI: 0.006134241661251816\n",
      "CMI: 0.00011616347339127309\n",
      "CMI: 0.0022643672838435214\n",
      "CMI: 0.0006708015821166591\n",
      "CMI: 0.013273455064194861\n",
      "CMI: 0.0001833600497532506\n",
      "CMI: 0.0002751168276584337\n",
      "CMI: 0.0010404581309299554\n",
      "CMI: 0.009402824781393315\n",
      "CMI: 0.005772136462908278\n",
      "CMI: 0.012274934731505927\n",
      "CMI: 0.001836385183576844\n",
      "CMI: 0.005916860866150231\n",
      "CMI: 0.002145962109848132\n",
      "CMI: 0.013894463945619884\n",
      "CMI: 0.003938442647779511\n",
      "CMI: 0.0016762181892237826\n",
      "CMI: 0.004287748223734039\n",
      "CMI: 0.0016150538922433122\n",
      "CMI: 0.004291524124436202\n",
      "CMI: 7.7100931318963e-05\n",
      "CMI: 0.0007443478612478571\n",
      "CMI: 0.002847075053011655\n",
      "CMI: 0.01859050406327395\n",
      "CMI: 0.009686819428027571\n",
      "CMI: 0.0012606253994876804\n",
      "CMI: 0.006300603737726701\n",
      "CMI: 0.009764815465179016\n",
      "CMI: 0.0037432567997895683\n",
      "CMI: 0.0031859487935552155\n",
      "CMI: 0.00452632168088965\n",
      "CMI: 0.0013698463110257686\n",
      "CMI: 0.0007342789178939879\n",
      "CMI: 0.005573736023236214\n",
      "CMI: 0.005318048610102405\n",
      "CMI: 0.010732988734060284\n",
      "CMI: 0.008662268961979774\n",
      "CMI: 0.009181565866311941\n",
      "CMI: 0.01743239456421561\n",
      "CMI: 0.012189429211855812\n",
      "CMI: 0.01475825316259069\n",
      "CMI: 0.014431491613032227\n",
      "CMI: 0.016618755871074975\n",
      "CMI: 0.018534414075641187\n",
      "CMI: 0.015068854277477367\n",
      "CMI: 0.01026043499341786\n",
      "CMI: 0.011256127302538138\n",
      "CMI: 0.010642216883188005\n",
      "CMI: 0.01332453943133144\n",
      "CMI: 0.011981513216901246\n",
      "CMI: 0.010935998471148817\n",
      "CMI: 0.012729473676379749\n",
      "CMI: 0.014132898590750759\n",
      "CMI: 0.021604102815409643\n",
      "CMI: 0.006103679295302894\n",
      "CMI: 0.004327027337039824\n",
      "CMI: 0.005164688116626348\n",
      "CMI: 0.009544633545449765\n",
      "CMI: 0.00014122765041113539\n",
      "CMI: 0.0020971039003959413\n",
      "CMI: 0.0021994744318733495\n",
      "CMI: 0.0004416521595214107\n",
      "CMI: 0.007836168708029945\n",
      "CMI: 0.02204082937405552\n",
      "CMI: 0.02583279287233195\n",
      "CMI: 0.01980488236846581\n",
      "CMI: 0.027042011799624233\n",
      "CMI: 0.027504282831298382\n",
      "CMI: 0.029748730379094646\n",
      "CMI: 0.03615915232604175\n",
      "CMI: 0.025088353740040148\n",
      "CMI: 0.02408880271818334\n",
      "CMI: 0.022598839120888864\n",
      "CMI: 0.008777610265828323\n",
      "CMI: 0.013790839229463198\n",
      "CMI: 0.010984285675127992\n",
      "CMI: 0.013827655255210736\n",
      "CMI: 0.010536317280058743\n",
      "CMI: 0.012492753275621132\n",
      "CMI: 0.019373755187871516\n",
      "CMI: 0.01152698001467009\n",
      "CMI: 0.00169987774714761\n",
      "CMI: 0.007557265276009556\n",
      "CMI: 0.0038319535919931758\n",
      "CMI: 0.008097929665206643\n",
      "CMI: 0.00573663364135929\n",
      "CMI: 0.0024945751331342247\n",
      "CMI: 0.004201995910159795\n",
      "CMI: 0.005564208656797437\n",
      "CMI: 0.012145010929459382\n",
      "CMI: 0.0099848910620417\n",
      "CMI: 0.006670067511440059\n",
      "CMI: 0.005987144522344251\n",
      "Highest CMI score: 0.03615915232604175\n",
      "Adding original feature: 287\n",
      "CMI: 0.0019017187503105326\n",
      "CMI: 0.004507084830865649\n",
      "CMI: 0.0008639491870002236\n",
      "CMI: 0.004341507160273483\n",
      "CMI: 0.006363427747934858\n",
      "CMI: 0.005324414319913429\n",
      "CMI: 0.0071798592929365745\n",
      "CMI: 0.024979353317641118\n",
      "CMI: 0.021097489383971768\n",
      "CMI: 0.0024556460286798976\n",
      "CMI: 0.004250220776860103\n",
      "CMI: 0.00102907326863938\n",
      "CMI: 0.0012889471987714285\n",
      "CMI: 0.003475147771112963\n",
      "CMI: 0.0008643370537766981\n",
      "CMI: 0.0018293534426879476\n",
      "CMI: 0.0034504082010891612\n",
      "CMI: 0.0005578652863132416\n",
      "CMI: 0.010556694084174312\n",
      "CMI: 0.0033337258487538823\n",
      "CMI: 0.00025667785756294803\n",
      "CMI: 0.012478428373238926\n",
      "CMI: 0.0038461661792881796\n",
      "CMI: 0.003181443887438601\n",
      "CMI: 0.004307566364543547\n",
      "CMI: 0.01126483747598811\n",
      "CMI: 0.009109267468652371\n",
      "CMI: 0.002596641141902445\n",
      "CMI: 0.005324490827578521\n",
      "CMI: 0.008291033936812908\n",
      "CMI: 0.0021587943659193976\n",
      "CMI: 0.002945763847709143\n",
      "CMI: 0.0010073871371633347\n",
      "CMI: 0.005505559709983371\n",
      "CMI: 0.007562257184337284\n",
      "CMI: 0.004839251725869742\n",
      "CMI: 0.0064443079190985575\n",
      "CMI: 0.006244823967702595\n",
      "CMI: 0.0074952982451402805\n",
      "CMI: 0.007864589385350784\n",
      "CMI: 0.005883797436144311\n",
      "CMI: 0.0027478065453365452\n",
      "CMI: 0.006135478805410544\n",
      "CMI: 0.01002308352766923\n",
      "CMI: 0.0011852495977820177\n",
      "CMI: 0.004541813555411417\n",
      "CMI: 3.738354038668179e-05\n",
      "CMI: 0.000628239928273322\n",
      "CMI: 0.0061255824506645795\n",
      "CMI: 0.006165076228614119\n",
      "CMI: 7.753489191991703e-05\n",
      "CMI: 0.005731580358107724\n",
      "CMI: 0.002483370230737386\n",
      "CMI: 0.0008701977199627176\n",
      "CMI: 0.0027633655296095405\n",
      "CMI: 0.0017244330050471823\n",
      "CMI: 0.001895077059330591\n",
      "CMI: 0.0004518679499307121\n",
      "CMI: 0.0026154384128244668\n",
      "CMI: 0.004113221291603991\n",
      "CMI: 0.0022088080893138684\n",
      "CMI: 0.004370820234198741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.0006035273452314749\n",
      "CMI: 3.618992502671392e-05\n",
      "Highest CMI score: 0.024979353317641118\n",
      "Adding original feature: 39\n",
      "CMI: 0.0032091418992964416\n",
      "CMI: 0.0008942894202733087\n",
      "CMI: 0.002739272539226012\n",
      "CMI: 0.007351530652911553\n",
      "CMI: 0.00016930223118094556\n",
      "CMI: 0.004201346521326921\n",
      "CMI: 0.005083858443273026\n",
      "CMI: 0.006048114193440091\n",
      "CMI: 0.00034858648974672723\n",
      "CMI: 0.006772058391635305\n",
      "CMI: 0.0008056199706832357\n",
      "CMI: 0.0028143002796073846\n",
      "Highest CMI score: 0.007351530652911553\n",
      "Adding original feature: 190\n",
      "CMI: 0.0002057690276580093\n",
      "CMI: 0.0006725562478376856\n",
      "CMI: 0.0004597813952617602\n",
      "CMI: 0.0036390601415288715\n",
      "CMI: 0.0019082953677819203\n",
      "CMI: 0.00040136867019896494\n",
      "Highest CMI score: 0.0036390601415288715\n",
      "Adding original feature: 233\n",
      "CMI: 0.00025101588972037403\n",
      "CMI: 0.0008836765954916559\n",
      "Highest CMI score: 0.0008836765954916559\n",
      "Adding original feature: 285\n",
      "CMI: 0.0021692715012219255\n",
      "Highest CMI score: 0.0021692715012219255\n",
      "Adding original feature: 200\n",
      "Highest CMI score: -0.00013951282603991144\n",
      "\n",
      "[191, 25, 287, 39, 190, 233, 285, 200]\n",
      "\n",
      "Full aggregate regression train score: 0.7301615350510935, test score: -2.802119948552454\n",
      "Aggregate regression train score with FS: 0.27266920063538613, test score: 0.10623998120375144\n"
     ]
    }
   ],
   "source": [
    "### all data\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_tg', \n",
    "                                                                         'cyclostationary_mean_tg_1w',\n",
    "                                                                         'cyclostationary_mean_tg_4w', \n",
    "                                                                         'cyclostationary_mean_tg_8w',\n",
    "                                                                         'cyclostationary_mean_tg_12w', \n",
    "                                                                         'cyclostationary_mean_tg_16w',\n",
    "                                                                         'cyclostationary_mean_tg_24w', \n",
    "                                                                         'cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w'  \n",
    "                                                                         ],target_df_trainVal,multiple=True, neigh=0)\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ceb6b6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 12\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 13\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 14\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 16\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 17\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 26\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 36\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 30\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 21\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 991\n",
      "\n",
      "Number of aggregated features: 16\n",
      "\n",
      "----- MI Scores -----\n",
      "[(203, 0.14355837775756955), (173, 0.13768140198491086), (174, 0.13631856652553526), (197, 0.13513961185319756), (164, 0.13314748811318639), (179, 0.13133916425325634), (201, 0.13077215637224784), (210, 0.12940937077645107), (7, 0.1286787791673458), (171, 0.12800303924902318), (142, 0.12776157435205412), (194, 0.12773768285015272), (175, 0.12589313998629875), (176, 0.12581966451285354), (0, 0.12374369750902679), (5, 0.1237203268683318), (18, 0.12336536931319297), (167, 0.12322133486841645), (138, 0.12261245758049465), (195, 0.12259646278618203), (166, 0.12247561578204438), (205, 0.12190367248356769), (11, 0.12187086949476401), (6, 0.12174013030552368), (204, 0.12131731402791014), (196, 0.1195466277847605), (206, 0.11935459557517307), (177, 0.11863013144173605), (3, 0.11859433507678267), (202, 0.116316281664481), (21, 0.11577905754372864), (136, 0.11577335968657665), (172, 0.11572919380605058), (199, 0.11500464062877018), (207, 0.1149532106544037), (229, 0.11397915203550381), (137, 0.11373749145800978), (128, 0.11363223689263681), (209, 0.11311314301417705), (20, 0.1122602436761078), (132, 0.11215634643910154), (168, 0.11139134112669105), (140, 0.11110177375212067), (170, 0.11094609892506647), (129, 0.11047003177135338), (243, 0.11002993252556946), (19, 0.10999168599163632), (134, 0.10980008890621286), (131, 0.10961698506481543), (178, 0.10952880477659725), (165, 0.10915090860445041), (230, 0.10887729066184709), (224, 0.10854986739176381), (198, 0.10842109370077785), (169, 0.10773788087664628), (9, 0.10770221065310064), (135, 0.10587611045595118), (1, 0.1050763244597484), (232, 0.1044016996746289), (231, 0.10413780200273227), (200, 0.1020698701738791), (236, 0.1020265124535254), (102, 0.10194430319429787), (208, 0.10069367714903134), (193, 0.09977330759904632), (241, 0.09902441152547063), (2, 0.09874399377609192), (8, 0.09779179707348827), (130, 0.09772263150344872), (227, 0.09768017693113938), (139, 0.09745711036293309), (233, 0.09730112144194526), (225, 0.09572845401960096), (10, 0.0946657003811646), (141, 0.09422985392702304), (13, 0.09403535625215567), (154, 0.09319334116992599), (24, 0.09299819006005038), (238, 0.09268049693371382), (235, 0.09218329814251448), (258, 0.09215578993034604), (237, 0.08918334467139254), (213, 0.08912960202552749), (144, 0.0873634985099328), (22, 0.08715696949460078), (143, 0.08659593744214443), (15, 0.0863988695840408), (246, 0.08624592249189425), (257, 0.08617356256809444), (215, 0.08582031160305832), (242, 0.08535050386355976), (12, 0.08498832851672089), (133, 0.08488082023727597), (228, 0.08384475209920172), (109, 0.08350349827058232), (181, 0.0835027641083921), (105, 0.08274029747752781), (212, 0.08263412532320004), (226, 0.08244670911682571), (103, 0.08233081542811345), (185, 0.08151108340944214), (211, 0.08129215084292556), (104, 0.0812638036768999), (219, 0.08055610686235969), (216, 0.08034126364411728), (218, 0.07964691902253347), (186, 0.07954846634223894), (239, 0.07922496088131074), (240, 0.07827625691624385), (106, 0.07812853841300374), (107, 0.07809985136145359), (114, 0.07809602128133689), (190, 0.0778133663495202), (182, 0.07778342993531409), (110, 0.07743919599614255), (149, 0.07732253147526302), (31, 0.0765693287429937), (262, 0.07646322063546719), (234, 0.07643493985941578), (191, 0.0760896232864488), (192, 0.07538612178216325), (184, 0.07531600016323282), (223, 0.07517384353492652), (245, 0.07402541320179462), (108, 0.0730802305726844), (214, 0.07198837029942018), (25, 0.07071454250748856), (188, 0.07048609699992324), (27, 0.07029979946542761), (183, 0.07023164308104615), (120, 0.07000142194521591), (256, 0.06976735121603825), (111, 0.0691025480517386), (250, 0.06891183335119605), (247, 0.06882787301797477), (42, 0.06865034085371216), (244, 0.0683769258029135), (180, 0.06796725354591977), (26, 0.06788241276823238), (156, 0.06769674134768101), (23, 0.0676616327423252), (221, 0.06711816131914451), (33, 0.06701783092393991), (189, 0.0659842873848529), (263, 0.06563474004763162), (155, 0.06547152361623924), (266, 0.06423086899290766), (41, 0.06381530102637038), (220, 0.06346396421036402), (115, 0.0627809222053309), (36, 0.06238377786135037), (259, 0.06236370405371424), (248, 0.062261570348160315), (249, 0.06161752152005982), (146, 0.0604918936542499), (14, 0.06022979432406476), (160, 0.06012333330044267), (217, 0.05970105597397844), (255, 0.0590328555827733), (148, 0.05897262422930583), (145, 0.0588240847733125), (147, 0.05863647477718676), (113, 0.05838305278312624), (4, 0.058232711160856696), (53, 0.0581741563964403), (89, 0.05756490460328236), (260, 0.055838286805899424), (39, 0.055703209790854386), (187, 0.05568856880074352), (112, 0.055575950836459116), (52, 0.05373669351232221), (261, 0.052697798611538754), (34, 0.05248964360310635), (222, 0.05246711871533758), (30, 0.05205689066100469), (38, 0.0515677706177128), (37, 0.051315422489554736), (265, 0.05062787355801183), (16, 0.05060157974805213), (267, 0.05058217332421378), (48, 0.04985087907120727), (95, 0.04949486861853071), (40, 0.04946873568368696), (264, 0.048409961933339365), (150, 0.04826807931778649), (32, 0.04805678471755705), (159, 0.04777766713787423), (45, 0.04764593560694752), (92, 0.044705574416161575), (151, 0.04455385156469544), (163, 0.04454066464627824), (88, 0.044504560200822135), (251, 0.044410241663400796), (87, 0.043940516159519084), (253, 0.04345337900952832), (43, 0.04338931174812443), (29, 0.042684707973634696), (17, 0.04252439749259397), (78, 0.042331977929834216), (28, 0.04081356826424111), (275, 0.04048637089050686), (93, 0.040480481880029104), (161, 0.040426793183453956), (252, 0.03991244299519263), (254, 0.03959551390531029), (158, 0.039518011396490416), (47, 0.03873541184551873), (77, 0.03856344065542209), (274, 0.03825899078277536), (46, 0.03800467039505655), (51, 0.03793704600933267), (60, 0.03714789224948342), (271, 0.03658165616385244), (162, 0.0356893733065745), (58, 0.034989901340466784), (116, 0.03432495017777366), (35, 0.03345984305801358), (44, 0.03295085256293885), (50, 0.032897557373887415), (49, 0.03285474669174279), (268, 0.03273618030565395), (98, 0.032157592205031074), (64, 0.03193117837298337), (63, 0.031307103166881824), (65, 0.03130312206351015), (100, 0.03062461397958284), (123, 0.030282826067192226), (152, 0.029750199540781657), (68, 0.029552154687657577), (76, 0.029222887130755937), (94, 0.029182132189701674), (84, 0.0290231132825773), (55, 0.02766998539791411), (91, 0.027152674862359952), (54, 0.025427957306889192), (96, 0.025413185114473196), (86, 0.024626800309625555), (126, 0.02414370605294078), (62, 0.024002597682001033), (80, 0.021937804163694827), (59, 0.021554928182712447), (73, 0.02123072479158509), (61, 0.020844115488792885), (72, 0.020742145285632105), (56, 0.020594433839239305), (269, 0.0205743832586117), (153, 0.019634142980389298), (67, 0.019442081356848693), (157, 0.0191941298203265), (57, 0.01822812321279784), (71, 0.018175852408074282), (85, 0.017205546183484455), (273, 0.016861860242097963), (122, 0.016736980901624326), (270, 0.016021337766796925), (82, 0.01477907034782731), (79, 0.013201622103443136), (97, 0.012538771781410947), (99, 0.011327502693749804), (125, 0.011100927000344788), (69, 0.010124880339942983), (66, 0.008940675939939123), (75, 0.007020172274815932), (90, 0.006117176106820127), (70, 0.005034260280979602), (121, 0.003485104946823075), (74, 0.0015859064817030834), (83, 0.0012357371651062709), (272, -0.0012968733903822728), (101, -0.003936314016123794), (124, -0.004800250683501454), (81, -0.005444637316576286), (127, -0.007319040533698376), (117, -0.008378746513857218), (118, -0.018062055661859172), (119, -0.02324881386697934)]\n",
      "Best MI score: 0.14355837775756955\n",
      "Adding first best original feature: 203\n",
      "CMI: 0.016806384039497524\n",
      "CMI: 0.023509245613706237\n",
      "CMI: 0.032103557997434806\n",
      "CMI: 0.043786065340627706\n",
      "CMI: 0.01578245885592855\n",
      "CMI: 0.025638274994562144\n",
      "CMI: 0.0207982577623064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.01428195255504991\n",
      "CMI: 0.03256366900763924\n",
      "CMI: 0.029665388684379373\n",
      "CMI: 0.027013601746230326\n",
      "CMI: 0.012643365123598788\n",
      "CMI: 0.01671131233678999\n",
      "CMI: 0.0031345444403633738\n",
      "CMI: 0.011750353764326288\n",
      "CMI: 0.0012921357467931827\n",
      "CMI: 0.019841829771252567\n",
      "CMI: 0.016796491205511632\n",
      "CMI: 0.016120039292750965\n",
      "CMI: 0.015716949066922142\n",
      "CMI: 0.01191769801120493\n",
      "CMI: 0.001232261932766654\n",
      "CMI: 0.02429438846756979\n",
      "CMI: 0.005425938540426473\n",
      "CMI: 0.008689413279253683\n",
      "CMI: 0.0003536689702657303\n",
      "CMI: 0.008181344715952443\n",
      "CMI: 0.014860575569413337\n",
      "CMI: 0.0012355611168958502\n",
      "CMI: 0.0012529521146077138\n",
      "CMI: 0.006798669994187989\n",
      "CMI: 0.023560170141508213\n",
      "CMI: 0.002818437438506155\n",
      "CMI: 0.03444433643488143\n",
      "CMI: 0.011127733827064612\n",
      "CMI: 0.007380057495515957\n",
      "CMI: 0.010354207451642533\n",
      "CMI: 0.003328127738646186\n",
      "CMI: 0.008391733530869167\n",
      "CMI: 0.012564329231227106\n",
      "CMI: 0.005600787448859251\n",
      "CMI: 0.004028937508749303\n",
      "CMI: 0.004766082430778584\n",
      "CMI: 0.008430836778387185\n",
      "CMI: 0.0009388299253688392\n",
      "CMI: 0.012611455976585945\n",
      "CMI: 0.0021057047063558765\n",
      "CMI: 0.005300827933198304\n",
      "CMI: 0.007826639817621911\n",
      "CMI: 0.02592549684949902\n",
      "CMI: 0.01545230562931893\n",
      "CMI: 0.0017219609859342733\n",
      "CMI: 0.015891368929779603\n",
      "CMI: 0.013089094634827575\n",
      "CMI: 0.02277474058687809\n",
      "CMI: 0.019746016874345657\n",
      "CMI: 0.011674537852056938\n",
      "CMI: 0.013096229464576031\n",
      "CMI: 0.014093601365289421\n",
      "CMI: 0.002302731099091959\n",
      "CMI: 0.002986443069904754\n",
      "CMI: 0.009013369511790686\n",
      "CMI: 0.0008570542526449842\n",
      "CMI: 0.009075917884910967\n",
      "CMI: 0.010453168798459811\n",
      "CMI: 0.010790796916926387\n",
      "CMI: 0.014827652296081267\n",
      "CMI: 0.010103668943505895\n",
      "CMI: 0.009535737328546956\n",
      "CMI: 0.0017901347908161058\n",
      "CMI: 0.01262281384880598\n",
      "CMI: 0.015134186246724385\n",
      "CMI: 0.01642412698152612\n",
      "CMI: 0.02112494035212692\n",
      "CMI: 0.02957636487886034\n",
      "CMI: 0.020434500266516692\n",
      "CMI: 0.024846552021263707\n",
      "CMI: 0.027414095955679507\n",
      "CMI: 0.020548982391023873\n",
      "CMI: 0.009033112792450726\n",
      "CMI: 0.022898955484991435\n",
      "CMI: 0.02363382075240661\n",
      "CMI: 0.02533992922056935\n",
      "CMI: 0.035363194637746315\n",
      "CMI: 0.0287842013520212\n",
      "CMI: 0.03806384644887917\n",
      "CMI: 0.006117685288830638\n",
      "CMI: 0.005515861669712213\n",
      "CMI: 0.006251424408710682\n",
      "CMI: 0.00801522777423505\n",
      "CMI: 0.007467964778863939\n",
      "CMI: 0.004786682860404762\n",
      "CMI: 0.024654237253254913\n",
      "CMI: 0.01839586203968313\n",
      "CMI: 0.015136273038408532\n",
      "Highest CMI score: 0.043786065340627706\n",
      "Adding original feature: 3\n",
      "CMI: 0.009825332651731633\n",
      "CMI: 0.008228442194511076\n",
      "CMI: 0.001786755522536737\n",
      "CMI: 0.017424467928644993\n",
      "CMI: 0.0035118660015181213\n",
      "CMI: 0.00214221569804815\n",
      "CMI: 0.004806419649527355\n",
      "CMI: 0.016266540970775706\n",
      "CMI: 0.001270343741076374\n",
      "CMI: 0.005590762116255421\n",
      "CMI: 0.001930007788097765\n",
      "CMI: 0.018748255494490745\n",
      "CMI: 0.024931399941021976\n",
      "CMI: 0.0019219458154890456\n",
      "CMI: 0.011521650619996132\n",
      "CMI: 0.016919203612052264\n",
      "CMI: 0.006356479245689606\n",
      "CMI: 0.01843660202292091\n",
      "CMI: 0.008378378508101081\n",
      "CMI: 0.01234313054394881\n",
      "CMI: 0.020751198953263716\n",
      "CMI: 0.002558799402054057\n",
      "CMI: 0.008356147865357239\n",
      "CMI: 0.0015030033671943888\n",
      "CMI: 0.0001983708050084798\n",
      "CMI: 0.00010743929042819622\n",
      "CMI: 0.010630541962932949\n",
      "CMI: 0.008667747548144367\n",
      "CMI: 0.01989940277525301\n",
      "CMI: 0.005587304926152031\n",
      "CMI: 0.007130979823859407\n",
      "CMI: 0.019734050887465687\n",
      "CMI: 0.012467347911401527\n",
      "CMI: 0.011721076566526656\n",
      "CMI: 0.0058444183704216834\n",
      "CMI: 8.54428204825064e-05\n",
      "CMI: 0.004048357663827246\n",
      "CMI: 0.0028255639446361502\n",
      "CMI: 0.009102130634173033\n",
      "CMI: 0.006607994625352581\n",
      "CMI: 0.0014326102694396659\n",
      "CMI: 0.01378282480399598\n",
      "CMI: 0.006246367032814115\n",
      "CMI: 0.0056318745083142885\n",
      "CMI: 0.008571953109367952\n",
      "CMI: 0.005363017744853371\n",
      "CMI: 0.012398602742214188\n",
      "CMI: 0.009458436732839998\n",
      "CMI: 0.010314430333177638\n",
      "CMI: 0.022074715651950072\n",
      "CMI: 0.016079987015347935\n",
      "CMI: 0.0004199380855952062\n",
      "CMI: 0.005647310537384681\n",
      "CMI: 0.01044082496926868\n",
      "CMI: 0.007725511481382508\n",
      "CMI: 0.012294085736981458\n",
      "CMI: 0.00267258821014707\n",
      "CMI: 0.005680554272090077\n",
      "CMI: 0.0013607903268511579\n",
      "CMI: 0.01165854236523775\n",
      "CMI: 0.011495535763996922\n",
      "CMI: 0.014195406089925505\n",
      "CMI: 0.01055437356151645\n",
      "CMI: 0.02366500151049228\n",
      "CMI: 0.02526971920497323\n",
      "CMI: 0.02908799835310666\n",
      "CMI: 0.028478900707066074\n",
      "CMI: 0.024542874079829635\n",
      "CMI: 0.02398427579166937\n",
      "CMI: 0.031324038158044715\n",
      "CMI: 0.012524395852799242\n",
      "CMI: 0.0327135291372663\n",
      "CMI: 0.014801879378617877\n",
      "CMI: 0.030236953058222132\n",
      "CMI: 0.011194872978255666\n",
      "CMI: 0.022057767952079782\n",
      "CMI: 0.02446259765115741\n",
      "CMI: 0.014892143035991373\n",
      "CMI: 0.02468320911022523\n",
      "CMI: 0.03895628569837223\n",
      "CMI: 0.013360719206692212\n",
      "CMI: 0.019090748616192782\n",
      "CMI: 0.01836486566096282\n",
      "CMI: 0.024197306200050478\n",
      "CMI: 0.0005953348868136532\n",
      "CMI: 0.007410072954538549\n",
      "Highest CMI score: 0.03895628569837223\n",
      "Adding original feature: 240\n",
      "CMI: 0.006558608214442541\n",
      "CMI: 0.012427844579806668\n",
      "CMI: 0.002616543570741453\n",
      "CMI: 0.002874458868799501\n",
      "CMI: 0.0019537585723699014\n",
      "CMI: 0.009333086868269447\n",
      "CMI: 0.009036263024850083\n",
      "CMI: 0.00444000356413865\n",
      "CMI: 0.005555015612700387\n",
      "CMI: 0.0022383778473399896\n",
      "CMI: 0.0002559451553516834\n",
      "CMI: 0.00042976935579258635\n",
      "CMI: 0.0011443106841926565\n",
      "CMI: 0.0005014156694381766\n",
      "CMI: 0.008183852502648581\n",
      "CMI: 0.008628979219082067\n",
      "CMI: 0.004261389956594613\n",
      "CMI: 0.005461051765005831\n",
      "CMI: 0.014269026343323249\n",
      "CMI: 0.010308151406426574\n",
      "CMI: 0.0071844897805543595\n",
      "CMI: 0.005004502703812003\n",
      "CMI: 0.0032207312628940166\n",
      "CMI: 0.0008479168847011498\n",
      "CMI: 0.001627073061545331\n",
      "CMI: 0.007630041300142526\n",
      "CMI: 0.011015551218941932\n",
      "CMI: 0.0015798795190012926\n",
      "CMI: 0.0058725058059647395\n",
      "CMI: 0.0053243422364528115\n",
      "CMI: 0.0038602509137046492\n",
      "CMI: 0.0017372302662900796\n",
      "CMI: 0.0012328526425622044\n",
      "CMI: 0.012765087581164403\n",
      "CMI: 0.0023014821801657648\n",
      "CMI: 0.004600265022480926\n",
      "CMI: 0.00112058859757036\n",
      "CMI: 0.007300414707424624\n",
      "Highest CMI score: 0.014269026343323249\n",
      "Adding original feature: 197\n",
      "CMI: 0.007622755274552612\n",
      "CMI: 0.011302248507568252\n",
      "CMI: 0.004022588424350854\n",
      "CMI: 0.005252180368894632\n",
      "CMI: 6.229306971811122e-05\n",
      "CMI: 0.001128305424857673\n",
      "CMI: 0.0021891618907996235\n",
      "CMI: 0.0008904135054791928\n",
      "CMI: 0.0019641381410622216\n",
      "CMI: 0.0020848319387639924\n",
      "CMI: 0.002111754642747876\n",
      "CMI: 0.001336588937663502\n",
      "Highest CMI score: 0.011302248507568252\n",
      "Adding original feature: 36\n",
      "CMI: 0.0011745699304934742\n",
      "CMI: 0.002263546097856728\n",
      "CMI: 0.0008476965582476792\n",
      "CMI: 0.0023190261105887067\n",
      "CMI: 0.005289663575812897\n",
      "CMI: 0.006067586928877322\n",
      "CMI: 0.0009189863733942705\n",
      "CMI: 0.0016840975046862883\n",
      "CMI: 0.0040621999579733\n",
      "CMI: 0.0009161963871727741\n",
      "CMI: 0.0003606501830292208\n",
      "CMI: 0.0025890715582105317\n",
      "CMI: 0.001132492835846377\n",
      "CMI: 0.0007742421392522014\n",
      "CMI: 0.003110558125989149\n",
      "CMI: 0.0020611160814718588\n",
      "CMI: 0.006236453540720999\n",
      "CMI: 0.007668885243622303\n",
      "CMI: 0.008711549396345553\n",
      "CMI: 0.00568838198723759\n",
      "CMI: 0.002808694837280301\n",
      "CMI: 0.002573081123885934\n",
      "Highest CMI score: 0.008711549396345553\n",
      "Adding original feature: 239\n",
      "CMI: 0.0025831243861906272\n",
      "CMI: 0.0017930216047212233\n",
      "CMI: 0.000714496623652694\n",
      "CMI: 0.0004968529861236193\n",
      "CMI: 0.005189977197334772\n",
      "Highest CMI score: 0.005189977197334772\n",
      "Adding original feature: 244\n",
      "CMI: 0.0008778924931793775\n",
      "CMI: 0.002130144760068564\n",
      "CMI: 0.0030260601803752674\n",
      "CMI: 0.003187428736704634\n",
      "Highest CMI score: 0.003187428736704634\n",
      "Adding original feature: 209\n",
      "CMI: 0.0007857443713614187\n",
      "CMI: 0.002843500916937969\n",
      "CMI: 0.0002500141999693395\n",
      "Highest CMI score: 0.002843500916937969\n",
      "Adding original feature: 221\n",
      "CMI: 0.0008724128356819572\n",
      "CMI: 0.0034518807975156274\n",
      "CMI: 0.00033190642081726285\n",
      "CMI: 0.001331610592006427\n",
      "CMI: 0.003091863651583704\n",
      "CMI: 0.0010107311838994937\n",
      "CMI: 0.00012352256334285938\n",
      "CMI: 0.0016724230267603502\n",
      "CMI: 0.0006256383709563607\n",
      "CMI: 0.0021770471599286134\n",
      "CMI: 0.0009062324636331387\n",
      "CMI: 0.00025661836623258605\n",
      "CMI: 0.000359092451642562\n",
      "CMI: 0.00022350426789885525\n",
      "Highest CMI score: 0.0034518807975156274\n",
      "Adding original feature: 37\n",
      "CMI: 0.0004373704173847859\n",
      "CMI: 0.002347893395204359\n",
      "CMI: 0.0007256046328776855\n",
      "CMI: 0.00011263640149988818\n",
      "CMI: 0.003268150313365914\n",
      "CMI: 0.003799973622347963\n",
      "CMI: 0.0018919990001579623\n",
      "CMI: 0.0036794011201267685\n",
      "CMI: 0.00299860039096006\n",
      "Highest CMI score: 0.003799973622347963\n",
      "Adding original feature: 208\n",
      "CMI: 0.00025726162084838133\n",
      "CMI: 0.000929865019408338\n",
      "CMI: 0.0003427571783904959\n",
      "CMI: 0.002288789627908294\n",
      "Highest CMI score: 0.002288789627908294\n",
      "Adding original feature: 219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.0011063359171046283\n",
      "CMI: 0.0009908087236589758\n",
      "Highest CMI score: 0.0011063359171046283\n",
      "Adding original feature: 195\n",
      "CMI: 0.0008210000740608292\n",
      "Highest CMI score: 0.0008210000740608292\n",
      "Adding original feature: 196\n",
      "Highest CMI score: -0.0001349625347940031\n",
      "\n",
      "[203, 3, 240, 197, 36, 239, 244, 209, 221, 37, 208, 219, 195, 196]\n",
      "\n",
      "Full aggregate regression train score: 0.7424846328561507, test score: -7.973731717396019\n",
      "Aggregate regression train score with FS: 0.25871954563399324, test score: 0.15149390026340126\n"
     ]
    }
   ],
   "source": [
    "### what happens without considering the last years?\n",
    "target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "\n",
    "path='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg'\n",
    "\n",
    "output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(path,['cyclostationary_mean_tg', \n",
    "                                                                         'cyclostationary_mean_tg_1w',\n",
    "                                                                         'cyclostationary_mean_tg_4w', \n",
    "                                                                         'cyclostationary_mean_tg_8w',\n",
    "                                                                         'cyclostationary_mean_tg_12w', \n",
    "                                                                         'cyclostationary_mean_tg_16w',\n",
    "                                                                         'cyclostationary_mean_tg_24w', \n",
    "                                                                         'cyclostationary_mean_rr', \n",
    "                                                                         'cyclostationary_mean_rr_1w',\n",
    "                                                                         'cyclostationary_mean_rr_4w', \n",
    "                                                                         'cyclostationary_mean_rr_8w',\n",
    "                                                                         'cyclostationary_mean_rr_12w', \n",
    "                                                                         'cyclostationary_mean_rr_16w',\n",
    "                                                                         'cyclostationary_mean_rr_24w'  \n",
    "                                                                         ],target_df_trainVal, max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', multiple=True, neigh=0)\n",
    "\n",
    "res = {\n",
    "    \"delta\" : [], # list with all deltas\n",
    "    \"numSelected\" : [], #\n",
    "    \"selectedFeatures\" : [] \n",
    "}\n",
    "\n",
    "res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "selectedFeatures='selectedFeatures'\n",
    "print(f'\\n{res[selectedFeatures]}\\n')\n",
    "selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n",
    "compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
