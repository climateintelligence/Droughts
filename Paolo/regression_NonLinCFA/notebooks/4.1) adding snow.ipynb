{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288de91a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87a19403",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/methods/CMI_FS\")\n",
    "from feature_selection import forwardFeatureSelection\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/methods/LinCFA\")\n",
    "from LinCFA import LinCFA\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/methods/NonLinCFA\")\n",
    "from NonLinCFA import NonLinCFA\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/Droughts/Paolo/regression_NonLinCFA\")\n",
    "from aux import standardize,unfold_dataset,compute_r2,prepare_target,prepare_features,aggregate_unfolded_data,aggregate_unfolded_data_onlyTrain,FS_with_linearWrapper,compare_methods, compute_r2, aggregate_data_withoutUnfolding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5728785a",
   "metadata": {},
   "source": [
    "# Piemonte Nord e Sud, Adda, Ticino, Dora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f7105",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Only temp+prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d692097",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################Piemonte_Nord####################\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278983    0.00  2001     1 -1.146332\n",
      "1    2001-01-13  0.494910    0.51  2001     2  0.371173\n",
      "2    2001-01-21  0.496092    0.51  2001     3  0.379474\n",
      "3    2001-01-29  0.427992    0.43  2001     5 -0.099118\n",
      "4    2001-02-06  0.400512    0.41  2001     6 -0.292244\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.363952    0.37  2009    48 -0.549184\n",
      "407  2009-12-05  0.400487    0.40  2009    49 -0.292423\n",
      "408  2009-12-13  0.506771    0.52  2009    50  0.454529\n",
      "409  2009-12-21  0.387530    0.53  2009    52 -0.383480\n",
      "410  2009-12-29  0.279894    0.27  2009    53 -1.139931\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 6\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 7\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 7\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 4\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_tg_24w_0', 'cyclostationary_mean_tg_24w_1', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_rr_8w_1', 'cyclostationary_mean_tg_4w_3', 'cyclostationary_mean_tg_4w_6', 'cyclostationary_mean_tg_4w_1', 'cyclostationary_mean_tg_1w_6', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_tg_8w_2', 'cyclostationary_mean_tg_4w_4', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_tg_1w_2'], \n",
      "\n",
      "validation score: 0.30240169972433983, \n",
      "\n",
      "number of selected features: 17\n",
      "\n",
      "Full model and selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.29468904557722275, test score: -0.0296699332561825\n",
      "Aggregate regression train score with FS: 0.24487371391348056, test score: -0.12759331002562058\n",
      "\n",
      "Full model and best 5 selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.29468904557722275, test score: -0.0296699332561825\n",
      "Aggregate regression train score with FS: 0.21393696998227474, test score: 0.1251930336479511\n",
      "----- MI Scores -----\n",
      "[(3, 0.13910140472027976), (2, 0.11677792896815278), (9, 0.11242702441643683), (12, 0.1099945104404797), (1, 0.09364422479893687), (5, 0.09137391410745542), (11, 0.09033835395319534), (0, 0.08989863929473699), (4, 0.07955295674086828), (6, 0.07882849186969863), (10, 0.07582271736345429), (8, 0.06847496241497947), (7, 0.06747165529112577), (34, 0.0615972198896565), (32, 0.06154299554550257), (36, 0.05948643955324653), (31, 0.05689324004667617), (21, 0.051278663503039786), (19, 0.04640481089462892), (37, 0.0436171911659015), (23, 0.04298170969016182), (22, 0.04157185322071468), (17, 0.040660866682886404), (30, 0.039899111869824436), (16, 0.03936901892080979), (25, 0.03918432776370937), (14, 0.03830309893680161), (28, 0.03728355960937508), (18, 0.03632912752056667), (27, 0.03426530035797391), (29, 0.03311292745027499), (13, 0.02987115006421647), (20, 0.028820625006538637), (35, 0.02793605401697919), (15, 0.025195321247282694), (24, 0.021472580302876094), (26, 0.02120089551670573), (33, 0.020718823068137063)]\n",
      "Best MI score: 0.13910140472027976\n",
      "Adding first best original feature: 3\n",
      "CMI: 0.0016920258761937146\n",
      "CMI: 0.003996013869582954\n",
      "CMI: 0.02801289279423999\n",
      "CMI: 0.022750208809280387\n",
      "CMI: 0.024493548072650195\n",
      "CMI: 0.005126950507696015\n",
      "CMI: 0.026068307490465237\n",
      "Highest CMI score: 0.02801289279423999\n",
      "Adding original feature: 31\n",
      "CMI: 0.012058698024091263\n",
      "CMI: 0.008014996072354647\n",
      "CMI: 0.005784212341584327\n",
      "CMI: 0.0048638057060270135\n",
      "CMI: 0.010711624133859982\n",
      "CMI: 0.012701478913980241\n",
      "CMI: 0.020252191019192956\n",
      "CMI: 0.012273370204484824\n",
      "CMI: 0.012692411560226186\n",
      "CMI: 0.014281674163654973\n",
      "CMI: 0.014442687384270597\n",
      "CMI: 0.0013287110970462146\n",
      "CMI: 0.0025512706459644985\n",
      "CMI: 0.0035517244924000158\n",
      "CMI: 0.003727240736091708\n",
      "CMI: 0.006265984242040806\n",
      "CMI: 0.007420925823884539\n",
      "Highest CMI score: 0.020252191019192956\n",
      "Adding original feature: 7\n",
      "CMI: 0.0028048132988725827\n",
      "CMI: 0.0036452635358895924\n",
      "CMI: 0.0005519262482181209\n",
      "CMI: 0.004405083316340291\n",
      "CMI: 0.0012605419474807644\n",
      "CMI: 0.001161476675276163\n",
      "Highest CMI score: 0.004405083316340291\n",
      "Adding original feature: 9\n",
      "CMI: 0.0010648378299236427\n",
      "CMI: 0.0006755238913739303\n",
      "Highest CMI score: 0.0010648378299236427\n",
      "Adding original feature: 10\n",
      "Highest CMI score: -0.00021449048079039135\n",
      "\n",
      "[3, 31, 7, 9, 10]\n",
      "\n",
      "\n",
      "Full model and selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.29468904557722275, test score: -0.0296699332561825\n",
      "Aggregate regression train score with FS: 0.21787703134105674, test score: 0.04024859458979424\n",
      "\n",
      "Full model and best 5 selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.29468904557722275, test score: -0.0296699332561825\n",
      "Aggregate regression train score with FS: 0.21787703134105674, test score: 0.04024859458979424\n",
      "####################Piemonte_Sud####################\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278060    0.09  2001     1 -0.967137\n",
      "1    2001-01-13  0.445159    0.48  2001     2  0.070382\n",
      "2    2001-01-21  0.488982    0.52  2001     3  0.342478\n",
      "3    2001-01-29  0.362487    0.37  2001     5 -0.442927\n",
      "4    2001-02-06  0.430732    0.45  2001     6 -0.019192\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.430379    0.44  2009    48 -0.021388\n",
      "407  2009-12-05  0.419919    0.43  2009    49 -0.086330\n",
      "408  2009-12-13  0.526648    0.55  2009    50  0.576347\n",
      "409  2009-12-21  0.457440    0.61  2009    52  0.146632\n",
      "410  2009-12-29  0.301938    0.38  2009    53 -0.818877\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 6\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 10\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 4\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_2', 'cyclostationary_mean_rr_24w_1', 'cyclostationary_mean_rr_1w_4', 'cyclostationary_mean_rr_16w_1', 'cyclostationary_mean_rr_16w_2', 'cyclostationary_mean_rr_12w_2', 'cyclostationary_mean_rr_12w_1', 'cyclostationary_mean_rr_4w_4', 'cyclostationary_mean_tg_12w_1', 'cyclostationary_mean_tg_12w_0', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_rr_3', 'cyclostationary_mean_rr_0', 'cyclostationary_mean_tg_16w_4', 'cyclostationary_mean_rr_8', 'cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_tg_4w_1', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_tg_16w_3', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_tg_0', 'cyclostationary_mean_tg_1'], \n",
      "\n",
      "validation score: 0.2905206556230484, \n",
      "\n",
      "number of selected features: 23\n",
      "\n",
      "Full model and selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.3925874391400853, test score: -0.28321734039059865\n",
      "Aggregate regression train score with FS: 0.2755009635324518, test score: 0.08554193746674954\n",
      "\n",
      "Full model and best 5 selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.3925874391400853, test score: -0.28321734039059865\n",
      "Aggregate regression train score with FS: 0.19987006688924702, test score: 0.12183304773875714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- MI Scores -----\n",
      "[(0, 0.10828140105633417), (42, 0.10540351107087807), (3, 0.10360024919751139), (1, 0.09732112095987412), (59, 0.09632459933985814), (51, 0.09504862903894257), (50, 0.09271731107050801), (2, 0.09221894148727858), (61, 0.09118775336609275), (55, 0.08847082224879566), (52, 0.08806435647689961), (41, 0.08736519266509175), (53, 0.08071317337658432), (47, 0.07680037628099362), (43, 0.075071626108866), (58, 0.07423403064202792), (4, 0.07235450820565101), (56, 0.07218705423176484), (60, 0.0697176298548119), (57, 0.06961542865992468), (45, 0.06924061086735848), (46, 0.06759455518696374), (39, 0.06692499909581603), (54, 0.06392844522143308), (5, 0.0600274074676265), (33, 0.05591576054731865), (36, 0.05220501936022941), (49, 0.048093215687404), (8, 0.046018442921380305), (40, 0.04583156722857606), (34, 0.044951332652584115), (30, 0.04309325411575538), (35, 0.04306263516036035), (7, 0.042308250947635566), (38, 0.03798035132289578), (32, 0.037792474675920285), (6, 0.03641377767532758), (10, 0.03639832237080823), (48, 0.03258338307864268), (27, 0.032539989706063206), (44, 0.032189802466501834), (31, 0.029886206900980677), (37, 0.025994041902723034), (23, 0.02348927247517369), (18, 0.022453659139718307), (26, 0.02216557705455127), (12, 0.021274811296509048), (16, 0.020087105903313127), (17, 0.01963405166552546), (19, 0.018087081363253727), (13, 0.016071453724833085), (22, 0.015607937369199007), (25, 0.013930921797819814), (11, 0.013249289038773426), (29, 0.01030325253108978), (24, 0.008910844165150767), (9, 0.006813952314611714), (14, 0.0042645202354480525), (15, 0.001198243294508687), (20, 0.0004654062670023816), (28, -0.003909646263992712), (21, -0.006047268830530692)]\n",
      "Best MI score: 0.10828140105633417\n",
      "Adding first best original feature: 0\n",
      "CMI: 0.003076573504731714\n",
      "CMI: 0.018363275878711824\n",
      "CMI: 0.02065469940992863\n",
      "CMI: 0.029939664294004423\n",
      "CMI: 0.006382600617030831\n",
      "CMI: 9.64905524285381e-05\n",
      "CMI: 0.006627243836128213\n",
      "CMI: 0.0444045792797841\n",
      "CMI: 0.030524678274264735\n",
      "CMI: 0.02310442513291698\n",
      "CMI: 0.002748674660840722\n",
      "CMI: 0.04278622521841709\n",
      "CMI: 0.02365970928324014\n",
      "CMI: 0.03383804257924174\n",
      "CMI: 0.014795776245194292\n",
      "CMI: 0.05087445114399329\n",
      "CMI: 0.04658449689252829\n",
      "CMI: 0.04837482897132779\n",
      "CMI: 0.0297594147908591\n",
      "CMI: 0.03692693296187917\n",
      "CMI: 0.051900572107322754\n",
      "CMI: 0.03465408921166786\n",
      "CMI: 0.03428397497168591\n",
      "CMI: 0.03545741125385231\n",
      "CMI: 0.03727913276350921\n",
      "CMI: 0.0752186512065552\n",
      "CMI: 0.03990189319681074\n",
      "Highest CMI score: 0.0752186512065552\n",
      "Adding original feature: 60\n",
      "CMI: 0.0031435902284474293\n",
      "CMI: 0.002422901620498491\n",
      "CMI: 0.019362171248324622\n",
      "CMI: 0.004232395382066406\n",
      "CMI: 0.010322928486835303\n",
      "CMI: 0.0018520825192369639\n",
      "CMI: 0.006650551057433812\n",
      "CMI: 0.003277120740056594\n",
      "Highest CMI score: 0.019362171248324622\n",
      "Adding original feature: 50\n",
      "CMI: 0.0008442225775371348\n",
      "CMI: 0.00036839488954834576\n",
      "CMI: 0.0029780897294469644\n",
      "CMI: 0.001297660653125532\n",
      "CMI: 0.00963797254145149\n",
      "CMI: 0.01354052922851609\n",
      "CMI: 0.010109574936722626\n",
      "CMI: 0.0064025254702609335\n",
      "Highest CMI score: 0.01354052922851609\n",
      "Adding original feature: 55\n",
      "CMI: 0.004209444957950975\n",
      "CMI: 0.014103657008593812\n",
      "CMI: 0.006998819571794351\n",
      "CMI: 0.010207660059123158\n",
      "CMI: 0.01073787612110988\n",
      "CMI: 0.011663823377888155\n",
      "CMI: 0.008928873971147333\n",
      "CMI: 0.0007300824973127673\n",
      "CMI: 0.004158983969937358\n",
      "CMI: 0.004703500658621129\n",
      "Highest CMI score: 0.014103657008593812\n",
      "Adding original feature: 3\n",
      "Highest CMI score: -0.0004260868884832514\n",
      "\n",
      "[0, 60, 50, 55, 3]\n",
      "\n",
      "\n",
      "Full model and selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.3925874391400853, test score: -0.28321734039059865\n",
      "Aggregate regression train score with FS: 0.15085308590131863, test score: 0.11458686296937504\n",
      "\n",
      "Full model and best 5 selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.3925874391400853, test score: -0.28321734039059865\n",
      "Aggregate regression train score with FS: 0.15085308590131863, test score: 0.11458686296937504\n",
      "####################Adda####################\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.039373    0.00  2001     1 -2.546951\n",
      "1    2001-01-13  0.380618    0.43  2001     2 -0.277191\n",
      "2    2001-01-21  0.341985    0.38  2001     3 -0.534156\n",
      "3    2001-01-29  0.322044    0.35  2001     5 -0.666789\n",
      "4    2001-02-06  0.354954    0.40  2001     6 -0.447894\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.382706    0.40  2009    48 -0.263306\n",
      "407  2009-12-05  0.409921    0.46  2009    49 -0.082282\n",
      "408  2009-12-13  0.472087    0.53  2009    50  0.331204\n",
      "409  2009-12-21  0.324728    0.00  2009    52 -0.648940\n",
      "410  2009-12-29  0.086512    0.00  2009    53 -2.233412\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 8\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 4\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 4\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 4\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_tg_1w_6', 'cyclostationary_mean_tg_1w_5', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_tg_16w_2', 'cyclostationary_mean_tg_1w_4', 'cyclostationary_mean_tg_12w_3', 'cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_rr_12w_1', 'cyclostationary_mean_rr_12w_2', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_rr_2', 'cyclostationary_mean_rr_3', 'cyclostationary_mean_rr_4', 'cyclostationary_mean_tg_4w_4', 'cyclostationary_mean_rr_1'], \n",
      "\n",
      "validation score: 0.33729581660235464, \n",
      "\n",
      "number of selected features: 19\n",
      "\n",
      "Full model and selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.3117105374314997, test score: -0.33005824107161486\n",
      "Aggregate regression train score with FS: 0.24115224664141943, test score: -0.03275775627162969\n",
      "\n",
      "Full model and best 5 selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.3117105374314997, test score: -0.33005824107161486\n",
      "Aggregate regression train score with FS: 0.20248698967308365, test score: 0.13863455849493866\n",
      "----- MI Scores -----\n",
      "[(11, 0.12382062882193837), (13, 0.11753363244877706), (12, 0.11627115251375528), (4, 0.11558499199875491), (3, 0.11556837299107342), (15, 0.10983396973374421), (1, 0.10696249667549634), (10, 0.10601183373702121), (2, 0.10360504540943304), (14, 0.10174648571540935), (5, 0.10099817700521793), (9, 0.10077079926856579), (7, 0.0995069836776427), (0, 0.0963063548120773), (16, 0.09256944158697891), (8, 0.08661809050846275), (41, 0.07999473041031913), (6, 0.07842385654585562), (20, 0.06838491122071422), (42, 0.05155755293289637), (48, 0.047334700475274924), (29, 0.04655332269180252), (18, 0.046336269299502165), (19, 0.045062184539707034), (21, 0.043591960643407576), (23, 0.03366738037728009), (37, 0.032674600261714704), (45, 0.032379547749356), (43, 0.03135657205267133), (28, 0.029624969112521), (34, 0.027285739250342222), (40, 0.02678637412285656), (39, 0.025421440120670227), (46, 0.024841567016598537), (27, 0.023235196010406422), (31, 0.020569903141526635), (26, 0.019781497581839183), (44, 0.018859847479014424), (17, 0.018819263367304592), (51, 0.016805935762419236), (25, 0.01643897456357112), (50, 0.012771325343636604), (49, 0.012104051385525436), (36, 0.011110037255563109), (32, 0.006341278313756974), (35, 0.006310199626343884), (22, 0.00030148475663156), (24, -0.0010043373736043793), (38, -0.0012011767816253746), (30, -0.0032094800181856034), (33, -0.006138128334639475), (47, -0.007314254626464375)]\n",
      "Best MI score: 0.12382062882193837\n",
      "Adding first best original feature: 11\n",
      "CMI: 0.0034282480889311073\n",
      "CMI: 0.00556266799650787\n",
      "CMI: 0.0017745605979289925\n",
      "CMI: 0.0242797556791938\n",
      "CMI: 0.014184639541659577\n",
      "CMI: 0.009190369240083013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.006624388253266861\n",
      "CMI: 0.0030981634182589424\n",
      "CMI: 0.006282864570508945\n",
      "CMI: 0.0029264662653806783\n",
      "CMI: 0.014122997852305863\n",
      "CMI: 0.006113992740532287\n",
      "CMI: 0.0030719299225818453\n",
      "CMI: 0.0024262826772420976\n",
      "CMI: 0.0010753876543792146\n",
      "CMI: 0.02810098729551408\n",
      "CMI: 0.024144132254435985\n",
      "CMI: 0.012342105593410813\n",
      "CMI: 0.006700675919893262\n",
      "CMI: 0.003896541867466491\n",
      "CMI: 0.002893936060894886\n",
      "CMI: 0.0003093615834881408\n",
      "CMI: 0.010107600077330414\n",
      "CMI: 0.0076079727244009465\n",
      "CMI: 0.01908967461476177\n",
      "CMI: 0.012462386718424756\n",
      "CMI: 0.009210478531231081\n",
      "CMI: 0.011094173889947156\n",
      "CMI: 0.014111781613090957\n",
      "CMI: 0.03333163300111361\n",
      "CMI: 0.01961083349465806\n",
      "CMI: 0.01130387795574253\n",
      "CMI: 0.0034721342846523173\n",
      "CMI: 0.0351507953297725\n",
      "CMI: 0.01716450610747053\n",
      "CMI: 0.023456973403961967\n",
      "Highest CMI score: 0.0351507953297725\n",
      "Adding original feature: 45\n",
      "CMI: 0.003828758131675769\n",
      "CMI: 0.001600282747443449\n",
      "CMI: 0.0006175627037483256\n",
      "CMI: 0.014636880627741128\n",
      "CMI: 0.006787718912100005\n",
      "CMI: 0.01805524894248961\n",
      "CMI: 0.0035822889386327716\n",
      "CMI: 0.006195223099898034\n",
      "CMI: 0.01611337274163549\n",
      "CMI: 0.011218681553707976\n",
      "CMI: 0.012498785776641902\n",
      "CMI: 0.0011920736225755346\n",
      "Highest CMI score: 0.01805524894248961\n",
      "Adding original feature: 30\n",
      "CMI: 0.0037261674436335213\n",
      "CMI: 0.003185174929665441\n",
      "CMI: 0.0065106627476308465\n",
      "CMI: 0.006695604858419357\n",
      "CMI: 0.0012067492602157726\n",
      "CMI: 0.006772490485793453\n",
      "CMI: 0.005569954623171253\n",
      "CMI: 0.008943645325141303\n",
      "CMI: 0.00353633801928932\n",
      "CMI: 0.002793006852596397\n",
      "CMI: 0.02447895278320536\n",
      "CMI: 0.006127627967195848\n",
      "CMI: 0.0022707698947910804\n",
      "CMI: 0.009265141791483883\n",
      "CMI: 0.0021601408194882044\n",
      "Highest CMI score: 0.02447895278320536\n",
      "Adding original feature: 35\n",
      "CMI: 0.002067243480556452\n",
      "CMI: 0.004265304663524649\n",
      "CMI: 0.0027934731221324893\n",
      "Highest CMI score: 0.004265304663524649\n",
      "Adding original feature: 33\n",
      "CMI: 0.0007972343158471895\n",
      "CMI: 0.0032526926037748927\n",
      "Highest CMI score: 0.0032526926037748927\n",
      "Adding original feature: 51\n",
      "CMI: 5.1114778654132165e-05\n",
      "CMI: 6.606377434972832e-05\n",
      "Highest CMI score: 6.606377434972832e-05\n",
      "Adding original feature: 32\n",
      "CMI: 6.435966642875934e-05\n",
      "CMI: 0.002485061274861755\n",
      "CMI: 8.758964488292387e-05\n",
      "Highest CMI score: 0.002485061274861755\n",
      "Adding original feature: 25\n",
      "CMI: 0.003583804160734755\n",
      "CMI: 0.0023240766212230535\n",
      "Highest CMI score: 0.003583804160734755\n",
      "Adding original feature: 28\n",
      "CMI: 0.0010205824126643392\n",
      "Highest CMI score: 0.0010205824126643392\n",
      "Adding original feature: 31\n",
      "Highest CMI score: -0.0037488519730639047\n",
      "\n",
      "[11, 45, 30, 35, 33, 51, 32, 25, 28, 31]\n",
      "\n",
      "\n",
      "Full model and selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.3117105374314997, test score: -0.33005824107161486\n",
      "Aggregate regression train score with FS: 0.17483172342240894, test score: 0.16183814280609732\n",
      "\n",
      "Full model and best 5 selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.3117105374314997, test score: -0.33005824107161486\n",
      "Aggregate regression train score with FS: 0.1517060797759482, test score: 0.1861320538978487\n",
      "####################Dora####################\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.010645    0.00  2001     1 -2.129508\n",
      "1    2001-01-13  0.206769    0.00  2001     2 -0.927136\n",
      "2    2001-01-21  0.267313    0.00  2001     3 -0.555958\n",
      "3    2001-01-29  0.240836    0.20  2001     5 -0.718282\n",
      "4    2001-02-06  0.193417    0.15  2001     6 -1.008995\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.230073    0.25  2009    48 -0.784269\n",
      "407  2009-12-05  0.243632    0.24  2009    49 -0.701139\n",
      "408  2009-12-13  0.251111    0.00  2009    50 -0.655289\n",
      "409  2009-12-21  0.099246    0.00  2009    52 -1.586325\n",
      "410  2009-12-29  0.064990    0.00  2009    53 -1.796340\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 4\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_tg_4w_1', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_tg_12w_1', 'cyclostationary_mean_tg_12w_0', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_tg_8w_1'], \n",
      "\n",
      "validation score: 0.17561097252367086, \n",
      "\n",
      "number of selected features: 11\n",
      "\n",
      "Full model and selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.1787030492380406, test score: -0.9235242776500767\n",
      "Aggregate regression train score with FS: 0.1391888143746839, test score: -0.6415345356585773\n",
      "\n",
      "Full model and best 5 selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.1787030492380406, test score: -0.9235242776500767\n",
      "Aggregate regression train score with FS: 0.12604208062934985, test score: -0.5149752171171809\n",
      "----- MI Scores -----\n",
      "[(6, 0.08564397327695021), (0, 0.08509598471294849), (1, 0.07947913957458219), (5, 0.06777331311132379), (21, 0.06403914196637761), (2, 0.06275881098073652), (23, 0.06171626575698934), (19, 0.06056112941717606), (20, 0.0590243394443204), (10, 0.0557261915917365), (3, 0.055522131453310905), (4, 0.054451972693187675), (7, 0.05013396464960597), (22, 0.04963889533470378), (18, 0.04686527556655052), (9, 0.04642124218639126), (11, 0.03994388732910318), (24, 0.03973911161712182), (8, 0.03364236729396663), (17, 0.026156781831893537), (13, 0.02434045565894693), (14, 0.017403935659882793), (16, 0.014858994314943258), (12, 0.010923977157029814), (15, 0.009337204656474401)]\n",
      "Best MI score: 0.08564397327695021\n",
      "Adding first best original feature: 6\n",
      "CMI: 0.021537401114826216\n",
      "CMI: 0.006462765963024739\n",
      "CMI: 0.0015108401661156623\n",
      "CMI: 0.0004886083155550419\n",
      "CMI: 0.029508573594346083\n",
      "CMI: 0.018073668550374705\n",
      "CMI: 0.014973335354002179\n",
      "CMI: 0.005021960716319676\n",
      "CMI: 0.004653706254433523\n",
      "CMI: 0.01110440126983879\n",
      "CMI: 0.0021433306122051188\n",
      "CMI: 0.004719366148103171\n",
      "CMI: 0.01371272892351462\n",
      "CMI: 0.012038454835250179\n",
      "CMI: 0.0036976972347477904\n",
      "CMI: 0.015097683001145529\n",
      "CMI: 0.014770753104761794\n",
      "CMI: 0.015707530058856084\n",
      "Highest CMI score: 0.029508573594346083\n",
      "Adding original feature: 9\n",
      "CMI: 0.0071005949324310785\n",
      "CMI: 0.014349402458092284\n",
      "CMI: 0.009741118894839224\n",
      "CMI: 0.0034684045593823404\n",
      "CMI: 0.0041382060252407316\n",
      "CMI: 0.0031749311461777147\n",
      "CMI: 0.007348274089656437\n",
      "CMI: 0.003673037119061945\n",
      "CMI: 0.029698452495875008\n",
      "CMI: 0.017410148728450855\n",
      "CMI: 0.022354373848918793\n",
      "CMI: 0.006330118256796302\n",
      "CMI: 0.047863595358105124\n",
      "CMI: 0.03449724242348977\n",
      "CMI: 0.01787952248265924\n",
      "CMI: 0.01004693014311335\n",
      "CMI: 0.003051464071423496\n",
      "CMI: 0.026004482014911776\n",
      "Highest CMI score: 0.047863595358105124\n",
      "Adding original feature: 19\n",
      "CMI: 0.0007994313032318179\n",
      "CMI: 0.003565228626269179\n",
      "CMI: 0.0011937398543369615\n",
      "CMI: 0.007255834779527598\n",
      "CMI: 0.01439749514183375\n",
      "CMI: 0.019793797829453286\n",
      "CMI: 0.009578970272738685\n",
      "CMI: 0.007883133468573417\n",
      "CMI: 0.0006650721873643628\n",
      "Highest CMI score: 0.019793797829453286\n",
      "Adding original feature: 14\n",
      "CMI: 0.0022035734578747523\n",
      "CMI: 0.005467367271881823\n",
      "CMI: 0.00048054171381958777\n",
      "CMI: 0.00015223731956801045\n",
      "Highest CMI score: 0.005467367271881823\n",
      "Adding original feature: 15\n",
      "Highest CMI score: -0.00023510177042859737\n",
      "\n",
      "[6, 9, 19, 14, 15]\n",
      "\n",
      "\n",
      "Full model and selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.1787030492380406, test score: -0.9235242776500767\n",
      "Aggregate regression train score with FS: 0.0861901145028352, test score: -0.4658929670569214\n",
      "\n",
      "Full model and best 5 selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.1787030492380406, test score: -0.9235242776500767\n",
      "Aggregate regression train score with FS: 0.0861901145028352, test score: -0.4658929670569214\n",
      "####################Ticino####################\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.264043    0.00  2001     1 -1.060146\n",
      "1    2001-01-13  0.354618    0.39  2001     2 -0.405065\n",
      "2    2001-01-21  0.427990    0.47  2001     3  0.125603\n",
      "3    2001-01-29  0.339495    0.35  2001     5 -0.514438\n",
      "4    2001-02-06  0.324134    0.34  2001     6 -0.625540\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.332713    0.35  2009    48 -0.563495\n",
      "407  2009-12-05  0.370253    0.40  2009    49 -0.291984\n",
      "408  2009-12-13  0.517201    0.57  2009    50  0.770822\n",
      "409  2009-12-21  0.353636    0.45  2009    52 -0.412164\n",
      "410  2009-12-29  0.261079    0.00  2009    53 -1.081585\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 4\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 6\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 7\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 6\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_tg_16w_3', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_rr_24w_1', 'cyclostationary_mean_tg_16w_1', 'cyclostationary_mean_tg_16w_0', 'cyclostationary_mean_tg_16w_8', 'cyclostationary_mean_tg_12w_4', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_tg_8w_5', 'cyclostationary_mean_tg_8w_2', 'cyclostationary_mean_tg_12w_1', 'cyclostationary_mean_rr_12w_0', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_tg_12w_0', 'cyclostationary_mean_tg_16w_6', 'cyclostationary_mean_tg_12w_5'], \n",
      "\n",
      "validation score: 0.3761986915518478, \n",
      "\n",
      "number of selected features: 20\n",
      "\n",
      "Full model and selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.3281476990638873, test score: -0.8917259772976176\n",
      "Aggregate regression train score with FS: 0.2637015197753546, test score: 0.0547275527786667\n",
      "\n",
      "Full model and best 5 selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.3281476990638873, test score: -0.8917259772976176\n",
      "Aggregate regression train score with FS: 0.21674247078919995, test score: 0.20390423793559653\n",
      "----- MI Scores -----\n",
      "[(0, 0.1233172834270275), (7, 0.11925446005307141), (5, 0.11429640516876576), (3, 0.10839192158463667), (8, 0.10397460958719837), (1, 0.10247714968806099), (2, 0.09513356575733153), (6, 0.0854421903059367), (11, 0.08419891406662146), (4, 0.08052176641110485), (10, 0.07931849119089665), (14, 0.07712008275236602), (44, 0.06849890021359188), (45, 0.06842462865595438), (12, 0.0624493611733322), (43, 0.061138128729906156), (18, 0.0541002468062679), (41, 0.04978620899883007), (46, 0.04938930727611444), (37, 0.04513908122631465), (25, 0.042000102589973554), (9, 0.041905160553517715), (13, 0.04075164347350076), (40, 0.03375222665168136), (38, 0.03366189924529926), (26, 0.03215149480826468), (42, 0.031252692960708414), (47, 0.02756612860711409), (19, 0.02626414242665474), (24, 0.021788321224037514), (17, 0.021397177752193127), (51, 0.019712095569191318), (50, 0.017996597853011345), (29, 0.017804654115437146), (33, 0.017273982036522778), (48, 0.016090289871205584), (49, 0.015432466829295709), (34, 0.013777851161168971), (22, 0.011143406803733038), (27, 0.010554288371655113), (35, 0.009481103488363257), (16, 0.008753686621271902), (15, 0.00834565549052766), (28, 0.006298198959056755), (20, 0.006163829033533268), (21, 0.005456890356179449), (36, 0.0022665275452120395), (30, -0.0004505725576902776), (32, -0.0013820670070942521), (23, -0.002147264619969846), (39, -0.005016984770803921), (31, -0.006762843222331876)]\n",
      "Best MI score: 0.1233172834270275\n",
      "Adding first best original feature: 0\n",
      "CMI: 0.004543104182696295\n",
      "CMI: 0.0021519894117754124\n",
      "CMI: 0.004261755704103393\n",
      "CMI: 0.01703074557484377\n",
      "CMI: 0.013273817049861997\n",
      "CMI: 0.02997244107067401\n",
      "CMI: 0.020362532670275407\n",
      "CMI: 0.03464001444320386\n",
      "CMI: 0.014964516543690548\n",
      "CMI: 0.005164152584752862\n",
      "CMI: 0.002274079728513567\n",
      "CMI: 0.0028850784639677107\n",
      "Highest CMI score: 0.03464001444320386\n",
      "Adding original feature: 45\n",
      "CMI: 0.007655272154292098\n",
      "CMI: 0.003154963910593084\n",
      "CMI: 0.007345252683788661\n",
      "CMI: 0.005906358169694703\n",
      "Highest CMI score: 0.007655272154292098\n",
      "Adding original feature: 1\n",
      "Highest CMI score: -3.514475417842888e-05\n",
      "\n",
      "[0, 45, 1]\n",
      "\n",
      "\n",
      "Full model and selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.3281476990638873, test score: -0.8917259772976176\n",
      "Aggregate regression train score with FS: 0.18673632578571386, test score: 0.16805571817724307\n",
      "\n",
      "Full model and best 5 selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.3281476990638873, test score: -0.8917259772976176\n",
      "Aggregate regression train score with FS: 0.18673632578571386, test score: 0.16805571817724307\n"
     ]
    }
   ],
   "source": [
    "### BOTH\n",
    "#basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona','Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n",
    "basins = ['Piemonte_Nord','Piemonte_Sud','Adda','Dora','Ticino']\n",
    "path_target = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/csv_VHI/'\n",
    "path_features='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/'\n",
    "\n",
    "for basin in basins:\n",
    "    print('####################' + basin + '####################')\n",
    "\n",
    "    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', path=path_target+basin+'.csv')\n",
    "\n",
    "    eps = 0.001\n",
    "    actual_path = path_features+basin+'_aggreg.csv'\n",
    "        \n",
    "    output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg', \n",
    "                                                                             'cyclostationary_mean_tg_1w',\n",
    "                                                                             'cyclostationary_mean_tg_4w', \n",
    "                                                                             'cyclostationary_mean_tg_8w',\n",
    "                                                                             'cyclostationary_mean_tg_12w', \n",
    "                                                                             'cyclostationary_mean_tg_16w',\n",
    "                                                                             'cyclostationary_mean_tg_24w',\n",
    "                                                                             'cyclostationary_mean_rr', \n",
    "                                                                             'cyclostationary_mean_rr_1w',\n",
    "                                                                             'cyclostationary_mean_rr_4w', \n",
    "                                                                             'cyclostationary_mean_rr_8w',\n",
    "                                                                             'cyclostationary_mean_rr_12w', \n",
    "                                                                             'cyclostationary_mean_rr_16w',\n",
    "                                                                             'cyclostationary_mean_rr_24w'\n",
    "                                                                            ],\n",
    "                                                                       target_df_trainVal, eps=eps,\n",
    "                                                                       max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "        \n",
    "    selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, min(50,aggregate_trainVal.shape[1]-1), 228)\n",
    "\n",
    "    print('\\nFull model and selected features with wrapper\\n')\n",
    "    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n",
    "    \n",
    "    print('\\nFull model and best 5 selected features with wrapper\\n')\n",
    "    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n",
    "    \n",
    "    res = {\n",
    "            \"delta\" : [], \n",
    "            \"numSelected\" : [], \n",
    "            \"selectedFeatures\" : [] \n",
    "        }\n",
    "        \n",
    "    res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "        \n",
    "    selectedFeatures='selectedFeatures'\n",
    "    print(f'\\n{res[selectedFeatures]}\\n')\n",
    "    selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n",
    "    \n",
    "    print('\\nFull model and selected features with CMI\\n')\n",
    "    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n",
    "    \n",
    "    print('\\nFull model and best 5 selected features with CMI\\n')\n",
    "    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42543283",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Only snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93fbc99f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>mean_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001-01-05</td>\n",
       "      <td>0.278983</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2001</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.146332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001-01-13</td>\n",
       "      <td>0.494910</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.371173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001-01-21</td>\n",
       "      <td>0.496092</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2001</td>\n",
       "      <td>3</td>\n",
       "      <td>0.379474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2001-01-29</td>\n",
       "      <td>0.427992</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2001</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.099118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001-02-06</td>\n",
       "      <td>0.400512</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.292244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>2009-11-27</td>\n",
       "      <td>0.363952</td>\n",
       "      <td>0.37</td>\n",
       "      <td>2009</td>\n",
       "      <td>48</td>\n",
       "      <td>-0.549184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2009-12-05</td>\n",
       "      <td>0.400487</td>\n",
       "      <td>0.40</td>\n",
       "      <td>2009</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.292423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>2009-12-13</td>\n",
       "      <td>0.506771</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2009</td>\n",
       "      <td>50</td>\n",
       "      <td>0.454529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>2009-12-21</td>\n",
       "      <td>0.387530</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2009</td>\n",
       "      <td>52</td>\n",
       "      <td>-0.383480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>2009-12-29</td>\n",
       "      <td>0.279894</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2009</td>\n",
       "      <td>53</td>\n",
       "      <td>-1.139931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date      mean  median  year  week  mean_std\n",
       "0    2001-01-05  0.278983    0.00  2001     1 -1.146332\n",
       "1    2001-01-13  0.494910    0.51  2001     2  0.371173\n",
       "2    2001-01-21  0.496092    0.51  2001     3  0.379474\n",
       "3    2001-01-29  0.427992    0.43  2001     5 -0.099118\n",
       "4    2001-02-06  0.400512    0.41  2001     6 -0.292244\n",
       "..          ...       ...     ...   ...   ...       ...\n",
       "406  2009-11-27  0.363952    0.37  2009    48 -0.549184\n",
       "407  2009-12-05  0.400487    0.40  2009    49 -0.292423\n",
       "408  2009-12-13  0.506771    0.52  2009    50  0.454529\n",
       "409  2009-12-21  0.387530    0.53  2009    52 -0.383480\n",
       "410  2009-12-29  0.279894    0.27  2009    53 -1.139931\n",
       "\n",
       "[411 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae78ebf1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################Piemonte_Nord####################\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278983    0.00  2001     1 -1.146332\n",
      "1    2001-01-13  0.494910    0.51  2001     2  0.371173\n",
      "2    2001-01-21  0.496092    0.51  2001     3  0.379474\n",
      "3    2001-01-29  0.427992    0.43  2001     5 -0.099118\n",
      "4    2001-02-06  0.400512    0.41  2001     6 -0.292244\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.363952    0.37  2009    48 -0.549184\n",
      "407  2009-12-05  0.400487    0.40  2009    49 -0.292423\n",
      "408  2009-12-13  0.506771    0.52  2009    50  0.454529\n",
      "409  2009-12-21  0.387530    0.53  2009    52 -0.383480\n",
      "410  2009-12-29  0.279894    0.27  2009    53 -1.139931\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 19\n",
      "\n",
      "Number of aggregated features: 8\n",
      "\n",
      "Number of features: 19\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "Number of features: 19\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "Number of features: 19\n",
      "\n",
      "Number of aggregated features: 8\n",
      "\n",
      "Number of features: 19\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "Number of features: 19\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "Number of features: 19\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_HS_8w_0', 'cyclostationary_mean_HS_12w_0', 'cyclostationary_mean_HS_16w_0', 'cyclostationary_mean_HS_1w_8', 'cyclostationary_mean_HS_8w_4', 'cyclostationary_mean_HS_4w_8', 'cyclostationary_mean_HS_24w_8', 'cyclostationary_mean_HS_16w_8', 'cyclostationary_mean_HS_24w_6', 'cyclostationary_mean_HS_24w_3', 'cyclostationary_mean_HS_12w_8', 'cyclostationary_mean_HS_24w_2', 'cyclostationary_mean_HS_8w_2', 'cyclostationary_mean_HS_24w_7', 'cyclostationary_mean_HS_16w_1'], \n",
      "\n",
      "validation score: 0.08955116637983551, \n",
      "\n",
      "number of selected features: 15\n",
      "\n",
      "Full model and selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.24778628823956994, test score: -2.689343854308359\n",
      "Aggregate regression train score with FS: 0.11865749993744013, test score: -0.5750169170824031\n",
      "\n",
      "Full model and best 5 selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.24778628823956994, test score: -2.689343854308359\n",
      "Aggregate regression train score with FS: 0.043999074344784006, test score: -0.11820901146291463\n",
      "----- MI Scores -----\n",
      "[(11, 0.14365568674798185), (3, 0.12707167703374447), (20, 0.11924120009065939), (29, 0.10386616017765742), (4, 0.08815210492609978), (9, 0.08421766766705253), (12, 0.08017755072869114), (21, 0.07887559002935869), (25, 0.07230763328254906), (37, 0.07175160335715061), (1, 0.07097117401022295), (6, 0.06896937166747809), (5, 0.06722239493185501), (19, 0.06711570671564134), (46, 0.06684685067124178), (30, 0.06676131832852844), (16, 0.06564193252390595), (28, 0.06339792549049147), (49, 0.06325572461196131), (2, 0.06084707594618672), (40, 0.05572225545712403), (51, 0.05553467472078985), (35, 0.05471875019643049), (36, 0.0538586201528578), (14, 0.05316168431014154), (7, 0.05239363816443657), (22, 0.052101834630313426), (8, 0.05151137304722634), (27, 0.05130000251969085), (0, 0.0488780203207252), (13, 0.04830462249122027), (38, 0.04793981991147005), (32, 0.04766385218192909), (10, 0.04734743200045985), (42, 0.04494989422529049), (39, 0.04484842949805793), (23, 0.043969559414108406), (44, 0.04366572653572677), (18, 0.042674479267682044), (24, 0.042222084043591686), (17, 0.04177446389646862), (15, 0.0391738039383144), (31, 0.03727095225160016), (52, 0.036391815069420005), (41, 0.03431157492502094), (33, 0.03365651189327741), (45, 0.032848634450730524), (57, 0.027072464898280923), (47, 0.025327502533424428), (55, 0.024165235405454788), (54, 0.02186275909877837), (56, 0.02140643122244307), (58, 0.020897213801472008), (48, 0.020118760466851935), (53, 0.01786261930712353), (43, 0.013742511765054836), (26, 0.0126790850440128), (50, 0.008762775300246037), (60, 0.007236713664429285), (34, 0.006814825420423811), (59, 0.004207936361840886)]\n",
      "Best MI score: 0.14365568674798185\n",
      "Adding first best original feature: 11\n",
      "CMI: 0.011296266458218795\n",
      "CMI: 0.02037953481656765\n",
      "CMI: 0.003774628493414117\n",
      "CMI: 0.007439559217372271\n",
      "CMI: 0.00779934317325387\n",
      "CMI: 0.015053644656301657\n",
      "CMI: 0.00616973452430683\n",
      "CMI: 0.008406423302366406\n",
      "CMI: 0.005763240427093752\n",
      "CMI: 0.009979218527449846\n",
      "CMI: 0.019734975716248104\n",
      "CMI: 0.001889552623933033\n",
      "CMI: 0.02442302574264904\n",
      "CMI: 0.005299473820312761\n",
      "CMI: 0.033428150745606566\n",
      "CMI: 0.009986391723459914\n",
      "CMI: 0.0030287726530822123\n",
      "CMI: 0.0012919678615237462\n",
      "Highest CMI score: 0.033428150745606566\n",
      "Adding original feature: 46\n",
      "CMI: 0.003694739775421646\n",
      "CMI: 0.03626357951368375\n",
      "CMI: 0.007270920418231658\n",
      "CMI: 0.011574596387607383\n",
      "CMI: 6.433520253321112e-05\n",
      "CMI: 0.007048771786939301\n",
      "CMI: 0.007464125192478466\n",
      "CMI: 0.0014592366545899127\n",
      "CMI: 0.007064492608220868\n",
      "CMI: 0.006642335879107064\n",
      "CMI: 0.000767332417118155\n",
      "Highest CMI score: 0.03626357951368375\n",
      "Adding original feature: 3\n",
      "Highest CMI score: -0.0017221967407159977\n",
      "\n",
      "[11, 46, 3]\n",
      "\n",
      "\n",
      "Full model and selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.24778628823956994, test score: -2.689343854308359\n",
      "Aggregate regression train score with FS: 0.001844373907331942, test score: -0.0001760536202353169\n",
      "\n",
      "Full model and best 5 selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.24778628823956994, test score: -2.689343854308359\n",
      "Aggregate regression train score with FS: 0.001844373907331942, test score: -0.0001760536202353169\n",
      "####################Piemonte_Sud####################\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278060    0.09  2001     1 -0.967137\n",
      "1    2001-01-13  0.445159    0.48  2001     2  0.070382\n",
      "2    2001-01-21  0.488982    0.52  2001     3  0.342478\n",
      "3    2001-01-29  0.362487    0.37  2001     5 -0.442927\n",
      "4    2001-02-06  0.430732    0.45  2001     6 -0.019192\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.430379    0.44  2009    48 -0.021388\n",
      "407  2009-12-05  0.419919    0.43  2009    49 -0.086330\n",
      "408  2009-12-13  0.526648    0.55  2009    50  0.576347\n",
      "409  2009-12-21  0.457440    0.61  2009    52  0.146632\n",
      "410  2009-12-29  0.301938    0.38  2009    53 -0.818877\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 17\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 17\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 17\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 17\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 17\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 17\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 17\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_HS_8w_7', 'cyclostationary_mean_HS_12w_7', 'cyclostationary_mean_HS_24w_4', 'cyclostationary_mean_HS_16w_4', 'cyclostationary_mean_HS_7', 'cyclostationary_mean_HS_4w_7', 'cyclostationary_mean_HS_1w_7', 'cyclostationary_mean_HS_4', 'cyclostationary_mean_HS_24w_2', 'cyclostationary_mean_HS_16w_13', 'cyclostationary_mean_HS_24w_14', 'cyclostationary_mean_HS_24w_9', 'cyclostationary_mean_HS_24w_11', 'cyclostationary_mean_HS_24w_5', 'cyclostationary_mean_HS_1w_5', 'cyclostationary_mean_HS_8w_3', 'cyclostationary_mean_HS_16w_2', 'cyclostationary_mean_HS_24w_10', 'cyclostationary_mean_HS_8', 'cyclostationary_mean_HS_11', 'cyclostationary_mean_HS_16w_14', 'cyclostationary_mean_HS_12w_1', 'cyclostationary_mean_HS_12w_9', 'cyclostationary_mean_HS_8w_11', 'cyclostationary_mean_HS_16w_12'], \n",
      "\n",
      "validation score: 0.004361915313129683, \n",
      "\n",
      "number of selected features: 25\n",
      "\n",
      "Full model and selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.3770250336505937, test score: -1.953505116445022\n",
      "Aggregate regression train score with FS: 0.15314387763330584, test score: -0.8255923303618706\n",
      "\n",
      "Full model and best 5 selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.3770250336505937, test score: -1.953505116445022\n",
      "Aggregate regression train score with FS: 0.020667753223425178, test score: -0.18498465147262877\n",
      "----- MI Scores -----\n",
      "[(17, 0.21875226536978648), (2, 0.21374091908173745), (1, 0.204448990836909), (11, 0.19693555074170313), (6, 0.19190146047541784), (12, 0.19002417301180852), (21, 0.18690698438108377), (8, 0.17869414642513945), (26, 0.17202841494176535), (32, 0.17151697582329645), (15, 0.1682074756660106), (16, 0.16641564314994703), (25, 0.16597117606947093), (0, 0.16085002910850713), (23, 0.15868663084149667), (10, 0.15784592045893767), (27, 0.15376979525583487), (18, 0.1520437041514943), (30, 0.14915615372570076), (40, 0.14019126692174005), (36, 0.13839916627464227), (42, 0.1371435997227461), (43, 0.13707147968900438), (13, 0.13702042546191306), (47, 0.13316765182878312), (3, 0.13310500790999882), (41, 0.13304257366874808), (31, 0.12931633116766195), (20, 0.12657415886561443), (14, 0.1265302792031968), (28, 0.12652545717300986), (57, 0.12587216859212413), (5, 0.1243476035411387), (29, 0.1236615526708375), (38, 0.11915086698693005), (55, 0.11793193170333696), (46, 0.11480374937639444), (74, 0.11224758237810327), (51, 0.10927574316136861), (58, 0.10510034364659328), (33, 0.10446619967030434), (44, 0.10422313178600479), (59, 0.10394424181729926), (72, 0.10248034998366963), (70, 0.10133448932189229), (71, 0.09855406697178773), (56, 0.09792035504033657), (39, 0.09756281720011716), (86, 0.09653883649821722), (77, 0.09589445826473077), (65, 0.09524095881415094), (61, 0.09515527385837713), (102, 0.09375855796034199), (85, 0.09253049468825796), (9, 0.09208386333208374), (54, 0.0918201587029308), (88, 0.0917084279009591), (89, 0.09071123191917115), (62, 0.08993933409441399), (63, 0.08969735136639347), (7, 0.08874145898956463), (49, 0.0874558662257424), (100, 0.08580104266207972), (24, 0.08562337282731507), (80, 0.08536349885044411), (50, 0.08465990526351332), (66, 0.08322293690376814), (69, 0.08278323806221637), (76, 0.08220634500797763), (84, 0.08117395444338327), (35, 0.08077267528901921), (101, 0.07919300595561575), (87, 0.07837052039638939), (73, 0.07814969234350179), (4, 0.07799241874989367), (45, 0.07777429303140802), (53, 0.07624633590288496), (75, 0.07542571668643637), (60, 0.0750814979413729), (34, 0.07479297535144605), (48, 0.07259747134092599), (78, 0.06811385924996534), (91, 0.06811192890026248), (92, 0.06784888773167011), (81, 0.0671236556520782), (37, 0.06510793043546502), (19, 0.06498859667096661), (22, 0.06304211323875665), (68, 0.06201394989560394), (93, 0.05825673990556566), (82, 0.053621285436937394), (67, 0.04789027369847377), (97, 0.047867360230184786), (64, 0.046154901479376), (52, 0.04460220694951919), (79, 0.04298646266243172), (96, 0.042565152468566736), (83, 0.04188066031248396), (104, 0.035876432006179765), (98, 0.033438077465131284), (95, 0.026692474094076452), (90, 0.018914761506734334), (99, 0.018180395602473254), (94, 0.01004816124869316), (103, -0.0004261176271423644)]\n",
      "Best MI score: 0.21875226536978648\n",
      "Adding first best original feature: 17\n",
      "CMI: 0.01752263774318924\n",
      "CMI: 0.028501857220909088\n",
      "CMI: 0.012014045342493729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.011356913637001947\n",
      "CMI: 0.0019027572668207926\n",
      "CMI: 0.00454805237325584\n",
      "CMI: 0.007699514695016285\n",
      "CMI: 0.0030619277641947273\n",
      "CMI: 0.015550076637784183\n",
      "CMI: 0.006343738537786275\n",
      "CMI: 0.012562477777008474\n",
      "Highest CMI score: 0.028501857220909088\n",
      "Adding original feature: 2\n",
      "CMI: 0.004557471001971958\n",
      "CMI: 0.01758707125885106\n",
      "CMI: 0.02308383529125957\n",
      "CMI: 0.0010671452568803141\n",
      "CMI: 0.012196243606450163\n",
      "CMI: 0.004665432531411051\n",
      "CMI: 0.01134518869498008\n",
      "CMI: 0.0031965860459245987\n",
      "CMI: 0.005929244487621166\n",
      "Highest CMI score: 0.02308383529125957\n",
      "Adding original feature: 10\n",
      "CMI: 0.007671947257277323\n",
      "CMI: 0.0032716760946586154\n",
      "CMI: 0.0011927143944516216\n",
      "CMI: 0.006255668852313323\n",
      "Highest CMI score: 0.007671947257277323\n",
      "Adding original feature: 1\n",
      "CMI: 0.001578439743518234\n",
      "CMI: 0.001165761724650216\n",
      "Highest CMI score: 0.001578439743518234\n",
      "Adding original feature: 25\n",
      "CMI: 0.0004715167352646876\n",
      "CMI: 0.007536217513409493\n",
      "CMI: 0.001954224168207841\n",
      "Highest CMI score: 0.007536217513409493\n",
      "Adding original feature: 32\n",
      "CMI: 0.0010871740382191741\n",
      "CMI: 0.002506928888652449\n",
      "Highest CMI score: 0.002506928888652449\n",
      "Adding original feature: 42\n",
      "Highest CMI score: -7.700073932648266e-05\n",
      "\n",
      "[17, 2, 10, 1, 25, 32, 42]\n",
      "\n",
      "\n",
      "Full model and selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.3770250336505937, test score: -1.953505116445022\n",
      "Aggregate regression train score with FS: 0.04291099248759678, test score: -0.08638529221689217\n",
      "\n",
      "Full model and best 5 selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.3770250336505937, test score: -1.953505116445022\n",
      "Aggregate regression train score with FS: 0.021918905796166288, test score: -0.04514199582686307\n",
      "####################Adda####################\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.039373    0.00  2001     1 -2.546951\n",
      "1    2001-01-13  0.380618    0.43  2001     2 -0.277191\n",
      "2    2001-01-21  0.341985    0.38  2001     3 -0.534156\n",
      "3    2001-01-29  0.322044    0.35  2001     5 -0.666789\n",
      "4    2001-02-06  0.354954    0.40  2001     6 -0.447894\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.382706    0.40  2009    48 -0.263306\n",
      "407  2009-12-05  0.409921    0.46  2009    49 -0.082282\n",
      "408  2009-12-13  0.472087    0.53  2009    50  0.331204\n",
      "409  2009-12-21  0.324728    0.00  2009    52 -0.648940\n",
      "410  2009-12-29  0.086512    0.00  2009    53 -2.233412\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 5\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 5\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 5\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 5\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 5\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 5\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 5\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_HS_0', 'cyclostationary_mean_HS_1', 'cyclostationary_mean_HS_3', 'cyclostationary_mean_HS_12w_3', 'cyclostationary_mean_HS_16w_3', 'cyclostationary_mean_HS_16w_0', 'cyclostationary_mean_HS_12w_1', 'cyclostationary_mean_HS_16w_1', 'cyclostationary_mean_HS_4', 'cyclostationary_mean_HS_16w_4', 'cyclostationary_mean_HS_12w_4', 'cyclostationary_mean_HS_24w_1', 'cyclostationary_mean_HS_24w_4', 'cyclostationary_mean_HS_24w_3'], \n",
      "\n",
      "validation score: 0.05649754003106533, \n",
      "\n",
      "number of selected features: 14\n",
      "\n",
      "Full model and selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.13460269043706208, test score: -0.5349210034888157\n",
      "Aggregate regression train score with FS: 0.10404515079017462, test score: -0.4477186238248607\n",
      "\n",
      "Full model and best 5 selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.13460269043706208, test score: -0.5349210034888157\n",
      "Aggregate regression train score with FS: 0.01752077256424278, test score: -0.023009357490666238\n",
      "----- MI Scores -----\n",
      "[(5, 0.1120418898875603), (6, 0.10990196790565648), (0, 0.10459086562810836), (1, 0.10404777033279888), (11, 0.09776607701396299), (3, 0.09454687685816096), (14, 0.09145332826815922), (9, 0.08920613917368424), (4, 0.08519553182985487), (8, 0.08202005074653325), (2, 0.07703198469189082), (33, 0.07079773979968454), (7, 0.07079179965435174), (13, 0.0657457176995818), (10, 0.06317660052684479), (16, 0.06255632373955927), (30, 0.06078284111641435), (12, 0.05430803998804412), (32, 0.05279706167142524), (34, 0.05085195352532044), (24, 0.049909026116643794), (31, 0.041219352914703605), (21, 0.04029166703578293), (18, 0.03492701282738845), (15, 0.03253504391273119), (19, 0.029041484075160454), (17, 0.028611534118950267), (29, 0.02605251014587864), (27, 0.024214973770620533), (25, 0.023876035259012742), (20, 0.022006359328764356), (22, 0.02078180417297369), (26, 0.01768518563017374), (23, 0.014959033381815723), (28, 0.009249234989614753)]\n",
      "Best MI score: 0.1120418898875603\n",
      "Adding first best original feature: 5\n",
      "CMI: 0.011979185818477261\n",
      "CMI: 0.024885624340019744\n",
      "CMI: 0.006655247093021455\n",
      "CMI: 0.009170149898236224\n",
      "CMI: 0.006992565234480469\n",
      "CMI: 0.01904812510891142\n",
      "CMI: 0.004821626936228118\n",
      "CMI: 0.011484909611145927\n",
      "CMI: 0.0027762093924971892\n",
      "CMI: 0.00040543660456733577\n",
      "CMI: 0.009875360734675445\n",
      "CMI: 0.009800178663908449\n",
      "CMI: 0.002381537036746789\n",
      "CMI: 0.004846958120121522\n",
      "CMI: 0.0022332504054448643\n",
      "CMI: 0.001096802804144717\n",
      "CMI: 0.011465976905921174\n",
      "CMI: 0.010275445384136397\n",
      "CMI: 0.0165379024993806\n",
      "CMI: 0.025169825755390077\n",
      "CMI: 0.04095942297279871\n",
      "CMI: 0.01769295961381541\n",
      "Highest CMI score: 0.04095942297279871\n",
      "Adding original feature: 33\n",
      "CMI: 0.008278799927573743\n",
      "CMI: 3.487415348013556e-05\n",
      "CMI: 0.018443357234473767\n",
      "CMI: 0.0019445980890022974\n",
      "CMI: 0.0009279462144937412\n",
      "CMI: 0.002005176648920609\n",
      "Highest CMI score: 0.018443357234473767\n",
      "Adding original feature: 11\n",
      "CMI: 0.005730801233897187\n",
      "Highest CMI score: 0.005730801233897187\n",
      "Adding original feature: 34\n",
      "CMI: 0.0045513362672057744\n",
      "CMI: 0.002972012729034107\n",
      "CMI: 0.006890316968084287\n",
      "CMI: 0.002107333925337518\n",
      "CMI: 0.0024081276520350747\n",
      "Highest CMI score: 0.006890316968084287\n",
      "Adding original feature: 22\n",
      "CMI: 0.0017847289910831732\n",
      "CMI: 0.0016564837974707702\n",
      "CMI: 0.0006283958124460032\n",
      "CMI: 0.0008101665211351916\n",
      "Highest CMI score: 0.0017847289910831732\n",
      "Adding original feature: 8\n",
      "CMI: 0.0006639060691649157\n",
      "CMI: 0.000880207103883951\n",
      "Highest CMI score: 0.000880207103883951\n",
      "Adding original feature: 26\n",
      "Highest CMI score: -0.002244961899764253\n",
      "\n",
      "[5, 33, 11, 34, 22, 8, 26]\n",
      "\n",
      "\n",
      "Full model and selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.13460269043706208, test score: -0.5349210034888157\n",
      "Aggregate regression train score with FS: 0.03977104784320762, test score: -0.14035534294712426\n",
      "\n",
      "Full model and best 5 selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.13460269043706208, test score: -0.5349210034888157\n",
      "Aggregate regression train score with FS: 0.03563927668653921, test score: -0.17599988034959568\n",
      "####################Dora####################\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.010645    0.00  2001     1 -2.129508\n",
      "1    2001-01-13  0.206769    0.00  2001     2 -0.927136\n",
      "2    2001-01-21  0.267313    0.00  2001     3 -0.555958\n",
      "3    2001-01-29  0.240836    0.20  2001     5 -0.718282\n",
      "4    2001-02-06  0.193417    0.15  2001     6 -1.008995\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.230073    0.25  2009    48 -0.784269\n",
      "407  2009-12-05  0.243632    0.24  2009    49 -0.701139\n",
      "408  2009-12-13  0.251111    0.00  2009    50 -0.655289\n",
      "409  2009-12-21  0.099246    0.00  2009    52 -1.586325\n",
      "410  2009-12-29  0.064990    0.00  2009    53 -1.796340\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 4\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 4\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 4\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 4\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 4\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 4\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 4\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_HS_8w_0', 'cyclostationary_mean_HS_4w_0', 'cyclostationary_mean_HS_12w_1', 'cyclostationary_mean_HS_12w_0', 'cyclostationary_mean_HS_0', 'cyclostationary_mean_HS_1w_0'], \n",
      "\n",
      "validation score: -0.056049361500471795, \n",
      "\n",
      "number of selected features: 6\n",
      "\n",
      "Full model and selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.06386299885719904, test score: 0.051307795785165866\n",
      "Aggregate regression train score with FS: 0.009704925782701324, test score: -0.09222911618889884\n",
      "\n",
      "Full model and best 5 selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.06386299885719904, test score: 0.051307795785165866\n",
      "Aggregate regression train score with FS: 0.009044621869447433, test score: -0.09350209584054148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- MI Scores -----\n",
      "[(0, 0.2952953612194227), (4, 0.2800096649013969), (1, 0.2693167342841738), (3, 0.2603664794085629), (6, 0.25701446205886175), (7, 0.23860945539357833), (10, 0.19815668502907816), (9, 0.18800812404496547), (2, 0.17546552232719306), (8, 0.17113211944503068), (5, 0.1680202883412306), (13, 0.1438600954804504), (12, 0.12664648185843275), (11, 0.12456958028513011), (16, 0.11228971442717278), (15, 0.0932113048755538), (14, 0.08664117588742813), (19, 0.06539741683854618), (18, 0.06531736410747108), (17, 0.04915301449338825), (20, 0.043050184000153854)]\n",
      "Best MI score: 0.2952953612194227\n",
      "Adding first best original feature: 0\n",
      "CMI: 0.024710538457889453\n",
      "CMI: 0.02686732677925613\n",
      "CMI: 0.016773178140698897\n",
      "CMI: 0.024457150389453453\n",
      "Highest CMI score: 0.02686732677925613\n",
      "Adding original feature: 4\n",
      "CMI: 0.01050465643320636\n",
      "Highest CMI score: 0.01050465643320636\n",
      "Adding original feature: 6\n",
      "Highest CMI score: -0.0036882955846470056\n",
      "\n",
      "[0, 4, 6]\n",
      "\n",
      "\n",
      "Full model and selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.06386299885719904, test score: 0.051307795785165866\n",
      "Aggregate regression train score with FS: 0.007645219292488514, test score: -0.056686885007104504\n",
      "\n",
      "Full model and best 5 selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.06386299885719904, test score: 0.051307795785165866\n",
      "Aggregate regression train score with FS: 0.007645219292488514, test score: -0.056686885007104504\n",
      "####################Ticino####################\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.264043    0.00  2001     1 -1.060146\n",
      "1    2001-01-13  0.354618    0.39  2001     2 -0.405065\n",
      "2    2001-01-21  0.427990    0.47  2001     3  0.125603\n",
      "3    2001-01-29  0.339495    0.35  2001     5 -0.514438\n",
      "4    2001-02-06  0.324134    0.34  2001     6 -0.625540\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.332713    0.35  2009    48 -0.563495\n",
      "407  2009-12-05  0.370253    0.40  2009    49 -0.291984\n",
      "408  2009-12-13  0.517201    0.57  2009    50  0.770822\n",
      "409  2009-12-21  0.353636    0.45  2009    52 -0.412164\n",
      "410  2009-12-29  0.261079    0.00  2009    53 -1.081585\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 6\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 6\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 6\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 6\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 6\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 6\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 6\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_HS_12w_1', 'cyclostationary_mean_HS_24w_0', 'cyclostationary_mean_HS_1w_1', 'cyclostationary_mean_HS_16w_0', 'cyclostationary_mean_HS_12w_0', 'cyclostationary_mean_HS_16w_1'], \n",
      "\n",
      "validation score: 0.021790796211229035, \n",
      "\n",
      "number of selected features: 6\n",
      "\n",
      "Full model and selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.07253937190563253, test score: -0.22757590968705665\n",
      "Aggregate regression train score with FS: 0.06109340207648162, test score: -0.22556755398967732\n",
      "\n",
      "Full model and best 5 selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.07253937190563253, test score: -0.22757590968705665\n",
      "Aggregate regression train score with FS: 0.06047274802407099, test score: -0.2180814712581658\n",
      "----- MI Scores -----\n",
      "[(0, 0.08715733872819754), (4, 0.06895004167102578), (2, 0.0623811389797085), (6, 0.03642580400780875), (8, 0.034449479536108156), (10, 0.02689195320563331), (3, 0.021212172668393092), (12, 0.019711741533919656), (9, 0.010430361801599335), (1, 0.00822058379684055), (5, 0.006261744310422687), (7, 0.005629310262079075), (11, 0.002927641603718372), (13, -4.354473501220265e-05)]\n",
      "Best MI score: 0.08715733872819754\n",
      "Adding first best original feature: 0\n",
      "CMI: 0.004690903792351653\n",
      "CMI: 0.01726031060124364\n",
      "Highest CMI score: 0.01726031060124364\n",
      "Adding original feature: 13\n",
      "Highest CMI score: -0.0002202064810226667\n",
      "\n",
      "[0, 13]\n",
      "\n",
      "\n",
      "Full model and selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.07253937190563253, test score: -0.22757590968705665\n",
      "Aggregate regression train score with FS: 0.010465040532001924, test score: -0.0161779792779444\n",
      "\n",
      "Full model and best 5 selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.07253937190563253, test score: -0.22757590968705665\n",
      "Aggregate regression train score with FS: 0.010465040532001924, test score: -0.0161779792779444\n"
     ]
    }
   ],
   "source": [
    "### BOTH\n",
    "#basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona','Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n",
    "basins = ['Piemonte_Nord','Piemonte_Sud','Adda','Dora','Ticino']\n",
    "path_target = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/csv_VHI/'\n",
    "path_features_snow='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/snow_aggreg_ARPA/all_coord/'\n",
    "\n",
    "for basin in basins:\n",
    "    print('####################' + basin + '####################')\n",
    "\n",
    "    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', path=path_target+basin+'.csv')\n",
    "\n",
    "    eps = 0.001\n",
    "    snow_actual_path = path_features_snow+basin+'_snowDepth_aggreg_allCoord.csv'\n",
    "        \n",
    "    output,aggregate_trainVal,aggregate_test = aggregate_unfolded_data(snow_actual_path,['cyclostationary_mean_HS', \n",
    "                                                                             'cyclostationary_mean_HS_1w',\n",
    "                                                                             'cyclostationary_mean_HS_4w', \n",
    "                                                                             'cyclostationary_mean_HS_8w',\n",
    "                                                                             'cyclostationary_mean_HS_12w', \n",
    "                                                                             'cyclostationary_mean_HS_16w',\n",
    "                                                                             'cyclostationary_mean_HS_24w'\n",
    "                                                                            ],\n",
    "                                                                       target_df_trainVal, eps=eps,\n",
    "                                                                       max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "        \n",
    "    selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, min(50,aggregate_trainVal.shape[1]-1), 228)\n",
    "\n",
    "    print('\\nFull model and selected features with wrapper\\n')\n",
    "    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n",
    "    \n",
    "    print('\\nFull model and best 5 selected features with wrapper\\n')\n",
    "    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n",
    "    \n",
    "    res = {\n",
    "            \"delta\" : [], \n",
    "            \"numSelected\" : [], \n",
    "            \"selectedFeatures\" : [] \n",
    "        }\n",
    "        \n",
    "    res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "        \n",
    "    selectedFeatures='selectedFeatures'\n",
    "    print(f'\\n{res[selectedFeatures]}\\n')\n",
    "    selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n",
    "    \n",
    "    print('\\nFull model and selected features with CMI\\n')\n",
    "    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n",
    "    \n",
    "    print('\\nFull model and best 5 selected features with CMI\\n')\n",
    "    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c68be9",
   "metadata": {},
   "source": [
    "## Temp + Prec + Snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "496d4d3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################Piemonte_Nord####################\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278983    0.00  2001     1 -1.146332\n",
      "1    2001-01-13  0.494910    0.51  2001     2  0.371173\n",
      "2    2001-01-21  0.496092    0.51  2001     3  0.379474\n",
      "3    2001-01-29  0.427992    0.43  2001     5 -0.099118\n",
      "4    2001-02-06  0.400512    0.41  2001     6 -0.292244\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.363952    0.37  2009    48 -0.549184\n",
      "407  2009-12-05  0.400487    0.40  2009    49 -0.292423\n",
      "408  2009-12-13  0.506771    0.52  2009    50  0.454529\n",
      "409  2009-12-21  0.387530    0.53  2009    52 -0.383480\n",
      "410  2009-12-29  0.279894    0.27  2009    53 -1.139931\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278983    0.00  2001     1 -1.146332\n",
      "1    2001-01-13  0.494910    0.51  2001     2  0.371173\n",
      "2    2001-01-21  0.496092    0.51  2001     3  0.379474\n",
      "3    2001-01-29  0.427992    0.43  2001     5 -0.099118\n",
      "4    2001-02-06  0.400512    0.41  2001     6 -0.292244\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.363952    0.37  2009    48 -0.549184\n",
      "407  2009-12-05  0.400487    0.40  2009    49 -0.292423\n",
      "408  2009-12-13  0.506771    0.52  2009    50  0.454529\n",
      "409  2009-12-21  0.387530    0.53  2009    52 -0.383480\n",
      "410  2009-12-29  0.279894    0.27  2009    53 -1.139931\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 6\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 7\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 7\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 4\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 89\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 19\n",
      "\n",
      "Number of aggregated features: 8\n",
      "\n",
      "Number of features: 19\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "Number of features: 19\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "Number of features: 19\n",
      "\n",
      "Number of aggregated features: 8\n",
      "\n",
      "Number of features: 19\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "Number of features: 19\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "Number of features: 19\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_rr_4w_0', 'cyclostationary_mean_HS_4w_0', 'cyclostationary_mean_HS_12w_4', 'cyclostationary_mean_HS_24w_2', 'cyclostationary_mean_HS_4w_8', 'cyclostationary_mean_HS_7', 'cyclostationary_mean_HS_24w_7', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_HS_8w_2', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_HS_24w_3', 'cyclostationary_mean_tg_24w_0', 'cyclostationary_mean_rr_8w_1', 'cyclostationary_mean_HS_16w_4', 'cyclostationary_mean_HS_16w_1', 'cyclostationary_mean_HS_1w_8', 'cyclostationary_mean_tg_8w_2', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_tg_24w_1', 'cyclostationary_mean_tg_1w_6', 'cyclostationary_mean_HS_8w_7', 'cyclostationary_mean_tg_4w_4', 'cyclostationary_mean_tg_4w_5', 'cyclostationary_mean_HS_24w_8', 'cyclostationary_mean_HS_12w_1', 'cyclostationary_mean_tg_4w_6', 'cyclostationary_mean_HS_24w_5', 'cyclostationary_mean_HS_24w_4', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_tg_4w_3'], \n",
      "\n",
      "validation score: 0.46858335037256593, \n",
      "\n",
      "number of selected features: 33\n",
      "\n",
      "Full model and selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.4932892593430278, test score: -1.7023041119989988\n",
      "Aggregate regression train score with FS: 0.36482926734754995, test score: -0.17318066541206645\n",
      "\n",
      "Full model and best 5 selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.4932892593430278, test score: -1.7023041119989988\n",
      "Aggregate regression train score with FS: 0.2455153112885584, test score: -0.1020107219606583\n",
      "----- MI Scores -----\n",
      "[(11, 0.14365568674798185), (64, 0.13910140472027976), (3, 0.12707167703374447), (20, 0.11924120009065939), (63, 0.11677792896815278), (70, 0.11242702441643683), (73, 0.1099945104404797), (29, 0.10386616017765742), (62, 0.09364422479893687), (66, 0.09137391410745542), (72, 0.09033835395319534), (61, 0.08989863929473699), (4, 0.08815210492609978), (9, 0.08421766766705253), (12, 0.08017755072869114), (65, 0.07955295674086828), (21, 0.07887559002935869), (67, 0.07882849186969863), (71, 0.07582271736345429), (25, 0.07230763328254906), (37, 0.07175160335715061), (1, 0.07097117401022295), (6, 0.06896937166747809), (69, 0.06847496241497947), (68, 0.06747165529112577), (5, 0.06722239493185501), (19, 0.06711570671564134), (46, 0.06684685067124178), (30, 0.06676131832852844), (16, 0.06564193252390595), (28, 0.06339792549049147), (49, 0.06325572461196131), (95, 0.0615972198896565), (93, 0.06154299554550257), (2, 0.06084707594618672), (97, 0.05948643955324653), (92, 0.05689324004667617), (40, 0.05572225545712403), (51, 0.05553467472078985), (35, 0.05471875019643049), (36, 0.0538586201528578), (14, 0.05316168431014154), (7, 0.05239363816443657), (22, 0.052101834630313426), (8, 0.05151137304722634), (27, 0.05130000251969085), (82, 0.051278663503039786), (0, 0.0488780203207252), (13, 0.04830462249122027), (38, 0.04793981991147005), (32, 0.04766385218192909), (10, 0.04734743200045985), (80, 0.04640481089462892), (42, 0.04494989422529049), (39, 0.04484842949805793), (23, 0.043969559414108406), (44, 0.04366572653572677), (98, 0.0436171911659015), (84, 0.04298170969016182), (18, 0.042674479267682044), (24, 0.042222084043591686), (17, 0.04177446389646862), (83, 0.04157185322071468), (78, 0.040660866682886404), (91, 0.039899111869824436), (77, 0.03936901892080979), (86, 0.03918432776370937), (15, 0.0391738039383144), (75, 0.03830309893680161), (89, 0.03728355960937508), (31, 0.03727095225160016), (52, 0.036391815069420005), (79, 0.03632912752056667), (41, 0.03431157492502094), (88, 0.03426530035797391), (33, 0.03365651189327741), (90, 0.03311292745027499), (45, 0.032848634450730524), (74, 0.02987115006421647), (81, 0.028820625006538637), (96, 0.02793605401697919), (57, 0.027072464898280923), (47, 0.025327502533424428), (76, 0.025195321247282694), (55, 0.024165235405454788), (54, 0.02186275909877837), (85, 0.021472580302876094), (56, 0.02140643122244307), (87, 0.02120089551670573), (58, 0.020897213801472008), (94, 0.020718823068137063), (48, 0.020118760466851935), (53, 0.01786261930712353), (43, 0.013742511765054836), (26, 0.0126790850440128), (50, 0.008762775300246037), (60, 0.007236713664429285), (34, 0.006814825420423811), (59, 0.004207936361840886)]\n",
      "Best MI score: 0.14365568674798185\n",
      "Adding first best original feature: 11\n",
      "CMI: 0.011296266458218795\n",
      "CMI: 0.02037953481656765\n",
      "CMI: 0.003774628493414117\n",
      "CMI: 0.007439559217372271\n",
      "CMI: 0.00779934317325387\n",
      "CMI: 0.015053644656301657\n",
      "CMI: 0.00616973452430683\n",
      "CMI: 0.008406423302366406\n",
      "CMI: 0.005763240427093752\n",
      "CMI: 0.009979218527449846\n",
      "CMI: 0.019734975716248104\n",
      "CMI: 0.001889552623933033\n",
      "CMI: 0.02442302574264904\n",
      "CMI: 0.005299473820312761\n",
      "CMI: 0.033428150745606566\n",
      "CMI: 0.009986391723459914\n",
      "CMI: 0.0030287726530822123\n",
      "CMI: 0.0012919678615237462\n",
      "CMI: 0.05275051219498511\n",
      "CMI: 0.036765508747547276\n",
      "CMI: 0.056939384709676466\n",
      "CMI: 0.07206180013602545\n",
      "CMI: 0.03230932835784461\n",
      "CMI: 0.03615204046712994\n",
      "CMI: 0.03237666470282527\n",
      "CMI: 0.028542150333380006\n",
      "CMI: 0.022359674611256153\n",
      "CMI: 0.06372572347087224\n",
      "CMI: 0.03314659997323441\n",
      "CMI: 0.0345547673104766\n",
      "CMI: 0.050596802393832074\n",
      "CMI: 0.0036837164383890786\n",
      "CMI: 0.0022630082784881878\n",
      "CMI: 0.0005083414600593195\n",
      "CMI: 0.004556484374973829\n",
      "CMI: 0.004371284428730637\n",
      "CMI: 0.0010437822738474656\n",
      "CMI: 0.007944990338103142\n",
      "CMI: 0.018119852845849244\n",
      "CMI: 0.03588384284573354\n",
      "CMI: 0.019138158008789957\n",
      "CMI: 0.006622320858648362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.0359277462700103\n",
      "CMI: 0.02382045724785256\n",
      "Highest CMI score: 0.07206180013602545\n",
      "Adding original feature: 64\n",
      "CMI: 0.004097826735380533\n",
      "CMI: 0.01382469702219985\n",
      "CMI: 0.022804920088717567\n",
      "CMI: 0.006471799938081668\n",
      "CMI: 0.017340425033274764\n",
      "CMI: 0.005242557232930073\n",
      "CMI: 0.003501818182803096\n",
      "CMI: 0.006798984089691651\n",
      "CMI: 0.004047481105508982\n",
      "CMI: 0.02269412516795624\n",
      "CMI: 0.019974154745878298\n",
      "CMI: 0.0013056142082672195\n",
      "CMI: 0.0012048020924234348\n",
      "CMI: 0.011879228399980096\n",
      "CMI: 0.01618542473647555\n",
      "CMI: 0.004005471289763168\n",
      "CMI: 0.010352518470938599\n",
      "CMI: 0.007789886664297113\n",
      "CMI: 0.002219751359468475\n",
      "CMI: 0.027737780307943105\n",
      "CMI: 0.005804630761545193\n",
      "CMI: 4.868514016087566e-05\n",
      "CMI: 0.011162802289949675\n",
      "CMI: 0.01037660794688236\n",
      "CMI: 0.011205941976104333\n",
      "CMI: 0.007962921859826944\n",
      "CMI: 0.011000460206570528\n",
      "CMI: 0.00042396560488558444\n",
      "CMI: 0.018661556220897435\n",
      "CMI: 0.004118284074363182\n",
      "CMI: 0.0011686348740115593\n",
      "CMI: 0.004816972950345277\n",
      "CMI: 0.019282992570370278\n",
      "CMI: 4.9136954729633864e-05\n",
      "CMI: 0.00465885736684149\n",
      "CMI: 0.0027431567241857635\n",
      "CMI: 0.008032549224010532\n",
      "CMI: 0.010178609470193195\n",
      "CMI: 0.00034242210764129366\n",
      "CMI: 0.001620375210681424\n",
      "CMI: 0.003739287474707531\n",
      "CMI: 0.0037183113941245682\n",
      "CMI: 8.596236787267175e-05\n",
      "CMI: 0.018229167824968084\n",
      "CMI: 0.017158380676383617\n",
      "CMI: 0.01809234672331883\n",
      "CMI: 0.003599065211540464\n",
      "CMI: 0.013567625089492635\n",
      "CMI: 0.004937922626010421\n",
      "CMI: 0.0026792677175080104\n",
      "CMI: 0.005396508901908376\n",
      "CMI: 0.000779672099395945\n",
      "CMI: 0.042475938014151976\n",
      "CMI: 0.034778725098041335\n",
      "CMI: 0.031065972962263155\n",
      "CMI: 0.005706523915757378\n",
      "CMI: 0.04929541340775381\n",
      "Highest CMI score: 0.04929541340775381\n",
      "Adding original feature: 98\n",
      "CMI: 0.0007413284928025066\n",
      "CMI: 0.002601614143678488\n",
      "Highest CMI score: 0.002601614143678488\n",
      "Adding original feature: 20\n",
      "CMI: 0.007148962984180884\n",
      "CMI: 0.0022716020603432696\n",
      "CMI: 0.002527142850938857\n",
      "CMI: 0.004853304337144537\n",
      "CMI: 0.0011156404399346176\n",
      "CMI: 0.0030868129691563606\n",
      "CMI: 0.0043128130746905025\n",
      "CMI: 0.0007694224370691227\n",
      "Highest CMI score: 0.007148962984180884\n",
      "Adding original feature: 3\n",
      "CMI: 0.004810937636133994\n",
      "CMI: 0.0077262671623190005\n",
      "CMI: 0.008513431846496111\n",
      "CMI: 0.00789784017411077\n",
      "CMI: 0.004801757034510079\n",
      "CMI: 0.020571021586108462\n",
      "CMI: 0.004370043626672759\n",
      "CMI: 0.009301753801915835\n",
      "CMI: 0.0034440487584833646\n",
      "CMI: 0.009580182471102316\n",
      "CMI: 0.0027054587520564666\n",
      "CMI: 0.0057401245049161775\n",
      "CMI: 0.005683249401272128\n",
      "CMI: 0.011113175294582556\n",
      "Highest CMI score: 0.020571021586108462\n",
      "Adding original feature: 19\n",
      "CMI: 0.00017009436373638387\n",
      "Highest CMI score: 0.00017009436373638387\n",
      "Adding original feature: 0\n",
      "Highest CMI score: -0.0015244830103585127\n",
      "\n",
      "[11, 64, 98, 20, 3, 19, 0]\n",
      "\n",
      "\n",
      "Full model and selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.4932892593430278, test score: -1.7023041119989988\n",
      "Aggregate regression train score with FS: 0.24975775329561467, test score: 0.06605338551967865\n",
      "\n",
      "Full model and best 5 selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.4932892593430278, test score: -1.7023041119989988\n",
      "Aggregate regression train score with FS: 0.20145893997428155, test score: 0.11343379141885379\n",
      "####################Piemonte_Sud####################\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278060    0.09  2001     1 -0.967137\n",
      "1    2001-01-13  0.445159    0.48  2001     2  0.070382\n",
      "2    2001-01-21  0.488982    0.52  2001     3  0.342478\n",
      "3    2001-01-29  0.362487    0.37  2001     5 -0.442927\n",
      "4    2001-02-06  0.430732    0.45  2001     6 -0.019192\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.430379    0.44  2009    48 -0.021388\n",
      "407  2009-12-05  0.419919    0.43  2009    49 -0.086330\n",
      "408  2009-12-13  0.526648    0.55  2009    50  0.576347\n",
      "409  2009-12-21  0.457440    0.61  2009    52  0.146632\n",
      "410  2009-12-29  0.301938    0.38  2009    53 -0.818877\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278060    0.09  2001     1 -0.967137\n",
      "1    2001-01-13  0.445159    0.48  2001     2  0.070382\n",
      "2    2001-01-21  0.488982    0.52  2001     3  0.342478\n",
      "3    2001-01-29  0.362487    0.37  2001     5 -0.442927\n",
      "4    2001-02-06  0.430732    0.45  2001     6 -0.019192\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.430379    0.44  2009    48 -0.021388\n",
      "407  2009-12-05  0.419919    0.43  2009    49 -0.086330\n",
      "408  2009-12-13  0.526648    0.55  2009    50  0.576347\n",
      "409  2009-12-21  0.457440    0.61  2009    52  0.146632\n",
      "410  2009-12-29  0.301938    0.38  2009    53 -0.818877\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 6\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 10\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 4\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 176\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 17\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 17\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 17\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 17\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 17\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 17\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "Number of features: 17\n",
      "\n",
      "Number of aggregated features: 15\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_2', 'cyclostationary_mean_rr_24w_1', 'cyclostationary_mean_HS_8w_7', 'cyclostationary_mean_rr_1w_4', 'cyclostationary_mean_rr_12w_2', 'cyclostationary_mean_rr_12w_1', 'cyclostationary_mean_rr_3', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_tg_0', 'cyclostationary_mean_tg_1', 'cyclostationary_mean_HS_16w_7', 'cyclostationary_mean_rr_4w_3', 'cyclostationary_mean_rr_0', 'cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_rr_8', 'cyclostationary_mean_tg_24w_5', 'cyclostationary_mean_HS_4', 'cyclostationary_mean_HS_16w_6', 'cyclostationary_mean_tg_24w_2', 'cyclostationary_mean_tg_24w_1', 'cyclostationary_mean_HS_8w_4', 'cyclostationary_mean_tg_16w_2', 'cyclostationary_mean_HS_24w_13', 'cyclostationary_mean_tg_12w_0', 'cyclostationary_mean_HS_16w_5', 'cyclostationary_mean_HS_24w_4', 'cyclostationary_mean_HS_12w_14', 'cyclostationary_mean_tg_24w_4', 'cyclostationary_mean_HS_24w_3', 'cyclostationary_mean_HS_24w_6', 'cyclostationary_mean_HS_16w_3', 'cyclostationary_mean_HS_7', 'cyclostationary_mean_tg_16w_3', 'cyclostationary_mean_tg_16w_4'], \n",
      "\n",
      "validation score: 0.354606049727633, \n",
      "\n",
      "number of selected features: 34\n",
      "\n",
      "Full model and selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.6154950191461779, test score: -2.202700940171159\n",
      "Aggregate regression train score with FS: 0.3685341984540811, test score: -0.10880850585129198\n",
      "\n",
      "Full model and best 5 selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.6154950191461779, test score: -2.202700940171159\n",
      "Aggregate regression train score with FS: 0.22519004605526727, test score: -0.021244711220348655\n",
      "----- MI Scores -----\n",
      "[(17, 0.21875226536978648), (2, 0.21374091908173745), (1, 0.204448990836909), (11, 0.19693555074170313), (6, 0.19190146047541784), (12, 0.19002417301180852), (21, 0.18690698438108377), (8, 0.17869414642513945), (26, 0.17202841494176535), (32, 0.17151697582329645), (15, 0.1682074756660106), (16, 0.16641564314994703), (25, 0.16597117606947093), (0, 0.16085002910850713), (23, 0.15868663084149667), (10, 0.15784592045893767), (27, 0.15376979525583487), (18, 0.1520437041514943), (30, 0.14915615372570076), (40, 0.14019126692174005), (36, 0.13839916627464227), (42, 0.1371435997227461), (43, 0.13707147968900438), (13, 0.13702042546191306), (47, 0.13316765182878312), (3, 0.13310500790999882), (41, 0.13304257366874808), (31, 0.12931633116766195), (20, 0.12657415886561443), (14, 0.1265302792031968), (28, 0.12652545717300986), (57, 0.12587216859212413), (5, 0.1243476035411387), (29, 0.1236615526708375), (38, 0.11915086698693005), (55, 0.11793193170333696), (46, 0.11480374937639444), (74, 0.11224758237810327), (51, 0.10927574316136861), (105, 0.10828140105633417), (147, 0.10540351107087807), (58, 0.10510034364659328), (33, 0.10446619967030434), (44, 0.10422313178600479), (59, 0.10394424181729926), (108, 0.10360024919751139), (72, 0.10248034998366963), (70, 0.10133448932189229), (71, 0.09855406697178773), (56, 0.09792035504033657), (39, 0.09756281720011716), (106, 0.09732112095987412), (86, 0.09653883649821722), (164, 0.09632459933985814), (77, 0.09589445826473077), (65, 0.09524095881415094), (61, 0.09515527385837713), (156, 0.09504862903894257), (102, 0.09375855796034199), (155, 0.09271731107050801), (85, 0.09253049468825796), (107, 0.09221894148727858), (9, 0.09208386333208374), (54, 0.0918201587029308), (88, 0.0917084279009591), (166, 0.09118775336609275), (89, 0.09071123191917115), (62, 0.08993933409441399), (63, 0.08969735136639347), (7, 0.08874145898956463), (160, 0.08847082224879566), (157, 0.08806435647689961), (49, 0.0874558662257424), (146, 0.08736519266509175), (100, 0.08580104266207972), (24, 0.08562337282731507), (80, 0.08536349885044411), (50, 0.08465990526351332), (66, 0.08322293690376814), (69, 0.08278323806221637), (76, 0.08220634500797763), (84, 0.08117395444338327), (35, 0.08077267528901921), (158, 0.08071317337658432), (101, 0.07919300595561575), (87, 0.07837052039638939), (73, 0.07814969234350179), (4, 0.07799241874989367), (45, 0.07777429303140802), (152, 0.07680037628099362), (53, 0.07624633590288496), (75, 0.07542571668643637), (60, 0.0750814979413729), (148, 0.075071626108866), (34, 0.07479297535144605), (163, 0.07423403064202792), (48, 0.07259747134092599), (109, 0.07235450820565101), (161, 0.07218705423176484), (165, 0.0697176298548119), (162, 0.06961542865992468), (150, 0.06924061086735848), (78, 0.06811385924996534), (91, 0.06811192890026248), (92, 0.06784888773167011), (151, 0.06759455518696374), (81, 0.0671236556520782), (144, 0.06692499909581603), (37, 0.06510793043546502), (19, 0.06498859667096661), (159, 0.06392844522143308), (22, 0.06304211323875665), (68, 0.06201394989560394), (110, 0.0600274074676265), (93, 0.05825673990556566), (138, 0.05591576054731865), (82, 0.053621285436937394), (141, 0.05220501936022941), (154, 0.048093215687404), (67, 0.04789027369847377), (97, 0.047867360230184786), (64, 0.046154901479376), (113, 0.046018442921380305), (145, 0.04583156722857606), (139, 0.044951332652584115), (52, 0.04460220694951919), (135, 0.04309325411575538), (140, 0.04306263516036035), (79, 0.04298646266243172), (96, 0.042565152468566736), (112, 0.042308250947635566), (83, 0.04188066031248396), (143, 0.03798035132289578), (137, 0.037792474675920285), (111, 0.03641377767532758), (115, 0.03639832237080823), (104, 0.035876432006179765), (98, 0.033438077465131284), (153, 0.03258338307864268), (132, 0.032539989706063206), (149, 0.032189802466501834), (136, 0.029886206900980677), (95, 0.026692474094076452), (142, 0.025994041902723034), (128, 0.02348927247517369), (123, 0.022453659139718307), (131, 0.02216557705455127), (117, 0.021274811296509048), (121, 0.020087105903313127), (122, 0.01963405166552546), (90, 0.018914761506734334), (99, 0.018180395602473254), (124, 0.018087081363253727), (118, 0.016071453724833085), (127, 0.015607937369199007), (130, 0.013930921797819814), (116, 0.013249289038773426), (134, 0.01030325253108978), (94, 0.01004816124869316), (129, 0.008910844165150767), (114, 0.006813952314611714), (119, 0.0042645202354480525), (120, 0.001198243294508687), (125, 0.0004654062670023816), (103, -0.0004261176271423644), (133, -0.003909646263992712), (126, -0.006047268830530692)]\n",
      "Best MI score: 0.21875226536978648\n",
      "Adding first best original feature: 17\n",
      "CMI: 0.01752263774318924\n",
      "CMI: 0.028501857220909088\n",
      "CMI: 0.012014045342493729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.011356913637001947\n",
      "CMI: 0.0019027572668207926\n",
      "CMI: 0.00454805237325584\n",
      "CMI: 0.007699514695016285\n",
      "CMI: 0.0030619277641947273\n",
      "CMI: 0.015550076637784183\n",
      "CMI: 0.006343738537786275\n",
      "CMI: 0.012562477777008474\n",
      "CMI: 0.0014976696878495066\n",
      "Highest CMI score: 0.028501857220909088\n",
      "Adding original feature: 2\n",
      "CMI: 0.004557471001971958\n",
      "CMI: 0.01758707125885106\n",
      "CMI: 0.02308383529125957\n",
      "CMI: 0.0010671452568803141\n",
      "CMI: 0.012196243606450163\n",
      "CMI: 0.004665432531411051\n",
      "CMI: 0.01134518869498008\n",
      "CMI: 0.0031965860459245987\n",
      "CMI: 0.005929244487621166\n",
      "Highest CMI score: 0.02308383529125957\n",
      "Adding original feature: 10\n",
      "CMI: 0.007671947257277323\n",
      "CMI: 0.0032716760946586154\n",
      "CMI: 0.0011927143944516216\n",
      "CMI: 0.006255668852313323\n",
      "Highest CMI score: 0.007671947257277323\n",
      "Adding original feature: 1\n",
      "CMI: 0.001578439743518234\n",
      "CMI: 0.001165761724650216\n",
      "Highest CMI score: 0.001578439743518234\n",
      "Adding original feature: 25\n",
      "CMI: 0.0004715167352646876\n",
      "CMI: 0.007536217513409493\n",
      "CMI: 0.001954224168207841\n",
      "Highest CMI score: 0.007536217513409493\n",
      "Adding original feature: 32\n",
      "CMI: 0.0010871740382191741\n",
      "CMI: 0.002506928888652449\n",
      "Highest CMI score: 0.002506928888652449\n",
      "Adding original feature: 42\n",
      "Highest CMI score: -7.700073932648266e-05\n",
      "\n",
      "[17, 2, 10, 1, 25, 32, 42]\n",
      "\n",
      "\n",
      "Full model and selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.6154950191461779, test score: -2.202700940171159\n",
      "Aggregate regression train score with FS: 0.04291099248759678, test score: -0.08638529221689217\n",
      "\n",
      "Full model and best 5 selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.6154950191461779, test score: -2.202700940171159\n",
      "Aggregate regression train score with FS: 0.021918905796166288, test score: -0.04514199582686307\n",
      "####################Adda####################\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.039373    0.00  2001     1 -2.546951\n",
      "1    2001-01-13  0.380618    0.43  2001     2 -0.277191\n",
      "2    2001-01-21  0.341985    0.38  2001     3 -0.534156\n",
      "3    2001-01-29  0.322044    0.35  2001     5 -0.666789\n",
      "4    2001-02-06  0.354954    0.40  2001     6 -0.447894\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.382706    0.40  2009    48 -0.263306\n",
      "407  2009-12-05  0.409921    0.46  2009    49 -0.082282\n",
      "408  2009-12-13  0.472087    0.53  2009    50  0.331204\n",
      "409  2009-12-21  0.324728    0.00  2009    52 -0.648940\n",
      "410  2009-12-29  0.086512    0.00  2009    53 -2.233412\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.039373    0.00  2001     1 -2.546951\n",
      "1    2001-01-13  0.380618    0.43  2001     2 -0.277191\n",
      "2    2001-01-21  0.341985    0.38  2001     3 -0.534156\n",
      "3    2001-01-29  0.322044    0.35  2001     5 -0.666789\n",
      "4    2001-02-06  0.354954    0.40  2001     6 -0.447894\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.382706    0.40  2009    48 -0.263306\n",
      "407  2009-12-05  0.409921    0.46  2009    49 -0.082282\n",
      "408  2009-12-13  0.472087    0.53  2009    50  0.331204\n",
      "409  2009-12-21  0.324728    0.00  2009    52 -0.648940\n",
      "410  2009-12-29  0.086512    0.00  2009    53 -2.233412\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 8\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 4\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 4\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 4\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 5\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 5\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 5\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 5\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 5\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 5\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 5\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_tg_1w_6', 'cyclostationary_mean_tg_1w_5', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_tg_16w_2', 'cyclostationary_mean_tg_1w_4', 'cyclostationary_mean_tg_12w_3', 'cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_rr_8w_0', 'cyclostationary_mean_rr_12w_1', 'cyclostationary_mean_rr_12w_2', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_rr_2', 'cyclostationary_mean_rr_3', 'cyclostationary_mean_rr_4', 'cyclostationary_mean_tg_4w_4', 'cyclostationary_mean_rr_1'], \n",
      "\n",
      "validation score: 0.33729581660235464, \n",
      "\n",
      "number of selected features: 19\n",
      "\n",
      "Full model and selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.39094954041387586, test score: -0.47080108323471714\n",
      "Aggregate regression train score with FS: 0.24115224664141943, test score: -0.03275775627162969\n",
      "\n",
      "Full model and best 5 selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.39094954041387586, test score: -0.47080108323471714\n",
      "Aggregate regression train score with FS: 0.20248698967308365, test score: 0.13863455849493866\n",
      "----- MI Scores -----\n",
      "[(46, 0.12382062882193837), (48, 0.11753363244877706), (47, 0.11627115251375528), (39, 0.11558499199875491), (38, 0.11556837299107342), (5, 0.1120418898875603), (6, 0.10990196790565648), (50, 0.10983396973374421), (36, 0.10696249667549634), (45, 0.10601183373702121), (0, 0.10459086562810836), (1, 0.10404777033279888), (37, 0.10360504540943304), (49, 0.10174648571540935), (40, 0.10099817700521793), (44, 0.10077079926856579), (42, 0.0995069836776427), (11, 0.09776607701396299), (35, 0.0963063548120773), (3, 0.09454687685816096), (51, 0.09256944158697891), (14, 0.09145332826815922), (9, 0.08920613917368424), (43, 0.08661809050846275), (4, 0.08519553182985487), (8, 0.08202005074653325), (76, 0.07999473041031913), (41, 0.07842385654585562), (2, 0.07703198469189082), (33, 0.07079773979968454), (7, 0.07079179965435174), (55, 0.06838491122071422), (13, 0.0657457176995818), (10, 0.06317660052684479), (16, 0.06255632373955927), (30, 0.06078284111641435), (12, 0.05430803998804412), (32, 0.05279706167142524), (77, 0.05155755293289637), (34, 0.05085195352532044), (24, 0.049909026116643794), (83, 0.047334700475274924), (64, 0.04655332269180252), (53, 0.046336269299502165), (54, 0.045062184539707034), (56, 0.043591960643407576), (31, 0.041219352914703605), (21, 0.04029166703578293), (18, 0.03492701282738845), (58, 0.03366738037728009), (72, 0.032674600261714704), (15, 0.03253504391273119), (80, 0.032379547749356), (78, 0.03135657205267133), (63, 0.029624969112521), (19, 0.029041484075160454), (17, 0.028611534118950267), (69, 0.027285739250342222), (75, 0.02678637412285656), (29, 0.02605251014587864), (74, 0.025421440120670227), (81, 0.024841567016598537), (27, 0.024214973770620533), (25, 0.023876035259012742), (62, 0.023235196010406422), (20, 0.022006359328764356), (22, 0.02078180417297369), (66, 0.020569903141526635), (61, 0.019781497581839183), (79, 0.018859847479014424), (52, 0.018819263367304592), (26, 0.01768518563017374), (86, 0.016805935762419236), (60, 0.01643897456357112), (23, 0.014959033381815723), (85, 0.012771325343636604), (84, 0.012104051385525436), (71, 0.011110037255563109), (28, 0.009249234989614753), (67, 0.006341278313756974), (70, 0.006310199626343884), (57, 0.00030148475663156), (59, -0.0010043373736043793), (73, -0.0012011767816253746), (65, -0.0032094800181856034), (68, -0.006138128334639475), (82, -0.007314254626464375)]\n",
      "Best MI score: 0.12382062882193837\n",
      "Adding first best original feature: 46\n",
      "CMI: 0.04656864906240321\n",
      "CMI: 0.05391574136240737\n",
      "CMI: 0.03828823617466853\n",
      "CMI: 0.03171956453065736\n",
      "CMI: 0.02477565818410782\n",
      "CMI: 0.050592410688952566\n",
      "CMI: 0.0652872080062194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CMI: 0.03254723152451919\n",
      "CMI: 0.03224173917336037\n",
      "CMI: 0.02321809892143742\n",
      "CMI: 0.03580837673917306\n",
      "CMI: 0.05144459620410957\n",
      "CMI: 0.03573094159557916\n",
      "CMI: 0.03248007530290292\n",
      "CMI: 0.020195551103674658\n",
      "CMI: 0.010482422110331763\n",
      "CMI: 0.005518327098399223\n",
      "CMI: 0.004149806638309217\n",
      "CMI: 0.006720953626461662\n",
      "CMI: 0.0036400905246349313\n",
      "CMI: 0.0010215428753105327\n",
      "CMI: 0.006418362640264741\n",
      "CMI: 0.025026297532601632\n",
      "CMI: 0.0225837927734672\n",
      "CMI: 0.05300599515140947\n",
      "CMI: 0.0011662821891593872\n",
      "CMI: 0.014154568539090778\n",
      "CMI: 0.0034282480889311073\n",
      "CMI: 0.00556266799650787\n",
      "CMI: 0.0017745605979289925\n",
      "CMI: 0.0242797556791938\n",
      "CMI: 0.014184639541659577\n",
      "CMI: 0.009190369240083013\n",
      "CMI: 0.006624388253266861\n",
      "CMI: 0.0030981634182589424\n",
      "CMI: 0.006282864570508945\n",
      "CMI: 0.0029264662653806783\n",
      "CMI: 0.014122997852305863\n",
      "CMI: 0.006113992740532287\n",
      "CMI: 0.0030719299225818453\n",
      "CMI: 0.0024262826772420976\n",
      "CMI: 0.0010753876543792146\n",
      "CMI: 0.02810098729551408\n",
      "CMI: 0.024144132254435985\n",
      "CMI: 0.012342105593410813\n",
      "CMI: 0.006700675919893262\n",
      "CMI: 0.003896541867466491\n",
      "CMI: 0.002893936060894886\n",
      "CMI: 0.0003093615834881408\n",
      "CMI: 0.010107600077330414\n",
      "CMI: 0.0076079727244009465\n",
      "CMI: 0.01908967461476177\n",
      "CMI: 0.012462386718424756\n",
      "CMI: 0.009210478531231081\n",
      "CMI: 0.011094173889947156\n",
      "CMI: 0.014111781613090957\n",
      "CMI: 0.03333163300111361\n",
      "CMI: 0.01961083349465806\n",
      "CMI: 0.01130387795574253\n",
      "CMI: 0.0034721342846523173\n",
      "CMI: 0.0351507953297725\n",
      "CMI: 0.01716450610747053\n",
      "CMI: 0.023456973403961967\n",
      "Highest CMI score: 0.0652872080062194\n",
      "Adding original feature: 6\n",
      "CMI: 0.005389486922646791\n",
      "CMI: 0.002661433232986843\n",
      "CMI: 0.004915625039619481\n",
      "CMI: 0.014867747880083187\n",
      "CMI: 0.009952630323123712\n",
      "CMI: 0.00016377681070961492\n",
      "CMI: 0.0007669698800530644\n",
      "CMI: 0.0011803665123220897\n",
      "CMI: 0.0032015778439735687\n",
      "CMI: 0.014215825698113888\n",
      "CMI: 0.002753519099056828\n",
      "CMI: 0.008203044875396776\n",
      "CMI: 0.00789881379425153\n",
      "CMI: 0.021514076132746474\n",
      "CMI: 0.02328702130154492\n",
      "CMI: 0.007102443470932973\n",
      "CMI: 0.018388975040063427\n",
      "CMI: 0.03088359454261716\n",
      "CMI: 0.02337965959702179\n",
      "CMI: 0.01937773453061925\n",
      "CMI: 0.020969140384469842\n",
      "CMI: 0.004935351108149882\n",
      "CMI: 0.0014744444700172388\n",
      "CMI: 0.0018507038346693427\n",
      "CMI: 0.014189000719922323\n",
      "CMI: 0.026378874114641987\n",
      "CMI: 0.02513863484948381\n",
      "CMI: 0.007374390570144218\n",
      "CMI: 0.002688959959234738\n",
      "CMI: 0.018429161738612587\n",
      "CMI: 0.007981036603603275\n",
      "CMI: 0.0076960848643468915\n",
      "CMI: 0.006514199645484192\n",
      "CMI: 0.004408331732591669\n",
      "CMI: 0.00027080326533746035\n",
      "Highest CMI score: 0.03088359454261716\n",
      "Adding original feature: 31\n",
      "CMI: 0.0005440569266056683\n",
      "CMI: 0.0003991169211401968\n",
      "CMI: 0.007868820449963648\n",
      "CMI: 0.0023165285790444634\n",
      "CMI: 0.0007678406023441664\n",
      "Highest CMI score: 0.007868820449963648\n",
      "Adding original feature: 61\n",
      "CMI: 0.002335825098003841\n",
      "CMI: 0.002849024889755386\n",
      "CMI: 0.0016266786375962183\n",
      "CMI: 0.012966018115842609\n",
      "CMI: 0.015285940900464229\n",
      "CMI: 0.0056414114389047865\n",
      "CMI: 0.00604318038655835\n",
      "CMI: 0.0037475921469580786\n",
      "CMI: 0.007027514856952688\n",
      "Highest CMI score: 0.015285940900464229\n",
      "Adding original feature: 79\n",
      "Highest CMI score: -0.0032009099262424734\n",
      "\n",
      "[46, 6, 31, 61, 79]\n",
      "\n",
      "\n",
      "Full model and selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.39094954041387586, test score: -0.47080108323471714\n",
      "Aggregate regression train score with FS: 0.14687657653786135, test score: 0.11246094743969515\n",
      "\n",
      "Full model and best 5 selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.39094954041387586, test score: -0.47080108323471714\n",
      "Aggregate regression train score with FS: 0.14687657653786135, test score: 0.11246094743969515\n",
      "####################Dora####################\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.010645    0.00  2001     1 -2.129508\n",
      "1    2001-01-13  0.206769    0.00  2001     2 -0.927136\n",
      "2    2001-01-21  0.267313    0.00  2001     3 -0.555958\n",
      "3    2001-01-29  0.240836    0.20  2001     5 -0.718282\n",
      "4    2001-02-06  0.193417    0.15  2001     6 -1.008995\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.230073    0.25  2009    48 -0.784269\n",
      "407  2009-12-05  0.243632    0.24  2009    49 -0.701139\n",
      "408  2009-12-13  0.251111    0.00  2009    50 -0.655289\n",
      "409  2009-12-21  0.099246    0.00  2009    52 -1.586325\n",
      "410  2009-12-29  0.064990    0.00  2009    53 -1.796340\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.010645    0.00  2001     1 -2.129508\n",
      "1    2001-01-13  0.206769    0.00  2001     2 -0.927136\n",
      "2    2001-01-21  0.267313    0.00  2001     3 -0.555958\n",
      "3    2001-01-29  0.240836    0.20  2001     5 -0.718282\n",
      "4    2001-02-06  0.193417    0.15  2001     6 -1.008995\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.230073    0.25  2009    48 -0.784269\n",
      "407  2009-12-05  0.243632    0.24  2009    49 -0.701139\n",
      "408  2009-12-13  0.251111    0.00  2009    50 -0.655289\n",
      "409  2009-12-21  0.099246    0.00  2009    52 -1.586325\n",
      "410  2009-12-29  0.064990    0.00  2009    53 -1.796340\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 4\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 44\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 4\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 4\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 4\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 4\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 4\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 4\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "Number of features: 4\n",
      "\n",
      "Number of aggregated features: 3\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_rr_4w_1', 'cyclostationary_mean_HS_1w_0', 'cyclostationary_mean_tg_1w_2', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_tg_24w_1', 'cyclostationary_mean_tg_24w_3', 'cyclostationary_mean_HS_24w_2', 'cyclostationary_mean_HS_12w_2', 'cyclostationary_mean_rr_16w_0', 'cyclostationary_mean_rr_12w_0', 'cyclostationary_mean_rr_0', 'cyclostationary_mean_HS_0'], \n",
      "\n",
      "validation score: 0.29657408485340486, \n",
      "\n",
      "number of selected features: 13\n",
      "\n",
      "Full model and selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.2940530674265355, test score: -1.2805750816952206\n",
      "Aggregate regression train score with FS: 0.21954715379728285, test score: -1.0842198238707228\n",
      "\n",
      "Full model and best 5 selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.2940530674265355, test score: -1.2805750816952206\n",
      "Aggregate regression train score with FS: 0.15624707651795888, test score: -0.5417700764789395\n",
      "----- MI Scores -----\n",
      "[(0, 0.2952953612194227), (4, 0.2800096649013969), (1, 0.2693167342841738), (3, 0.2603664794085629), (6, 0.25701446205886175), (7, 0.23860945539357833), (10, 0.19815668502907816), (9, 0.18800812404496547), (2, 0.17546552232719306), (8, 0.17113211944503068), (5, 0.1680202883412306), (13, 0.1438600954804504), (12, 0.12664648185843275), (11, 0.12456958028513011), (16, 0.11228971442717278), (15, 0.0932113048755538), (14, 0.08664117588742813), (27, 0.08564397327695021), (21, 0.08509598471294849), (22, 0.07947913957458219), (26, 0.06777331311132379), (19, 0.06539741683854618), (18, 0.06531736410747108), (42, 0.06403914196637761), (23, 0.06275881098073652), (44, 0.06171626575698934), (40, 0.06056112941717606), (41, 0.0590243394443204), (31, 0.0557261915917365), (24, 0.055522131453310905), (25, 0.054451972693187675), (28, 0.05013396464960597), (43, 0.04963889533470378), (17, 0.04915301449338825), (39, 0.04686527556655052), (30, 0.04642124218639126), (20, 0.043050184000153854), (32, 0.03994388732910318), (45, 0.03973911161712182), (29, 0.03364236729396663), (38, 0.026156781831893537), (34, 0.02434045565894693), (35, 0.017403935659882793), (37, 0.014858994314943258), (33, 0.010923977157029814), (36, 0.009337204656474401)]\n",
      "Best MI score: 0.2952953612194227\n",
      "Adding first best original feature: 0\n",
      "CMI: 0.024710538457889453\n",
      "CMI: 0.02686732677925613\n",
      "CMI: 0.016773178140698897\n",
      "CMI: 0.024457150389453453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest CMI score: 0.02686732677925613\n",
      "Adding original feature: 4\n",
      "CMI: 0.01050465643320636\n",
      "CMI: 0.003958875484086188\n",
      "CMI: 0.0072140253759021\n",
      "Highest CMI score: 0.01050465643320636\n",
      "Adding original feature: 6\n",
      "CMI: 0.0019662718605416574\n",
      "CMI: 0.0015827816359185731\n",
      "Highest CMI score: 0.0019662718605416574\n",
      "Adding original feature: 41\n",
      "CMI: 0.00013856595464561972\n",
      "Highest CMI score: 0.00013856595464561972\n",
      "Adding original feature: 3\n",
      "Highest CMI score: -0.001135299287123026\n",
      "\n",
      "[0, 4, 6, 41, 3]\n",
      "\n",
      "\n",
      "Full model and selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.2940530674265355, test score: -1.2805750816952206\n",
      "Aggregate regression train score with FS: 0.07041643049702362, test score: -0.6891718117396826\n",
      "\n",
      "Full model and best 5 selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.2940530674265355, test score: -1.2805750816952206\n",
      "Aggregate regression train score with FS: 0.07041643049702362, test score: -0.6891718117396826\n",
      "####################Ticino####################\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.264043    0.00  2001     1 -1.060146\n",
      "1    2001-01-13  0.354618    0.39  2001     2 -0.405065\n",
      "2    2001-01-21  0.427990    0.47  2001     3  0.125603\n",
      "3    2001-01-29  0.339495    0.35  2001     5 -0.514438\n",
      "4    2001-02-06  0.324134    0.34  2001     6 -0.625540\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.332713    0.35  2009    48 -0.563495\n",
      "407  2009-12-05  0.370253    0.40  2009    49 -0.291984\n",
      "408  2009-12-13  0.517201    0.57  2009    50  0.770822\n",
      "409  2009-12-21  0.353636    0.45  2009    52 -0.412164\n",
      "410  2009-12-29  0.261079    0.00  2009    53 -1.081585\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.264043    0.00  2001     1 -1.060146\n",
      "1    2001-01-13  0.354618    0.39  2001     2 -0.405065\n",
      "2    2001-01-21  0.427990    0.47  2001     3  0.125603\n",
      "3    2001-01-29  0.339495    0.35  2001     5 -0.514438\n",
      "4    2001-02-06  0.324134    0.34  2001     6 -0.625540\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.332713    0.35  2009    48 -0.563495\n",
      "407  2009-12-05  0.370253    0.40  2009    49 -0.291984\n",
      "408  2009-12-13  0.517201    0.57  2009    50  0.770822\n",
      "409  2009-12-21  0.353636    0.45  2009    52 -0.412164\n",
      "410  2009-12-29  0.261079    0.00  2009    53 -1.081585\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 4\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 6\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 7\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 6\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 9\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 5\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 1\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 92\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 6\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 6\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 6\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 6\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 6\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 6\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "Number of features: 6\n",
      "\n",
      "Number of aggregated features: 2\n",
      "\n",
      "\n",
      "\n",
      "selected columns: ['cyclostationary_mean_tg_1w_3', 'cyclostationary_mean_rr_1w_1', 'cyclostationary_mean_HS_12w_1', 'cyclostationary_mean_rr_24w_0', 'cyclostationary_mean_tg_16w_3', 'cyclostationary_mean_HS_24w_0', 'cyclostationary_mean_HS_16w_0', 'cyclostationary_mean_HS_1w_1', 'cyclostationary_mean_tg_16w_8', 'cyclostationary_mean_HS_12w_0', 'cyclostationary_mean_HS_0', 'cyclostationary_mean_tg_16w_4', 'cyclostationary_mean_tg_16w_5', 'cyclostationary_mean_tg_8w_4', 'cyclostationary_mean_tg_8w_2', 'cyclostationary_mean_tg_8w_5', 'cyclostationary_mean_tg_8w_0', 'cyclostationary_mean_tg_1w_0', 'cyclostationary_mean_tg_12w_5', 'cyclostationary_mean_tg_12w_2', 'cyclostationary_mean_HS_16w_1', 'cyclostationary_mean_tg_4w_2', 'cyclostationary_mean_tg_4w_5', 'cyclostationary_mean_tg_8w_1', 'cyclostationary_mean_HS_8w_1', 'cyclostationary_mean_HS_4w_1', 'cyclostationary_mean_HS_1', 'cyclostationary_mean_rr_1w_0', 'cyclostationary_mean_rr_16w_1', 'cyclostationary_mean_tg_1w_4', 'cyclostationary_mean_tg_4w_3', 'cyclostationary_mean_tg_1w_1', 'cyclostationary_mean_tg_4w_0', 'cyclostationary_mean_tg_1w_2'], \n",
      "\n",
      "validation score: 0.4404773039540958, \n",
      "\n",
      "number of selected features: 34\n",
      "\n",
      "Full model and selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.3637813776798461, test score: -0.3041716642835559\n",
      "Aggregate regression train score with FS: 0.3152020023248201, test score: 0.09492734792200141\n",
      "\n",
      "Full model and best 5 selected features with wrapper\n",
      "\n",
      "Full aggregate regression train score: 0.3637813776798461, test score: -0.3041716642835559\n",
      "Aggregate regression train score with FS: 0.25575974789392186, test score: 0.09114358744353745\n",
      "----- MI Scores -----\n",
      "[(14, 0.1233172834270275), (21, 0.11925446005307141), (19, 0.11429640516876576), (17, 0.10839192158463667), (22, 0.10397460958719837), (15, 0.10247714968806099), (16, 0.09513356575733153), (0, 0.08715733872819754), (20, 0.0854421903059367), (25, 0.08419891406662146), (18, 0.08052176641110485), (24, 0.07931849119089665), (28, 0.07712008275236602), (4, 0.06895004167102578), (58, 0.06849890021359188), (59, 0.06842462865595438), (26, 0.0624493611733322), (2, 0.0623811389797085), (57, 0.061138128729906156), (32, 0.0541002468062679), (55, 0.04978620899883007), (60, 0.04938930727611444), (51, 0.04513908122631465), (39, 0.042000102589973554), (23, 0.041905160553517715), (27, 0.04075164347350076), (6, 0.03642580400780875), (8, 0.034449479536108156), (54, 0.03375222665168136), (52, 0.03366189924529926), (40, 0.03215149480826468), (56, 0.031252692960708414), (61, 0.02756612860711409), (10, 0.02689195320563331), (33, 0.02626414242665474), (38, 0.021788321224037514), (31, 0.021397177752193127), (3, 0.021212172668393092), (65, 0.019712095569191318), (12, 0.019711741533919656), (64, 0.017996597853011345), (43, 0.017804654115437146), (47, 0.017273982036522778), (62, 0.016090289871205584), (63, 0.015432466829295709), (48, 0.013777851161168971), (36, 0.011143406803733038), (41, 0.010554288371655113), (9, 0.010430361801599335), (49, 0.009481103488363257), (30, 0.008753686621271902), (29, 0.00834565549052766), (1, 0.00822058379684055), (42, 0.006298198959056755), (5, 0.006261744310422687), (34, 0.006163829033533268), (7, 0.005629310262079075), (35, 0.005456890356179449), (11, 0.002927641603718372), (50, 0.0022665275452120395), (13, -4.354473501220265e-05), (44, -0.0004505725576902776), (46, -0.0013820670070942521), (37, -0.002147264619969846), (53, -0.005016984770803921), (45, -0.006762843222331876)]\n",
      "Best MI score: 0.1233172834270275\n",
      "Adding first best original feature: 14\n",
      "CMI: 0.06580172935056916\n",
      "CMI: 0.06176583615658496\n",
      "CMI: 0.010009827299481217\n",
      "CMI: 0.052083355688995886\n",
      "CMI: 0.00835171294468598\n",
      "CMI: 0.06125904853649086\n",
      "CMI: 0.01828023072610041\n",
      "CMI: 0.024305157688085194\n",
      "CMI: 0.005127383224285215\n",
      "CMI: 0.00018903157586414032\n",
      "CMI: 0.004543104182696295\n",
      "CMI: 0.0021519894117754124\n",
      "CMI: 0.004261755704103393\n",
      "CMI: 0.01703074557484377\n",
      "CMI: 0.013273817049861997\n",
      "CMI: 0.02997244107067401\n",
      "CMI: 0.020362532670275407\n",
      "CMI: 0.03464001444320386\n",
      "CMI: 0.014964516543690548\n",
      "CMI: 0.005164152584752862\n",
      "CMI: 0.002274079728513567\n",
      "CMI: 0.0028850784639677107\n",
      "Highest CMI score: 0.06580172935056916\n",
      "Adding original feature: 0\n",
      "CMI: 0.006059927838511586\n",
      "CMI: 0.008724687179935381\n",
      "CMI: 0.014993887004583872\n",
      "CMI: 4.746571973282543e-05\n",
      "CMI: 0.006091684768811667\n",
      "CMI: 0.0088831419975475\n",
      "CMI: 0.005021419122360954\n",
      "CMI: 0.021914181655212417\n",
      "CMI: 0.016298206289656197\n",
      "CMI: 0.019122456294674767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest CMI score: 0.021914181655212417\n",
      "Adding original feature: 57\n",
      "CMI: 0.010908361371905123\n",
      "CMI: 0.007542907661369391\n",
      "CMI: 0.005061658330239249\n",
      "CMI: 0.0011935791613940372\n",
      "CMI: 0.0016799219463409232\n",
      "CMI: 0.002670821427885217\n",
      "CMI: 0.007000442607198398\n",
      "CMI: 0.003108722376250761\n",
      "CMI: 0.00414769034600021\n",
      "CMI: 0.001562008896103445\n",
      "Highest CMI score: 0.010908361371905123\n",
      "Adding original feature: 2\n",
      "Highest CMI score: -0.004894442474831201\n",
      "\n",
      "[14, 0, 57, 2]\n",
      "\n",
      "\n",
      "Full model and selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.3637813776798461, test score: -0.3041716642835559\n",
      "Aggregate regression train score with FS: 0.20094525347181302, test score: 0.04903072533524233\n",
      "\n",
      "Full model and best 5 selected features with CMI\n",
      "\n",
      "Full aggregate regression train score: 0.3637813776798461, test score: -0.3041716642835559\n",
      "Aggregate regression train score with FS: 0.20094525347181302, test score: 0.04903072533524233\n"
     ]
    }
   ],
   "source": [
    "### Without 12 months\n",
    "#basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona','Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n",
    "basins = ['Piemonte_Nord','Piemonte_Sud','Adda','Dora','Ticino']\n",
    "path_target = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/csv_VHI/'\n",
    "path_features_snow='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/snow_aggreg_ARPA/all_coord/'\n",
    "path_features='/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/features/csv_allvalues/temporal_aggreg/'\n",
    "\n",
    "for basin in basins:\n",
    "    print('####################' + basin + '####################')\n",
    "\n",
    "    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', path=path_target+basin+'.csv')\n",
    "\n",
    "    eps = 0.001\n",
    "    actual_path = path_features+basin+'_aggreg.csv'\n",
    "    snow_actual_path = path_features_snow+basin+'_snowDepth_aggreg_allCoord.csv'\n",
    "\n",
    "    path_target = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/csv_VHI/'\n",
    "    \n",
    "    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', path=path_target+basin+'.csv')\n",
    "    \n",
    "    output,aggregate_trainVal_temp_prec,aggregate_test_temp_prec = aggregate_unfolded_data(actual_path,['cyclostationary_mean_tg', \n",
    "                                                                             'cyclostationary_mean_tg_1w',\n",
    "                                                                             'cyclostationary_mean_tg_4w', \n",
    "                                                                             'cyclostationary_mean_tg_8w',\n",
    "                                                                             'cyclostationary_mean_tg_12w', \n",
    "                                                                             'cyclostationary_mean_tg_16w',\n",
    "                                                                             'cyclostationary_mean_tg_24w',\n",
    "                                                                             'cyclostationary_mean_rr', \n",
    "                                                                             'cyclostationary_mean_rr_1w',\n",
    "                                                                             'cyclostationary_mean_rr_4w', \n",
    "                                                                             'cyclostationary_mean_rr_8w',\n",
    "                                                                             'cyclostationary_mean_rr_12w', \n",
    "                                                                             'cyclostationary_mean_rr_16w',\n",
    "                                                                             'cyclostationary_mean_rr_24w'\n",
    "                                                                            ],\n",
    "                                                                       target_df_trainVal, eps=eps,\n",
    "                                                                       max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "    \n",
    "    output_snow,aggregate_trainVal_snow,aggregate_test_snow = aggregate_unfolded_data(snow_actual_path,['cyclostationary_mean_HS', \n",
    "                                                                             'cyclostationary_mean_HS_1w',\n",
    "                                                                             'cyclostationary_mean_HS_4w', \n",
    "                                                                             'cyclostationary_mean_HS_8w',\n",
    "                                                                             'cyclostationary_mean_HS_12w', \n",
    "                                                                             'cyclostationary_mean_HS_16w',\n",
    "                                                                             'cyclostationary_mean_HS_24w'\n",
    "                                                                            ],\n",
    "                                                                       target_df_trainVal, eps=eps,\n",
    "                                                                       max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01')\n",
    "        \n",
    "    \n",
    "    aggregate_trainVal = pd.concat((aggregate_trainVal_snow,aggregate_trainVal_temp_prec),axis=1)\n",
    "    aggregate_test = pd.concat((aggregate_test_snow,aggregate_test_temp_prec),axis=1)\n",
    "    \n",
    "    selected_colnames = FS_with_linearWrapper(aggregate_trainVal, target_df_train, target_df_val, min(50,aggregate_trainVal.shape[1]-1), 228)\n",
    "\n",
    "    print('\\nFull model and selected features with wrapper\\n')\n",
    "    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n",
    "    \n",
    "    print('\\nFull model and best 5 selected features with wrapper\\n')\n",
    "    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n",
    "    \n",
    "    train_string = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'+basin+'_wrapper_best5_train_withSnow.csv'\n",
    "    val_string = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'+basin+'_wrapper_best5_val_withSnow.csv'\n",
    "    test_string = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'+basin+'_wrapper_best5_test_withSnow.csv'\n",
    "        \n",
    "    aggregate_trainVal.loc[:410,selected_colnames[0:5]].to_csv(train_string, index=False)\n",
    "    aggregate_trainVal.loc[411:,selected_colnames[0:5]].to_csv(val_string, index=False)\n",
    "    aggregate_test.loc[:,selected_colnames[0:5]].to_csv(test_string, index=False)\n",
    "    \n",
    "    res = {\n",
    "            \"delta\" : [], \n",
    "            \"numSelected\" : [], \n",
    "            \"selectedFeatures\" : [] \n",
    "        }\n",
    "        \n",
    "    res['selectedFeatures'] = forwardFeatureSelection(10,np.array(aggregate_trainVal),np.array(target_df_trainVal.mean_std),res,10,1)\n",
    "        \n",
    "    selectedFeatures='selectedFeatures'\n",
    "    print(f'\\n{res[selectedFeatures]}\\n')\n",
    "    selected_colnames = aggregate_trainVal.columns[res['selectedFeatures']]\n",
    "    \n",
    "    print('\\nFull model and selected features with CMI\\n')\n",
    "    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames)\n",
    "    \n",
    "    print('\\nFull model and best 5 selected features with CMI\\n')\n",
    "    compare_methods(aggregate_trainVal, aggregate_test, target_df_trainVal, target_df_test, selected_colnames[0:5])\n",
    "    \n",
    "    train_string = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'+basin+'_nonLinCFA_best5_CMI_train_withSnow.csv'\n",
    "    val_string = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'+basin+'_nonLinCFA_best5_CMI_val_withSnow.csv'\n",
    "    test_string = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'+basin+'_nonLinCFA_best5_CMI_test_withSnow.csv'\n",
    "            \n",
    "    aggregate_trainVal.loc[:410,selected_colnames[0:5]].to_csv(train_string, index=False)\n",
    "    aggregate_trainVal.loc[411:,selected_colnames[0:5]].to_csv(val_string, index=False)\n",
    "    aggregate_test.loc[:,selected_colnames[0:5]].to_csv(test_string, index=False)\n",
    "\n",
    "    train_string = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'+basin+'_nonLinCFA_CMI_train_withSnow.csv'\n",
    "    val_string = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'+basin+'_nonLinCFA_CMI_val_withSnow.csv'\n",
    "    test_string = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'+basin+'_nonLinCFA_CMI_test_withSnow.csv'\n",
    "        \n",
    "    aggregate_trainVal.loc[:410,selected_colnames].to_csv(train_string, index=False)\n",
    "    aggregate_trainVal.loc[411:,selected_colnames].to_csv(val_string, index=False)\n",
    "    aggregate_test.loc[:,selected_colnames].to_csv(test_string, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0486429",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solo nevi: tutti e tre negativi sia per Piemonte Nord che Sud\n",
    "### Piemonte Nord: 0.086 per tutti e 3\n",
    "### Piemonte Sud: 0.09, 0.18, 0.16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc23dac7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# MTL with snow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4b77ec0",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.039373    0.00  2001     1 -2.546951\n",
      "1    2001-01-13  0.380618    0.43  2001     2 -0.277191\n",
      "2    2001-01-21  0.341985    0.38  2001     3 -0.534156\n",
      "3    2001-01-29  0.322044    0.35  2001     5 -0.666789\n",
      "4    2001-02-06  0.354954    0.40  2001     6 -0.447894\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.382706    0.40  2009    48 -0.263306\n",
      "407  2009-12-05  0.409921    0.46  2009    49 -0.082282\n",
      "408  2009-12-13  0.472087    0.53  2009    50  0.331204\n",
      "409  2009-12-21  0.324728    0.00  2009    52 -0.648940\n",
      "410  2009-12-29  0.086512    0.00  2009    53 -2.233412\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.010645    0.00  2001     1 -2.129508\n",
      "1    2001-01-13  0.206769    0.00  2001     2 -0.927136\n",
      "2    2001-01-21  0.267313    0.00  2001     3 -0.555958\n",
      "3    2001-01-29  0.240836    0.20  2001     5 -0.718282\n",
      "4    2001-02-06  0.193417    0.15  2001     6 -1.008995\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.230073    0.25  2009    48 -0.784269\n",
      "407  2009-12-05  0.243632    0.24  2009    49 -0.701139\n",
      "408  2009-12-13  0.251111    0.00  2009    50 -0.655289\n",
      "409  2009-12-21  0.099246    0.00  2009    52 -1.586325\n",
      "410  2009-12-29  0.064990    0.00  2009    53 -1.796340\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.379890    0.50  2001     1 -0.382765\n",
      "1    2001-01-13  0.482679    0.58  2001     2  0.319215\n",
      "2    2001-01-21  0.516259    0.59  2001     3  0.548542\n",
      "3    2001-01-29  0.434421    0.50  2001     5 -0.010351\n",
      "4    2001-02-06  0.494805    0.54  2001     6  0.402030\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.427085    0.43  2009    48 -0.060454\n",
      "407  2009-12-05  0.547380    0.57  2009    49  0.761079\n",
      "408  2009-12-13  0.531070    0.58  2009    50  0.649694\n",
      "409  2009-12-21  0.295704    0.00  2009    52 -0.957702\n",
      "410  2009-12-29  0.027861    0.00  2009    53 -2.786888\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.102270    0.00  2001     1 -1.996014\n",
      "1    2001-01-13  0.454431    0.53  2001     2  0.498869\n",
      "2    2001-01-21  0.323514    0.32  2001     3 -0.428613\n",
      "3    2001-01-29  0.301661    0.31  2001     5 -0.583432\n",
      "4    2001-02-06  0.394733    0.44  2001     6  0.075938\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.388573    0.44  2009    48  0.032299\n",
      "407  2009-12-05  0.402760    0.47  2009    49  0.132804\n",
      "408  2009-12-13  0.353782    0.44  2009    50 -0.214182\n",
      "409  2009-12-21  0.043947    0.00  2009    52 -2.409204\n",
      "410  2009-12-29  0.006670    0.00  2009    53 -2.673294\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.369625    0.45  2001     1 -0.439541\n",
      "1    2001-01-13  0.429563    0.43  2001     2 -0.019547\n",
      "2    2001-01-21  0.470784    0.48  2001     3  0.269293\n",
      "3    2001-01-29  0.370358    0.37  2001     5 -0.434406\n",
      "4    2001-02-06  0.372263    0.37  2001     6 -0.421060\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.402059    0.40  2009    48 -0.212272\n",
      "407  2009-12-05  0.389658    0.39  2009    49 -0.299172\n",
      "408  2009-12-13  0.545184    0.56  2009    50  0.790614\n",
      "409  2009-12-21  0.447916    0.55  2009    52  0.109054\n",
      "410  2009-12-29  0.277300    0.32  2009    53 -1.086474\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.243674    0.26  2001     1 -1.223671\n",
      "1    2001-01-13  0.424116    0.44  2001     2 -0.087252\n",
      "2    2001-01-21  0.393786    0.39  2001     3 -0.278268\n",
      "3    2001-01-29  0.314939    0.31  2001     5 -0.774846\n",
      "4    2001-02-06  0.464902    0.48  2001     6  0.169616\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.465734    0.48  2009    48  0.174854\n",
      "407  2009-12-05  0.447390    0.47  2009    49  0.059327\n",
      "408  2009-12-13  0.556760    0.59  2009    50  0.748131\n",
      "409  2009-12-21  0.307880    0.00  2009    52 -0.819305\n",
      "410  2009-12-29  0.034211    0.00  2009    53 -2.542862\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278983    0.00  2001     1 -1.146332\n",
      "1    2001-01-13  0.494910    0.51  2001     2  0.371173\n",
      "2    2001-01-21  0.496092    0.51  2001     3  0.379474\n",
      "3    2001-01-29  0.427992    0.43  2001     5 -0.099118\n",
      "4    2001-02-06  0.400512    0.41  2001     6 -0.292244\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.363952    0.37  2009    48 -0.549184\n",
      "407  2009-12-05  0.400487    0.40  2009    49 -0.292423\n",
      "408  2009-12-13  0.506771    0.52  2009    50  0.454529\n",
      "409  2009-12-21  0.387530    0.53  2009    52 -0.383480\n",
      "410  2009-12-29  0.279894    0.27  2009    53 -1.139931\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278060    0.09  2001     1 -0.967137\n",
      "1    2001-01-13  0.445159    0.48  2001     2  0.070382\n",
      "2    2001-01-21  0.488982    0.52  2001     3  0.342478\n",
      "3    2001-01-29  0.362487    0.37  2001     5 -0.442927\n",
      "4    2001-02-06  0.430732    0.45  2001     6 -0.019192\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.430379    0.44  2009    48 -0.021388\n",
      "407  2009-12-05  0.419919    0.43  2009    49 -0.086330\n",
      "408  2009-12-13  0.526648    0.55  2009    50  0.576347\n",
      "409  2009-12-21  0.457440    0.61  2009    52  0.146632\n",
      "410  2009-12-29  0.301938    0.38  2009    53 -0.818877\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.264043    0.00  2001     1 -1.060146\n",
      "1    2001-01-13  0.354618    0.39  2001     2 -0.405065\n",
      "2    2001-01-21  0.427990    0.47  2001     3  0.125603\n",
      "3    2001-01-29  0.339495    0.35  2001     5 -0.514438\n",
      "4    2001-02-06  0.324134    0.34  2001     6 -0.625540\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.332713    0.35  2009    48 -0.563495\n",
      "407  2009-12-05  0.370253    0.40  2009    49 -0.291984\n",
      "408  2009-12-13  0.517201    0.57  2009    50  0.770822\n",
      "409  2009-12-21  0.353636    0.45  2009    52 -0.412164\n",
      "410  2009-12-29  0.261079    0.00  2009    53 -1.081585\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n"
     ]
    }
   ],
   "source": [
    "### targets\n",
    "basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona','Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n",
    "path_targets = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/csv_VHI/'\n",
    "targets_df_train = pd.DataFrame()\n",
    "targets_df_val = pd.DataFrame()\n",
    "targets_df_test = pd.DataFrame()\n",
    "targets_df_trainVal = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', path=path_targets+basin+'.csv')\n",
    "    targets_df_train[basin] = target_df_train.mean_std\n",
    "    targets_df_val[basin] = target_df_val.mean_std\n",
    "    targets_df_test[basin] = target_df_test.mean_std\n",
    "    targets_df_trainVal[basin] = target_df_trainVal.mean_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f75ec",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Dora-Piemonte Nord-Piemonte Sud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03f0538c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### wrapper best 5 features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "best5_wrapper_fulldf_train = pd.DataFrame()\n",
    "best5_wrapper_fulldf_val = pd.DataFrame()\n",
    "best5_wrapper_fulldf_test = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    best5_wrapper_train_temp = pd.read_csv(path_features+basin+'_wrapper_best5_train_withSnow.csv')\n",
    "    best5_wrapper_val_temp = pd.read_csv(path_features+basin+'_wrapper_best5_val_withSnow.csv')\n",
    "    best5_wrapper_test_temp = pd.read_csv(path_features+basin+'_wrapper_best5_test_withSnow.csv')\n",
    "    best5_wrapper_fulldf_train[basin+'_'+best5_wrapper_train_temp.columns.values] = best5_wrapper_train_temp\n",
    "    best5_wrapper_fulldf_val[basin+'_'+best5_wrapper_val_temp.columns.values] = best5_wrapper_val_temp\n",
    "    best5_wrapper_fulldf_test[basin+'_'+best5_wrapper_test_temp.columns.values] = best5_wrapper_test_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab5b8347",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CMI features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "CMI_fulldf_train = pd.DataFrame()\n",
    "CMI_fulldf_val = pd.DataFrame()\n",
    "CMI_fulldf_test = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_train_withSnow.csv')\n",
    "    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_val_withSnow.csv')\n",
    "    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_test_withSnow.csv')\n",
    "    CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n",
    "    CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n",
    "    CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f713a615",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CMI best5 features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "best5_CMI_fulldf_train = pd.DataFrame()\n",
    "best5_CMI_fulldf_val = pd.DataFrame()\n",
    "best5_CMI_fulldf_test = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_train_withSnow.csv')\n",
    "    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_val_withSnow.csv')\n",
    "    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_test_withSnow.csv')\n",
    "    best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n",
    "    best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n",
    "    best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1eb826dc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fulldf_train_withClass = pd.DataFrame()\n",
    "fulldf_val_withClass = pd.DataFrame()\n",
    "fulldf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "    fulldf_train_withClass = pd.concat((fulldf_train_withClass,pd.concat((CMI_fulldf_train,pd.DataFrame(1+i*np.ones(len(CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    fulldf_val_withClass = pd.concat((fulldf_val_withClass,pd.concat((CMI_fulldf_val,pd.DataFrame(1+i*np.ones(len(CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    fulldf_test_withClass = pd.concat((fulldf_test_withClass,pd.concat((CMI_fulldf_test,pd.DataFrame(1+i*np.ones(len(CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdaa86af",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n",
    "colnames = [x for x in best5_wrapper_fulldf_train.columns if x.startswith('Dora') or x.startswith('Piemonte_Nord') or x.startswith('Piemonte_Sud')]\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass = pd.DataFrame()\n",
    "best5_wrapper_clusterdf_val_withClass = pd.DataFrame()\n",
    "best5_wrapper_clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    best5_wrapper_clusterdf_train_withClass = pd.concat((best5_wrapper_clusterdf_train_withClass,pd.concat((best5_wrapper_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_clusterdf_val_withClass = pd.concat((best5_wrapper_clusterdf_val_withClass,pd.concat((best5_wrapper_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_clusterdf_test_withClass = pd.concat((best5_wrapper_clusterdf_test_withClass,pd.concat((best5_wrapper_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    best5_wrapper_clusterdf_train_withClass[clust_basins[i]] = best5_wrapper_clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_clusterdf_val_withClass[clust_basins[i]] = best5_wrapper_clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_clusterdf_test_withClass[clust_basins[i]] = best5_wrapper_clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass = best5_wrapper_clusterdf_train_withClass.loc[:,best5_wrapper_clusterdf_train_withClass.columns != 'basin']\n",
    "best5_wrapper_clusterdf_val_withClass = best5_wrapper_clusterdf_val_withClass.loc[:,best5_wrapper_clusterdf_val_withClass.columns != 'basin']\n",
    "best5_wrapper_clusterdf_test_withClass = best5_wrapper_clusterdf_test_withClass.loc[:,best5_wrapper_clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e94208d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f17d980",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2318881490677389\n",
      "-0.08430042638033441\n",
      "-0.00022427793868806667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((best5_wrapper_clusterdf_train_withClass,best5_wrapper_clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66faea30",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n",
    "colnames = [x for x in CMI_fulldf_train.columns if x.startswith('Dora') or x.startswith('Piemonte_Nord') or x.startswith('Piemonte_Sud')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c8f7748",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14a53dab",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4171782877437771\n",
      "-0.16586872266323027\n",
      "-0.3353356345507341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "695da2c3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n",
    "colnames = [x for x in best5_CMI_fulldf_train.columns if x.startswith('Dora') or x.startswith('Piemonte_Nord') or x.startswith('Piemonte_Sud')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((best5_CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((best5_CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((best5_CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03a14a0c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92e79e49",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6080459173843054\n",
      "-0.23544322028458642\n",
      "-0.3642241420355754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea987e5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Adda - Ticino - LambroOlona - OglioIseo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4f45472",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### wrapper best 5 features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "best5_wrapper_fulldf_train = pd.DataFrame()\n",
    "best5_wrapper_fulldf_val = pd.DataFrame()\n",
    "best5_wrapper_fulldf_test = pd.DataFrame()\n",
    "\n",
    "for basin in ['Lambro_Olona','Oglio_Iseo']:\n",
    "    best5_wrapper_train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_train.csv')\n",
    "    best5_wrapper_val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_val.csv')\n",
    "    best5_wrapper_test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_test.csv')\n",
    "    best5_wrapper_fulldf_train[basin+'_'+best5_wrapper_train_temp.columns.values] = best5_wrapper_train_temp\n",
    "    best5_wrapper_fulldf_val[basin+'_'+best5_wrapper_val_temp.columns.values] = best5_wrapper_val_temp\n",
    "    best5_wrapper_fulldf_test[basin+'_'+best5_wrapper_test_temp.columns.values] = best5_wrapper_test_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a3c652c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### wrapper best 5 features\n",
    "\n",
    "for basin in ['Adda','Ticino']:\n",
    "    best5_wrapper_train_temp = pd.read_csv(path_features+basin+'_wrapper_best5_train_withSnow.csv')\n",
    "    best5_wrapper_val_temp = pd.read_csv(path_features+basin+'_wrapper_best5_val_withSnow.csv')\n",
    "    best5_wrapper_test_temp = pd.read_csv(path_features+basin+'_wrapper_best5_test_withSnow.csv')\n",
    "    best5_wrapper_fulldf_train[basin+'_'+best5_wrapper_train_temp.columns.values] = best5_wrapper_train_temp\n",
    "    best5_wrapper_fulldf_val[basin+'_'+best5_wrapper_val_temp.columns.values] = best5_wrapper_val_temp\n",
    "    best5_wrapper_fulldf_test[basin+'_'+best5_wrapper_test_temp.columns.values] = best5_wrapper_test_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43b25300",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino']\n",
    "colnames = [x for x in best5_wrapper_fulldf_train.columns if x.startswith('Adda') or x.startswith('Lambro_Olona') or x.startswith('Oglio_Iseo') or x.startswith('Ticino')]\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass = pd.DataFrame()\n",
    "best5_wrapper_clusterdf_val_withClass = pd.DataFrame()\n",
    "best5_wrapper_clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    best5_wrapper_clusterdf_train_withClass = pd.concat((best5_wrapper_clusterdf_train_withClass,pd.concat((best5_wrapper_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_clusterdf_val_withClass = pd.concat((best5_wrapper_clusterdf_val_withClass,pd.concat((best5_wrapper_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_clusterdf_test_withClass = pd.concat((best5_wrapper_clusterdf_test_withClass,pd.concat((best5_wrapper_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    best5_wrapper_clusterdf_train_withClass[clust_basins[i]] = best5_wrapper_clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_clusterdf_val_withClass[clust_basins[i]] = best5_wrapper_clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_clusterdf_test_withClass[clust_basins[i]] = best5_wrapper_clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass = best5_wrapper_clusterdf_train_withClass.loc[:,best5_wrapper_clusterdf_train_withClass.columns != 'basin']\n",
    "best5_wrapper_clusterdf_val_withClass = best5_wrapper_clusterdf_val_withClass.loc[:,best5_wrapper_clusterdf_val_withClass.columns != 'basin']\n",
    "best5_wrapper_clusterdf_test_withClass = best5_wrapper_clusterdf_test_withClass.loc[:,best5_wrapper_clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bbf34353",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdcd3a80",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.065274154848455\n",
      "-0.07392322281319319\n",
      "0.005305886280704719\n",
      "0.0181809008659527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((best5_wrapper_clusterdf_train_withClass,best5_wrapper_clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "235efa3f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CMI features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "CMI_fulldf_train = pd.DataFrame()\n",
    "CMI_fulldf_val = pd.DataFrame()\n",
    "CMI_fulldf_test = pd.DataFrame()\n",
    "\n",
    "for basin in ['Lambro_Olona','Oglio_Iseo']:\n",
    "    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_train.csv')\n",
    "    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_val.csv')\n",
    "    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_test.csv')\n",
    "    CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n",
    "    CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n",
    "    CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ddcf00f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CMI features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "for basin in ['Adda','Ticino']:\n",
    "    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_train_withSnow.csv')\n",
    "    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_val_withSnow.csv')\n",
    "    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_test_withSnow.csv')\n",
    "    CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n",
    "    CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n",
    "    CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b79835af",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino']\n",
    "colnames = [x for x in CMI_fulldf_train.columns if x.startswith('Adda') or x.startswith('Lambro_Olona') or x.startswith('Oglio_Iseo') or x.startswith('Ticino')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6ef5728",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d3cf704",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.013986823920808522\n",
      "0.03628562869164598\n",
      "0.00023305432522968683\n",
      "0.09976086057892153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b767091",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CMI best5 features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "best5_CMI_fulldf_train = pd.DataFrame()\n",
    "best5_CMI_fulldf_val = pd.DataFrame()\n",
    "best5_CMI_fulldf_test = pd.DataFrame()\n",
    "\n",
    "for basin in ['Lambro_Olona','Oglio_Iseo']:\n",
    "    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_train.csv')\n",
    "    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_val.csv')\n",
    "    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_test.csv')\n",
    "    best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n",
    "    best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n",
    "    best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "34f2cbaa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CMI best5 features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "for basin in ['Adda','Ticino']:\n",
    "    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_train_withSnow.csv')\n",
    "    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_val_withSnow.csv')\n",
    "    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_test_withSnow.csv')\n",
    "    best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n",
    "    best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n",
    "    best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "56ddbd91",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino']\n",
    "colnames = [x for x in best5_CMI_fulldf_train.columns if x.startswith('Adda') or x.startswith('Lambro_Olona') or x.startswith('Oglio_Iseo') or x.startswith('Ticino')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((best5_CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((best5_CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((best5_CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4ede74d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6822d44a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05067608676059154\n",
      "0.07380032998319885\n",
      "0.03200274171462392\n",
      "0.13688562773577584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
