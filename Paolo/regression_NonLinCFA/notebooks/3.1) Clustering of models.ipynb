{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288de91a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f5d87f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/methods/CMI_FS\")\n",
    "from feature_selection import forwardFeatureSelection\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/methods/LinCFA\")\n",
    "from LinCFA import LinCFA\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/methods/NonLinCFA\")\n",
    "from NonLinCFA import NonLinCFA\n",
    "\n",
    "sys.path.append(\"/Users/paolo/Documents/Droughts/Paolo/regression_NonLinCFA\")\n",
    "from aux import standardize,unfold_dataset,compute_r2,prepare_target,prepare_features,aggregate_unfolded_data,aggregate_unfolded_data_onlyTrain,FS_with_linearWrapper,compare_methods, compute_r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c37799f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_cells(output,selected_colnames, xmin=9, xmax=11, ymin=44, ymax=45.5):\n",
    "    x = []\n",
    "    y = []\n",
    "    colors = cm.rainbow(np.linspace(0,1,len(output)))\n",
    "    np.random.shuffle(colors)\n",
    "    fig, ax = plt.subplots(2)\n",
    "    ax[0].set_xlim(xmin,xmax)\n",
    "    ax[1].set_xlim(xmin,xmax)\n",
    "    ax[0].set_ylim(ymin,ymax)\n",
    "    ax[1].set_ylim(ymin,ymax)\n",
    "    for i in range(len(output)): \n",
    "        #print(len(output[i]))\n",
    "        x = []\n",
    "        y = []\n",
    "        \n",
    "        for datum in output[i]:\n",
    "            x.append(float(datum.split('_')[1]))\n",
    "            y.append(float(datum.split('_')[2]))\n",
    "        ax[0].scatter(x,y,color=colors[i])\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    col = cm.rainbow(np.linspace(0,1,len(selected_colnames)))\n",
    "    for i in range(len(selected_colnames)): \n",
    "        idx = int(selected_colnames[i].split('_')[-1])\n",
    "        for datum in output[idx]:\n",
    "            x.append(float(datum.split('_')[1]))\n",
    "            y.append(float(datum.split('_')[2]))\n",
    "        ax[1].scatter(x,y,color=col[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c16e3a3",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(f'tensorflow version {tf.__version__}')\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from numpy import * \n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e18af23d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "\n",
    "    # Children of hierarchical clustering\n",
    "    children = model.children_\n",
    "\n",
    "    # Distances between each pair of children\n",
    "    # Since we don't have this information, we can use a uniform one for plotting\n",
    "    distance = np.arange(children.shape[0])\n",
    "\n",
    "    # The number of observations contained in each cluster level\n",
    "    no_of_observations = np.arange(2, children.shape[0]+2)\n",
    "\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "    linkage_matrix = np.column_stack([children, distance, no_of_observations]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee498c00",
   "metadata": {},
   "source": [
    "# Emiliani1-Emiliani2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65b4ef7",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6748c934",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.379890    0.50  2001     1 -0.382765\n",
      "1    2001-01-13  0.482679    0.58  2001     2  0.319215\n",
      "2    2001-01-21  0.516259    0.59  2001     3  0.548542\n",
      "3    2001-01-29  0.434421    0.50  2001     5 -0.010351\n",
      "4    2001-02-06  0.494805    0.54  2001     6  0.402030\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.427085    0.43  2009    48 -0.060454\n",
      "407  2009-12-05  0.547380    0.57  2009    49  0.761079\n",
      "408  2009-12-13  0.531070    0.58  2009    50  0.649694\n",
      "409  2009-12-21  0.295704    0.00  2009    52 -0.957702\n",
      "410  2009-12-29  0.027861    0.00  2009    53 -2.786888\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n"
     ]
    }
   ],
   "source": [
    "### targets\n",
    "path_targets = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/csv_VHI/'\n",
    "target_df_train_E1,target_df_val_E1,target_df_test_E1,target_df_trainVal_E1 = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', path=path_targets+'Emiliani1.csv')\n",
    "target_df_train_E2,target_df_val_E2,target_df_test_E2,target_df_trainVal_E2 = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', path=path_targets+'Emiliani2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34c444cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### wrapper best 5 features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "best5_wrapper_train_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_wrapper_best5_train.csv')\n",
    "best5_wrapper_val_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_wrapper_best5_val.csv')\n",
    "best5_wrapper_test_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_wrapper_best5_test.csv')\n",
    "\n",
    "best5_wrapper_train_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_wrapper_best5_train.csv')\n",
    "best5_wrapper_val_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_wrapper_best5_val.csv')\n",
    "best5_wrapper_test_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_wrapper_best5_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "459fde2e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CMI features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "CMI_train_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_CMI_train.csv')\n",
    "CMI_val_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_CMI_val.csv')\n",
    "CMI_test_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_CMI_test.csv')\n",
    "\n",
    "CMI_train_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_CMI_train.csv')\n",
    "CMI_val_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_CMI_val.csv')\n",
    "CMI_test_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_CMI_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89b9c9e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CMI best 5 features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "best5_CMI_train_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_best5_CMI_train.csv')\n",
    "best5_CMI_val_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_best5_CMI_val.csv')\n",
    "best5_CMI_test_E1 = pd.read_csv(path_features+'Emiliani1_nonLinCFA_best5_CMI_test.csv')\n",
    "\n",
    "best5_CMI_train_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_best5_CMI_train.csv')\n",
    "best5_CMI_val_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_best5_CMI_val.csv')\n",
    "best5_CMI_test_E2 = pd.read_csv(path_features+'Emiliani2_nonLinCFA_best5_CMI_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13b11c2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## feedforward NN with wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb5d622",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Emiliani1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "95f6a5ea",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:01:40.769632: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-01 10:01:40.770898: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model_emiliani1_wrapperBest5 = Sequential()\n",
    "model_emiliani1_wrapperBest5.add(Dense(5, input_dim=5, activation='relu')) \n",
    "model_emiliani1_wrapperBest5.add(Dense(1)) # Output\n",
    "\n",
    "model_emiliani1_wrapperBest5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani1_wrapperBest5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "52c2a87e",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.6589 - val_loss: 0.6451\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6589 - val_loss: 0.6459\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6592 - val_loss: 0.6463\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6581 - val_loss: 0.6458\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6578 - val_loss: 0.6459\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6574 - val_loss: 0.6458\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6573 - val_loss: 0.6454\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6569 - val_loss: 0.6460\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6567 - val_loss: 0.6457\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6566 - val_loss: 0.6463\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6565 - val_loss: 0.6460\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6560 - val_loss: 0.6464\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6558 - val_loss: 0.6463\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6556 - val_loss: 0.6460\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6556 - val_loss: 0.6461\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6552 - val_loss: 0.6467\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6552 - val_loss: 0.6480\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6549 - val_loss: 0.6467\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6545 - val_loss: 0.6476\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6542 - val_loss: 0.6478\n",
      "Epoch 21/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6240Restoring model weights from the end of the best epoch: 1.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6542 - val_loss: 0.6473\n",
      "Epoch 21: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28be7c850>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emiliani1_wrapperBest5.fit(best5_wrapper_train_E1,target_df_train_E1.mean_std,validation_data=(best5_wrapper_val_E1,target_df_val_E1.mean_std),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6ce97aa7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:05:16.217225: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3041542505571182"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(target_df_test_E1.mean_std, model_emiliani1_wrapperBest5.predict(best5_wrapper_test_E1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574bb196",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Emiliani2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aff8d7f7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_emiliani2_wrapperBest5 = Sequential()\n",
    "model_emiliani2_wrapperBest5.add(Dense(5, input_dim=5, activation='relu')) \n",
    "model_emiliani2_wrapperBest5.add(Dense(1)) # Output\n",
    "\n",
    "model_emiliani2_wrapperBest5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani2_wrapperBest5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2d56a708",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.7843 - val_loss: 0.7550\n",
      "Epoch 2/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6532"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:06:33.435236: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-01 10:06:33.588508: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7776 - val_loss: 0.7471\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7722 - val_loss: 0.7403\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7674 - val_loss: 0.7359\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7642 - val_loss: 0.7310\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7611 - val_loss: 0.7263\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7585 - val_loss: 0.7237\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7565 - val_loss: 0.7209\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7542 - val_loss: 0.7187\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7526 - val_loss: 0.7169\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7514 - val_loss: 0.7157\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7500 - val_loss: 0.7132\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7487 - val_loss: 0.7118\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7476 - val_loss: 0.7103\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7467 - val_loss: 0.7075\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7457 - val_loss: 0.7065\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7441 - val_loss: 0.7056\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7431 - val_loss: 0.7047\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7416 - val_loss: 0.7036\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7410 - val_loss: 0.7030\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7403 - val_loss: 0.7011\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7397 - val_loss: 0.7012\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7392 - val_loss: 0.6994\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7384 - val_loss: 0.6993\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7378 - val_loss: 0.6968\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7371 - val_loss: 0.6958\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7364 - val_loss: 0.6957\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7360 - val_loss: 0.6940\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7354 - val_loss: 0.6940\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7351 - val_loss: 0.6937\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7348 - val_loss: 0.6940\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7343 - val_loss: 0.6928\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7340 - val_loss: 0.6923\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7337 - val_loss: 0.6918\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7334 - val_loss: 0.6912\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7329 - val_loss: 0.6926\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7325 - val_loss: 0.6931\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7318 - val_loss: 0.6925\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7316 - val_loss: 0.6909\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7310 - val_loss: 0.6917\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7306 - val_loss: 0.6914\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7307 - val_loss: 0.6895\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7299 - val_loss: 0.6897\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7297 - val_loss: 0.6888\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7289 - val_loss: 0.6891\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7287 - val_loss: 0.6892\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7282 - val_loss: 0.6891\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7278 - val_loss: 0.6888\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7273 - val_loss: 0.6881\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7271 - val_loss: 0.6879\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7264 - val_loss: 0.6863\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7259 - val_loss: 0.6859\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7256 - val_loss: 0.6845\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7253 - val_loss: 0.6833\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7249 - val_loss: 0.6850\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7248 - val_loss: 0.6829\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7242 - val_loss: 0.6830\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7240 - val_loss: 0.6827\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7235 - val_loss: 0.6819\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7234 - val_loss: 0.6806\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7229 - val_loss: 0.6807\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7229 - val_loss: 0.6806\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7222 - val_loss: 0.6806\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7218 - val_loss: 0.6789\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7214 - val_loss: 0.6787\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7210 - val_loss: 0.6780\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7209 - val_loss: 0.6766\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7206 - val_loss: 0.6779\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7200 - val_loss: 0.6770\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7198 - val_loss: 0.6765\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7194 - val_loss: 0.6770\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7191 - val_loss: 0.6777\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7189 - val_loss: 0.6771\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7187 - val_loss: 0.6762\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7181 - val_loss: 0.6767\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7181 - val_loss: 0.6758\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7177 - val_loss: 0.6751\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7177 - val_loss: 0.6755\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7171 - val_loss: 0.6737\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7170 - val_loss: 0.6730\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7164 - val_loss: 0.6737\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7166 - val_loss: 0.6725\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7164 - val_loss: 0.6734\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7158 - val_loss: 0.6720\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7157 - val_loss: 0.6700\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7156 - val_loss: 0.6717\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7157 - val_loss: 0.6703\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7152 - val_loss: 0.6699\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7146 - val_loss: 0.6689\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7146 - val_loss: 0.6710\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7147 - val_loss: 0.6697\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7136 - val_loss: 0.6678\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7131 - val_loss: 0.6681\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7130 - val_loss: 0.6669\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7126 - val_loss: 0.6665\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7125 - val_loss: 0.6650\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7123 - val_loss: 0.6661\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7122 - val_loss: 0.6653\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7120 - val_loss: 0.6633\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7114 - val_loss: 0.6641\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7120 - val_loss: 0.6640\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7113 - val_loss: 0.6639\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7112 - val_loss: 0.6624\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7111 - val_loss: 0.6642\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7108 - val_loss: 0.6627\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7109 - val_loss: 0.6636\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7107 - val_loss: 0.6627\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7115 - val_loss: 0.6616\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7102 - val_loss: 0.6634\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7100 - val_loss: 0.6624\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7098 - val_loss: 0.6610\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7096 - val_loss: 0.6620\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7094 - val_loss: 0.6614\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7097 - val_loss: 0.6628\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7094 - val_loss: 0.6611\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7092 - val_loss: 0.6604\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7092 - val_loss: 0.6597\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7090 - val_loss: 0.6597\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7086 - val_loss: 0.6595\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7087 - val_loss: 0.6597\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7084 - val_loss: 0.6598\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7082 - val_loss: 0.6600\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7085 - val_loss: 0.6599\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7082 - val_loss: 0.6589\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7079 - val_loss: 0.6590\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7082 - val_loss: 0.6586\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7077 - val_loss: 0.6587\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7074 - val_loss: 0.6588\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7074 - val_loss: 0.6577\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7073 - val_loss: 0.6575\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7072 - val_loss: 0.6573\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7073 - val_loss: 0.6586\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7070 - val_loss: 0.6581\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7067 - val_loss: 0.6578\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7068 - val_loss: 0.6563\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7070 - val_loss: 0.6585\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7066 - val_loss: 0.6569\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7063 - val_loss: 0.6555\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7062 - val_loss: 0.6562\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7060 - val_loss: 0.6559\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7060 - val_loss: 0.6571\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7060 - val_loss: 0.6571\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7060 - val_loss: 0.6570\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7057 - val_loss: 0.6564\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7057 - val_loss: 0.6554\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7056 - val_loss: 0.6570\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7058 - val_loss: 0.6558\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7054 - val_loss: 0.6567\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7059 - val_loss: 0.6546\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7052 - val_loss: 0.6569\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7053 - val_loss: 0.6576\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7056 - val_loss: 0.6579\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7051 - val_loss: 0.6555\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7049 - val_loss: 0.6553\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7051 - val_loss: 0.6568\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7046 - val_loss: 0.6563\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7046 - val_loss: 0.6567\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7044 - val_loss: 0.6572\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7044 - val_loss: 0.6568\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7043 - val_loss: 0.6566\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7044 - val_loss: 0.6563\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7043 - val_loss: 0.6561\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7045 - val_loss: 0.6556\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7040 - val_loss: 0.6557\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7039 - val_loss: 0.6554\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7039 - val_loss: 0.6577\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7038 - val_loss: 0.6567\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7038 - val_loss: 0.6554\n",
      "Epoch 169/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5948Restoring model weights from the end of the best epoch: 149.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7034 - val_loss: 0.6559\n",
      "Epoch 169: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28bd6f490>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emiliani2_wrapperBest5.fit(best5_wrapper_train_E2,target_df_train_E2.mean_std,validation_data=(best5_wrapper_val_E2,target_df_val_E2.mean_std),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f7efb11b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:06:57.197486: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.16591095103637798"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(target_df_test_E2.mean_std, model_emiliani2_wrapperBest5.predict(best5_wrapper_test_E2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "58b9b2ae",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_46 (Dense)            (None, 4)                 52        \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 57\n",
      "Trainable params: 57\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.0964"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:48:54.189288: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-01 10:48:54.353162: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 12ms/step - loss: 1.0964 - val_loss: 1.4965\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0148 - val_loss: 1.3574\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9536 - val_loss: 1.2370\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9072 - val_loss: 1.1516\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8768 - val_loss: 1.0846\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8534 - val_loss: 1.0262\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8331 - val_loss: 0.9803\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8170 - val_loss: 0.9393\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8056 - val_loss: 0.9088\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7959 - val_loss: 0.8898\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7888 - val_loss: 0.8802\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7819 - val_loss: 0.8707\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7760 - val_loss: 0.8607\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7702 - val_loss: 0.8565\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7662 - val_loss: 0.8495\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7610 - val_loss: 0.8436\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7577 - val_loss: 0.8392\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7545 - val_loss: 0.8296\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7511 - val_loss: 0.8248\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7489 - val_loss: 0.8268\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7455 - val_loss: 0.8291\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7429 - val_loss: 0.8341\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7397 - val_loss: 0.8298\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7370 - val_loss: 0.8268\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7343 - val_loss: 0.8208\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7319 - val_loss: 0.8171\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7293 - val_loss: 0.8117\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7267 - val_loss: 0.8065\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7244 - val_loss: 0.8060\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7223 - val_loss: 0.8022\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7200 - val_loss: 0.7965\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7177 - val_loss: 0.7998\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7153 - val_loss: 0.7969\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7128 - val_loss: 0.7919\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7106 - val_loss: 0.7876\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7084 - val_loss: 0.7847\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7063 - val_loss: 0.7820\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7041 - val_loss: 0.7861\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7023 - val_loss: 0.7850\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7008 - val_loss: 0.7862\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6992 - val_loss: 0.7745\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6971 - val_loss: 0.7759\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6958 - val_loss: 0.7719\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6941 - val_loss: 0.7675\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6922 - val_loss: 0.7616\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6913 - val_loss: 0.7521\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6891 - val_loss: 0.7554\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6872 - val_loss: 0.7479\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6857 - val_loss: 0.7457\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6843 - val_loss: 0.7433\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6828 - val_loss: 0.7374\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6809 - val_loss: 0.7322\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6803 - val_loss: 0.7299\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6780 - val_loss: 0.7285\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6770 - val_loss: 0.7254\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6756 - val_loss: 0.7236\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6746 - val_loss: 0.7240\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6731 - val_loss: 0.7271\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6728 - val_loss: 0.7300\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6714 - val_loss: 0.7214\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6703 - val_loss: 0.7180\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6693 - val_loss: 0.7178\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6688 - val_loss: 0.7216\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6680 - val_loss: 0.7192\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6672 - val_loss: 0.7165\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6664 - val_loss: 0.7152\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6655 - val_loss: 0.7168\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6643 - val_loss: 0.7152\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6639 - val_loss: 0.7143\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6635 - val_loss: 0.7143\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6623 - val_loss: 0.7131\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6615 - val_loss: 0.7153\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6607 - val_loss: 0.7141\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6602 - val_loss: 0.7161\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6596 - val_loss: 0.7144\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6590 - val_loss: 0.7170\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6589 - val_loss: 0.7204\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6582 - val_loss: 0.7134\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6575 - val_loss: 0.7160\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6565 - val_loss: 0.7160\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6556 - val_loss: 0.7150\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6550 - val_loss: 0.7166\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6545 - val_loss: 0.7208\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6545 - val_loss: 0.7193\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6534 - val_loss: 0.7158\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6531 - val_loss: 0.7200\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6526 - val_loss: 0.7194\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6519 - val_loss: 0.7187\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6511 - val_loss: 0.7131\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6506 - val_loss: 0.7153\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6498 - val_loss: 0.7184\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6494 - val_loss: 0.7173\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6496 - val_loss: 0.7226\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.7153\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.7162\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6478 - val_loss: 0.7215\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6471 - val_loss: 0.7221\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6465 - val_loss: 0.7220\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6463 - val_loss: 0.7206\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6457 - val_loss: 0.7167\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6454 - val_loss: 0.7184\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6448 - val_loss: 0.7182\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6442 - val_loss: 0.7175\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6442 - val_loss: 0.7146\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6443 - val_loss: 0.7134\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6428 - val_loss: 0.7222\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6434 - val_loss: 0.7270\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6425 - val_loss: 0.7169\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6422 - val_loss: 0.7194\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6418 - val_loss: 0.7178\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6420 - val_loss: 0.7203\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6413 - val_loss: 0.7213\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6407 - val_loss: 0.7210\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6402 - val_loss: 0.7210\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6398 - val_loss: 0.7187\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6395 - val_loss: 0.7213\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6396 - val_loss: 0.7194\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6393 - val_loss: 0.7265\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6393 - val_loss: 0.7258\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6390 - val_loss: 0.7261\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6382 - val_loss: 0.7275\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6385 - val_loss: 0.7190\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6379 - val_loss: 0.7227\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6372 - val_loss: 0.7229\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6369 - val_loss: 0.7231\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6366 - val_loss: 0.7227\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6363 - val_loss: 0.7281\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6362 - val_loss: 0.7218\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6359 - val_loss: 0.7272\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6353 - val_loss: 0.7248\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6352 - val_loss: 0.7265\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6350 - val_loss: 0.7208\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6348 - val_loss: 0.7256\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6343 - val_loss: 0.7258\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6343 - val_loss: 0.7257\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6340 - val_loss: 0.7215\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6335 - val_loss: 0.7266\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6333 - val_loss: 0.7257\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6336 - val_loss: 0.7239\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6329 - val_loss: 0.7187\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6331 - val_loss: 0.7288\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6326 - val_loss: 0.7218\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6325 - val_loss: 0.7233\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6318 - val_loss: 0.7238\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6316 - val_loss: 0.7234\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6315 - val_loss: 0.7188\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6309 - val_loss: 0.7180\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6305 - val_loss: 0.7199\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6302 - val_loss: 0.7205\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6300 - val_loss: 0.7189\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6296 - val_loss: 0.7177\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6293 - val_loss: 0.7151\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6287 - val_loss: 0.7180\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6284 - val_loss: 0.7194\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6282 - val_loss: 0.7164\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6278 - val_loss: 0.7199\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6276 - val_loss: 0.7170\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6274 - val_loss: 0.7193\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6276 - val_loss: 0.7115\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6265 - val_loss: 0.7205\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6267 - val_loss: 0.7182\n",
      "Epoch 162/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6270 - val_loss: 0.7131\n",
      "Epoch 163/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6255 - val_loss: 0.7201\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6260 - val_loss: 0.7189\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6252 - val_loss: 0.7164\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6248 - val_loss: 0.7130\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6251 - val_loss: 0.7108\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6243 - val_loss: 0.7178\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6241 - val_loss: 0.7140\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6240 - val_loss: 0.7149\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6236 - val_loss: 0.7146\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6235 - val_loss: 0.7143\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6233 - val_loss: 0.7140\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6230 - val_loss: 0.7102\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6223 - val_loss: 0.7121\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6224 - val_loss: 0.7120\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6219 - val_loss: 0.7146\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6223 - val_loss: 0.7126\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6215 - val_loss: 0.7134\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6218 - val_loss: 0.7096\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6210 - val_loss: 0.7136\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6207 - val_loss: 0.7157\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6209 - val_loss: 0.7126\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6200 - val_loss: 0.7105\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6198 - val_loss: 0.7102\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6197 - val_loss: 0.7043\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6194 - val_loss: 0.7092\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6185 - val_loss: 0.7098\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6197 - val_loss: 0.7123\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6179 - val_loss: 0.7023\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6176 - val_loss: 0.7046\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6174 - val_loss: 0.7136\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6170 - val_loss: 0.7056\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6165 - val_loss: 0.7064\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6161 - val_loss: 0.7052\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6160 - val_loss: 0.7094\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6164 - val_loss: 0.7017\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6156 - val_loss: 0.7072\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6149 - val_loss: 0.7045\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6145 - val_loss: 0.7100\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6151 - val_loss: 0.7054\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6140 - val_loss: 0.7044\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6142 - val_loss: 0.7094\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6141 - val_loss: 0.7044\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6141 - val_loss: 0.7029\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6136 - val_loss: 0.7076\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6129 - val_loss: 0.7031\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6130 - val_loss: 0.7006\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6128 - val_loss: 0.7053\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6126 - val_loss: 0.7023\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6121 - val_loss: 0.7023\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6119 - val_loss: 0.7022\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6118 - val_loss: 0.7035\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6113 - val_loss: 0.7045\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6112 - val_loss: 0.7031\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6113 - val_loss: 0.7013\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6111 - val_loss: 0.7041\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6104 - val_loss: 0.7017\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6110 - val_loss: 0.6995\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6100 - val_loss: 0.7075\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6104 - val_loss: 0.7056\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6100 - val_loss: 0.6965\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6108 - val_loss: 0.6978\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6095 - val_loss: 0.7009\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6090 - val_loss: 0.6979\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6089 - val_loss: 0.7033\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6088 - val_loss: 0.7003\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6084 - val_loss: 0.7003\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6085 - val_loss: 0.7002\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6082 - val_loss: 0.6985\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6087 - val_loss: 0.6934\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6077 - val_loss: 0.7022\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6076 - val_loss: 0.6997\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6072 - val_loss: 0.6975\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6069 - val_loss: 0.6993\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6068 - val_loss: 0.6957\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6069 - val_loss: 0.7008\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6062 - val_loss: 0.6988\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6060 - val_loss: 0.6953\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6062 - val_loss: 0.6956\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6062 - val_loss: 0.6943\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6056 - val_loss: 0.7024\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6056 - val_loss: 0.7027\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6054 - val_loss: 0.6938\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6055 - val_loss: 0.6958\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6047 - val_loss: 0.7023\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6047 - val_loss: 0.6956\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6046 - val_loss: 0.6977\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6042 - val_loss: 0.6964\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6049 - val_loss: 0.6998\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6038 - val_loss: 0.6926\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6034 - val_loss: 0.7018\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6039 - val_loss: 0.7001\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6040 - val_loss: 0.6954\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6030 - val_loss: 0.7000\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6029 - val_loss: 0.6967\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6028 - val_loss: 0.6943\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6029 - val_loss: 0.6995\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6025 - val_loss: 0.6971\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6022 - val_loss: 0.7011\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6031 - val_loss: 0.6940\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6017 - val_loss: 0.7017\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6015 - val_loss: 0.6978\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6014 - val_loss: 0.6999\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6016 - val_loss: 0.6973\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6018 - val_loss: 0.7049\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6011 - val_loss: 0.6994\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6017 - val_loss: 0.6915\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6011 - val_loss: 0.7036\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6007 - val_loss: 0.7035\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6001 - val_loss: 0.6959\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6003 - val_loss: 0.7027\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6007 - val_loss: 0.7030\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5993 - val_loss: 0.6970\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5998 - val_loss: 0.6961\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5998 - val_loss: 0.6993\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5991 - val_loss: 0.7002\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5998 - val_loss: 0.6945\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5996 - val_loss: 0.6969\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5989 - val_loss: 0.7054\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5997 - val_loss: 0.6969\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5988 - val_loss: 0.7026\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5988 - val_loss: 0.6968\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5980 - val_loss: 0.7001\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5984 - val_loss: 0.6994\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5978 - val_loss: 0.7003\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5978 - val_loss: 0.7000\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5974 - val_loss: 0.6991\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5977 - val_loss: 0.6955\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5970 - val_loss: 0.7018\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5976 - val_loss: 0.6988\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5968 - val_loss: 0.7022\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5971 - val_loss: 0.7057\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5964 - val_loss: 0.7007\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5970 - val_loss: 0.6971\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5967 - val_loss: 0.7030\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5964 - val_loss: 0.6919\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5966 - val_loss: 0.6986\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5958 - val_loss: 0.6991\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5953 - val_loss: 0.7029\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5957 - val_loss: 0.7025\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5957 - val_loss: 0.6991\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5958 - val_loss: 0.7063\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5953 - val_loss: 0.6982\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5952 - val_loss: 0.6997\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5945 - val_loss: 0.7065\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5946 - val_loss: 0.7033\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5943 - val_loss: 0.6989\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5942 - val_loss: 0.7017\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5949 - val_loss: 0.7029\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5935 - val_loss: 0.7065\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5933 - val_loss: 0.7016\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5933 - val_loss: 0.7040\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5932 - val_loss: 0.7001\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5929 - val_loss: 0.7015\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5928 - val_loss: 0.7035\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5927 - val_loss: 0.7088\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5931 - val_loss: 0.7025\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5930 - val_loss: 0.7047\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.7033\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.7069\n",
      "Epoch 322/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.7078\n",
      "Epoch 323/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5933 - val_loss: 0.7022\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5916 - val_loss: 0.7069\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5919 - val_loss: 0.7039\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5926 - val_loss: 0.7099\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5918 - val_loss: 0.7014\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5920 - val_loss: 0.7121\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5914 - val_loss: 0.7053\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5911 - val_loss: 0.7065\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5914 - val_loss: 0.7065\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5911 - val_loss: 0.7053\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5929 - val_loss: 0.7191\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5905 - val_loss: 0.7034\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5907 - val_loss: 0.7063\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5904 - val_loss: 0.7066\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5900 - val_loss: 0.7056\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5898 - val_loss: 0.7049\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5900 - val_loss: 0.7088\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5907 - val_loss: 0.7066\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5905 - val_loss: 0.7141\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5894 - val_loss: 0.7045\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5893 - val_loss: 0.7067\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5892 - val_loss: 0.7096\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5894 - val_loss: 0.7123\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5888 - val_loss: 0.7079\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5888 - val_loss: 0.7106\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5885 - val_loss: 0.7133\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5892 - val_loss: 0.7080\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5885 - val_loss: 0.7106\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5886 - val_loss: 0.7080\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5881 - val_loss: 0.7095\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5892 - val_loss: 0.7108\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5883 - val_loss: 0.7129\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5883 - val_loss: 0.7107\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5879 - val_loss: 0.7090\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5879 - val_loss: 0.7065\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5878 - val_loss: 0.7126\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5880 - val_loss: 0.7138\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5878 - val_loss: 0.7034\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5872 - val_loss: 0.7135\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5874 - val_loss: 0.7090\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5876 - val_loss: 0.7155\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5875 - val_loss: 0.7046\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5868 - val_loss: 0.7060\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5865 - val_loss: 0.7105\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5874 - val_loss: 0.7045\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5862 - val_loss: 0.7107\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5880 - val_loss: 0.7151\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5868 - val_loss: 0.7133\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5861 - val_loss: 0.7102\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5862 - val_loss: 0.7114\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5858 - val_loss: 0.7066\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5857 - val_loss: 0.7109\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5854 - val_loss: 0.7110\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5855 - val_loss: 0.7094\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5853 - val_loss: 0.7112\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5862 - val_loss: 0.7090\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5850 - val_loss: 0.7071\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5855 - val_loss: 0.7160\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5848 - val_loss: 0.7119\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5848 - val_loss: 0.7103\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5848 - val_loss: 0.7105\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5846 - val_loss: 0.7121\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5846 - val_loss: 0.7089\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5844 - val_loss: 0.7121\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5845 - val_loss: 0.7081\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5847 - val_loss: 0.7156\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5839 - val_loss: 0.7065\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5841 - val_loss: 0.7115\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5836 - val_loss: 0.7162\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5837 - val_loss: 0.7110\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5837 - val_loss: 0.7065\n",
      "Epoch 394/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5838 - val_loss: 0.7113\n",
      "Epoch 395/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5833 - val_loss: 0.7167\n",
      "Epoch 396/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5843 - val_loss: 0.7201\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5837 - val_loss: 0.7149\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5840 - val_loss: 0.7144\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5832 - val_loss: 0.7155\n",
      "Epoch 400/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5829 - val_loss: 0.7146\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5832 - val_loss: 0.7173\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5833 - val_loss: 0.7165\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5830 - val_loss: 0.7075\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5832 - val_loss: 0.7188\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5827 - val_loss: 0.7134\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5826 - val_loss: 0.7171\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5823 - val_loss: 0.7115\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5825 - val_loss: 0.7157\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5825 - val_loss: 0.7135\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5837 - val_loss: 0.7194\n",
      "Epoch 411/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5819 - val_loss: 0.7129\n",
      "Epoch 412/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5822 - val_loss: 0.7088\n",
      "Epoch 413/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5819 - val_loss: 0.7186\n",
      "Epoch 414/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5820 - val_loss: 0.7163\n",
      "Epoch 415/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5815 - val_loss: 0.7136\n",
      "Epoch 416/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5821 - val_loss: 0.7191\n",
      "Epoch 417/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5815 - val_loss: 0.7190\n",
      "Epoch 418/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5820 - val_loss: 0.7182\n",
      "Epoch 419/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5822 - val_loss: 0.7189\n",
      "Epoch 420/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5817 - val_loss: 0.7192\n",
      "Epoch 421/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5815 - val_loss: 0.7174\n",
      "Epoch 422/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5815 - val_loss: 0.7221\n",
      "Epoch 423/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5813 - val_loss: 0.7159\n",
      "Epoch 424/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5808 - val_loss: 0.7189\n",
      "Epoch 425/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5806 - val_loss: 0.7211\n",
      "Epoch 426/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5809 - val_loss: 0.7176\n",
      "Epoch 427/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5815 - val_loss: 0.7277\n",
      "Epoch 428/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5807 - val_loss: 0.7164\n",
      "Epoch 429/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5802 - val_loss: 0.7173\n",
      "Epoch 430/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5803 - val_loss: 0.7202\n",
      "Epoch 431/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5806 - val_loss: 0.7176\n",
      "Epoch 432/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5803 - val_loss: 0.7241\n",
      "Epoch 433/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5810 - val_loss: 0.7178\n",
      "Epoch 434/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5819 - val_loss: 0.7151\n",
      "Epoch 435/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5804 - val_loss: 0.7230\n",
      "Epoch 436/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5802 - val_loss: 0.7241\n",
      "Epoch 437/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5804 - val_loss: 0.7166\n",
      "Epoch 438/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5798 - val_loss: 0.7272\n",
      "Epoch 439/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5796 - val_loss: 0.7275\n",
      "Epoch 440/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5801 - val_loss: 0.7221\n",
      "Epoch 441/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5799 - val_loss: 0.7272\n",
      "Epoch 442/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5802 - val_loss: 0.7186\n",
      "Epoch 443/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5796 - val_loss: 0.7206\n",
      "Epoch 444/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5791 - val_loss: 0.7273\n",
      "Epoch 445/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5795 - val_loss: 0.7262\n",
      "Epoch 446/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5793 - val_loss: 0.7240\n",
      "Epoch 447/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5790 - val_loss: 0.7287\n",
      "Epoch 448/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5789 - val_loss: 0.7310\n",
      "Epoch 449/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5790 - val_loss: 0.7268\n",
      "Epoch 450/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5791 - val_loss: 0.7254\n",
      "Epoch 451/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5791 - val_loss: 0.7312\n",
      "Epoch 452/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5780 - val_loss: 0.7241\n",
      "Epoch 453/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5788 - val_loss: 0.7202\n",
      "Epoch 454/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5781 - val_loss: 0.7280\n",
      "Epoch 455/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5787 - val_loss: 0.7244\n",
      "Epoch 456/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5785 - val_loss: 0.7234\n",
      "Epoch 457/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5777 - val_loss: 0.7319\n",
      "Epoch 458/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5780 - val_loss: 0.7299\n",
      "Epoch 459/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5784 - val_loss: 0.7295\n",
      "Epoch 460/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5779 - val_loss: 0.7317\n",
      "Epoch 461/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5771 - val_loss: 0.7270\n",
      "Epoch 462/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5781 - val_loss: 0.7286\n",
      "Epoch 463/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5777 - val_loss: 0.7213\n",
      "Epoch 464/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5771 - val_loss: 0.7267\n",
      "Epoch 465/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5778 - val_loss: 0.7297\n",
      "Epoch 466/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5770 - val_loss: 0.7273\n",
      "Epoch 467/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5764 - val_loss: 0.7309\n",
      "Epoch 468/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.4749Restoring model weights from the end of the best epoch: 268.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.5769 - val_loss: 0.7333\n",
      "Epoch 468: early stopping\n",
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:49:24.924581: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.07439536372502698"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emiliani2_wrapperBest5 = Sequential()\n",
    "model_emiliani2_wrapperBest5.add(Dense(4, input_dim=12, activation='relu')) \n",
    "model_emiliani2_wrapperBest5.add(Dense(1)) # Output\n",
    "\n",
    "model_emiliani2_wrapperBest5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=200, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani2_wrapperBest5.summary()\n",
    "\n",
    "model_emiliani2_wrapperBest5.fit(CMI_train_E2,target_df_train_E2.mean_std,validation_data=(CMI_val_E2,target_df_val_E2.mean_std),epochs=1000,callbacks=[monitor])\n",
    "\n",
    "r2_score(target_df_test_E2.mean_std, model_emiliani2_wrapperBest5.predict(CMI_test_E2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de44ecd",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5b190de5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_emiliani12_wrapperBest5 = Sequential()\n",
    "model_emiliani12_wrapperBest5.add(Dense(5, input_dim=10, activation='relu')) \n",
    "model_emiliani12_wrapperBest5.add(Dense(2)) # Output\n",
    "\n",
    "model_emiliani12_wrapperBest5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani12_wrapperBest5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "655803a7",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:11:38.444757: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 16ms/step - loss: 0.9697 - val_loss: 0.9344\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9364 - val_loss: 0.9047\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9078 - val_loss: 0.8797\n",
      "Epoch 4/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.9573"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:11:38.956587: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8837 - val_loss: 0.8583\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8633 - val_loss: 0.8416\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8472 - val_loss: 0.8291\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8340 - val_loss: 0.8178\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8220 - val_loss: 0.8081\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8106 - val_loss: 0.7999\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8018 - val_loss: 0.7909\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7937 - val_loss: 0.7835\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7867 - val_loss: 0.7765\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7800 - val_loss: 0.7713\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7738 - val_loss: 0.7668\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7677 - val_loss: 0.7639\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7630 - val_loss: 0.7610\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7584 - val_loss: 0.7583\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7552 - val_loss: 0.7564\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7520 - val_loss: 0.7551\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7493 - val_loss: 0.7533\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7468 - val_loss: 0.7518\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7448 - val_loss: 0.7495\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7425 - val_loss: 0.7481\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7405 - val_loss: 0.7470\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7383 - val_loss: 0.7449\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7362 - val_loss: 0.7441\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7342 - val_loss: 0.7425\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7325 - val_loss: 0.7426\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7308 - val_loss: 0.7409\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7293 - val_loss: 0.7397\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7276 - val_loss: 0.7376\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7262 - val_loss: 0.7355\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7248 - val_loss: 0.7346\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7234 - val_loss: 0.7344\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7220 - val_loss: 0.7335\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7207 - val_loss: 0.7331\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7194 - val_loss: 0.7318\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7180 - val_loss: 0.7299\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7167 - val_loss: 0.7292\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7157 - val_loss: 0.7285\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7140 - val_loss: 0.7272\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7129 - val_loss: 0.7253\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7116 - val_loss: 0.7231\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7102 - val_loss: 0.7213\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7088 - val_loss: 0.7206\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7073 - val_loss: 0.7187\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7061 - val_loss: 0.7165\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7049 - val_loss: 0.7138\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7035 - val_loss: 0.7139\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7019 - val_loss: 0.7114\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7005 - val_loss: 0.7103\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6992 - val_loss: 0.7078\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6977 - val_loss: 0.7079\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6963 - val_loss: 0.7060\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6950 - val_loss: 0.7051\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6936 - val_loss: 0.7042\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6924 - val_loss: 0.7022\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6912 - val_loss: 0.7018\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6901 - val_loss: 0.7027\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6888 - val_loss: 0.7030\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6877 - val_loss: 0.7032\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6864 - val_loss: 0.7015\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6856 - val_loss: 0.7008\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6844 - val_loss: 0.7001\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6838 - val_loss: 0.7021\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6823 - val_loss: 0.7006\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6812 - val_loss: 0.7003\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6803 - val_loss: 0.6992\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6792 - val_loss: 0.7004\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6784 - val_loss: 0.7000\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6778 - val_loss: 0.7013\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6765 - val_loss: 0.6997\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6756 - val_loss: 0.6984\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6748 - val_loss: 0.7007\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6734 - val_loss: 0.6997\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6724 - val_loss: 0.7000\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6714 - val_loss: 0.6995\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6709 - val_loss: 0.7004\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6696 - val_loss: 0.7002\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6692 - val_loss: 0.7004\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6679 - val_loss: 0.6996\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6670 - val_loss: 0.7003\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6660 - val_loss: 0.6992\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6651 - val_loss: 0.6987\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6644 - val_loss: 0.6996\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6634 - val_loss: 0.6974\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6627 - val_loss: 0.6991\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6618 - val_loss: 0.6996\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6605 - val_loss: 0.6986\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6599 - val_loss: 0.6979\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6586 - val_loss: 0.6982\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6579 - val_loss: 0.6979\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6569 - val_loss: 0.6976\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6562 - val_loss: 0.6953\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6554 - val_loss: 0.6983\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6548 - val_loss: 0.7002\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6535 - val_loss: 0.6978\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6529 - val_loss: 0.6990\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6522 - val_loss: 0.6963\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6511 - val_loss: 0.6967\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6502 - val_loss: 0.6997\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6495 - val_loss: 0.6984\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6968\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6967\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6467 - val_loss: 0.6980\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6458 - val_loss: 0.6988\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6454 - val_loss: 0.6992\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6446 - val_loss: 0.6964\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6439 - val_loss: 0.6993\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6427 - val_loss: 0.6973\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6426 - val_loss: 0.6940\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6415 - val_loss: 0.6965\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6408 - val_loss: 0.6971\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6402 - val_loss: 0.6972\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6395 - val_loss: 0.6972\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6390 - val_loss: 0.6947\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6390 - val_loss: 0.6980\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6378 - val_loss: 0.6991\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6373 - val_loss: 0.6987\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6370 - val_loss: 0.6954\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6359 - val_loss: 0.6990\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6352 - val_loss: 0.6992\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6345 - val_loss: 0.6989\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6337 - val_loss: 0.6991\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6331 - val_loss: 0.6995\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6328 - val_loss: 0.7005\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6320 - val_loss: 0.6972\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6313 - val_loss: 0.6968\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6307 - val_loss: 0.6984\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6306 - val_loss: 0.6979\n",
      "Epoch 131/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6912Restoring model weights from the end of the best epoch: 111.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6300 - val_loss: 0.6976\n",
      "Epoch 131: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28bd1c670>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best5_wrapper_train_E12 = pd.concat((best5_wrapper_train_E1,best5_wrapper_train_E2),axis=1)\n",
    "best5_wrapper_val_E12 = pd.concat((best5_wrapper_val_E1,best5_wrapper_val_E2),axis=1)\n",
    "best5_wrapper_test_E12 = pd.concat((best5_wrapper_test_E1,best5_wrapper_test_E2),axis=1)\n",
    "\n",
    "target_train_E12 = pd.concat((target_df_train_E1.mean_std,target_df_train_E2.mean_std),axis=1)\n",
    "target_val_E12 = pd.concat((target_df_val_E1.mean_std,target_df_val_E2.mean_std),axis=1)\n",
    "target_test_E12 = pd.concat((target_df_test_E1.mean_std,target_df_test_E2.mean_std),axis=1)\n",
    "\n",
    "model_emiliani12_wrapperBest5.fit(best5_wrapper_train_E12,target_train_E12,validation_data=(best5_wrapper_val_E12,target_val_E12),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "af954713",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step\n",
      "0.13858849170586363\n",
      "0.04033818912352716\n"
     ]
    }
   ],
   "source": [
    "res = model_emiliani12_wrapperBest5.predict(best5_wrapper_test_E12)\n",
    "\n",
    "print(r2_score(target_df_test_E1.mean_std, res[:,0]))\n",
    "print(r2_score(target_df_test_E2.mean_std, res[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8361be",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## feedforward NN with CMI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7530fef0",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Emiliani1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "49e3d9cb",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 41\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_emiliani1_CMI = Sequential()\n",
    "model_emiliani1_CMI.add(Dense(5, input_dim=6, activation='relu')) \n",
    "model_emiliani1_CMI.add(Dense(1)) # Output\n",
    "\n",
    "model_emiliani1_CMI.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani1_CMI.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4cf4073e",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.8032 - val_loss: 1.0234\n",
      "Epoch 2/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6544"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:17:47.411090: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-01 10:17:47.561985: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7866 - val_loss: 0.9913\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7745 - val_loss: 0.9581\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7629 - val_loss: 0.9315\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7540 - val_loss: 0.9070\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7464 - val_loss: 0.8842\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7400 - val_loss: 0.8635\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7349 - val_loss: 0.8444\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7296 - val_loss: 0.8327\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7260 - val_loss: 0.8198\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7223 - val_loss: 0.8099\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7197 - val_loss: 0.7983\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7164 - val_loss: 0.7923\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7139 - val_loss: 0.7836\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7116 - val_loss: 0.7741\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7090 - val_loss: 0.7678\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7067 - val_loss: 0.7625\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7050 - val_loss: 0.7540\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7029 - val_loss: 0.7490\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7008 - val_loss: 0.7470\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6989 - val_loss: 0.7442\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6977 - val_loss: 0.7429\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6959 - val_loss: 0.7413\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6941 - val_loss: 0.7392\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6928 - val_loss: 0.7360\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6914 - val_loss: 0.7347\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6900 - val_loss: 0.7334\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6889 - val_loss: 0.7298\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6882 - val_loss: 0.7304\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6869 - val_loss: 0.7267\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6860 - val_loss: 0.7237\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6853 - val_loss: 0.7218\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6841 - val_loss: 0.7203\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6834 - val_loss: 0.7203\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6829 - val_loss: 0.7161\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6816 - val_loss: 0.7156\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6808 - val_loss: 0.7168\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6798 - val_loss: 0.7133\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6791 - val_loss: 0.7135\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6782 - val_loss: 0.7125\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6775 - val_loss: 0.7115\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6769 - val_loss: 0.7091\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6759 - val_loss: 0.7094\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6751 - val_loss: 0.7083\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6745 - val_loss: 0.7074\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6737 - val_loss: 0.7075\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6732 - val_loss: 0.7069\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6724 - val_loss: 0.7075\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6716 - val_loss: 0.7033\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6711 - val_loss: 0.7016\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6703 - val_loss: 0.6985\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6697 - val_loss: 0.6972\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6692 - val_loss: 0.6960\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6686 - val_loss: 0.6962\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6680 - val_loss: 0.6984\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6678 - val_loss: 0.6948\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6672 - val_loss: 0.6970\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6665 - val_loss: 0.6967\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6661 - val_loss: 0.6952\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6657 - val_loss: 0.6935\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6654 - val_loss: 0.6915\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6646 - val_loss: 0.6925\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6641 - val_loss: 0.6943\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6641 - val_loss: 0.6916\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6630 - val_loss: 0.6923\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6627 - val_loss: 0.6915\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6621 - val_loss: 0.6878\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6615 - val_loss: 0.6873\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6612 - val_loss: 0.6871\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6608 - val_loss: 0.6856\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6601 - val_loss: 0.6863\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6601 - val_loss: 0.6901\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6590 - val_loss: 0.6867\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6587 - val_loss: 0.6853\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6581 - val_loss: 0.6839\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6578 - val_loss: 0.6833\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6574 - val_loss: 0.6828\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6570 - val_loss: 0.6811\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6566 - val_loss: 0.6817\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6564 - val_loss: 0.6806\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6563 - val_loss: 0.6821\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6556 - val_loss: 0.6816\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6556 - val_loss: 0.6777\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6549 - val_loss: 0.6797\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6549 - val_loss: 0.6824\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6545 - val_loss: 0.6818\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6539 - val_loss: 0.6802\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6538 - val_loss: 0.6787\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6532 - val_loss: 0.6807\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6531 - val_loss: 0.6822\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6527 - val_loss: 0.6816\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6523 - val_loss: 0.6795\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6521 - val_loss: 0.6804\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6517 - val_loss: 0.6804\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6516 - val_loss: 0.6818\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6515 - val_loss: 0.6797\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6512 - val_loss: 0.6818\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6511 - val_loss: 0.6799\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6507 - val_loss: 0.6815\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6505 - val_loss: 0.6794\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6500 - val_loss: 0.6823\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6499 - val_loss: 0.6818\n",
      "Epoch 103/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6871Restoring model weights from the end of the best epoch: 83.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6495 - val_loss: 0.6833\n",
      "Epoch 103: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x291223ca0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emiliani1_CMI.fit(CMI_train_E1,target_df_train_E1.mean_std,validation_data=(CMI_val_E1,target_df_val_E1.mean_std),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6d55356f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:18:11.989475: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18709398689292256"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(target_df_test_E1.mean_std, model_emiliani1_CMI.predict(CMI_test_E1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa917e7",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Emiliani2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1488f207",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 5)                 65        \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 71\n",
      "Trainable params: 71\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_emiliani2_CMI = Sequential()\n",
    "model_emiliani2_CMI.add(Dense(5, input_dim=12, activation='relu')) \n",
    "model_emiliani2_CMI.add(Dense(1)) # Output\n",
    "\n",
    "model_emiliani2_CMI.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani2_CMI.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7d8e835d",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.9858 - val_loss: 0.8875\n",
      "Epoch 2/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.7841"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:39:19.776018: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-01 10:39:19.918607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9429 - val_loss: 0.8642\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9069 - val_loss: 0.8439\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8753 - val_loss: 0.8280\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8542 - val_loss: 0.8152\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8374 - val_loss: 0.8067\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8247 - val_loss: 0.7950\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8143 - val_loss: 0.7855\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8066 - val_loss: 0.7770\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7999 - val_loss: 0.7673\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7927 - val_loss: 0.7623\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7858 - val_loss: 0.7573\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7800 - val_loss: 0.7512\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7737 - val_loss: 0.7481\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7674 - val_loss: 0.7447\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7621 - val_loss: 0.7421\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7565 - val_loss: 0.7365\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7518 - val_loss: 0.7339\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7471 - val_loss: 0.7299\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7422 - val_loss: 0.7271\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7377 - val_loss: 0.7246\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7336 - val_loss: 0.7185\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7292 - val_loss: 0.7181\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7248 - val_loss: 0.7149\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7208 - val_loss: 0.7129\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7164 - val_loss: 0.7139\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7128 - val_loss: 0.7126\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7086 - val_loss: 0.7136\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7047 - val_loss: 0.7143\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7009 - val_loss: 0.7125\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6984 - val_loss: 0.7138\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6942 - val_loss: 0.7124\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6909 - val_loss: 0.7118\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6877 - val_loss: 0.7090\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6847 - val_loss: 0.7082\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6813 - val_loss: 0.7083\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6782 - val_loss: 0.7124\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6750 - val_loss: 0.7121\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6723 - val_loss: 0.7099\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6700 - val_loss: 0.7100\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6669 - val_loss: 0.7101\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6646 - val_loss: 0.7091\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6625 - val_loss: 0.7100\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6605 - val_loss: 0.7075\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6601 - val_loss: 0.7091\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6583 - val_loss: 0.7131\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6563 - val_loss: 0.7127\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6557 - val_loss: 0.7131\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6540 - val_loss: 0.7125\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6524 - val_loss: 0.7142\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6511 - val_loss: 0.7137\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6500 - val_loss: 0.7142\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.7156\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6474 - val_loss: 0.7163\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6462 - val_loss: 0.7184\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6455 - val_loss: 0.7163\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6446 - val_loss: 0.7174\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6433 - val_loss: 0.7210\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6426 - val_loss: 0.7212\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6419 - val_loss: 0.7202\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6404 - val_loss: 0.7205\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6402 - val_loss: 0.7255\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6384 - val_loss: 0.7259\n",
      "Epoch 64/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5996Restoring model weights from the end of the best epoch: 44.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6372 - val_loss: 0.7268\n",
      "Epoch 64: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x297349d90>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emiliani2_CMI.fit(CMI_train_E2,target_df_train_E2.mean_std,validation_data=(CMI_val_E2,target_df_val_E2.mean_std),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e412d8e8",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:39:24.127706: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2523916814140521"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(target_df_test_E2.mean_std, model_emiliani2_CMI.predict(CMI_test_E2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c4b6cc",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1e4c7f25",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 5)                 95        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107\n",
      "Trainable params: 107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_emiliani12_CMI = Sequential()\n",
    "model_emiliani12_CMI.add(Dense(5, input_dim=18, activation='relu')) \n",
    "model_emiliani12_CMI.add(Dense(2)) # Output\n",
    "\n",
    "model_emiliani12_CMI.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani12_CMI.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "67cfd91a",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.9050"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:21:57.149898: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-01 10:21:57.319303: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 13ms/step - loss: 0.9050 - val_loss: 1.1153\n",
      "Epoch 2/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8695 - val_loss: 1.0542\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8426 - val_loss: 1.0049\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8225 - val_loss: 0.9554\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8055 - val_loss: 0.9124\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7917 - val_loss: 0.8862\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7804 - val_loss: 0.8606\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7698 - val_loss: 0.8344\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7594 - val_loss: 0.8116\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7522 - val_loss: 0.7901\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7429 - val_loss: 0.7736\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7363 - val_loss: 0.7622\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7307 - val_loss: 0.7494\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7244 - val_loss: 0.7445\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7194 - val_loss: 0.7378\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7153 - val_loss: 0.7326\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7108 - val_loss: 0.7293\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7066 - val_loss: 0.7278\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7028 - val_loss: 0.7253\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6991 - val_loss: 0.7221\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6958 - val_loss: 0.7266\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6925 - val_loss: 0.7217\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6889 - val_loss: 0.7213\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6863 - val_loss: 0.7206\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6832 - val_loss: 0.7218\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6801 - val_loss: 0.7217\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6771 - val_loss: 0.7132\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6745 - val_loss: 0.7130\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6723 - val_loss: 0.7185\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6698 - val_loss: 0.7138\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6669 - val_loss: 0.7179\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6645 - val_loss: 0.7166\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6622 - val_loss: 0.7196\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6596 - val_loss: 0.7169\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6571 - val_loss: 0.7180\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6551 - val_loss: 0.7095\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6520 - val_loss: 0.7125\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6496 - val_loss: 0.7172\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6471 - val_loss: 0.7124\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6446 - val_loss: 0.7127\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6420 - val_loss: 0.7127\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6403 - val_loss: 0.7097\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6375 - val_loss: 0.7173\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6351 - val_loss: 0.7150\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6337 - val_loss: 0.7165\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6314 - val_loss: 0.7246\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6288 - val_loss: 0.7158\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6265 - val_loss: 0.7157\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6251 - val_loss: 0.7131\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6226 - val_loss: 0.7229\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6211 - val_loss: 0.7244\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6190 - val_loss: 0.7268\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6177 - val_loss: 0.7325\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.7307\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6142 - val_loss: 0.7273\n",
      "Epoch 56/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5984Restoring model weights from the end of the best epoch: 36.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6123 - val_loss: 0.7316\n",
      "Epoch 56: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2984b2b50>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMI_train_E12 = pd.concat((CMI_train_E1,CMI_train_E2),axis=1)\n",
    "CMI_val_E12 = pd.concat((CMI_val_E1,CMI_val_E2),axis=1)\n",
    "CMI_test_E12 = pd.concat((CMI_test_E1,CMI_test_E2),axis=1)\n",
    "\n",
    "target_train_E12 = pd.concat((target_df_train_E1.mean_std,target_df_train_E2.mean_std),axis=1)\n",
    "target_val_E12 = pd.concat((target_df_val_E1.mean_std,target_df_val_E2.mean_std),axis=1)\n",
    "target_test_E12 = pd.concat((target_df_test_E1.mean_std,target_df_test_E2.mean_std),axis=1)\n",
    "\n",
    "model_emiliani12_CMI.fit(CMI_train_E12,target_train_E12,validation_data=(CMI_val_E12,target_val_E12),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5b686adc",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n",
      "0.06809134446862464\n",
      "0.04497803527098665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-01 10:22:18.815802: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "res = model_emiliani12_CMI.predict(CMI_test_E12)\n",
    "\n",
    "print(r2_score(target_df_test_E1.mean_std, res[:,0]))\n",
    "print(r2_score(target_df_test_E2.mean_std, res[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4db848",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## feedforward NN with CMI best 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba9eb6b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Emiliani1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50202dde",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_emiliani1_CMI_best5 = Sequential()\n",
    "model_emiliani1_CMI_best5.add(Dense(5, input_dim=5, activation='relu')) \n",
    "model_emiliani1_CMI_best5.add(Dense(1)) # Output\n",
    "\n",
    "model_emiliani1_CMI_best5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=100, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani1_CMI_best5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76665b70",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.8526 - val_loss: 1.0863\n",
      "Epoch 2/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.8534"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:16:22.424875: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-13 14:16:22.570913: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8273 - val_loss: 1.0323\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8047 - val_loss: 0.9817\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7867 - val_loss: 0.9379\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7725 - val_loss: 0.9026\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7628 - val_loss: 0.8717\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7549 - val_loss: 0.8470\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7483 - val_loss: 0.8248\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7411 - val_loss: 0.8094\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7367 - val_loss: 0.7892\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7325 - val_loss: 0.7734\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7284 - val_loss: 0.7622\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7252 - val_loss: 0.7556\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7229 - val_loss: 0.7476\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7208 - val_loss: 0.7412\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7188 - val_loss: 0.7368\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7170 - val_loss: 0.7353\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7154 - val_loss: 0.7317\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7141 - val_loss: 0.7278\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7123 - val_loss: 0.7259\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7110 - val_loss: 0.7244\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7097 - val_loss: 0.7232\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7086 - val_loss: 0.7201\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7071 - val_loss: 0.7195\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7060 - val_loss: 0.7209\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7046 - val_loss: 0.7186\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7034 - val_loss: 0.7165\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7024 - val_loss: 0.7196\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7011 - val_loss: 0.7153\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7000 - val_loss: 0.7126\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6989 - val_loss: 0.7126\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6976 - val_loss: 0.7101\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6967 - val_loss: 0.7038\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6956 - val_loss: 0.7032\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6946 - val_loss: 0.7026\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6930 - val_loss: 0.6967\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6918 - val_loss: 0.6928\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6907 - val_loss: 0.6911\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6892 - val_loss: 0.6877\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6881 - val_loss: 0.6875\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6869 - val_loss: 0.6837\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6858 - val_loss: 0.6838\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6843 - val_loss: 0.6781\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6830 - val_loss: 0.6773\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6819 - val_loss: 0.6739\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6807 - val_loss: 0.6747\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6795 - val_loss: 0.6746\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6782 - val_loss: 0.6723\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6768 - val_loss: 0.6721\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6753 - val_loss: 0.6729\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6739 - val_loss: 0.6679\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6721 - val_loss: 0.6693\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6704 - val_loss: 0.6680\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6688 - val_loss: 0.6697\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6672 - val_loss: 0.6680\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6652 - val_loss: 0.6668\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6632 - val_loss: 0.6678\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6616 - val_loss: 0.6678\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6595 - val_loss: 0.6676\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6581 - val_loss: 0.6639\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6562 - val_loss: 0.6653\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6551 - val_loss: 0.6639\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6533 - val_loss: 0.6616\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6512 - val_loss: 0.6576\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6500 - val_loss: 0.6569\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6575\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6628\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6472 - val_loss: 0.6630\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6468 - val_loss: 0.6640\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6462 - val_loss: 0.6636\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6457 - val_loss: 0.6632\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6454 - val_loss: 0.6635\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6448 - val_loss: 0.6646\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6447 - val_loss: 0.6609\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6442 - val_loss: 0.6614\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6436 - val_loss: 0.6629\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6434 - val_loss: 0.6636\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6431 - val_loss: 0.6619\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6425 - val_loss: 0.6632\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6423 - val_loss: 0.6621\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6420 - val_loss: 0.6645\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6415 - val_loss: 0.6631\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6411 - val_loss: 0.6624\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6407 - val_loss: 0.6625\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6403 - val_loss: 0.6630\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6402 - val_loss: 0.6640\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6408 - val_loss: 0.6653\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6393 - val_loss: 0.6634\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6392 - val_loss: 0.6603\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6394 - val_loss: 0.6644\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6385 - val_loss: 0.6629\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6385 - val_loss: 0.6637\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6381 - val_loss: 0.6626\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6382 - val_loss: 0.6607\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6377 - val_loss: 0.6637\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6378 - val_loss: 0.6657\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6377 - val_loss: 0.6658\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6372 - val_loss: 0.6631\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6373 - val_loss: 0.6620\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6369 - val_loss: 0.6609\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6367 - val_loss: 0.6625\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6366 - val_loss: 0.6615\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6364 - val_loss: 0.6642\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6363 - val_loss: 0.6648\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6363 - val_loss: 0.6622\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6362 - val_loss: 0.6609\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6358 - val_loss: 0.6620\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6358 - val_loss: 0.6634\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6357 - val_loss: 0.6648\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6357 - val_loss: 0.6636\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6353 - val_loss: 0.6604\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6356 - val_loss: 0.6583\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6352 - val_loss: 0.6617\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6353 - val_loss: 0.6634\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6352 - val_loss: 0.6608\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6349 - val_loss: 0.6618\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6346 - val_loss: 0.6625\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6347 - val_loss: 0.6629\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6345 - val_loss: 0.6607\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6347 - val_loss: 0.6623\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6344 - val_loss: 0.6605\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6342 - val_loss: 0.6597\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6344 - val_loss: 0.6626\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6342 - val_loss: 0.6612\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6344 - val_loss: 0.6598\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6344 - val_loss: 0.6579\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6337 - val_loss: 0.6604\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6337 - val_loss: 0.6610\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6339 - val_loss: 0.6620\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6339 - val_loss: 0.6564\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6333 - val_loss: 0.6601\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6335 - val_loss: 0.6613\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6335 - val_loss: 0.6583\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6333 - val_loss: 0.6594\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6337 - val_loss: 0.6591\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6332 - val_loss: 0.6598\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6330 - val_loss: 0.6602\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6328 - val_loss: 0.6604\n",
      "Epoch 139/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6328 - val_loss: 0.6584\n",
      "Epoch 140/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6326 - val_loss: 0.6581\n",
      "Epoch 141/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6327 - val_loss: 0.6593\n",
      "Epoch 142/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6325 - val_loss: 0.6586\n",
      "Epoch 143/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6324 - val_loss: 0.6605\n",
      "Epoch 144/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6324 - val_loss: 0.6586\n",
      "Epoch 145/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6321 - val_loss: 0.6610\n",
      "Epoch 146/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6321 - val_loss: 0.6589\n",
      "Epoch 147/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6320 - val_loss: 0.6569\n",
      "Epoch 148/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6320 - val_loss: 0.6599\n",
      "Epoch 149/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6318 - val_loss: 0.6594\n",
      "Epoch 150/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6316 - val_loss: 0.6579\n",
      "Epoch 151/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6317 - val_loss: 0.6580\n",
      "Epoch 152/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6315 - val_loss: 0.6608\n",
      "Epoch 153/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6317 - val_loss: 0.6594\n",
      "Epoch 154/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6312 - val_loss: 0.6569\n",
      "Epoch 155/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6316 - val_loss: 0.6604\n",
      "Epoch 156/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6314 - val_loss: 0.6562\n",
      "Epoch 157/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6310 - val_loss: 0.6570\n",
      "Epoch 158/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6312 - val_loss: 0.6581\n",
      "Epoch 159/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6311 - val_loss: 0.6589\n",
      "Epoch 160/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6309 - val_loss: 0.6559\n",
      "Epoch 161/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6310 - val_loss: 0.6553\n",
      "Epoch 162/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6308 - val_loss: 0.6585\n",
      "Epoch 163/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6310 - val_loss: 0.6598\n",
      "Epoch 164/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6307 - val_loss: 0.6552\n",
      "Epoch 165/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6313 - val_loss: 0.6580\n",
      "Epoch 166/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6303 - val_loss: 0.6557\n",
      "Epoch 167/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6305 - val_loss: 0.6546\n",
      "Epoch 168/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6306 - val_loss: 0.6569\n",
      "Epoch 169/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6302 - val_loss: 0.6596\n",
      "Epoch 170/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6303 - val_loss: 0.6571\n",
      "Epoch 171/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6304 - val_loss: 0.6592\n",
      "Epoch 172/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6301 - val_loss: 0.6571\n",
      "Epoch 173/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6300 - val_loss: 0.6574\n",
      "Epoch 174/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6298 - val_loss: 0.6566\n",
      "Epoch 175/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6300 - val_loss: 0.6560\n",
      "Epoch 176/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6300 - val_loss: 0.6567\n",
      "Epoch 177/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6297 - val_loss: 0.6576\n",
      "Epoch 178/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6297 - val_loss: 0.6572\n",
      "Epoch 179/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6297 - val_loss: 0.6560\n",
      "Epoch 180/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6296 - val_loss: 0.6550\n",
      "Epoch 181/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6295 - val_loss: 0.6545\n",
      "Epoch 182/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6296 - val_loss: 0.6575\n",
      "Epoch 183/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6296 - val_loss: 0.6587\n",
      "Epoch 184/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6298 - val_loss: 0.6575\n",
      "Epoch 185/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6295 - val_loss: 0.6560\n",
      "Epoch 186/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6298 - val_loss: 0.6547\n",
      "Epoch 187/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6298 - val_loss: 0.6574\n",
      "Epoch 188/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6292 - val_loss: 0.6552\n",
      "Epoch 189/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6293 - val_loss: 0.6557\n",
      "Epoch 190/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6291 - val_loss: 0.6579\n",
      "Epoch 191/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6292 - val_loss: 0.6572\n",
      "Epoch 192/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6289 - val_loss: 0.6550\n",
      "Epoch 193/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6289 - val_loss: 0.6539\n",
      "Epoch 194/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6290 - val_loss: 0.6557\n",
      "Epoch 195/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6288 - val_loss: 0.6559\n",
      "Epoch 196/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6285 - val_loss: 0.6576\n",
      "Epoch 197/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6291 - val_loss: 0.6574\n",
      "Epoch 198/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6284 - val_loss: 0.6591\n",
      "Epoch 199/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6286 - val_loss: 0.6553\n",
      "Epoch 200/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6290 - val_loss: 0.6551\n",
      "Epoch 201/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6283 - val_loss: 0.6573\n",
      "Epoch 202/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6280 - val_loss: 0.6564\n",
      "Epoch 203/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6283 - val_loss: 0.6571\n",
      "Epoch 204/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6280 - val_loss: 0.6576\n",
      "Epoch 205/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6279 - val_loss: 0.6575\n",
      "Epoch 206/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6279 - val_loss: 0.6567\n",
      "Epoch 207/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6279 - val_loss: 0.6581\n",
      "Epoch 208/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6284 - val_loss: 0.6552\n",
      "Epoch 209/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6276 - val_loss: 0.6583\n",
      "Epoch 210/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6276 - val_loss: 0.6586\n",
      "Epoch 211/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6274 - val_loss: 0.6562\n",
      "Epoch 212/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6274 - val_loss: 0.6584\n",
      "Epoch 213/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6276 - val_loss: 0.6565\n",
      "Epoch 214/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6270 - val_loss: 0.6554\n",
      "Epoch 215/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6274 - val_loss: 0.6541\n",
      "Epoch 216/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6271 - val_loss: 0.6577\n",
      "Epoch 217/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6270 - val_loss: 0.6596\n",
      "Epoch 218/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6267 - val_loss: 0.6578\n",
      "Epoch 219/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6264 - val_loss: 0.6572\n",
      "Epoch 220/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6263 - val_loss: 0.6575\n",
      "Epoch 221/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6262 - val_loss: 0.6558\n",
      "Epoch 222/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6260 - val_loss: 0.6586\n",
      "Epoch 223/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6259 - val_loss: 0.6589\n",
      "Epoch 224/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6258 - val_loss: 0.6585\n",
      "Epoch 225/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6257 - val_loss: 0.6578\n",
      "Epoch 226/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6255 - val_loss: 0.6572\n",
      "Epoch 227/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6253 - val_loss: 0.6583\n",
      "Epoch 228/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6254 - val_loss: 0.6565\n",
      "Epoch 229/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6252 - val_loss: 0.6555\n",
      "Epoch 230/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6250 - val_loss: 0.6563\n",
      "Epoch 231/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6248 - val_loss: 0.6575\n",
      "Epoch 232/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6245 - val_loss: 0.6589\n",
      "Epoch 233/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6246 - val_loss: 0.6576\n",
      "Epoch 234/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6243 - val_loss: 0.6559\n",
      "Epoch 235/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6245 - val_loss: 0.6565\n",
      "Epoch 236/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6250 - val_loss: 0.6577\n",
      "Epoch 237/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6242 - val_loss: 0.6581\n",
      "Epoch 238/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6243 - val_loss: 0.6582\n",
      "Epoch 239/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6241 - val_loss: 0.6551\n",
      "Epoch 240/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6237 - val_loss: 0.6576\n",
      "Epoch 241/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6236 - val_loss: 0.6560\n",
      "Epoch 242/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6236 - val_loss: 0.6580\n",
      "Epoch 243/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6237 - val_loss: 0.6561\n",
      "Epoch 244/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6231 - val_loss: 0.6574\n",
      "Epoch 245/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6234 - val_loss: 0.6576\n",
      "Epoch 246/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6232 - val_loss: 0.6582\n",
      "Epoch 247/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6229 - val_loss: 0.6564\n",
      "Epoch 248/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6228 - val_loss: 0.6578\n",
      "Epoch 249/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6228 - val_loss: 0.6562\n",
      "Epoch 250/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6226 - val_loss: 0.6570\n",
      "Epoch 251/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6227 - val_loss: 0.6565\n",
      "Epoch 252/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6224 - val_loss: 0.6577\n",
      "Epoch 253/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6224 - val_loss: 0.6584\n",
      "Epoch 254/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6228 - val_loss: 0.6546\n",
      "Epoch 255/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6221 - val_loss: 0.6567\n",
      "Epoch 256/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6222 - val_loss: 0.6594\n",
      "Epoch 257/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6221 - val_loss: 0.6541\n",
      "Epoch 258/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6217 - val_loss: 0.6552\n",
      "Epoch 259/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6220 - val_loss: 0.6563\n",
      "Epoch 260/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6217 - val_loss: 0.6540\n",
      "Epoch 261/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6217 - val_loss: 0.6552\n",
      "Epoch 262/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6213 - val_loss: 0.6555\n",
      "Epoch 263/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6217 - val_loss: 0.6567\n",
      "Epoch 264/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6209 - val_loss: 0.6541\n",
      "Epoch 265/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6211 - val_loss: 0.6525\n",
      "Epoch 266/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6208 - val_loss: 0.6544\n",
      "Epoch 267/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6208 - val_loss: 0.6538\n",
      "Epoch 268/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6210 - val_loss: 0.6540\n",
      "Epoch 269/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6205 - val_loss: 0.6537\n",
      "Epoch 270/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6205 - val_loss: 0.6524\n",
      "Epoch 271/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6202 - val_loss: 0.6537\n",
      "Epoch 272/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6202 - val_loss: 0.6530\n",
      "Epoch 273/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6203 - val_loss: 0.6530\n",
      "Epoch 274/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6199 - val_loss: 0.6531\n",
      "Epoch 275/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6204 - val_loss: 0.6537\n",
      "Epoch 276/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6197 - val_loss: 0.6519\n",
      "Epoch 277/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6199 - val_loss: 0.6512\n",
      "Epoch 278/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6199 - val_loss: 0.6536\n",
      "Epoch 279/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6204 - val_loss: 0.6504\n",
      "Epoch 280/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6192 - val_loss: 0.6514\n",
      "Epoch 281/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6192 - val_loss: 0.6532\n",
      "Epoch 282/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6194 - val_loss: 0.6525\n",
      "Epoch 283/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6189 - val_loss: 0.6519\n",
      "Epoch 284/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6190 - val_loss: 0.6493\n",
      "Epoch 285/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6190 - val_loss: 0.6484\n",
      "Epoch 286/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6187 - val_loss: 0.6506\n",
      "Epoch 287/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6186 - val_loss: 0.6506\n",
      "Epoch 288/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6188 - val_loss: 0.6487\n",
      "Epoch 289/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6186 - val_loss: 0.6490\n",
      "Epoch 290/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6182 - val_loss: 0.6481\n",
      "Epoch 291/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6188 - val_loss: 0.6512\n",
      "Epoch 292/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6182 - val_loss: 0.6506\n",
      "Epoch 293/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6180 - val_loss: 0.6492\n",
      "Epoch 294/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6181 - val_loss: 0.6482\n",
      "Epoch 295/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6182 - val_loss: 0.6463\n",
      "Epoch 296/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6178 - val_loss: 0.6483\n",
      "Epoch 297/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6175 - val_loss: 0.6477\n",
      "Epoch 298/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6176 - val_loss: 0.6475\n",
      "Epoch 299/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6174 - val_loss: 0.6476\n",
      "Epoch 300/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6176 - val_loss: 0.6488\n",
      "Epoch 301/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6173 - val_loss: 0.6464\n",
      "Epoch 302/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6172 - val_loss: 0.6467\n",
      "Epoch 303/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6171 - val_loss: 0.6463\n",
      "Epoch 304/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6171 - val_loss: 0.6458\n",
      "Epoch 305/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6172 - val_loss: 0.6471\n",
      "Epoch 306/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6171 - val_loss: 0.6454\n",
      "Epoch 307/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6169 - val_loss: 0.6433\n",
      "Epoch 308/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6169 - val_loss: 0.6449\n",
      "Epoch 309/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6164 - val_loss: 0.6443\n",
      "Epoch 310/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6169 - val_loss: 0.6465\n",
      "Epoch 311/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6162 - val_loss: 0.6441\n",
      "Epoch 312/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6173 - val_loss: 0.6404\n",
      "Epoch 313/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6167 - val_loss: 0.6454\n",
      "Epoch 314/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6162 - val_loss: 0.6445\n",
      "Epoch 315/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6164 - val_loss: 0.6415\n",
      "Epoch 316/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6164 - val_loss: 0.6439\n",
      "Epoch 317/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6163 - val_loss: 0.6464\n",
      "Epoch 318/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6159 - val_loss: 0.6451\n",
      "Epoch 319/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6157 - val_loss: 0.6429\n",
      "Epoch 320/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6162 - val_loss: 0.6436\n",
      "Epoch 321/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6162 - val_loss: 0.6408\n",
      "Epoch 322/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6159 - val_loss: 0.6424\n",
      "Epoch 323/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6157 - val_loss: 0.6426\n",
      "Epoch 324/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6157 - val_loss: 0.6428\n",
      "Epoch 325/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6153 - val_loss: 0.6430\n",
      "Epoch 326/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6156 - val_loss: 0.6427\n",
      "Epoch 327/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.6419\n",
      "Epoch 328/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6154 - val_loss: 0.6426\n",
      "Epoch 329/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6153 - val_loss: 0.6444\n",
      "Epoch 330/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.6444\n",
      "Epoch 331/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6155 - val_loss: 0.6413\n",
      "Epoch 332/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6149 - val_loss: 0.6451\n",
      "Epoch 333/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.6460\n",
      "Epoch 334/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6150 - val_loss: 0.6436\n",
      "Epoch 335/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6148 - val_loss: 0.6416\n",
      "Epoch 336/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6149 - val_loss: 0.6432\n",
      "Epoch 337/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6147 - val_loss: 0.6436\n",
      "Epoch 338/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6147 - val_loss: 0.6429\n",
      "Epoch 339/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6152 - val_loss: 0.6427\n",
      "Epoch 340/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6147 - val_loss: 0.6441\n",
      "Epoch 341/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6146 - val_loss: 0.6439\n",
      "Epoch 342/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6144 - val_loss: 0.6423\n",
      "Epoch 343/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6144 - val_loss: 0.6446\n",
      "Epoch 344/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6145 - val_loss: 0.6451\n",
      "Epoch 345/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6142 - val_loss: 0.6436\n",
      "Epoch 346/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6141 - val_loss: 0.6419\n",
      "Epoch 347/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6144 - val_loss: 0.6450\n",
      "Epoch 348/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6141 - val_loss: 0.6416\n",
      "Epoch 349/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6146 - val_loss: 0.6420\n",
      "Epoch 350/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6139 - val_loss: 0.6454\n",
      "Epoch 351/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6139 - val_loss: 0.6433\n",
      "Epoch 352/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6137 - val_loss: 0.6454\n",
      "Epoch 353/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6141 - val_loss: 0.6430\n",
      "Epoch 354/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6138 - val_loss: 0.6455\n",
      "Epoch 355/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6140 - val_loss: 0.6430\n",
      "Epoch 356/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6134 - val_loss: 0.6438\n",
      "Epoch 357/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6134 - val_loss: 0.6427\n",
      "Epoch 358/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6136 - val_loss: 0.6438\n",
      "Epoch 359/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6139 - val_loss: 0.6443\n",
      "Epoch 360/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6139 - val_loss: 0.6421\n",
      "Epoch 361/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6131 - val_loss: 0.6426\n",
      "Epoch 362/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6142 - val_loss: 0.6426\n",
      "Epoch 363/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6130 - val_loss: 0.6427\n",
      "Epoch 364/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6136 - val_loss: 0.6441\n",
      "Epoch 365/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6129 - val_loss: 0.6448\n",
      "Epoch 366/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6129 - val_loss: 0.6444\n",
      "Epoch 367/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6130 - val_loss: 0.6440\n",
      "Epoch 368/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6132 - val_loss: 0.6444\n",
      "Epoch 369/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6129 - val_loss: 0.6411\n",
      "Epoch 370/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6129 - val_loss: 0.6439\n",
      "Epoch 371/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6126 - val_loss: 0.6432\n",
      "Epoch 372/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6128 - val_loss: 0.6426\n",
      "Epoch 373/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6126 - val_loss: 0.6424\n",
      "Epoch 374/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6125 - val_loss: 0.6428\n",
      "Epoch 375/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6133 - val_loss: 0.6448\n",
      "Epoch 376/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6128 - val_loss: 0.6415\n",
      "Epoch 377/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6125 - val_loss: 0.6436\n",
      "Epoch 378/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6124 - val_loss: 0.6433\n",
      "Epoch 379/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6124 - val_loss: 0.6442\n",
      "Epoch 380/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6122 - val_loss: 0.6419\n",
      "Epoch 381/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6124 - val_loss: 0.6422\n",
      "Epoch 382/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6122 - val_loss: 0.6430\n",
      "Epoch 383/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6125 - val_loss: 0.6440\n",
      "Epoch 384/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6125 - val_loss: 0.6404\n",
      "Epoch 385/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6119 - val_loss: 0.6420\n",
      "Epoch 386/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6121 - val_loss: 0.6434\n",
      "Epoch 387/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6120 - val_loss: 0.6422\n",
      "Epoch 388/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6122 - val_loss: 0.6408\n",
      "Epoch 389/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6119 - val_loss: 0.6435\n",
      "Epoch 390/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6117 - val_loss: 0.6409\n",
      "Epoch 391/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6117 - val_loss: 0.6419\n",
      "Epoch 392/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6120 - val_loss: 0.6449\n",
      "Epoch 393/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6117 - val_loss: 0.6437\n",
      "Epoch 394/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6119 - val_loss: 0.6436\n",
      "Epoch 395/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6115 - val_loss: 0.6416\n",
      "Epoch 396/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6116 - val_loss: 0.6425\n",
      "Epoch 397/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6115 - val_loss: 0.6441\n",
      "Epoch 398/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6115 - val_loss: 0.6445\n",
      "Epoch 399/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6116 - val_loss: 0.6415\n",
      "Epoch 400/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6114 - val_loss: 0.6423\n",
      "Epoch 401/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6125 - val_loss: 0.6407\n",
      "Epoch 402/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6115 - val_loss: 0.6441\n",
      "Epoch 403/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6117 - val_loss: 0.6408\n",
      "Epoch 404/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6117 - val_loss: 0.6402\n",
      "Epoch 405/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6112 - val_loss: 0.6423\n",
      "Epoch 406/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6116 - val_loss: 0.6442\n",
      "Epoch 407/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6116 - val_loss: 0.6394\n",
      "Epoch 408/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6112 - val_loss: 0.6395\n",
      "Epoch 409/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6108 - val_loss: 0.6431\n",
      "Epoch 410/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6111 - val_loss: 0.6460\n",
      "Epoch 411/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6111 - val_loss: 0.6432\n",
      "Epoch 412/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6106 - val_loss: 0.6420\n",
      "Epoch 413/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6109 - val_loss: 0.6409\n",
      "Epoch 414/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6110 - val_loss: 0.6418\n",
      "Epoch 415/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6104 - val_loss: 0.6440\n",
      "Epoch 416/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6111 - val_loss: 0.6481\n",
      "Epoch 417/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6110 - val_loss: 0.6429\n",
      "Epoch 418/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6109 - val_loss: 0.6425\n",
      "Epoch 419/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6104 - val_loss: 0.6454\n",
      "Epoch 420/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6105 - val_loss: 0.6429\n",
      "Epoch 421/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6109 - val_loss: 0.6429\n",
      "Epoch 422/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6105 - val_loss: 0.6435\n",
      "Epoch 423/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6102 - val_loss: 0.6433\n",
      "Epoch 424/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6104 - val_loss: 0.6431\n",
      "Epoch 425/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6108 - val_loss: 0.6457\n",
      "Epoch 426/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6099 - val_loss: 0.6428\n",
      "Epoch 427/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6102 - val_loss: 0.6442\n",
      "Epoch 428/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6099 - val_loss: 0.6427\n",
      "Epoch 429/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6104 - val_loss: 0.6420\n",
      "Epoch 430/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6102 - val_loss: 0.6446\n",
      "Epoch 431/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6102 - val_loss: 0.6433\n",
      "Epoch 432/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6099 - val_loss: 0.6438\n",
      "Epoch 433/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6102 - val_loss: 0.6457\n",
      "Epoch 434/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6101 - val_loss: 0.6420\n",
      "Epoch 435/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6104 - val_loss: 0.6425\n",
      "Epoch 436/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6102 - val_loss: 0.6448\n",
      "Epoch 437/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6097 - val_loss: 0.6439\n",
      "Epoch 438/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6095 - val_loss: 0.6440\n",
      "Epoch 439/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6098 - val_loss: 0.6434\n",
      "Epoch 440/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6098 - val_loss: 0.6464\n",
      "Epoch 441/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6095 - val_loss: 0.6438\n",
      "Epoch 442/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6098 - val_loss: 0.6464\n",
      "Epoch 443/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6093 - val_loss: 0.6454\n",
      "Epoch 444/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6098 - val_loss: 0.6428\n",
      "Epoch 445/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6092 - val_loss: 0.6467\n",
      "Epoch 446/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6091 - val_loss: 0.6456\n",
      "Epoch 447/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6091 - val_loss: 0.6453\n",
      "Epoch 448/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6093 - val_loss: 0.6465\n",
      "Epoch 449/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6088 - val_loss: 0.6442\n",
      "Epoch 450/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6093 - val_loss: 0.6446\n",
      "Epoch 451/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6088 - val_loss: 0.6455\n",
      "Epoch 452/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6091 - val_loss: 0.6467\n",
      "Epoch 453/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6092 - val_loss: 0.6474\n",
      "Epoch 454/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6091 - val_loss: 0.6441\n",
      "Epoch 455/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6093 - val_loss: 0.6452\n",
      "Epoch 456/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6088 - val_loss: 0.6448\n",
      "Epoch 457/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6087 - val_loss: 0.6469\n",
      "Epoch 458/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6087 - val_loss: 0.6475\n",
      "Epoch 459/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6087 - val_loss: 0.6440\n",
      "Epoch 460/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6084 - val_loss: 0.6458\n",
      "Epoch 461/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6086 - val_loss: 0.6495\n",
      "Epoch 462/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6090 - val_loss: 0.6464\n",
      "Epoch 463/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6084 - val_loss: 0.6462\n",
      "Epoch 464/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6087 - val_loss: 0.6488\n",
      "Epoch 465/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6088 - val_loss: 0.6472\n",
      "Epoch 466/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6086 - val_loss: 0.6484\n",
      "Epoch 467/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6080 - val_loss: 0.6458\n",
      "Epoch 468/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6084 - val_loss: 0.6446\n",
      "Epoch 469/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6084 - val_loss: 0.6484\n",
      "Epoch 470/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6088 - val_loss: 0.6435\n",
      "Epoch 471/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6087 - val_loss: 0.6461\n",
      "Epoch 472/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6085 - val_loss: 0.6469\n",
      "Epoch 473/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6081 - val_loss: 0.6486\n",
      "Epoch 474/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6084 - val_loss: 0.6498\n",
      "Epoch 475/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6080 - val_loss: 0.6468\n",
      "Epoch 476/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6081 - val_loss: 0.6443\n",
      "Epoch 477/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6080 - val_loss: 0.6462\n",
      "Epoch 478/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6083 - val_loss: 0.6469\n",
      "Epoch 479/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6078 - val_loss: 0.6462\n",
      "Epoch 480/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6083 - val_loss: 0.6477\n",
      "Epoch 481/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6082 - val_loss: 0.6433\n",
      "Epoch 482/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6078 - val_loss: 0.6448\n",
      "Epoch 483/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6081 - val_loss: 0.6510\n",
      "Epoch 484/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6078 - val_loss: 0.6514\n",
      "Epoch 485/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6076 - val_loss: 0.6493\n",
      "Epoch 486/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6076 - val_loss: 0.6451\n",
      "Epoch 487/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6082 - val_loss: 0.6460\n",
      "Epoch 488/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6079 - val_loss: 0.6448\n",
      "Epoch 489/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6076 - val_loss: 0.6476\n",
      "Epoch 490/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6078 - val_loss: 0.6506\n",
      "Epoch 491/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6077 - val_loss: 0.6475\n",
      "Epoch 492/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6074 - val_loss: 0.6470\n",
      "Epoch 493/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6073 - val_loss: 0.6486\n",
      "Epoch 494/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6074 - val_loss: 0.6490\n",
      "Epoch 495/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6074 - val_loss: 0.6478\n",
      "Epoch 496/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6071 - val_loss: 0.6496\n",
      "Epoch 497/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6073 - val_loss: 0.6489\n",
      "Epoch 498/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6071 - val_loss: 0.6473\n",
      "Epoch 499/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6071 - val_loss: 0.6493\n",
      "Epoch 500/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6073 - val_loss: 0.6502\n",
      "Epoch 501/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6071 - val_loss: 0.6479\n",
      "Epoch 502/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6076 - val_loss: 0.6443\n",
      "Epoch 503/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6071 - val_loss: 0.6465\n",
      "Epoch 504/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6072 - val_loss: 0.6494\n",
      "Epoch 505/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6068 - val_loss: 0.6477\n",
      "Epoch 506/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6070 - val_loss: 0.6498\n",
      "Epoch 507/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.3982Restoring model weights from the end of the best epoch: 407.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6069 - val_loss: 0.6471\n",
      "Epoch 507: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x177b1c760>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emiliani1_CMI_best5.fit(best5_CMI_train_E1,target_df_train_E1.mean_std,validation_data=(best5_CMI_val_E1,target_df_val_E1.mean_std),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e1d9ddbf",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:16:56.773016: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2524697745336094"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(target_df_test_E1.mean_std, model_emiliani1_CMI_best5.predict(best5_CMI_test_E1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059020db",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Emiliani2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d7614e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36\n",
      "Trainable params: 36\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_emiliani2_CMI_best5 = Sequential()\n",
    "model_emiliani2_CMI_best5.add(Dense(5, input_dim=5, activation='relu')) \n",
    "model_emiliani2_CMI_best5.add(Dense(1)) # Output\n",
    "\n",
    "model_emiliani2_CMI_best5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=100, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani2_CMI_best5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae9a41d0",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 1.0360 - val_loss: 0.9248\n",
      "Epoch 2/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.9788"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:17:06.486447: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-13 14:17:06.638054: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 1.0047 - val_loss: 0.8981\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9747 - val_loss: 0.8766\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9489 - val_loss: 0.8571\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9249 - val_loss: 0.8387\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.9038 - val_loss: 0.8229\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8847 - val_loss: 0.8085\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8681 - val_loss: 0.7945\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8521 - val_loss: 0.7816\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8385 - val_loss: 0.7690\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8245 - val_loss: 0.7583\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8122 - val_loss: 0.7484\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.8018 - val_loss: 0.7412\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7937 - val_loss: 0.7354\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7866 - val_loss: 0.7298\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7803 - val_loss: 0.7249\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7752 - val_loss: 0.7200\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7700 - val_loss: 0.7179\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7659 - val_loss: 0.7150\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7623 - val_loss: 0.7124\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7596 - val_loss: 0.7098\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7559 - val_loss: 0.7085\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7533 - val_loss: 0.7060\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7502 - val_loss: 0.7032\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7480 - val_loss: 0.7007\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7460 - val_loss: 0.6981\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7434 - val_loss: 0.6972\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7410 - val_loss: 0.6963\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7390 - val_loss: 0.6940\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7370 - val_loss: 0.6921\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7348 - val_loss: 0.6930\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7325 - val_loss: 0.6913\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7304 - val_loss: 0.6918\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7282 - val_loss: 0.6904\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7262 - val_loss: 0.6906\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7239 - val_loss: 0.6901\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7217 - val_loss: 0.6900\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7195 - val_loss: 0.6897\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7176 - val_loss: 0.6882\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7160 - val_loss: 0.6884\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7143 - val_loss: 0.6884\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7132 - val_loss: 0.6882\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7112 - val_loss: 0.6901\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7099 - val_loss: 0.6892\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7087 - val_loss: 0.6896\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7076 - val_loss: 0.6902\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7064 - val_loss: 0.6901\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7050 - val_loss: 0.6908\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7040 - val_loss: 0.6910\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7029 - val_loss: 0.6913\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7021 - val_loss: 0.6901\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7011 - val_loss: 0.6905\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7002 - val_loss: 0.6909\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6993 - val_loss: 0.6912\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6985 - val_loss: 0.6905\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6977 - val_loss: 0.6906\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6972 - val_loss: 0.6915\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6964 - val_loss: 0.6911\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6957 - val_loss: 0.6913\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6953 - val_loss: 0.6908\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6946 - val_loss: 0.6898\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6940 - val_loss: 0.6904\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6938 - val_loss: 0.6894\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6929 - val_loss: 0.6895\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6926 - val_loss: 0.6886\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6922 - val_loss: 0.6894\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6922 - val_loss: 0.6890\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6911 - val_loss: 0.6893\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6909 - val_loss: 0.6899\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6906 - val_loss: 0.6889\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6904 - val_loss: 0.6901\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6898 - val_loss: 0.6903\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6894 - val_loss: 0.6908\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6892 - val_loss: 0.6905\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6888 - val_loss: 0.6906\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6888 - val_loss: 0.6900\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6882 - val_loss: 0.6911\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6881 - val_loss: 0.6903\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6877 - val_loss: 0.6907\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6875 - val_loss: 0.6915\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6871 - val_loss: 0.6902\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6868 - val_loss: 0.6905\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6864 - val_loss: 0.6909\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6866 - val_loss: 0.6910\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6860 - val_loss: 0.6924\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6862 - val_loss: 0.6925\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6858 - val_loss: 0.6913\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6853 - val_loss: 0.6922\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6852 - val_loss: 0.6908\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6848 - val_loss: 0.6915\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6845 - val_loss: 0.6924\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6844 - val_loss: 0.6926\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6843 - val_loss: 0.6916\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6844 - val_loss: 0.6930\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6839 - val_loss: 0.6921\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6838 - val_loss: 0.6928\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6838 - val_loss: 0.6927\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6833 - val_loss: 0.6935\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6831 - val_loss: 0.6936\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6831 - val_loss: 0.6940\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6827 - val_loss: 0.6931\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6827 - val_loss: 0.6934\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6826 - val_loss: 0.6941\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6823 - val_loss: 0.6949\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6821 - val_loss: 0.6937\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6820 - val_loss: 0.6937\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6819 - val_loss: 0.6940\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6816 - val_loss: 0.6943\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6815 - val_loss: 0.6949\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6815 - val_loss: 0.6951\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6813 - val_loss: 0.6950\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6815 - val_loss: 0.6952\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6813 - val_loss: 0.6944\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6812 - val_loss: 0.6947\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6810 - val_loss: 0.6952\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6811 - val_loss: 0.6952\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6807 - val_loss: 0.6943\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6808 - val_loss: 0.6951\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6807 - val_loss: 0.6929\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6806 - val_loss: 0.6932\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6806 - val_loss: 0.6939\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6803 - val_loss: 0.6951\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6804 - val_loss: 0.6946\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6804 - val_loss: 0.6960\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6802 - val_loss: 0.6963\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6801 - val_loss: 0.6953\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6799 - val_loss: 0.6958\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6800 - val_loss: 0.6951\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6799 - val_loss: 0.6961\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6797 - val_loss: 0.6952\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6797 - val_loss: 0.6950\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6796 - val_loss: 0.6957\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6796 - val_loss: 0.6948\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6797 - val_loss: 0.6964\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6792 - val_loss: 0.6961\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6792 - val_loss: 0.6964\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6792 - val_loss: 0.6962\n",
      "Epoch 138/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6793 - val_loss: 0.6971\n",
      "Epoch 139/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.5825Restoring model weights from the end of the best epoch: 39.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6791 - val_loss: 0.6980\n",
      "Epoch 139: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x169fb8490>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_emiliani2_CMI_best5.fit(best5_CMI_train_E2,target_df_train_E2.mean_std,validation_data=(best5_CMI_val_E2,target_df_val_E2.mean_std),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b490632",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:17:16.161300: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2570693400412608"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(target_df_test_E2.mean_std, model_emiliani2_CMI_best5.predict(best5_CMI_test_E2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56c6504",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed02b9c6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 67\n",
      "Trainable params: 67\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_emiliani12_CMI_best5 = Sequential()\n",
    "model_emiliani12_CMI_best5.add(Dense(5, input_dim=10, activation='relu')) \n",
    "model_emiliani12_CMI_best5.add(Dense(2)) # Output\n",
    "\n",
    "model_emiliani12_CMI_best5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=100, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_emiliani12_CMI_best5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00120377",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "13/13 [==============================] - 1s 12ms/step - loss: 0.8394 - val_loss: 0.8951\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:17:28.995569: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-02-13 14:17:29.147892: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8057 - val_loss: 0.8407\n",
      "Epoch 3/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7803 - val_loss: 0.7987\n",
      "Epoch 4/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7640 - val_loss: 0.7626\n",
      "Epoch 5/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7537 - val_loss: 0.7389\n",
      "Epoch 6/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7463 - val_loss: 0.7293\n",
      "Epoch 7/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7417 - val_loss: 0.7219\n",
      "Epoch 8/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7384 - val_loss: 0.7156\n",
      "Epoch 9/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7344 - val_loss: 0.7103\n",
      "Epoch 10/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7315 - val_loss: 0.7077\n",
      "Epoch 11/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7285 - val_loss: 0.7023\n",
      "Epoch 12/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7256 - val_loss: 0.6997\n",
      "Epoch 13/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7231 - val_loss: 0.6966\n",
      "Epoch 14/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7208 - val_loss: 0.6920\n",
      "Epoch 15/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7183 - val_loss: 0.6885\n",
      "Epoch 16/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7162 - val_loss: 0.6894\n",
      "Epoch 17/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7141 - val_loss: 0.6859\n",
      "Epoch 18/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7120 - val_loss: 0.6805\n",
      "Epoch 19/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7101 - val_loss: 0.6775\n",
      "Epoch 20/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7083 - val_loss: 0.6760\n",
      "Epoch 21/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7065 - val_loss: 0.6758\n",
      "Epoch 22/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7051 - val_loss: 0.6746\n",
      "Epoch 23/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7035 - val_loss: 0.6731\n",
      "Epoch 24/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7019 - val_loss: 0.6711\n",
      "Epoch 25/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.7010 - val_loss: 0.6674\n",
      "Epoch 26/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6996 - val_loss: 0.6682\n",
      "Epoch 27/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6985 - val_loss: 0.6673\n",
      "Epoch 28/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6978 - val_loss: 0.6686\n",
      "Epoch 29/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6962 - val_loss: 0.6635\n",
      "Epoch 30/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6953 - val_loss: 0.6625\n",
      "Epoch 31/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6942 - val_loss: 0.6606\n",
      "Epoch 32/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6933 - val_loss: 0.6589\n",
      "Epoch 33/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6924 - val_loss: 0.6586\n",
      "Epoch 34/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6915 - val_loss: 0.6576\n",
      "Epoch 35/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6905 - val_loss: 0.6572\n",
      "Epoch 36/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6896 - val_loss: 0.6573\n",
      "Epoch 37/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6889 - val_loss: 0.6571\n",
      "Epoch 38/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6879 - val_loss: 0.6560\n",
      "Epoch 39/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6878 - val_loss: 0.6590\n",
      "Epoch 40/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6862 - val_loss: 0.6565\n",
      "Epoch 41/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6854 - val_loss: 0.6560\n",
      "Epoch 42/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6848 - val_loss: 0.6573\n",
      "Epoch 43/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6843 - val_loss: 0.6572\n",
      "Epoch 44/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6837 - val_loss: 0.6571\n",
      "Epoch 45/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6825 - val_loss: 0.6568\n",
      "Epoch 46/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6821 - val_loss: 0.6574\n",
      "Epoch 47/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6811 - val_loss: 0.6571\n",
      "Epoch 48/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6808 - val_loss: 0.6580\n",
      "Epoch 49/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6805 - val_loss: 0.6607\n",
      "Epoch 50/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6793 - val_loss: 0.6590\n",
      "Epoch 51/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6788 - val_loss: 0.6596\n",
      "Epoch 52/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6783 - val_loss: 0.6580\n",
      "Epoch 53/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6778 - val_loss: 0.6592\n",
      "Epoch 54/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6775 - val_loss: 0.6610\n",
      "Epoch 55/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6765 - val_loss: 0.6614\n",
      "Epoch 56/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6762 - val_loss: 0.6601\n",
      "Epoch 57/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6756 - val_loss: 0.6605\n",
      "Epoch 58/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6750 - val_loss: 0.6619\n",
      "Epoch 59/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6746 - val_loss: 0.6640\n",
      "Epoch 60/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6745 - val_loss: 0.6673\n",
      "Epoch 61/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6743 - val_loss: 0.6650\n",
      "Epoch 62/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6735 - val_loss: 0.6667\n",
      "Epoch 63/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6725 - val_loss: 0.6682\n",
      "Epoch 64/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6724 - val_loss: 0.6681\n",
      "Epoch 65/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6715 - val_loss: 0.6691\n",
      "Epoch 66/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6706 - val_loss: 0.6692\n",
      "Epoch 67/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6703 - val_loss: 0.6677\n",
      "Epoch 68/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6700 - val_loss: 0.6700\n",
      "Epoch 69/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6692 - val_loss: 0.6705\n",
      "Epoch 70/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6691 - val_loss: 0.6705\n",
      "Epoch 71/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6682 - val_loss: 0.6694\n",
      "Epoch 72/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6678 - val_loss: 0.6693\n",
      "Epoch 73/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6672 - val_loss: 0.6696\n",
      "Epoch 74/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6667 - val_loss: 0.6712\n",
      "Epoch 75/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6664 - val_loss: 0.6707\n",
      "Epoch 76/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6663 - val_loss: 0.6717\n",
      "Epoch 77/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6653 - val_loss: 0.6728\n",
      "Epoch 78/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6650 - val_loss: 0.6740\n",
      "Epoch 79/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6646 - val_loss: 0.6738\n",
      "Epoch 80/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6642 - val_loss: 0.6752\n",
      "Epoch 81/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6636 - val_loss: 0.6752\n",
      "Epoch 82/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6631 - val_loss: 0.6758\n",
      "Epoch 83/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6629 - val_loss: 0.6764\n",
      "Epoch 84/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6630 - val_loss: 0.6753\n",
      "Epoch 85/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6619 - val_loss: 0.6776\n",
      "Epoch 86/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6624 - val_loss: 0.6763\n",
      "Epoch 87/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6612 - val_loss: 0.6778\n",
      "Epoch 88/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6609 - val_loss: 0.6787\n",
      "Epoch 89/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6607 - val_loss: 0.6784\n",
      "Epoch 90/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6604 - val_loss: 0.6777\n",
      "Epoch 91/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6601 - val_loss: 0.6783\n",
      "Epoch 92/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6602 - val_loss: 0.6776\n",
      "Epoch 93/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6595 - val_loss: 0.6753\n",
      "Epoch 94/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6593 - val_loss: 0.6789\n",
      "Epoch 95/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6588 - val_loss: 0.6790\n",
      "Epoch 96/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6582 - val_loss: 0.6776\n",
      "Epoch 97/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6579 - val_loss: 0.6793\n",
      "Epoch 98/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6578 - val_loss: 0.6790\n",
      "Epoch 99/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6576 - val_loss: 0.6787\n",
      "Epoch 100/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6575 - val_loss: 0.6805\n",
      "Epoch 101/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6571 - val_loss: 0.6788\n",
      "Epoch 102/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6568 - val_loss: 0.6779\n",
      "Epoch 103/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6569 - val_loss: 0.6769\n",
      "Epoch 104/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6564 - val_loss: 0.6783\n",
      "Epoch 105/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6562 - val_loss: 0.6801\n",
      "Epoch 106/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6561 - val_loss: 0.6781\n",
      "Epoch 107/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6557 - val_loss: 0.6773\n",
      "Epoch 108/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6557 - val_loss: 0.6768\n",
      "Epoch 109/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6553 - val_loss: 0.6776\n",
      "Epoch 110/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6554 - val_loss: 0.6791\n",
      "Epoch 111/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6553 - val_loss: 0.6756\n",
      "Epoch 112/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6547 - val_loss: 0.6777\n",
      "Epoch 113/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6548 - val_loss: 0.6787\n",
      "Epoch 114/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6545 - val_loss: 0.6778\n",
      "Epoch 115/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6542 - val_loss: 0.6787\n",
      "Epoch 116/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6540 - val_loss: 0.6769\n",
      "Epoch 117/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6542 - val_loss: 0.6786\n",
      "Epoch 118/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6536 - val_loss: 0.6769\n",
      "Epoch 119/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6535 - val_loss: 0.6795\n",
      "Epoch 120/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6532 - val_loss: 0.6787\n",
      "Epoch 121/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6532 - val_loss: 0.6774\n",
      "Epoch 122/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6529 - val_loss: 0.6773\n",
      "Epoch 123/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6767\n",
      "Epoch 124/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6531 - val_loss: 0.6812\n",
      "Epoch 125/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6525 - val_loss: 0.6793\n",
      "Epoch 126/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6522 - val_loss: 0.6796\n",
      "Epoch 127/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6523 - val_loss: 0.6786\n",
      "Epoch 128/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6519 - val_loss: 0.6766\n",
      "Epoch 129/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6517 - val_loss: 0.6765\n",
      "Epoch 130/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6515 - val_loss: 0.6794\n",
      "Epoch 131/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6518 - val_loss: 0.6760\n",
      "Epoch 132/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6512 - val_loss: 0.6772\n",
      "Epoch 133/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6509 - val_loss: 0.6782\n",
      "Epoch 134/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6507 - val_loss: 0.6780\n",
      "Epoch 135/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6506 - val_loss: 0.6773\n",
      "Epoch 136/1000\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.6502 - val_loss: 0.6772\n",
      "Epoch 137/1000\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6504 - val_loss: 0.6773\n",
      "Epoch 138/1000\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6784Restoring model weights from the end of the best epoch: 38.\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.6499 - val_loss: 0.6773\n",
      "Epoch 138: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x177e1a7f0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best5_CMI_train_E12 = pd.concat((best5_CMI_train_E1,best5_CMI_train_E2),axis=1)\n",
    "best5_CMI_val_E12 = pd.concat((best5_CMI_val_E1,best5_CMI_val_E2),axis=1)\n",
    "best5_CMI_test_E12 = pd.concat((best5_CMI_test_E1,best5_CMI_test_E2),axis=1)\n",
    "\n",
    "target_train_E12 = pd.concat((target_df_train_E1.mean_std,target_df_train_E2.mean_std),axis=1)\n",
    "target_val_E12 = pd.concat((target_df_val_E1.mean_std,target_df_val_E2.mean_std),axis=1)\n",
    "target_test_E12 = pd.concat((target_df_test_E1.mean_std,target_df_test_E2.mean_std),axis=1)\n",
    "\n",
    "model_emiliani12_CMI_best5.fit(best5_CMI_train_E12,target_train_E12,validation_data=(best5_CMI_val_E12,target_val_E12),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df768dfc",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n",
      "0.2646020300846088\n",
      "0.2860979483350553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:17:55.725250: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "res = model_emiliani12_CMI_best5.predict(best5_CMI_test_E12)\n",
    "\n",
    "print(r2_score(target_df_test_E1.mean_std, res[:,0]))\n",
    "print(r2_score(target_df_test_E2.mean_std, res[:,1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d526fd1",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Together, another structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47647e9e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 5)                 35        \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41\n",
      "Trainable params: 41\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_both_CMI_best5 = Sequential()\n",
    "model_both_CMI_best5.add(Dense(5, input_dim=6, activation='relu')) \n",
    "model_both_CMI_best5.add(Dense(1)) # Output\n",
    "\n",
    "model_both_CMI_best5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=100, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_both_CMI_best5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb279692",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_CMI_train_withClass0 = pd.concat((best5_CMI_train_E1,pd.DataFrame(np.zeros(len(best5_CMI_train_E1)),columns=['basin'])),axis=1)\n",
    "best5_CMI_train_withClass1 = pd.concat((best5_CMI_train_E2,pd.DataFrame(np.ones(len(best5_CMI_train_E1)),columns=['basin'])),axis=1)\n",
    "best5_CMI_train_withClass01 = np.concatenate((best5_CMI_train_withClass0.values,best5_CMI_train_withClass1.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "443246ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_CMI_val_withClass0 = pd.concat((best5_CMI_val_E1,pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin'])),axis=1)\n",
    "best5_CMI_val_withClass1 = pd.concat((best5_CMI_val_E2,pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin'])),axis=1)\n",
    "best5_CMI_val_withClass01 = np.concatenate((best5_CMI_val_withClass0.values,best5_CMI_val_withClass1.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "077d37d7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_CMI_test_withClass0 = pd.concat((best5_CMI_test_E1,pd.DataFrame(np.zeros(len(best5_CMI_test_E1)),columns=['basin'])),axis=1)\n",
    "best5_CMI_test_withClass1 = pd.concat((best5_CMI_test_E2,pd.DataFrame(np.ones(len(best5_CMI_test_E1)),columns=['basin'])),axis=1)\n",
    "best5_CMI_test_withClass01 = np.concatenate((best5_CMI_test_withClass0.values,best5_CMI_test_withClass1.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1b63c6ec",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_train_withClass01 = pd.concat((target_df_train_E1.mean_std,target_df_train_E2.mean_std),axis=0)\n",
    "target_val_withClass01 = pd.concat((target_df_val_E1.mean_std,target_df_val_E2.mean_std),axis=0)\n",
    "target_test_withClass01 = pd.concat((target_df_test_E1.mean_std,target_df_test_E2.mean_std),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dced8ed2",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:45:09.461116: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 1s 12ms/step - loss: 1.0354 - val_loss: 0.9807\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.9517 - val_loss: 0.9125\n",
      "Epoch 3/1000\n",
      " 1/26 [>.............................] - ETA: 0s - loss: 0.9551"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:45:10.209832: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8976 - val_loss: 0.8774\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8628 - val_loss: 0.8597\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8423 - val_loss: 0.8472\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8291 - val_loss: 0.8396\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8193 - val_loss: 0.8338\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8123 - val_loss: 0.8301\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8056 - val_loss: 0.8253\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8006 - val_loss: 0.8215\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7954 - val_loss: 0.8166\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7901 - val_loss: 0.8124\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7855 - val_loss: 0.8085\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7812 - val_loss: 0.8041\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7772 - val_loss: 0.8016\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7737 - val_loss: 0.7989\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7699 - val_loss: 0.7964\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7669 - val_loss: 0.7927\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7634 - val_loss: 0.7910\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7601 - val_loss: 0.7885\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7568 - val_loss: 0.7844\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7541 - val_loss: 0.7821\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7514 - val_loss: 0.7804\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7485 - val_loss: 0.7778\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7459 - val_loss: 0.7751\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7436 - val_loss: 0.7732\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7415 - val_loss: 0.7725\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7388 - val_loss: 0.7692\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7366 - val_loss: 0.7660\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7346 - val_loss: 0.7636\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7325 - val_loss: 0.7606\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7307 - val_loss: 0.7588\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7288 - val_loss: 0.7580\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7268 - val_loss: 0.7554\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7249 - val_loss: 0.7526\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7229 - val_loss: 0.7503\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7215 - val_loss: 0.7489\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7201 - val_loss: 0.7455\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7188 - val_loss: 0.7437\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7176 - val_loss: 0.7419\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7159 - val_loss: 0.7407\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7147 - val_loss: 0.7389\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7135 - val_loss: 0.7386\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7126 - val_loss: 0.7358\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7109 - val_loss: 0.7348\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7104 - val_loss: 0.7322\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7086 - val_loss: 0.7303\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7074 - val_loss: 0.7275\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7061 - val_loss: 0.7251\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7051 - val_loss: 0.7241\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7039 - val_loss: 0.7216\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7030 - val_loss: 0.7198\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7021 - val_loss: 0.7179\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7009 - val_loss: 0.7171\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6994 - val_loss: 0.7149\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6983 - val_loss: 0.7127\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6974 - val_loss: 0.7107\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6966 - val_loss: 0.7080\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6952 - val_loss: 0.7066\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6944 - val_loss: 0.7055\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6935 - val_loss: 0.7025\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6920 - val_loss: 0.7016\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6917 - val_loss: 0.7001\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6903 - val_loss: 0.6996\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6899 - val_loss: 0.6969\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6888 - val_loss: 0.6962\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6879 - val_loss: 0.6942\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6876 - val_loss: 0.6926\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6862 - val_loss: 0.6925\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6853 - val_loss: 0.6908\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6846 - val_loss: 0.6892\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6840 - val_loss: 0.6879\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6831 - val_loss: 0.6868\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6830 - val_loss: 0.6858\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6820 - val_loss: 0.6846\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6822 - val_loss: 0.6822\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6808 - val_loss: 0.6816\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6801 - val_loss: 0.6804\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6805 - val_loss: 0.6801\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6794 - val_loss: 0.6807\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6789 - val_loss: 0.6805\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6781 - val_loss: 0.6793\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6790 - val_loss: 0.6767\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6774 - val_loss: 0.6776\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6769 - val_loss: 0.6770\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6764 - val_loss: 0.6759\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6757 - val_loss: 0.6749\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6751 - val_loss: 0.6741\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6742 - val_loss: 0.6736\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6735 - val_loss: 0.6719\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6729 - val_loss: 0.6709\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6725 - val_loss: 0.6711\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6715 - val_loss: 0.6700\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6707 - val_loss: 0.6703\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6699 - val_loss: 0.6694\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6694 - val_loss: 0.6673\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6688 - val_loss: 0.6674\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6681 - val_loss: 0.6661\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6675 - val_loss: 0.6658\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6676 - val_loss: 0.6642\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6668 - val_loss: 0.6652\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6666 - val_loss: 0.6642\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6663 - val_loss: 0.6622\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6660 - val_loss: 0.6624\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6658 - val_loss: 0.6614\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6655 - val_loss: 0.6606\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6660 - val_loss: 0.6615\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6656 - val_loss: 0.6590\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6648 - val_loss: 0.6593\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6639 - val_loss: 0.6587\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6649 - val_loss: 0.6594\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6642 - val_loss: 0.6576\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6633 - val_loss: 0.6573\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6635 - val_loss: 0.6564\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6632 - val_loss: 0.6559\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6627 - val_loss: 0.6565\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6630 - val_loss: 0.6566\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6632 - val_loss: 0.6555\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6628 - val_loss: 0.6551\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6624 - val_loss: 0.6545\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6620 - val_loss: 0.6549\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6619 - val_loss: 0.6554\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6614 - val_loss: 0.6547\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6614 - val_loss: 0.6548\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6612 - val_loss: 0.6539\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6612 - val_loss: 0.6539\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6615 - val_loss: 0.6533\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6608 - val_loss: 0.6534\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6609 - val_loss: 0.6536\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6603 - val_loss: 0.6525\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6604 - val_loss: 0.6522\n",
      "Epoch 132/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6603 - val_loss: 0.6509\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6602 - val_loss: 0.6520\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6600 - val_loss: 0.6525\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6603 - val_loss: 0.6521\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6605 - val_loss: 0.6517\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6595 - val_loss: 0.6518\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6592 - val_loss: 0.6521\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6596 - val_loss: 0.6516\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6591 - val_loss: 0.6502\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6589 - val_loss: 0.6509\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6586 - val_loss: 0.6498\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6591 - val_loss: 0.6508\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6591 - val_loss: 0.6514\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6593 - val_loss: 0.6501\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6581 - val_loss: 0.6500\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6587 - val_loss: 0.6502\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6579 - val_loss: 0.6494\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6579 - val_loss: 0.6504\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6584 - val_loss: 0.6488\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6579 - val_loss: 0.6500\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6570 - val_loss: 0.6489\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6576 - val_loss: 0.6468\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6566 - val_loss: 0.6488\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6564 - val_loss: 0.6483\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6567 - val_loss: 0.6475\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6569 - val_loss: 0.6468\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6568 - val_loss: 0.6480\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6564 - val_loss: 0.6470\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6559 - val_loss: 0.6471\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6555 - val_loss: 0.6472\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6559 - val_loss: 0.6466\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6556 - val_loss: 0.6462\n",
      "Epoch 164/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6551 - val_loss: 0.6456\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6550 - val_loss: 0.6453\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6553 - val_loss: 0.6453\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6547 - val_loss: 0.6451\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6549 - val_loss: 0.6452\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6547 - val_loss: 0.6445\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6547 - val_loss: 0.6439\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6544 - val_loss: 0.6451\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6544 - val_loss: 0.6443\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6543 - val_loss: 0.6447\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6543 - val_loss: 0.6450\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6546 - val_loss: 0.6443\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6541 - val_loss: 0.6439\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6539 - val_loss: 0.6438\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6538 - val_loss: 0.6434\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6538 - val_loss: 0.6453\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6536 - val_loss: 0.6431\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6535 - val_loss: 0.6454\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6532 - val_loss: 0.6444\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6532 - val_loss: 0.6434\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6454\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6530 - val_loss: 0.6450\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6441\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6530 - val_loss: 0.6445\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6526 - val_loss: 0.6443\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6434\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6531 - val_loss: 0.6460\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6524 - val_loss: 0.6427\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6438\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6524 - val_loss: 0.6443\n",
      "Epoch 194/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6521 - val_loss: 0.6427\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6526 - val_loss: 0.6434\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6523 - val_loss: 0.6436\n",
      "Epoch 197/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6520 - val_loss: 0.6440\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6518 - val_loss: 0.6436\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6515 - val_loss: 0.6445\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6514 - val_loss: 0.6421\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6515 - val_loss: 0.6428\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6514 - val_loss: 0.6439\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6513 - val_loss: 0.6418\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6510 - val_loss: 0.6435\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6513 - val_loss: 0.6432\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6513 - val_loss: 0.6428\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6510 - val_loss: 0.6428\n",
      "Epoch 208/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6508 - val_loss: 0.6429\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6508 - val_loss: 0.6432\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.6508 - val_loss: 0.6425\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.6508 - val_loss: 0.6419\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.6509 - val_loss: 0.6426\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6505 - val_loss: 0.6420\n",
      "Epoch 214/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6506 - val_loss: 0.6425\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6508 - val_loss: 0.6427\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6505 - val_loss: 0.6417\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6506 - val_loss: 0.6417\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6503 - val_loss: 0.6430\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6507 - val_loss: 0.6421\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6507 - val_loss: 0.6414\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6502 - val_loss: 0.6412\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6504 - val_loss: 0.6424\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6502 - val_loss: 0.6414\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6500 - val_loss: 0.6434\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6504 - val_loss: 0.6410\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6503 - val_loss: 0.6413\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6498 - val_loss: 0.6425\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6499 - val_loss: 0.6416\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6501 - val_loss: 0.6416\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6498 - val_loss: 0.6423\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6501 - val_loss: 0.6419\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6501 - val_loss: 0.6408\n",
      "Epoch 233/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6499 - val_loss: 0.6413\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.6410\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6500 - val_loss: 0.6420\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6498 - val_loss: 0.6420\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6495 - val_loss: 0.6422\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6500 - val_loss: 0.6421\n",
      "Epoch 239/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6494 - val_loss: 0.6403\n",
      "Epoch 240/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6494 - val_loss: 0.6408\n",
      "Epoch 241/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6498 - val_loss: 0.6412\n",
      "Epoch 242/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6496 - val_loss: 0.6430\n",
      "Epoch 243/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6494 - val_loss: 0.6412\n",
      "Epoch 244/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 0.6424\n",
      "Epoch 245/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6495 - val_loss: 0.6414\n",
      "Epoch 246/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6497 - val_loss: 0.6413\n",
      "Epoch 247/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6496 - val_loss: 0.6415\n",
      "Epoch 248/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6494 - val_loss: 0.6420\n",
      "Epoch 249/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6493 - val_loss: 0.6401\n",
      "Epoch 250/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.6416\n",
      "Epoch 251/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6495 - val_loss: 0.6421\n",
      "Epoch 252/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6493 - val_loss: 0.6412\n",
      "Epoch 253/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 0.6416\n",
      "Epoch 254/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.6413\n",
      "Epoch 255/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6496 - val_loss: 0.6406\n",
      "Epoch 256/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6504 - val_loss: 0.6418\n",
      "Epoch 257/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6495 - val_loss: 0.6415\n",
      "Epoch 258/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 0.6406\n",
      "Epoch 259/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6490 - val_loss: 0.6400\n",
      "Epoch 260/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.6420\n",
      "Epoch 261/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.6408\n",
      "Epoch 262/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6493 - val_loss: 0.6409\n",
      "Epoch 263/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6493 - val_loss: 0.6424\n",
      "Epoch 264/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6497 - val_loss: 0.6405\n",
      "Epoch 265/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.6422\n",
      "Epoch 266/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6496 - val_loss: 0.6403\n",
      "Epoch 267/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6495 - val_loss: 0.6395\n",
      "Epoch 268/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.6404\n",
      "Epoch 269/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6407\n",
      "Epoch 270/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6405\n",
      "Epoch 271/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6493 - val_loss: 0.6411\n",
      "Epoch 272/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6490 - val_loss: 0.6406\n",
      "Epoch 273/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6490 - val_loss: 0.6386\n",
      "Epoch 274/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6397\n",
      "Epoch 275/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6412\n",
      "Epoch 276/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.6407\n",
      "Epoch 277/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6402\n",
      "Epoch 278/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6391\n",
      "Epoch 279/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6403\n",
      "Epoch 280/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.6491 - val_loss: 0.6412\n",
      "Epoch 281/1000\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.6489 - val_loss: 0.6393\n",
      "Epoch 282/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 0.6398\n",
      "Epoch 283/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6401\n",
      "Epoch 284/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6417\n",
      "Epoch 285/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6490 - val_loss: 0.6405\n",
      "Epoch 286/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6485 - val_loss: 0.6414\n",
      "Epoch 287/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6491 - val_loss: 0.6415\n",
      "Epoch 288/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6400\n",
      "Epoch 289/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6406\n",
      "Epoch 290/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6396\n",
      "Epoch 291/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6493 - val_loss: 0.6398\n",
      "Epoch 292/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 0.6394\n",
      "Epoch 293/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6390\n",
      "Epoch 294/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6495 - val_loss: 0.6402\n",
      "Epoch 295/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6499 - val_loss: 0.6397\n",
      "Epoch 296/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6490 - val_loss: 0.6410\n",
      "Epoch 297/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6488 - val_loss: 0.6416\n",
      "Epoch 298/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6492 - val_loss: 0.6423\n",
      "Epoch 299/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6494 - val_loss: 0.6409\n",
      "Epoch 300/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6487 - val_loss: 0.6402\n",
      "Epoch 301/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6487 - val_loss: 0.6403\n",
      "Epoch 302/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6485 - val_loss: 0.6399\n",
      "Epoch 303/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6405\n",
      "Epoch 304/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6387\n",
      "Epoch 305/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 0.6403\n",
      "Epoch 306/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6411\n",
      "Epoch 307/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6400\n",
      "Epoch 308/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 0.6403\n",
      "Epoch 309/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6485 - val_loss: 0.6422\n",
      "Epoch 310/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6490 - val_loss: 0.6408\n",
      "Epoch 311/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6408\n",
      "Epoch 312/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.6400\n",
      "Epoch 313/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6484 - val_loss: 0.6402\n",
      "Epoch 314/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6407\n",
      "Epoch 315/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6485 - val_loss: 0.6412\n",
      "Epoch 316/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6411\n",
      "Epoch 317/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6484 - val_loss: 0.6395\n",
      "Epoch 318/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6492 - val_loss: 0.6410\n",
      "Epoch 319/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6397\n",
      "Epoch 320/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6484 - val_loss: 0.6402\n",
      "Epoch 321/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.6414\n",
      "Epoch 322/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6392\n",
      "Epoch 323/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6406\n",
      "Epoch 324/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6420\n",
      "Epoch 325/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6409\n",
      "Epoch 326/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6485 - val_loss: 0.6405\n",
      "Epoch 327/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6481 - val_loss: 0.6410\n",
      "Epoch 328/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.6405\n",
      "Epoch 329/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6481 - val_loss: 0.6404\n",
      "Epoch 330/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6484 - val_loss: 0.6405\n",
      "Epoch 331/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6482 - val_loss: 0.6396\n",
      "Epoch 332/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6485 - val_loss: 0.6419\n",
      "Epoch 333/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6400\n",
      "Epoch 334/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6482 - val_loss: 0.6402\n",
      "Epoch 335/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6485 - val_loss: 0.6396\n",
      "Epoch 336/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6396\n",
      "Epoch 337/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6408\n",
      "Epoch 338/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.6409\n",
      "Epoch 339/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6484 - val_loss: 0.6397\n",
      "Epoch 340/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6414\n",
      "Epoch 341/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6415\n",
      "Epoch 342/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6481 - val_loss: 0.6421\n",
      "Epoch 343/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6490 - val_loss: 0.6413\n",
      "Epoch 344/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.6401\n",
      "Epoch 345/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6480 - val_loss: 0.6404\n",
      "Epoch 346/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6485 - val_loss: 0.6403\n",
      "Epoch 347/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6413\n",
      "Epoch 348/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6484 - val_loss: 0.6397\n",
      "Epoch 349/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6484 - val_loss: 0.6388\n",
      "Epoch 350/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6480 - val_loss: 0.6398\n",
      "Epoch 351/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6487 - val_loss: 0.6402\n",
      "Epoch 352/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6478 - val_loss: 0.6390\n",
      "Epoch 353/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6485 - val_loss: 0.6387\n",
      "Epoch 354/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6399\n",
      "Epoch 355/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6391\n",
      "Epoch 356/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6481 - val_loss: 0.6390\n",
      "Epoch 357/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6485 - val_loss: 0.6411\n",
      "Epoch 358/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6482 - val_loss: 0.6404\n",
      "Epoch 359/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6409\n",
      "Epoch 360/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6480 - val_loss: 0.6403\n",
      "Epoch 361/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6405\n",
      "Epoch 362/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6415\n",
      "Epoch 363/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6489 - val_loss: 0.6401\n",
      "Epoch 364/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6412\n",
      "Epoch 365/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6486 - val_loss: 0.6418\n",
      "Epoch 366/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6478 - val_loss: 0.6402\n",
      "Epoch 367/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6403\n",
      "Epoch 368/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6412\n",
      "Epoch 369/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6478 - val_loss: 0.6391\n",
      "Epoch 370/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6477 - val_loss: 0.6391\n",
      "Epoch 371/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6478 - val_loss: 0.6393\n",
      "Epoch 372/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6392\n",
      "Epoch 373/1000\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.6490Restoring model weights from the end of the best epoch: 273.\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6477 - val_loss: 0.6387\n",
      "Epoch 373: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bce33850>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_both_CMI_best5.fit(best5_CMI_train_withClass01,target_train_withClass01,validation_data=(best5_CMI_val_withClass01,target_val_withClass01),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1a817cf6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "0.2557372464499036\n",
      "0.2790083231613376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-13 14:48:07.285909: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "res0 = model_both_CMI_best5.predict(best5_CMI_test_withClass0.values)\n",
    "res1 = model_both_CMI_best5.predict(best5_CMI_test_withClass1.values)\n",
    "\n",
    "print(r2_score(target_df_test_E1.mean_std, res0))\n",
    "print(r2_score(target_df_test_E2.mean_std, res1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14cbdd5",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### one additional feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1cced3e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_28 (Dense)            (None, 15)                195       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_both_CMI_best5 = Sequential()\n",
    "model_both_CMI_best5.add(Dense(15, input_dim=12, activation='relu')) \n",
    "model_both_CMI_best5.add(Dense(1)) # Output\n",
    "\n",
    "model_both_CMI_best5.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=100, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "model_both_CMI_best5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "683d8ed6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_CMI_train_withClass0 = pd.concat((best5_CMI_train_E1,best5_CMI_train_E2,pd.DataFrame(np.zeros(len(best5_CMI_train_E1)),columns=['basin']),pd.DataFrame(np.zeros(len(best5_CMI_train_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_train_withClass1 = pd.concat((best5_CMI_train_E1,best5_CMI_train_E2,pd.DataFrame(np.ones(len(best5_CMI_train_E1)),columns=['basin']),pd.DataFrame(np.ones(len(best5_CMI_train_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_train_withClass01 = np.concatenate((best5_CMI_train_withClass0.values,best5_CMI_train_withClass1.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9053c301",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_CMI_val_withClass0 = pd.concat((best5_CMI_val_E1,best5_CMI_val_E2,pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin2']),pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin'])),axis=1)\n",
    "best5_CMI_val_withClass1 = pd.concat((best5_CMI_val_E1,best5_CMI_val_E2,pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin2']),pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin'])),axis=1)\n",
    "best5_CMI_val_withClass01 = np.concatenate((best5_CMI_val_withClass0.values,best5_CMI_val_withClass1.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3ef708e7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_CMI_test_withClass0 = pd.concat((best5_CMI_test_E1,best5_CMI_test_E2,pd.DataFrame(np.zeros(len(best5_CMI_test_E1)),columns=['basin']),pd.DataFrame(np.zeros(len(best5_CMI_test_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_test_withClass1 = pd.concat((best5_CMI_test_E1,best5_CMI_test_E2,pd.DataFrame(np.ones(len(best5_CMI_test_E1)),columns=['basin']),pd.DataFrame(np.ones(len(best5_CMI_test_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_test_withClass01 = np.concatenate((best5_CMI_test_withClass0.values,best5_CMI_test_withClass1.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9493f027",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_train_withClass01 = pd.concat((target_df_train_E1.mean_std,target_df_train_E2.mean_std),axis=0)\n",
    "target_val_withClass01 = pd.concat((target_df_val_E1.mean_std,target_df_val_E2.mean_std),axis=0)\n",
    "target_test_withClass01 = pd.concat((target_df_test_E1.mean_std,target_df_test_E2.mean_std),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "39063634",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.6599 - val_loss: 0.6987\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6587 - val_loss: 0.6995\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6555 - val_loss: 0.7014\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6534 - val_loss: 0.6984\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6520 - val_loss: 0.7005\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6513 - val_loss: 0.7000\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6497 - val_loss: 0.7049\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6494 - val_loss: 0.7057\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6471 - val_loss: 0.7085\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6449 - val_loss: 0.7052\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6437 - val_loss: 0.7055\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6429 - val_loss: 0.7009\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6413 - val_loss: 0.7012\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6397 - val_loss: 0.7054\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6396 - val_loss: 0.7078\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6375 - val_loss: 0.7142\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6367 - val_loss: 0.7067\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6341 - val_loss: 0.7112\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6345 - val_loss: 0.7138\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6324 - val_loss: 0.7095\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6320 - val_loss: 0.7135\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6299 - val_loss: 0.7125\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6292 - val_loss: 0.7133\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6283 - val_loss: 0.7151\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6268 - val_loss: 0.7112\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6267 - val_loss: 0.7154\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6261 - val_loss: 0.7169\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6252 - val_loss: 0.7134\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6251 - val_loss: 0.7145\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6256 - val_loss: 0.7150\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6231 - val_loss: 0.7215\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6232 - val_loss: 0.7184\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6216 - val_loss: 0.7183\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6222 - val_loss: 0.7230\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6212 - val_loss: 0.7199\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6204 - val_loss: 0.7169\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6189 - val_loss: 0.7223\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6175 - val_loss: 0.7254\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6174 - val_loss: 0.7243\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6166 - val_loss: 0.7241\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6172 - val_loss: 0.7264\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6167 - val_loss: 0.7259\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6147 - val_loss: 0.7277\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6142 - val_loss: 0.7296\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6133 - val_loss: 0.7302\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6124 - val_loss: 0.7281\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6126 - val_loss: 0.7221\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6124 - val_loss: 0.7337\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6114 - val_loss: 0.7328\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6105 - val_loss: 0.7289\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6092 - val_loss: 0.7293\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6088 - val_loss: 0.7315\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6089 - val_loss: 0.7355\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6094 - val_loss: 0.7361\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6082 - val_loss: 0.7334\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6075 - val_loss: 0.7345\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6068 - val_loss: 0.7355\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6064 - val_loss: 0.7344\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6058 - val_loss: 0.7333\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6050 - val_loss: 0.7363\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6042 - val_loss: 0.7312\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6041 - val_loss: 0.7418\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6036 - val_loss: 0.7338\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6021 - val_loss: 0.7328\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6029 - val_loss: 0.7321\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6036 - val_loss: 0.7420\n",
      "Epoch 67/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6030 - val_loss: 0.7299\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6017 - val_loss: 0.7350\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6012 - val_loss: 0.7349\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6003 - val_loss: 0.7354\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6006 - val_loss: 0.7363\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5993 - val_loss: 0.7361\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5983 - val_loss: 0.7390\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5985 - val_loss: 0.7388\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5982 - val_loss: 0.7370\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5970 - val_loss: 0.7381\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5967 - val_loss: 0.7397\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5957 - val_loss: 0.7424\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5952 - val_loss: 0.7337\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5964 - val_loss: 0.7441\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5949 - val_loss: 0.7424\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5948 - val_loss: 0.7410\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5945 - val_loss: 0.7423\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5948 - val_loss: 0.7441\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5933 - val_loss: 0.7433\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5930 - val_loss: 0.7433\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.7431\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5921 - val_loss: 0.7429\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5911 - val_loss: 0.7469\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5919 - val_loss: 0.7425\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5917 - val_loss: 0.7436\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5918 - val_loss: 0.7481\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5905 - val_loss: 0.7494\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5895 - val_loss: 0.7466\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5907 - val_loss: 0.7431\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5882 - val_loss: 0.7477\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5892 - val_loss: 0.7407\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5886 - val_loss: 0.7507\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5878 - val_loss: 0.7428\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5877 - val_loss: 0.7547\n",
      "Epoch 101/1000\n",
      "18/26 [===================>..........] - ETA: 0s - loss: 0.5936Restoring model weights from the end of the best epoch: 1.\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5872 - val_loss: 0.7429\n",
      "Epoch 101: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c23b3b50>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_both_CMI_best5.fit(best5_CMI_train_withClass01,target_train_withClass01,validation_data=(best5_CMI_val_withClass01,target_val_withClass01),\n",
    "        callbacks=[monitor],epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a9948022",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n",
      "8/8 [==============================] - 0s 2ms/step\n",
      "0.14092015375049294\n",
      "0.11483063130551474\n"
     ]
    }
   ],
   "source": [
    "res0 = model_both_CMI_best5.predict(best5_CMI_test_withClass0.values)\n",
    "res1 = model_both_CMI_best5.predict(best5_CMI_test_withClass1.values)\n",
    "\n",
    "print(r2_score(target_df_test_E1.mean_std, res0))\n",
    "print(r2_score(target_df_test_E2.mean_std, res1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d4877e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### additive linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d021d4e4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>cyclostationary_mean_rr_8w_1</th>\n",
       "      <th>cyclostationary_mean_tg_9</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>cyclostationary_mean_rr_4w_3</th>\n",
       "      <th>cyclostationary_mean_tg_4</th>\n",
       "      <th>cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>basin</th>\n",
       "      <th>basin2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.112078</td>\n",
       "      <td>0.345989</td>\n",
       "      <td>1.690770</td>\n",
       "      <td>3.965287</td>\n",
       "      <td>0.268224</td>\n",
       "      <td>-0.415835</td>\n",
       "      <td>0.733822</td>\n",
       "      <td>-0.736407</td>\n",
       "      <td>2.581050</td>\n",
       "      <td>1.579481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.404523</td>\n",
       "      <td>1.128851</td>\n",
       "      <td>1.865833</td>\n",
       "      <td>1.655892</td>\n",
       "      <td>0.977612</td>\n",
       "      <td>0.237307</td>\n",
       "      <td>0.849889</td>\n",
       "      <td>0.294888</td>\n",
       "      <td>2.460299</td>\n",
       "      <td>1.146518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.162736</td>\n",
       "      <td>0.786460</td>\n",
       "      <td>1.429151</td>\n",
       "      <td>1.672157</td>\n",
       "      <td>-0.780151</td>\n",
       "      <td>-0.259989</td>\n",
       "      <td>0.518355</td>\n",
       "      <td>-1.191392</td>\n",
       "      <td>1.657472</td>\n",
       "      <td>0.697926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861999</td>\n",
       "      <td>0.564161</td>\n",
       "      <td>0.611897</td>\n",
       "      <td>1.593990</td>\n",
       "      <td>0.408553</td>\n",
       "      <td>-0.565851</td>\n",
       "      <td>0.239497</td>\n",
       "      <td>0.067063</td>\n",
       "      <td>1.600489</td>\n",
       "      <td>0.578318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.461930</td>\n",
       "      <td>0.604584</td>\n",
       "      <td>4.150391</td>\n",
       "      <td>1.782496</td>\n",
       "      <td>-0.260577</td>\n",
       "      <td>-0.187005</td>\n",
       "      <td>0.696217</td>\n",
       "      <td>-0.894857</td>\n",
       "      <td>1.249495</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.211596</td>\n",
       "      <td>0.739113</td>\n",
       "      <td>-0.281990</td>\n",
       "      <td>-0.636426</td>\n",
       "      <td>1.599630</td>\n",
       "      <td>1.352614</td>\n",
       "      <td>-0.220555</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>-0.187672</td>\n",
       "      <td>-0.422427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.765747</td>\n",
       "      <td>0.855313</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-1.204469</td>\n",
       "      <td>0.920235</td>\n",
       "      <td>1.040390</td>\n",
       "      <td>0.346445</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>-0.358316</td>\n",
       "      <td>-0.518833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.609296</td>\n",
       "      <td>0.697286</td>\n",
       "      <td>-0.562017</td>\n",
       "      <td>-1.089158</td>\n",
       "      <td>0.341994</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>0.429694</td>\n",
       "      <td>0.796373</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>-0.588942</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.836849</td>\n",
       "      <td>-0.719738</td>\n",
       "      <td>-0.028118</td>\n",
       "      <td>-0.925439</td>\n",
       "      <td>-1.523290</td>\n",
       "      <td>-0.631908</td>\n",
       "      <td>-0.434877</td>\n",
       "      <td>-2.562406</td>\n",
       "      <td>-0.028237</td>\n",
       "      <td>-0.468533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.283715</td>\n",
       "      <td>-1.078052</td>\n",
       "      <td>0.226971</td>\n",
       "      <td>-0.799403</td>\n",
       "      <td>-0.625862</td>\n",
       "      <td>-1.226069</td>\n",
       "      <td>0.334461</td>\n",
       "      <td>-0.263730</td>\n",
       "      <td>0.344734</td>\n",
       "      <td>-0.241170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cyclostationary_mean_rr_4w_0  cyclostationary_mean_tg_1w_4  \\\n",
       "0                        2.112078                      0.345989   \n",
       "1                        1.404523                      1.128851   \n",
       "2                        1.162736                      0.786460   \n",
       "3                        0.861999                      0.564161   \n",
       "4                        1.461930                      0.604584   \n",
       "..                            ...                           ...   \n",
       "406                     -0.211596                      0.739113   \n",
       "407                     -0.765747                      0.855313   \n",
       "408                     -0.609296                      0.697286   \n",
       "409                     -0.836849                     -0.719738   \n",
       "410                     -0.283715                     -1.078052   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1  cyclostationary_mean_rr_8w_1  \\\n",
       "0                         1.690770                      3.965287   \n",
       "1                         1.865833                      1.655892   \n",
       "2                         1.429151                      1.672157   \n",
       "3                         0.611897                      1.593990   \n",
       "4                         4.150391                      1.782496   \n",
       "..                             ...                           ...   \n",
       "406                      -0.281990                     -0.636426   \n",
       "407                      -0.234571                     -1.204469   \n",
       "408                      -0.562017                     -1.089158   \n",
       "409                      -0.028118                     -0.925439   \n",
       "410                       0.226971                     -0.799403   \n",
       "\n",
       "     cyclostationary_mean_tg_9  cyclostationary_mean_tg_1w_4  \\\n",
       "0                     0.268224                     -0.415835   \n",
       "1                     0.977612                      0.237307   \n",
       "2                    -0.780151                     -0.259989   \n",
       "3                     0.408553                     -0.565851   \n",
       "4                    -0.260577                     -0.187005   \n",
       "..                         ...                           ...   \n",
       "406                   1.599630                      1.352614   \n",
       "407                   0.920235                      1.040390   \n",
       "408                   0.341994                      0.830698   \n",
       "409                  -1.523290                     -0.631908   \n",
       "410                  -0.625862                     -1.226069   \n",
       "\n",
       "     cyclostationary_mean_rr_4w_3  cyclostationary_mean_tg_4  \\\n",
       "0                        0.733822                  -0.736407   \n",
       "1                        0.849889                   0.294888   \n",
       "2                        0.518355                  -1.191392   \n",
       "3                        0.239497                   0.067063   \n",
       "4                        0.696217                  -0.894857   \n",
       "..                            ...                        ...   \n",
       "406                     -0.220555                   0.471800   \n",
       "407                      0.346445                   0.034058   \n",
       "408                      0.429694                   0.796373   \n",
       "409                     -0.434877                  -2.562406   \n",
       "410                      0.334461                  -0.263730   \n",
       "\n",
       "     cyclostationary_mean_rr_8w_0  cyclostationary_mean_rr_12w_1  basin  \\\n",
       "0                        2.581050                       1.579481    0.0   \n",
       "1                        2.460299                       1.146518    0.0   \n",
       "2                        1.657472                       0.697926    0.0   \n",
       "3                        1.600489                       0.578318    0.0   \n",
       "4                        1.249495                       0.843396    0.0   \n",
       "..                            ...                            ...    ...   \n",
       "406                     -0.187672                      -0.422427    1.0   \n",
       "407                     -0.358316                      -0.518833    1.0   \n",
       "408                     -0.106524                      -0.588942    1.0   \n",
       "409                     -0.028237                      -0.468533    1.0   \n",
       "410                      0.344734                      -0.241170    1.0   \n",
       "\n",
       "     basin2  \n",
       "0       1.0  \n",
       "1       1.0  \n",
       "2       1.0  \n",
       "3       1.0  \n",
       "4       1.0  \n",
       "..      ...  \n",
       "406     0.0  \n",
       "407     0.0  \n",
       "408     0.0  \n",
       "409     0.0  \n",
       "410     0.0  \n",
       "\n",
       "[822 rows x 12 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best5_CMI_train_withClass0 = pd.concat((best5_CMI_train_E1,best5_CMI_train_E2,pd.DataFrame(np.zeros(len(best5_CMI_train_E1)),columns=['basin']),pd.DataFrame(np.ones(len(best5_CMI_train_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_train_withClass1 = pd.concat((best5_CMI_train_E1,best5_CMI_train_E2,pd.DataFrame(np.ones(len(best5_CMI_train_E1)),columns=['basin']),pd.DataFrame(np.zeros(len(best5_CMI_train_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_train_withClass01 = pd.concat((best5_CMI_train_withClass0,best5_CMI_train_withClass1),axis=0)\n",
    "best5_CMI_train_withClass01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cb560a2a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_CMI_val_withClass0 = pd.concat((best5_CMI_val_E1,best5_CMI_val_E2,pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin']),pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_val_withClass1 = pd.concat((best5_CMI_val_E1,best5_CMI_val_E2,pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin']),pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_val_withClass01 = pd.concat((best5_CMI_val_withClass0,best5_CMI_val_withClass1),axis=0)\n",
    "\n",
    "best5_CMI_test_withClass0 = pd.concat((best5_CMI_test_E1,best5_CMI_test_E2,pd.DataFrame(np.zeros(len(best5_CMI_test_E1)),columns=['basin']),pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_test_withClass1 = pd.concat((best5_CMI_test_E1,best5_CMI_test_E2,pd.DataFrame(np.ones(len(best5_CMI_test_E1)),columns=['basin']),pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_test_withClass01 = pd.concat((best5_CMI_test_withClass0,best5_CMI_test_withClass1),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b6c67758",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_train_withClass01 = pd.concat((target_df_train_E1.mean_std,target_df_train_E2.mean_std),axis=0)\n",
    "target_val_withClass01 = pd.concat((target_df_val_E1.mean_std,target_df_val_E2.mean_std),axis=0)\n",
    "target_test_withClass01 = pd.concat((target_df_test_E1.mean_std,target_df_test_E2.mean_std),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9e81e4a4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(pd.concat((best5_CMI_train_withClass01,best5_CMI_val_withClass01)),pd.concat((target_train_withClass01,target_val_withClass01)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "7671fe2d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34484914195705985\n",
      "0.2496609343242968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res0 = model.predict(best5_CMI_test_withClass0.values)\n",
    "res1 = model.predict(best5_CMI_test_withClass1.values)\n",
    "\n",
    "print(r2_score(target_df_test_E1.mean_std, res0))\n",
    "print(r2_score(target_df_test_E2.mean_std, res1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "c10bf4e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.23585931, -0.11134115,  0.17230418, -0.0261571 , -0.14259048,\n",
       "        0.06147449,  0.08651069, -0.13714384,  0.04001579, -0.03765344,\n",
       "        0.0128004 , -0.0128004 ])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "102d10db",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00598513085606607"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2fd9f126",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3364734050935926\n"
     ]
    }
   ],
   "source": [
    "model0 = LinearRegression()\n",
    "model0.fit(pd.concat((best5_CMI_train_E1,best5_CMI_val_E1)),pd.concat((target_df_train_E1.mean_std,target_df_val_E1.mean_std)))\n",
    "res00 = model0.predict(best5_CMI_test_E1)\n",
    "print(r2_score(target_df_test_E1.mean_std, res00))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d68552ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.33220598, -0.09123719,  0.18002624,  0.0414309 , -0.24917049])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "996bbdb0",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.009909447498446716"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2f1b3d1d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23062800854005472\n"
     ]
    }
   ],
   "source": [
    "model1 = LinearRegression()\n",
    "model1.fit(pd.concat((best5_CMI_train_E2,best5_CMI_val_E2)),pd.concat((target_df_train_E2.mean_std,target_df_val_E2.mean_std)))\n",
    "res11 = model1.predict(best5_CMI_test_E2)\n",
    "print(r2_score(target_df_test_E2.mean_std, res11))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "215bc4f4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(pd.concat((best5_CMI_train_withClass01.iloc[:,:-2],best5_CMI_val_withClass01.iloc[:,:-2])),pd.concat((target_train_withClass01,target_val_withClass01)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0a183e7e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34785910131234443\n",
      "0.24779119186940968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res0_noclass = model.predict(best5_CMI_test_withClass0.iloc[:,:-2].values)\n",
    "res1_noclasss1 = model.predict(best5_CMI_test_withClass1.iloc[:,:-2].values)\n",
    "\n",
    "print(r2_score(target_df_test_E1.mean_std, res0_noclass))\n",
    "print(r2_score(target_df_test_E2.mean_std, res1_noclasss1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "aa5c4cc6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.005985130856066084"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "915e25a4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_only0 = LinearRegression()\n",
    "model_only0.fit(pd.concat((best5_CMI_train_withClass0.iloc[:,:-2],best5_CMI_val_withClass0.iloc[:,:-2])),pd.concat((target_df_train_E1.mean_std,target_df_val_E1.mean_std)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "34930f45",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3471864948497688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res_only0 = model_only0.predict(best5_CMI_test_withClass0.iloc[:,:-2].values)\n",
    "print(r2_score(target_df_test_E1.mean_std, res_only0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b1a789",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_only0 = LinearRegression()\n",
    "model_only0.fit(pd.concat((best5_CMI_train_withClass0.iloc[:,:-2],best5_CMI_val_withClass0.iloc[:,:-2])),pd.concat((target_df_train_E1.mean_std,target_df_val_E1.mean_std)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faaf2d6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_only0 = LinearRegression()\n",
    "model_only0.fit(pd.concat((best5_CMI_train_withClass0.iloc[:,:-2],best5_CMI_val_withClass0.iloc[:,:-2])),pd.concat((target_df_train_E1.mean_std,target_df_val_E1.mean_std)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ea6ae05b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### metto anche tutte le interazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "17c5032a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyclostationary_mean_rr_4w_0_basin</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4_basin</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1_basin</th>\n",
       "      <th>cyclostationary_mean_rr_8w_1_basin</th>\n",
       "      <th>cyclostationary_mean_tg_9_basin</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_4w_3_basin2</th>\n",
       "      <th>cyclostationary_mean_tg_4_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_8w_0_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1_basin2</th>\n",
       "      <th>basin</th>\n",
       "      <th>basin2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.112078</td>\n",
       "      <td>0.345989</td>\n",
       "      <td>1.690770</td>\n",
       "      <td>3.965287</td>\n",
       "      <td>0.268224</td>\n",
       "      <td>-0.415835</td>\n",
       "      <td>0.733822</td>\n",
       "      <td>-0.736407</td>\n",
       "      <td>2.581050</td>\n",
       "      <td>1.579481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.404523</td>\n",
       "      <td>1.128851</td>\n",
       "      <td>1.865833</td>\n",
       "      <td>1.655892</td>\n",
       "      <td>0.977612</td>\n",
       "      <td>0.237307</td>\n",
       "      <td>0.849889</td>\n",
       "      <td>0.294888</td>\n",
       "      <td>2.460299</td>\n",
       "      <td>1.146518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.162736</td>\n",
       "      <td>0.786460</td>\n",
       "      <td>1.429151</td>\n",
       "      <td>1.672157</td>\n",
       "      <td>-0.780151</td>\n",
       "      <td>-0.259989</td>\n",
       "      <td>0.518355</td>\n",
       "      <td>-1.191392</td>\n",
       "      <td>1.657472</td>\n",
       "      <td>0.697926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861999</td>\n",
       "      <td>0.564161</td>\n",
       "      <td>0.611897</td>\n",
       "      <td>1.593990</td>\n",
       "      <td>0.408553</td>\n",
       "      <td>-0.565851</td>\n",
       "      <td>0.239497</td>\n",
       "      <td>0.067063</td>\n",
       "      <td>1.600489</td>\n",
       "      <td>0.578318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.461930</td>\n",
       "      <td>0.604584</td>\n",
       "      <td>4.150391</td>\n",
       "      <td>1.782496</td>\n",
       "      <td>-0.260577</td>\n",
       "      <td>-0.187005</td>\n",
       "      <td>0.696217</td>\n",
       "      <td>-0.894857</td>\n",
       "      <td>1.249495</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.211596</td>\n",
       "      <td>0.739113</td>\n",
       "      <td>-0.281990</td>\n",
       "      <td>-0.636426</td>\n",
       "      <td>1.599630</td>\n",
       "      <td>1.352614</td>\n",
       "      <td>-0.220555</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>-0.187672</td>\n",
       "      <td>-0.422427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.765747</td>\n",
       "      <td>0.855313</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-1.204469</td>\n",
       "      <td>0.920235</td>\n",
       "      <td>1.040390</td>\n",
       "      <td>0.346445</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>-0.358316</td>\n",
       "      <td>-0.518833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.609296</td>\n",
       "      <td>0.697286</td>\n",
       "      <td>-0.562017</td>\n",
       "      <td>-1.089158</td>\n",
       "      <td>0.341994</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>0.429694</td>\n",
       "      <td>0.796373</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>-0.588942</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.836849</td>\n",
       "      <td>-0.719738</td>\n",
       "      <td>-0.028118</td>\n",
       "      <td>-0.925439</td>\n",
       "      <td>-1.523290</td>\n",
       "      <td>-0.631908</td>\n",
       "      <td>-0.434877</td>\n",
       "      <td>-2.562406</td>\n",
       "      <td>-0.028237</td>\n",
       "      <td>-0.468533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.283715</td>\n",
       "      <td>-1.078052</td>\n",
       "      <td>0.226971</td>\n",
       "      <td>-0.799403</td>\n",
       "      <td>-0.625862</td>\n",
       "      <td>-1.226069</td>\n",
       "      <td>0.334461</td>\n",
       "      <td>-0.263730</td>\n",
       "      <td>0.344734</td>\n",
       "      <td>-0.241170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cyclostationary_mean_rr_4w_0_basin  cyclostationary_mean_tg_1w_4_basin  \\\n",
       "0                              2.112078                            0.345989   \n",
       "1                              1.404523                            1.128851   \n",
       "2                              1.162736                            0.786460   \n",
       "3                              0.861999                            0.564161   \n",
       "4                              1.461930                            0.604584   \n",
       "..                                  ...                                 ...   \n",
       "406                           -0.211596                            0.739113   \n",
       "407                           -0.765747                            0.855313   \n",
       "408                           -0.609296                            0.697286   \n",
       "409                           -0.836849                           -0.719738   \n",
       "410                           -0.283715                           -1.078052   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1_basin  cyclostationary_mean_rr_8w_1_basin  \\\n",
       "0                               1.690770                            3.965287   \n",
       "1                               1.865833                            1.655892   \n",
       "2                               1.429151                            1.672157   \n",
       "3                               0.611897                            1.593990   \n",
       "4                               4.150391                            1.782496   \n",
       "..                                   ...                                 ...   \n",
       "406                            -0.281990                           -0.636426   \n",
       "407                            -0.234571                           -1.204469   \n",
       "408                            -0.562017                           -1.089158   \n",
       "409                            -0.028118                           -0.925439   \n",
       "410                             0.226971                           -0.799403   \n",
       "\n",
       "     cyclostationary_mean_tg_9_basin  cyclostationary_mean_tg_1w_4_basin2  \\\n",
       "0                           0.268224                            -0.415835   \n",
       "1                           0.977612                             0.237307   \n",
       "2                          -0.780151                            -0.259989   \n",
       "3                           0.408553                            -0.565851   \n",
       "4                          -0.260577                            -0.187005   \n",
       "..                               ...                                  ...   \n",
       "406                         1.599630                             1.352614   \n",
       "407                         0.920235                             1.040390   \n",
       "408                         0.341994                             0.830698   \n",
       "409                        -1.523290                            -0.631908   \n",
       "410                        -0.625862                            -1.226069   \n",
       "\n",
       "     cyclostationary_mean_rr_4w_3_basin2  cyclostationary_mean_tg_4_basin2  \\\n",
       "0                               0.733822                         -0.736407   \n",
       "1                               0.849889                          0.294888   \n",
       "2                               0.518355                         -1.191392   \n",
       "3                               0.239497                          0.067063   \n",
       "4                               0.696217                         -0.894857   \n",
       "..                                   ...                               ...   \n",
       "406                            -0.220555                          0.471800   \n",
       "407                             0.346445                          0.034058   \n",
       "408                             0.429694                          0.796373   \n",
       "409                            -0.434877                         -2.562406   \n",
       "410                             0.334461                         -0.263730   \n",
       "\n",
       "     cyclostationary_mean_rr_8w_0_basin2  \\\n",
       "0                               2.581050   \n",
       "1                               2.460299   \n",
       "2                               1.657472   \n",
       "3                               1.600489   \n",
       "4                               1.249495   \n",
       "..                                   ...   \n",
       "406                            -0.187672   \n",
       "407                            -0.358316   \n",
       "408                            -0.106524   \n",
       "409                            -0.028237   \n",
       "410                             0.344734   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1_basin2  basin  basin2  \n",
       "0                                1.579481    0.0     1.0  \n",
       "1                                1.146518    0.0     1.0  \n",
       "2                                0.697926    0.0     1.0  \n",
       "3                                0.578318    0.0     1.0  \n",
       "4                                0.843396    0.0     1.0  \n",
       "..                                    ...    ...     ...  \n",
       "406                             -0.422427    1.0     0.0  \n",
       "407                             -0.518833    1.0     0.0  \n",
       "408                             -0.588942    1.0     0.0  \n",
       "409                             -0.468533    1.0     0.0  \n",
       "410                             -0.241170    1.0     0.0  \n",
       "\n",
       "[822 rows x 12 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best5_CMI_train_withClass0 = pd.concat((best5_CMI_train_E1.add_suffix('_basin'),best5_CMI_train_E2.add_suffix('_basin2'),pd.DataFrame(np.zeros(len(best5_CMI_train_E1)),columns=['basin']),pd.DataFrame(np.ones(len(best5_CMI_train_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_train_withClass1 = pd.concat((best5_CMI_train_E1.add_suffix('_basin'),best5_CMI_train_E2.add_suffix('_basin2'),pd.DataFrame(np.ones(len(best5_CMI_train_E1)),columns=['basin']),pd.DataFrame(np.zeros(len(best5_CMI_train_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_train_withClass01 = pd.concat((best5_CMI_train_withClass0,best5_CMI_train_withClass1),axis=0)\n",
    "best5_CMI_train_withClass01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "87238cba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_CMI_val_withClass0 = pd.concat((best5_CMI_val_E1.add_suffix('_basin'),best5_CMI_val_E2.add_suffix('_basin2'),pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin']),pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_val_withClass1 = pd.concat((best5_CMI_val_E1.add_suffix('_basin'),best5_CMI_val_E2.add_suffix('_basin2'),pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin']),pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_val_withClass01 = pd.concat((best5_CMI_val_withClass0,best5_CMI_val_withClass1),axis=0)\n",
    "\n",
    "best5_CMI_test_withClass0 = pd.concat((best5_CMI_test_E1.add_suffix('_basin'),best5_CMI_test_E2.add_suffix('_basin2'),pd.DataFrame(np.zeros(len(best5_CMI_test_E1)),columns=['basin']),pd.DataFrame(np.ones(len(best5_CMI_val_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_test_withClass1 = pd.concat((best5_CMI_test_E1.add_suffix('_basin'),best5_CMI_test_E2.add_suffix('_basin2'),pd.DataFrame(np.ones(len(best5_CMI_test_E1)),columns=['basin']),pd.DataFrame(np.zeros(len(best5_CMI_val_E1)),columns=['basin2'])),axis=1)\n",
    "best5_CMI_test_withClass01 = pd.concat((best5_CMI_test_withClass0,best5_CMI_test_withClass1),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "35864fbe",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyclostationary_mean_rr_4w_0_basin</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4_basin</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1_basin</th>\n",
       "      <th>cyclostationary_mean_rr_8w_1_basin</th>\n",
       "      <th>cyclostationary_mean_tg_9_basin</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_4w_3_basin2</th>\n",
       "      <th>cyclostationary_mean_tg_4_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_8w_0_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1_basin2</th>\n",
       "      <th>basin</th>\n",
       "      <th>basin2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.112078</td>\n",
       "      <td>0.345989</td>\n",
       "      <td>1.690770</td>\n",
       "      <td>3.965287</td>\n",
       "      <td>0.268224</td>\n",
       "      <td>-0.415835</td>\n",
       "      <td>0.733822</td>\n",
       "      <td>-0.736407</td>\n",
       "      <td>2.581050</td>\n",
       "      <td>1.579481</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.404523</td>\n",
       "      <td>1.128851</td>\n",
       "      <td>1.865833</td>\n",
       "      <td>1.655892</td>\n",
       "      <td>0.977612</td>\n",
       "      <td>0.237307</td>\n",
       "      <td>0.849889</td>\n",
       "      <td>0.294888</td>\n",
       "      <td>2.460299</td>\n",
       "      <td>1.146518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.162736</td>\n",
       "      <td>0.786460</td>\n",
       "      <td>1.429151</td>\n",
       "      <td>1.672157</td>\n",
       "      <td>-0.780151</td>\n",
       "      <td>-0.259989</td>\n",
       "      <td>0.518355</td>\n",
       "      <td>-1.191392</td>\n",
       "      <td>1.657472</td>\n",
       "      <td>0.697926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861999</td>\n",
       "      <td>0.564161</td>\n",
       "      <td>0.611897</td>\n",
       "      <td>1.593990</td>\n",
       "      <td>0.408553</td>\n",
       "      <td>-0.565851</td>\n",
       "      <td>0.239497</td>\n",
       "      <td>0.067063</td>\n",
       "      <td>1.600489</td>\n",
       "      <td>0.578318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.461930</td>\n",
       "      <td>0.604584</td>\n",
       "      <td>4.150391</td>\n",
       "      <td>1.782496</td>\n",
       "      <td>-0.260577</td>\n",
       "      <td>-0.187005</td>\n",
       "      <td>0.696217</td>\n",
       "      <td>-0.894857</td>\n",
       "      <td>1.249495</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>-0.608772</td>\n",
       "      <td>2.159366</td>\n",
       "      <td>1.128914</td>\n",
       "      <td>0.745100</td>\n",
       "      <td>0.624547</td>\n",
       "      <td>2.050920</td>\n",
       "      <td>1.182447</td>\n",
       "      <td>0.848215</td>\n",
       "      <td>1.287369</td>\n",
       "      <td>0.181394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>-0.325822</td>\n",
       "      <td>1.311011</td>\n",
       "      <td>0.790244</td>\n",
       "      <td>0.037201</td>\n",
       "      <td>1.691934</td>\n",
       "      <td>1.776750</td>\n",
       "      <td>1.931919</td>\n",
       "      <td>1.300383</td>\n",
       "      <td>1.500711</td>\n",
       "      <td>0.244831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.588081</td>\n",
       "      <td>1.354429</td>\n",
       "      <td>1.428052</td>\n",
       "      <td>0.170754</td>\n",
       "      <td>1.924323</td>\n",
       "      <td>1.963611</td>\n",
       "      <td>2.777644</td>\n",
       "      <td>1.044000</td>\n",
       "      <td>1.878066</td>\n",
       "      <td>0.317723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.360721</td>\n",
       "      <td>1.653467</td>\n",
       "      <td>1.152108</td>\n",
       "      <td>0.094855</td>\n",
       "      <td>1.546077</td>\n",
       "      <td>1.734032</td>\n",
       "      <td>2.563059</td>\n",
       "      <td>1.124935</td>\n",
       "      <td>1.799993</td>\n",
       "      <td>0.278011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.107863</td>\n",
       "      <td>1.265916</td>\n",
       "      <td>0.578823</td>\n",
       "      <td>-0.634415</td>\n",
       "      <td>1.023210</td>\n",
       "      <td>1.748151</td>\n",
       "      <td>0.244175</td>\n",
       "      <td>1.295160</td>\n",
       "      <td>1.036511</td>\n",
       "      <td>0.081538</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1278 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cyclostationary_mean_rr_4w_0_basin  cyclostationary_mean_tg_1w_4_basin  \\\n",
       "0                              2.112078                            0.345989   \n",
       "1                              1.404523                            1.128851   \n",
       "2                              1.162736                            0.786460   \n",
       "3                              0.861999                            0.564161   \n",
       "4                              1.461930                            0.604584   \n",
       "..                                  ...                                 ...   \n",
       "223                           -0.608772                            2.159366   \n",
       "224                           -0.325822                            1.311011   \n",
       "225                            0.588081                            1.354429   \n",
       "226                            0.360721                            1.653467   \n",
       "227                            0.107863                            1.265916   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1_basin  cyclostationary_mean_rr_8w_1_basin  \\\n",
       "0                               1.690770                            3.965287   \n",
       "1                               1.865833                            1.655892   \n",
       "2                               1.429151                            1.672157   \n",
       "3                               0.611897                            1.593990   \n",
       "4                               4.150391                            1.782496   \n",
       "..                                   ...                                 ...   \n",
       "223                             1.128914                            0.745100   \n",
       "224                             0.790244                            0.037201   \n",
       "225                             1.428052                            0.170754   \n",
       "226                             1.152108                            0.094855   \n",
       "227                             0.578823                           -0.634415   \n",
       "\n",
       "     cyclostationary_mean_tg_9_basin  cyclostationary_mean_tg_1w_4_basin2  \\\n",
       "0                           0.268224                            -0.415835   \n",
       "1                           0.977612                             0.237307   \n",
       "2                          -0.780151                            -0.259989   \n",
       "3                           0.408553                            -0.565851   \n",
       "4                          -0.260577                            -0.187005   \n",
       "..                               ...                                  ...   \n",
       "223                         0.624547                             2.050920   \n",
       "224                         1.691934                             1.776750   \n",
       "225                         1.924323                             1.963611   \n",
       "226                         1.546077                             1.734032   \n",
       "227                         1.023210                             1.748151   \n",
       "\n",
       "     cyclostationary_mean_rr_4w_3_basin2  cyclostationary_mean_tg_4_basin2  \\\n",
       "0                               0.733822                         -0.736407   \n",
       "1                               0.849889                          0.294888   \n",
       "2                               0.518355                         -1.191392   \n",
       "3                               0.239497                          0.067063   \n",
       "4                               0.696217                         -0.894857   \n",
       "..                                   ...                               ...   \n",
       "223                             1.182447                          0.848215   \n",
       "224                             1.931919                          1.300383   \n",
       "225                             2.777644                          1.044000   \n",
       "226                             2.563059                          1.124935   \n",
       "227                             0.244175                          1.295160   \n",
       "\n",
       "     cyclostationary_mean_rr_8w_0_basin2  \\\n",
       "0                               2.581050   \n",
       "1                               2.460299   \n",
       "2                               1.657472   \n",
       "3                               1.600489   \n",
       "4                               1.249495   \n",
       "..                                   ...   \n",
       "223                             1.287369   \n",
       "224                             1.500711   \n",
       "225                             1.878066   \n",
       "226                             1.799993   \n",
       "227                             1.036511   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1_basin2  basin  basin2  \n",
       "0                                1.579481    0.0     1.0  \n",
       "1                                1.146518    0.0     1.0  \n",
       "2                                0.697926    0.0     1.0  \n",
       "3                                0.578318    0.0     1.0  \n",
       "4                                0.843396    0.0     1.0  \n",
       "..                                    ...    ...     ...  \n",
       "223                              0.181394    1.0     0.0  \n",
       "224                              0.244831    1.0     0.0  \n",
       "225                              0.317723    1.0     0.0  \n",
       "226                              0.278011    1.0     0.0  \n",
       "227                              0.081538    1.0     0.0  \n",
       "\n",
       "[1278 rows x 12 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trainVal = pd.concat((best5_CMI_train_withClass01,best5_CMI_val_withClass01))\n",
    "df_trainVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "79ca1b94",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(df_trainVal.shape[1]-2):\n",
    "    for j in ['basin','basin2']:\n",
    "        df_trainVal[df_trainVal.columns[i]+'_'+j] = df_trainVal.apply(lambda x:x[i]*x[j], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "957109ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cyclostationary_mean_rr_4w_0_basin',\n",
       "       'cyclostationary_mean_tg_1w_4_basin',\n",
       "       'cyclostationary_mean_rr_12w_1_basin',\n",
       "       'cyclostationary_mean_rr_8w_1_basin', 'cyclostationary_mean_tg_9_basin',\n",
       "       'cyclostationary_mean_tg_1w_4_basin2',\n",
       "       'cyclostationary_mean_rr_4w_3_basin2',\n",
       "       'cyclostationary_mean_tg_4_basin2',\n",
       "       'cyclostationary_mean_rr_8w_0_basin2',\n",
       "       'cyclostationary_mean_rr_12w_1_basin2', 'basin', 'basin2',\n",
       "       'cyclostationary_mean_rr_4w_0_basin_basin',\n",
       "       'cyclostationary_mean_rr_4w_0_basin_basin2',\n",
       "       'cyclostationary_mean_tg_1w_4_basin_basin',\n",
       "       'cyclostationary_mean_tg_1w_4_basin_basin2',\n",
       "       'cyclostationary_mean_rr_12w_1_basin_basin',\n",
       "       'cyclostationary_mean_rr_12w_1_basin_basin2',\n",
       "       'cyclostationary_mean_rr_8w_1_basin_basin',\n",
       "       'cyclostationary_mean_rr_8w_1_basin_basin2',\n",
       "       'cyclostationary_mean_tg_9_basin_basin',\n",
       "       'cyclostationary_mean_tg_9_basin_basin2',\n",
       "       'cyclostationary_mean_tg_1w_4_basin2_basin',\n",
       "       'cyclostationary_mean_tg_1w_4_basin2_basin2',\n",
       "       'cyclostationary_mean_rr_4w_3_basin2_basin',\n",
       "       'cyclostationary_mean_rr_4w_3_basin2_basin2',\n",
       "       'cyclostationary_mean_tg_4_basin2_basin',\n",
       "       'cyclostationary_mean_tg_4_basin2_basin2',\n",
       "       'cyclostationary_mean_rr_8w_0_basin2_basin',\n",
       "       'cyclostationary_mean_rr_8w_0_basin2_basin2',\n",
       "       'cyclostationary_mean_rr_12w_1_basin2_basin',\n",
       "       'cyclostationary_mean_rr_12w_1_basin2_basin2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trainVal.columns ## 32 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "0badcb14",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_withInteractions = LinearRegression()\n",
    "model_withInteractions.fit(df_trainVal,pd.concat((target_train_withClass01,target_val_withClass01)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e2d0bc40",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cyclostationary_mean_rr_4w_0_basin</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4_basin</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1_basin</th>\n",
       "      <th>cyclostationary_mean_rr_8w_1_basin</th>\n",
       "      <th>cyclostationary_mean_tg_9_basin</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_4w_3_basin2</th>\n",
       "      <th>cyclostationary_mean_tg_4_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_8w_0_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1_basin2</th>\n",
       "      <th>...</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4_basin2_basin</th>\n",
       "      <th>cyclostationary_mean_tg_1w_4_basin2_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_4w_3_basin2_basin</th>\n",
       "      <th>cyclostationary_mean_rr_4w_3_basin2_basin2</th>\n",
       "      <th>cyclostationary_mean_tg_4_basin2_basin</th>\n",
       "      <th>cyclostationary_mean_tg_4_basin2_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_8w_0_basin2_basin</th>\n",
       "      <th>cyclostationary_mean_rr_8w_0_basin2_basin2</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1_basin2_basin</th>\n",
       "      <th>cyclostationary_mean_rr_12w_1_basin2_basin2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.024229</td>\n",
       "      <td>-0.130768</td>\n",
       "      <td>0.384819</td>\n",
       "      <td>-0.288379</td>\n",
       "      <td>-0.758823</td>\n",
       "      <td>0.630622</td>\n",
       "      <td>0.209123</td>\n",
       "      <td>-0.468881</td>\n",
       "      <td>1.304173</td>\n",
       "      <td>-0.159103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630622</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209123</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.468881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.304173</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.159103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.074161</td>\n",
       "      <td>0.394246</td>\n",
       "      <td>0.534957</td>\n",
       "      <td>0.217974</td>\n",
       "      <td>0.366976</td>\n",
       "      <td>1.194474</td>\n",
       "      <td>-0.138681</td>\n",
       "      <td>2.708734</td>\n",
       "      <td>1.737154</td>\n",
       "      <td>0.039609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.194474</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.138681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.708734</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.737154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.638893</td>\n",
       "      <td>2.401322</td>\n",
       "      <td>0.493120</td>\n",
       "      <td>-0.194728</td>\n",
       "      <td>1.391103</td>\n",
       "      <td>2.327133</td>\n",
       "      <td>-0.078662</td>\n",
       "      <td>0.847627</td>\n",
       "      <td>1.497008</td>\n",
       "      <td>0.156356</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.327133</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.078662</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.847627</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.497008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.651903</td>\n",
       "      <td>1.977750</td>\n",
       "      <td>0.507575</td>\n",
       "      <td>-0.865029</td>\n",
       "      <td>0.986028</td>\n",
       "      <td>1.311114</td>\n",
       "      <td>-0.056919</td>\n",
       "      <td>0.457849</td>\n",
       "      <td>-0.104933</td>\n",
       "      <td>-0.191401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.311114</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.056919</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.457849</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.104933</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.191401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.167088</td>\n",
       "      <td>0.399292</td>\n",
       "      <td>0.660056</td>\n",
       "      <td>-0.736970</td>\n",
       "      <td>-0.209023</td>\n",
       "      <td>0.207879</td>\n",
       "      <td>0.234950</td>\n",
       "      <td>-0.705268</td>\n",
       "      <td>-0.056618</td>\n",
       "      <td>0.317671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207879</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234950</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.705268</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.056618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.317671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>1.026728</td>\n",
       "      <td>0.066188</td>\n",
       "      <td>-0.652764</td>\n",
       "      <td>0.439127</td>\n",
       "      <td>0.883587</td>\n",
       "      <td>0.875518</td>\n",
       "      <td>2.874361</td>\n",
       "      <td>0.462921</td>\n",
       "      <td>1.142723</td>\n",
       "      <td>1.436723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.875518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.874361</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.142723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.436723</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>1.105928</td>\n",
       "      <td>1.178374</td>\n",
       "      <td>-0.697788</td>\n",
       "      <td>0.713387</td>\n",
       "      <td>1.798072</td>\n",
       "      <td>2.013869</td>\n",
       "      <td>3.403684</td>\n",
       "      <td>1.646370</td>\n",
       "      <td>1.647574</td>\n",
       "      <td>1.695675</td>\n",
       "      <td>...</td>\n",
       "      <td>2.013869</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.403684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.646370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.647574</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.695675</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>1.567359</td>\n",
       "      <td>1.150618</td>\n",
       "      <td>-0.291633</td>\n",
       "      <td>0.585251</td>\n",
       "      <td>0.789272</td>\n",
       "      <td>2.283123</td>\n",
       "      <td>3.730013</td>\n",
       "      <td>0.712357</td>\n",
       "      <td>1.696177</td>\n",
       "      <td>1.558532</td>\n",
       "      <td>...</td>\n",
       "      <td>2.283123</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.730013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.712357</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.696177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.558532</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>1.613891</td>\n",
       "      <td>0.412975</td>\n",
       "      <td>-0.312164</td>\n",
       "      <td>0.673733</td>\n",
       "      <td>0.695963</td>\n",
       "      <td>1.756730</td>\n",
       "      <td>3.393080</td>\n",
       "      <td>0.854092</td>\n",
       "      <td>1.702425</td>\n",
       "      <td>1.751665</td>\n",
       "      <td>...</td>\n",
       "      <td>1.756730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.393080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.854092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.702425</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.751665</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>1.507916</td>\n",
       "      <td>1.993004</td>\n",
       "      <td>-0.265331</td>\n",
       "      <td>1.166676</td>\n",
       "      <td>3.332968</td>\n",
       "      <td>2.984542</td>\n",
       "      <td>3.161020</td>\n",
       "      <td>2.842276</td>\n",
       "      <td>2.101849</td>\n",
       "      <td>1.875668</td>\n",
       "      <td>...</td>\n",
       "      <td>2.984542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.161020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.842276</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.101849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.875668</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cyclostationary_mean_rr_4w_0_basin  cyclostationary_mean_tg_1w_4_basin  \\\n",
       "0                             -0.024229                           -0.130768   \n",
       "1                             -0.074161                            0.394246   \n",
       "2                             -0.638893                            2.401322   \n",
       "3                             -0.651903                            1.977750   \n",
       "4                             -0.167088                            0.399292   \n",
       "..                                  ...                                 ...   \n",
       "223                            1.026728                            0.066188   \n",
       "224                            1.105928                            1.178374   \n",
       "225                            1.567359                            1.150618   \n",
       "226                            1.613891                            0.412975   \n",
       "227                            1.507916                            1.993004   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1_basin  cyclostationary_mean_rr_8w_1_basin  \\\n",
       "0                               0.384819                           -0.288379   \n",
       "1                               0.534957                            0.217974   \n",
       "2                               0.493120                           -0.194728   \n",
       "3                               0.507575                           -0.865029   \n",
       "4                               0.660056                           -0.736970   \n",
       "..                                   ...                                 ...   \n",
       "223                            -0.652764                            0.439127   \n",
       "224                            -0.697788                            0.713387   \n",
       "225                            -0.291633                            0.585251   \n",
       "226                            -0.312164                            0.673733   \n",
       "227                            -0.265331                            1.166676   \n",
       "\n",
       "     cyclostationary_mean_tg_9_basin  cyclostationary_mean_tg_1w_4_basin2  \\\n",
       "0                          -0.758823                             0.630622   \n",
       "1                           0.366976                             1.194474   \n",
       "2                           1.391103                             2.327133   \n",
       "3                           0.986028                             1.311114   \n",
       "4                          -0.209023                             0.207879   \n",
       "..                               ...                                  ...   \n",
       "223                         0.883587                             0.875518   \n",
       "224                         1.798072                             2.013869   \n",
       "225                         0.789272                             2.283123   \n",
       "226                         0.695963                             1.756730   \n",
       "227                         3.332968                             2.984542   \n",
       "\n",
       "     cyclostationary_mean_rr_4w_3_basin2  cyclostationary_mean_tg_4_basin2  \\\n",
       "0                               0.209123                         -0.468881   \n",
       "1                              -0.138681                          2.708734   \n",
       "2                              -0.078662                          0.847627   \n",
       "3                              -0.056919                          0.457849   \n",
       "4                               0.234950                         -0.705268   \n",
       "..                                   ...                               ...   \n",
       "223                             2.874361                          0.462921   \n",
       "224                             3.403684                          1.646370   \n",
       "225                             3.730013                          0.712357   \n",
       "226                             3.393080                          0.854092   \n",
       "227                             3.161020                          2.842276   \n",
       "\n",
       "     cyclostationary_mean_rr_8w_0_basin2  \\\n",
       "0                               1.304173   \n",
       "1                               1.737154   \n",
       "2                               1.497008   \n",
       "3                              -0.104933   \n",
       "4                              -0.056618   \n",
       "..                                   ...   \n",
       "223                             1.142723   \n",
       "224                             1.647574   \n",
       "225                             1.696177   \n",
       "226                             1.702425   \n",
       "227                             2.101849   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1_basin2  ...  \\\n",
       "0                               -0.159103  ...   \n",
       "1                                0.039609  ...   \n",
       "2                                0.156356  ...   \n",
       "3                               -0.191401  ...   \n",
       "4                                0.317671  ...   \n",
       "..                                    ...  ...   \n",
       "223                              1.436723  ...   \n",
       "224                              1.695675  ...   \n",
       "225                              1.558532  ...   \n",
       "226                              1.751665  ...   \n",
       "227                              1.875668  ...   \n",
       "\n",
       "     cyclostationary_mean_tg_1w_4_basin2_basin  \\\n",
       "0                                     0.000000   \n",
       "1                                     0.000000   \n",
       "2                                     0.000000   \n",
       "3                                     0.000000   \n",
       "4                                     0.000000   \n",
       "..                                         ...   \n",
       "223                                   0.875518   \n",
       "224                                   2.013869   \n",
       "225                                   2.283123   \n",
       "226                                   1.756730   \n",
       "227                                   2.984542   \n",
       "\n",
       "     cyclostationary_mean_tg_1w_4_basin2_basin2  \\\n",
       "0                                      0.630622   \n",
       "1                                      1.194474   \n",
       "2                                      2.327133   \n",
       "3                                      1.311114   \n",
       "4                                      0.207879   \n",
       "..                                          ...   \n",
       "223                                    0.000000   \n",
       "224                                    0.000000   \n",
       "225                                    0.000000   \n",
       "226                                    0.000000   \n",
       "227                                    0.000000   \n",
       "\n",
       "     cyclostationary_mean_rr_4w_3_basin2_basin  \\\n",
       "0                                     0.000000   \n",
       "1                                    -0.000000   \n",
       "2                                    -0.000000   \n",
       "3                                    -0.000000   \n",
       "4                                     0.000000   \n",
       "..                                         ...   \n",
       "223                                   2.874361   \n",
       "224                                   3.403684   \n",
       "225                                   3.730013   \n",
       "226                                   3.393080   \n",
       "227                                   3.161020   \n",
       "\n",
       "     cyclostationary_mean_rr_4w_3_basin2_basin2  \\\n",
       "0                                      0.209123   \n",
       "1                                     -0.138681   \n",
       "2                                     -0.078662   \n",
       "3                                     -0.056919   \n",
       "4                                      0.234950   \n",
       "..                                          ...   \n",
       "223                                    0.000000   \n",
       "224                                    0.000000   \n",
       "225                                    0.000000   \n",
       "226                                    0.000000   \n",
       "227                                    0.000000   \n",
       "\n",
       "     cyclostationary_mean_tg_4_basin2_basin  \\\n",
       "0                                 -0.000000   \n",
       "1                                  0.000000   \n",
       "2                                  0.000000   \n",
       "3                                  0.000000   \n",
       "4                                 -0.000000   \n",
       "..                                      ...   \n",
       "223                                0.462921   \n",
       "224                                1.646370   \n",
       "225                                0.712357   \n",
       "226                                0.854092   \n",
       "227                                2.842276   \n",
       "\n",
       "     cyclostationary_mean_tg_4_basin2_basin2  \\\n",
       "0                                  -0.468881   \n",
       "1                                   2.708734   \n",
       "2                                   0.847627   \n",
       "3                                   0.457849   \n",
       "4                                  -0.705268   \n",
       "..                                       ...   \n",
       "223                                 0.000000   \n",
       "224                                 0.000000   \n",
       "225                                 0.000000   \n",
       "226                                 0.000000   \n",
       "227                                 0.000000   \n",
       "\n",
       "     cyclostationary_mean_rr_8w_0_basin2_basin  \\\n",
       "0                                     0.000000   \n",
       "1                                     0.000000   \n",
       "2                                     0.000000   \n",
       "3                                    -0.000000   \n",
       "4                                    -0.000000   \n",
       "..                                         ...   \n",
       "223                                   1.142723   \n",
       "224                                   1.647574   \n",
       "225                                   1.696177   \n",
       "226                                   1.702425   \n",
       "227                                   2.101849   \n",
       "\n",
       "     cyclostationary_mean_rr_8w_0_basin2_basin2  \\\n",
       "0                                      1.304173   \n",
       "1                                      1.737154   \n",
       "2                                      1.497008   \n",
       "3                                     -0.104933   \n",
       "4                                     -0.056618   \n",
       "..                                          ...   \n",
       "223                                    0.000000   \n",
       "224                                    0.000000   \n",
       "225                                    0.000000   \n",
       "226                                    0.000000   \n",
       "227                                    0.000000   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1_basin2_basin  \\\n",
       "0                                     -0.000000   \n",
       "1                                      0.000000   \n",
       "2                                      0.000000   \n",
       "3                                     -0.000000   \n",
       "4                                      0.000000   \n",
       "..                                          ...   \n",
       "223                                    1.436723   \n",
       "224                                    1.695675   \n",
       "225                                    1.558532   \n",
       "226                                    1.751665   \n",
       "227                                    1.875668   \n",
       "\n",
       "     cyclostationary_mean_rr_12w_1_basin2_basin2  \n",
       "0                                      -0.159103  \n",
       "1                                       0.039609  \n",
       "2                                       0.156356  \n",
       "3                                      -0.191401  \n",
       "4                                       0.317671  \n",
       "..                                           ...  \n",
       "223                                     0.000000  \n",
       "224                                     0.000000  \n",
       "225                                     0.000000  \n",
       "226                                     0.000000  \n",
       "227                                     0.000000  \n",
       "\n",
       "[456 rows x 32 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(best5_CMI_test_withClass01.shape[1]-2):\n",
    "    for j in ['basin','basin2']:\n",
    "        best5_CMI_test_withClass01[best5_CMI_test_withClass01.columns[i]+'_'+j] = best5_CMI_test_withClass01.apply(lambda x:x[i]*x[j], axis=1)\n",
    "best5_CMI_test_withClass01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e64a19ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3471864948497686\n",
      "0.2506733686648961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res0_withInteraction = model_withInteractions.predict(best5_CMI_test_withClass01[0:228].values)\n",
    "res1_withInteraction = model_withInteractions.predict(best5_CMI_test_withClass01[228:].values)\n",
    "\n",
    "print(r2_score(target_df_test_E1.mean_std, res0_withInteraction))\n",
    "print(r2_score(target_df_test_E2.mean_std, res1_withInteraction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "8da39f41",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.57239538e-01, -7.42274305e-02,  1.14869453e-01, -1.74380669e-02,\n",
       "       -9.50603216e-02,  4.09829946e-02,  5.76737955e-02, -9.14292290e-02,\n",
       "        2.66771908e-02, -2.51022919e-02,  1.74496692e-02, -1.74496692e-02,\n",
       "        1.89327870e-02,  1.38306751e-01,  9.49798810e-02, -1.69207311e-01,\n",
       "        5.36612143e-02,  6.12082385e-02, -8.29049400e-02,  6.54668730e-02,\n",
       "       -8.60571614e-03, -8.64546055e-02, -1.07736145e-01,  1.48719140e-01,\n",
       "        8.28210205e-02, -2.51472250e-02, -6.98269558e-02, -2.16022732e-02,\n",
       "        3.30761680e-02, -6.39897727e-03, -2.50412115e-02, -6.10804163e-05])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_withInteractions.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83524fe8",
   "metadata": {},
   "source": [
    "# Linear regression comparisons (additive term)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2e5e0b",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Clusters of basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "016a36c8",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.039373    0.00  2001     1 -2.546951\n",
      "1    2001-01-13  0.380618    0.43  2001     2 -0.277191\n",
      "2    2001-01-21  0.341985    0.38  2001     3 -0.534156\n",
      "3    2001-01-29  0.322044    0.35  2001     5 -0.666789\n",
      "4    2001-02-06  0.354954    0.40  2001     6 -0.447894\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.382706    0.40  2009    48 -0.263306\n",
      "407  2009-12-05  0.409921    0.46  2009    49 -0.082282\n",
      "408  2009-12-13  0.472087    0.53  2009    50  0.331204\n",
      "409  2009-12-21  0.324728    0.00  2009    52 -0.648940\n",
      "410  2009-12-29  0.086512    0.00  2009    53 -2.233412\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.010645    0.00  2001     1 -2.129508\n",
      "1    2001-01-13  0.206769    0.00  2001     2 -0.927136\n",
      "2    2001-01-21  0.267313    0.00  2001     3 -0.555958\n",
      "3    2001-01-29  0.240836    0.20  2001     5 -0.718282\n",
      "4    2001-02-06  0.193417    0.15  2001     6 -1.008995\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.230073    0.25  2009    48 -0.784269\n",
      "407  2009-12-05  0.243632    0.24  2009    49 -0.701139\n",
      "408  2009-12-13  0.251111    0.00  2009    50 -0.655289\n",
      "409  2009-12-21  0.099246    0.00  2009    52 -1.586325\n",
      "410  2009-12-29  0.064990    0.00  2009    53 -1.796340\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.379890    0.50  2001     1 -0.382765\n",
      "1    2001-01-13  0.482679    0.58  2001     2  0.319215\n",
      "2    2001-01-21  0.516259    0.59  2001     3  0.548542\n",
      "3    2001-01-29  0.434421    0.50  2001     5 -0.010351\n",
      "4    2001-02-06  0.494805    0.54  2001     6  0.402030\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.427085    0.43  2009    48 -0.060454\n",
      "407  2009-12-05  0.547380    0.57  2009    49  0.761079\n",
      "408  2009-12-13  0.531070    0.58  2009    50  0.649694\n",
      "409  2009-12-21  0.295704    0.00  2009    52 -0.957702\n",
      "410  2009-12-29  0.027861    0.00  2009    53 -2.786888\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.102270    0.00  2001     1 -1.996014\n",
      "1    2001-01-13  0.454431    0.53  2001     2  0.498869\n",
      "2    2001-01-21  0.323514    0.32  2001     3 -0.428613\n",
      "3    2001-01-29  0.301661    0.31  2001     5 -0.583432\n",
      "4    2001-02-06  0.394733    0.44  2001     6  0.075938\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.388573    0.44  2009    48  0.032299\n",
      "407  2009-12-05  0.402760    0.47  2009    49  0.132804\n",
      "408  2009-12-13  0.353782    0.44  2009    50 -0.214182\n",
      "409  2009-12-21  0.043947    0.00  2009    52 -2.409204\n",
      "410  2009-12-29  0.006670    0.00  2009    53 -2.673294\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.369625    0.45  2001     1 -0.439541\n",
      "1    2001-01-13  0.429563    0.43  2001     2 -0.019547\n",
      "2    2001-01-21  0.470784    0.48  2001     3  0.269293\n",
      "3    2001-01-29  0.370358    0.37  2001     5 -0.434406\n",
      "4    2001-02-06  0.372263    0.37  2001     6 -0.421060\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.402059    0.40  2009    48 -0.212272\n",
      "407  2009-12-05  0.389658    0.39  2009    49 -0.299172\n",
      "408  2009-12-13  0.545184    0.56  2009    50  0.790614\n",
      "409  2009-12-21  0.447916    0.55  2009    52  0.109054\n",
      "410  2009-12-29  0.277300    0.32  2009    53 -1.086474\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.243674    0.26  2001     1 -1.223671\n",
      "1    2001-01-13  0.424116    0.44  2001     2 -0.087252\n",
      "2    2001-01-21  0.393786    0.39  2001     3 -0.278268\n",
      "3    2001-01-29  0.314939    0.31  2001     5 -0.774846\n",
      "4    2001-02-06  0.464902    0.48  2001     6  0.169616\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.465734    0.48  2009    48  0.174854\n",
      "407  2009-12-05  0.447390    0.47  2009    49  0.059327\n",
      "408  2009-12-13  0.556760    0.59  2009    50  0.748131\n",
      "409  2009-12-21  0.307880    0.00  2009    52 -0.819305\n",
      "410  2009-12-29  0.034211    0.00  2009    53 -2.542862\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278983    0.00  2001     1 -1.146332\n",
      "1    2001-01-13  0.494910    0.51  2001     2  0.371173\n",
      "2    2001-01-21  0.496092    0.51  2001     3  0.379474\n",
      "3    2001-01-29  0.427992    0.43  2001     5 -0.099118\n",
      "4    2001-02-06  0.400512    0.41  2001     6 -0.292244\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.363952    0.37  2009    48 -0.549184\n",
      "407  2009-12-05  0.400487    0.40  2009    49 -0.292423\n",
      "408  2009-12-13  0.506771    0.52  2009    50  0.454529\n",
      "409  2009-12-21  0.387530    0.53  2009    52 -0.383480\n",
      "410  2009-12-29  0.279894    0.27  2009    53 -1.139931\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278060    0.09  2001     1 -0.967137\n",
      "1    2001-01-13  0.445159    0.48  2001     2  0.070382\n",
      "2    2001-01-21  0.488982    0.52  2001     3  0.342478\n",
      "3    2001-01-29  0.362487    0.37  2001     5 -0.442927\n",
      "4    2001-02-06  0.430732    0.45  2001     6 -0.019192\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.430379    0.44  2009    48 -0.021388\n",
      "407  2009-12-05  0.419919    0.43  2009    49 -0.086330\n",
      "408  2009-12-13  0.526648    0.55  2009    50  0.576347\n",
      "409  2009-12-21  0.457440    0.61  2009    52  0.146632\n",
      "410  2009-12-29  0.301938    0.38  2009    53 -0.818877\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.264043    0.00  2001     1 -1.060146\n",
      "1    2001-01-13  0.354618    0.39  2001     2 -0.405065\n",
      "2    2001-01-21  0.427990    0.47  2001     3  0.125603\n",
      "3    2001-01-29  0.339495    0.35  2001     5 -0.514438\n",
      "4    2001-02-06  0.324134    0.34  2001     6 -0.625540\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.332713    0.35  2009    48 -0.563495\n",
      "407  2009-12-05  0.370253    0.40  2009    49 -0.291984\n",
      "408  2009-12-13  0.517201    0.57  2009    50  0.770822\n",
      "409  2009-12-21  0.353636    0.45  2009    52 -0.412164\n",
      "410  2009-12-29  0.261079    0.00  2009    53 -1.081585\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n"
     ]
    }
   ],
   "source": [
    "### targets\n",
    "basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona','Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n",
    "path_targets = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/csv_VHI/'\n",
    "targets_df_train = pd.DataFrame()\n",
    "targets_df_val = pd.DataFrame()\n",
    "targets_df_test = pd.DataFrame()\n",
    "targets_df_trainVal = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', path=path_targets+basin+'.csv')\n",
    "    targets_df_train[basin] = target_df_train.mean_std\n",
    "    targets_df_val[basin] = target_df_val.mean_std\n",
    "    targets_df_test[basin] = target_df_test.mean_std\n",
    "    targets_df_trainVal[basin] = target_df_trainVal.mean_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "0b3ff08f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl8AAAH+CAYAAACiF2vLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOydd3iUVdqH72npvXcSEtJIo/fQIkG6WLCggqKrqFg+VwRBYFlFWXERNLqsoAi4KKKggPQmNdQUktDTgCSk90ymfH8MThgyCRkIROXc1/VeV+bMc8755bztec/zvGckWq1Wi0AgEAgEAoHgriBtawECgUAgEAgE9xLC+RIIBAKBQCC4iwjnSyAQCAQCgeAuIpwvgUAgEAgEgruIcL4EAoFAIBAI7iLC+RIIBAKBQCC4iwjnSyAQCAQCgeAuIpwvgUAgEAgEgruIcL4EAoFAIBAI7iLC+RIIBAKBQCC4iwjnSyAQCAQCwT3J3r17GTlyJF5eXkgkEtatW3fTOrt376Zz586Ym5sTFBTE119/bXK/wvkSCAQCgUBwT1JVVUV0dDSfffZZi+wvXrzI8OHDGThwICdPnuS1115j0qRJbNmyxaR+JeKHtQUCgUAgENzrSCQSfvrpJ8aMGdOkzdSpU9m4cSOpqan6skcffZTS0lI2b97c4r7EzJdAIBAIBIK/BHV1dZSXlxtsdXV1rdb+wYMHiYuLMyiLj4/n4MGDJrUjbzVFgj8N9YUX2lpCs6jWJ7S1hGbRFFxtawlNIu3So60lNE+9sq0VNIu0Xce2ltA0ZpZtraBZNBdPtrWE5iktamsFTSIJ7dbWEprFInrYHe+jte5L8z79hjlz5hiUzZo1i9mzZ7dK+3l5ebi7uxuUubu7U15eTk1NDZaWLTtPhfMlEAgEAoHgL8G0adN44403DMrMzc3bSE3TCOdLIBAIBAJB26JRt0oz5ubmd9TZ8vDwID8/36AsPz8fOzu7Fs96gXC+BAKBQCAQtDVaTVsraBG9evVi06ZNBmXbtm2jV69eJrUjEu4FAoFAIBDck1RWVnLy5ElOnjwJ6JaSOHnyJNnZ2YAujPnUU0/p7V944QUuXLjAW2+9RUZGBgkJCXz//fe8/vrrJvUrZr4EAoFAIBC0LZq2mfk6evQoAwcO1H/+PV/s6aef5uuvv+bKlSt6RwwgICCAjRs38vrrr/PJJ5/g4+PDl19+SXx8vEn9CudLIBAIBAJBm6Jto7DjgAEDaG65U2Or1w8YMIATJ07cVr/C+RIIBAKBQNC2tNHMV1shcr4EAoFAIBAI7iJi5ksgEAgEAkHb8id527G1EM6XQCAQCASCtqWV1vn6syDCjgKBQCAQCAR3EeF8tRGzZ88mJiamWZsJEyY0++vqAoFAIBD8JdBqWmf7kyDCjq3IwYMH6du3L0OHDmXjxo1tLeeOcvRkCl99+wNpGee4WlTMJ/NmMji2d5toWX38IssTz1NUVUewmx1T4yKI9HRs0n7l0QusOZFJXkUNDpZmxAV7MqV/GOZy2W1rkXcejKLH/Uhs7NEU5KDcuhLNFeM/GGvx+NvI2oU1KledO0ndmn8DYDZ8EoqofobfX0im7rsFt6Rv9d4klu84RlF5NcHeLkx9aACR/h5N2q/cdYI1+5LJK6nAwdqSuJggpozqg7lCd+m4f9YyrhRXNKr3SL8opj8ysFF5s9r2pbJ810mKKqoJ9nJm6gN9iWzn3qT9yj1JrDlwirySShxsLIiLCmTK8B56bQD5pZV8suEQ+zOyqVWq8HWxZ85jA+no62aSNoDVv+7h6/U7KCwtJ9jfm2nPPkxkB3+jtvUqNUt/3MrPuw9TUFyKv5c7rz05mr6dwvU2323+je+3/Mblq8UABPp68LeH76df51v7ce/VG3fy9Y+bKSwpIzjAl2l/e5zI4PZN6FOxdM0mft55gIKiEvy9PXhtwkP07RKpt0n4dj1f/O9ng3r+3h78/MV7pmvbm8zyncevO+5iiWzX3HF3kjX7UwyPu5G9Gu/bnw+wPy2L2vp6fF0cmPPEYDr6NX3MNKnv8BmW70+nqLKGYHdHpg7vQqSPS9P6DmSw5shZ8sqqcbAyJ66jL1PiYjBX6K4hS/eeYkdaDpmF5ZgrZET7uvLakBj8XexM1gawevM+lv+yk8LSCoLbefH2M2OJDGpn1LZepWbpuu38sucIBcVl+Hu58doTI+gT03Ct+X7rfr7fur/h2PPx4G8PxdO3U+Pr0V3jHnvbUThfrcjSpUt55ZVXWLp0KZcvX8bLy6utJd0xampqCQlqzwPDh/Da9H+2mY4t6ZdYsCuNd4ZEEunpyKqjF5j8/WHWTxqIk3Xj3/falJbLoj3pzL4/mmhvJ7KKK5m16SQSiYQ3B93aTe93ZGHdMRv8GMrNy1FfPo+iWzwW496keslUqG7soNT+uBiJ7LpT0NIGy2fnos44YmCnOp+McuOX+s9adf0t6dty7AwLfvqNd8YNJLKdB6t2n2RywjrWz3wKJ1urRvabjmaw6Of9zH4ijugAL7IKSpi1cpturMbGArDqzUfRXLdGzrnLRbzw2U/c16mDadpOnGPB+v2883B/Iv3cWLU3mclLNrD+7ceMazt2hkUbDzN73ACiAzzIulrGrP/tRCKBN0f3AaC8uo4Ji9fRLciLT58bjpONJVmFZdhZmv67b5v3H+NfX//EzL+NI7KDPys37OKFuZ/x8+J3cba3bWT/6f9+YePeI8x64XECvN3ZfzKd1+f/l2/ee4Ow9r4AuDs78Nr40fh5uqJFy8+7DvPqh0v4/l9vE+TnaZq+3xL515ffMfOlJ4kMbs/Kn7fxwrv/5ucv3sPZofEN/9OVP7Fx1yFmvfI0AT6e7D+eyuvvf8Y386cRFthwUw/08+K//3xT/1kmNT1YsuX4DcfdnpNMTviZ9TPGN3HcnWbRLweY/fhgogM8ySooZdaq7UiAN8fqHkTKq2uZsPAHunXw4dMXR+r2bUEZdpYWputLyWLB5uO8M7IbkT4urDqYweRvdrF+ykicbBq3tyk5k0XbTzJ7TE+ifV3IKqpg1k+HdPru7wLAscwCxvUIpqO3E2qNlsXbknhx+U5+fGUElmam3XY3HzjBR9+sY8ZzDxPZoR2rNu7hxff+w/qF04wfe6s3sfG3Y8z62yMEeLtxIOk0r//rK5b/cwphAT4AuDnZ8+rjI3THnlbLL3uO8Or8pXw3//8I8jXt2BPcGiLs2EpUVlby3Xff8eKLLzJ8+PBGC7N98MEHuLu7Y2try7PPPkttba3B92q1mjfeeAMHBwecnZ156623Gi38tnnzZvr27au3GTFiBOfPn7/T/5pR+vXqxpTnnyauf5826f93Vhy9wNgoP8ZE+hHoYsuM+CgsFDLWpWQbtU+6VEKMtxPDwn3wtreid4AbQ8O8Sb1ScttaFN2HokragyrlN7RFl1Fu/hqtSokiKtZ4hdoqtFVl+k0W0BHqlagyEg3t1PUGdtRW35K+FbuOM7ZXR8b07EigpzMzxg3CwkzOuoOnjNonXbhCTHtPhnUNxdvZjt5h7RjaJZjUrDy9jZOtFS521vpt76mL+LrY0zXI2zRte5IY2zOcMd1DCfRwYsZD/bFQKFiXmGFcW2Y+MQEeDOsSjLeTHb1DfBnaqQOp2QV6m692nsDDwZp/PDaIyHbuuv8hxBdfF3uTtAF888tOHozrzZhBvQj09WTm3x7F0tyMdTsOGrXfsCeRSWOH0K9LR3w8XBg3tB99O4XzzS879TYDukXSr0tH2nm54e/lzpQnRmFlYU7ymYum61u3lQfjYxkT15dAPy9mTn5Sp2/bPuP6dh1k0iPD6dc1Ch8PV8YNG0jfLpF8s26rgZ1cJsPF0V6/ORq52d+MFbtOMrZ3R8b0DCfQ04kZjwzUHXeH0ozaJ138/bgLuXbc+TG0SwdSsxt+zPir7cfwcLDhH0/EEdnOA29ne3qH+eHravq+XXEgg7FdAhnTOZBAN3tmjOyOhULOuuPGr61J2VeJ8XVlWJQ/3o429A7yZGhkO1IvFettEp4ayOhO7QlycyDEw5F/jO3JlbJq0i4XG22zWX0bdjN2cC/GDOxBoI8HM557GAszM9btOmzUfuNvR5n0QBz9Oofj4+7CI0P60LdTGN/8sltvM6BrBP06h9PO0xV/LzdeeWy47tg7m2WyvtZCq9W0yvZnQThfrcT3339PaGgoISEhjB8/nmXLlumdp++//57Zs2fz/vvvc/ToUTw9PUlISDCov2DBAr7++muWLVvGvn37KC4u5qeffjKwqaqq4o033uDo0aPs2LEDqVTKAw88gOYem679nXq1hvS8Mnr4N4QHpBIJPdq5kHzZuDMV7e1IWn4pKdecrdzSKvZdKKBve9NDFQZIZUg9/FFfvN6R0aLOPIXUO6hFTSiiYlGlHYZ6pUG5zC8UqymLsXz+A8zinwZLa5Pl1avUpOcU0CPEr0GyVEKPED+SM/OM1olu70laTgEp177PLSxjX1omfcP9m+xj05EMRvcMRyKRmKYt9yo9gn0MtQV7k5yZb7ROtL87aTlXScnSfZ9bVM6+9Cz6hjX8f3tOZRLu68aby7cw8N2vGLdgDWsPGr/hN6uvXkX6+Rx6RoVcp09Kj6gQkppwlJT1KswUCoMyC3MzTqQbv6Gr1Rp+3XeUmlol0SEBpus7l0XP6IaQkVQqpUdMOEmnjffXpL60swZlWZfzGfz0G9w/aSpvf7SEKwVFpmnTH3e+12mT0CPEl+SLTRx3AdeOu6zrj7ss+oY3zMjtSblIuJ87by77lYHTv2Tch/9j7YFUk7Tp9V0ppkdgQwhUKpXQI9CD5NxC4/r8XEm7UkzKte9ziyvZd+YyfTs0HemorNXNVttbmpmoT0X6hVx6RgZfp09Kz8gOJJ8x7igp61WY3TC7Zm6m4ORp4+kPao2GX/cfp6aujuhgf5P0tSoaTetsfxJE2LGVWLp0KePHjwdg6NChlJWVsWfPHgYMGMDChQt59tlnefbZZwH45z//yfbt2w1mvxYuXMi0adMYO3YsAF988QVbtmwx6OPBBx80+Lxs2TJcXV1JS0sjIiLiTv57f0hKqpWotVqcrQzDSM7W5mQWVxqtMyzch9IaJRNX7QdApdHycEw7JvUyLUx2IxIrWyRSGdrqMoNybVUZUuebT+NLPdsjdfOlbtMyg3L1hRTUp4+hKbuK1MENswEPYfHIm9R+8w9o5icxbqSkqga1RouznWGYx9nWisx840/jw7qGUlpZy8SFa0ALKo2Gh/tGMim+u1H7ncnnqaipY1TPcKPfN62tVqfN1rKxtoJS49q6BFNaVcvET9c1aOsdzqS4Lnqb3KJy1hw4xfj+UUwa3JnUnKvM/2kfCrmUUd1CW66vohK1RoOzg+Gsj7O9HRcvGXcOe8eEseKXnXQJD8LXw4XDKafZcegkao3hPjuTdYknpy9AqVRhZWHOwreeI9DEsE9JeYVOn6NheNHZwY6LuVeM6+sUwYp1W+kSEYyvhyuHk9LZceA46utuXpHB7fnna8/g7+3B1ZIyvvjfz0x4+wN+/PQfWFtZGm23kbbfjztbY8ed8QekYV1DdPt24dqGfdsngklDuultcovKWbMvhfEDY5h0X1dSs/OZv3YvCpmMUT1anrdUUl2n02dtGF50trYg82q5cX1R/pRW1zFx6XbQanXXkG5BTOpvPG1Bo9Hyr1+PEePnSpC7Q4u1AZSUVxk/9hxsuXi5wGid3tGhrNiwmy5hgfi6O3M49Sw7E5MN9i3A2ezLPPnOJyjrVVhZmPHvN58h0KfpPDxB6yKcr1bg9OnTJCYm6meq5HI548aNY+nSpQwYMID09HReeOEFgzq9evVi165dAJSVlXHlyhV69Oih/14ul9O1a1eD0OPZs2d59913OXz4MIWFhfoZr+zs7Cadr7q6Ourq6gzKpHV1mJubnvfyV+BIdiFLD51j+n2RRHo5klNSxfwdqSw5cIbnewffvIE7hDw6Fk1BTqPkfHV6Q2hBfTWX2qs5WL34EVK/MDRZps/imMKRs7ks3XqE6Y8MJNLfg5yrpcxfu4clmw/z/NAejezXHTxFn3B/3Oxt7qgugCPnLrF0x3GmP9iPSD93cgrLmL9uP0u2HuX5IV0B0Gi1hPu6MmV4TwBCfVw5f6WYHw6kmeR83QpTn3mIOZ//j9GvzkWCBB8PF0YP6sm6nYcM7AK83Fnz0TQqq2vYdvAEMz5dwbJ/vGqyA2ayvucfY87irxn94js6fZ6ujI7rw7rtDWHKfl0bku+DA3yJDG7P0GffYsu+o4wd0s9Ys62C7rg7yvSHBxDp707O1TLm/7iXJZsTeX6ozvHX7Vs3pozUveQT6uvK+StF/LA/1STn65b0Xcxn6d5TTB/RlUgfF3KKKpj/6zGW7E7h+QGRjeznbTzCuYIyvn72vjuq63femvgA//jiO8a8Ng+JRIKPuzOjB3Rn3S7DdAZ/Lze+/9ebVFbXsu1QEjM/+5alc15uOwfsTxQybA2E89UKLF26FJVKZZBgr9VqMTc359NPP221fkaOHEm7du3473//i5eXFxqNhoiICJRKZZN15s2bx5w5cwzKZvx9Cu++9Wqr6WorHK3MkEkkFFUbOpdFVXW4GEm2B0jYd5rh4T6MjdaFMDq42lFTr2buliQm9eqA1IRw2fVoqyvQatRIrAxzTiTW9mgry5qodQ2FGfKwHih/+/Hm/ZReRVtdjtTRzSTny9HaEplUQlG5Yb5YUUU1LnbGw5gJGw4yvHsoY3vrHPsOXi7UKFXM/d8OJg3pjlTaMFaXi8s5fDqHBZOGt1hTgzYLnbaKmsbajCRkAyT8msjwLsGMvTbL1sHLWadtzR4mxXVBKpXgamdFoLvhW68B7g5sTzYefmlSn60NMqmUolLDlyaKyspxMZLMDuBkb8snbz9PnbKe0ooq3JzsWbhyPT5uzgZ2CoUcP09XAMID/Ug9l82qjbt594XHWq7Pzlanr8RwpqaotBwXR+M5UE72tnwy45Vr+ipxc3Jg4fIf8HF3bbIfOxsr2nm5k3PF+IyLUW2/H3cVRo67pvbtxkMM7xbC2N66mSTdcVfP3NW7mDSk27V9a02gh5NBvQB3J7YnmZYD62hlrtNXZZiDW1RVi4ut8eT9hB3JDI8OYGwXXTpBB3cHaupVzP05kUmxEQbnxbwNR9h7+jLLno3D3d74/9usPjtr48deaUXTx56dDQvfela3byurcHO0Z+GqDXi7G46XQi7Hz+Pasdfel1Pns1m1aS/vPv+IyTpbBbHIqsAUVCoV33zzDQsWLODkyZP6LSkpCS8vL/73v/8RFhbG4cOGyZGHDjU8Advb2+Pp6Wlgo1KpOHbsmP5zUVERp0+fZsaMGQwePJiwsDBKSm6eJD5t2jTKysoMtqmvvnDTen8GFDIpYR72JGY15GZotFoSswqJ8jK+1ERtvRrpDf7V7w6XCVG8xmjUaPIykflfH3KTIGsXjubSuWarykO7g1yO6tSBm3YjsXUES5ubO3Q3oJDLCPN1I/FMToNkjZbEMzlENbHURG29qpEzqh8rDAdr/aE0nGwt6dfRtHwlvTYfVxLP5hpqO3uJKH/juXhGtUkNtUX7ezQKW2ZdLcPTybSZOYVCTligL4dTTl+nT8Ph5DNEBzf//5qbKXB3dkCl1rD90EkGdI9q1l6j1aKsV5muL6gdh5PTDfUlpRMdEtgCfY6o1Gq2HzjOgJ4xTdpW19SSk1fQpENnVJv+uLth357OISqgieNOaWzf6m5V+n3b3pPMAsPrX9bVUjwdTXshQCGXEebpROKFhvCxRqMl8UIeUU0sNaE79gzLbjwvtFot8zYcYWd6LksmDsLb8dZmgxVyOWHtfTiceuY6fRoOp54lKtj4UhO/Y26mwN1Jd+ztOJzMwK6NZ+WuR6PRUm/isdeqiHW+BKawYcMGSkpKePbZZ7G3N7woPfjggyxdupQ333yTCRMm0LVrV/r06cOqVas4deoU7ds3rMHz6quv8sEHH9ChQwdCQ0P5+OOPKS0t1X/v6OiIs7MzS5YswdPTk+zsbN5+++2b6jM3N28UYqxXGk8kNYXq6hqycy/rP1+6nE/GmfPY29ni6WH6Gkq3ypNd2zNz00nCPRyI8HRg1dEL1NSrGR2pS7yesfEEbjYWTOmvC0XEBrqz8ugFQt3tifR0JLu0ioR9GcQGeiC78YpqIvWJmzEf8RyavIuoL19A0S0eicKc+uTfADAb8TzaihLq96wxqCePjkV95jjUVBk2qDBH0XcM6tNH0VaVIXFww2zgOLQlBagvppis78mBnZm5civhfm5EtPNg1e4T1NTVM/ra7NGMb7bg5mDDlFG6N1hjIwJYuesEoT6uRLbzILuwlISNB4mNCDBYckCj0fLzoTRGdg9DLru157kn+0cz8387Cfd1JcLPnVV7kqlR1jO6uy48OOPbHbjZWTNlhC6EGBvuz8o9SYT6uBDp5052YRkJvyYS27GdXtv4/tFMWPQTX24/xpDoIFKz81l7KI2ZD/c3Wd9TIwcxY/EKwgP99EtN1NTVMWaQTs/0Rd/g7mTPq+NHA5B8JpOC4lJC/X3ILy7l8+83odFomTgmTt/mJyvX06dTRzxdHamqqeXX345y9NRZvpg52XR9Y4Yw499LCQ/yJzI4gJXrt1NTW8eYON2+nP7xl7g7O/Lq07q80eTTFygoKiG0vR/5RSV8/u16NBoNE8fer2/zo6XfMaB7DJ5uzlwtLiXh2/XIpFLu79845NwcTw6MYebK7YT7uhHRzp1Vu09So1Qxuse1427FVtzsbZgyShdCNDju/N3JvlpGwsZDxEb4N+zbATFM+PcPfLn1CEM6dSA1K5+1B1KZOW6QyWP3ZO9QZv50kHAvJyJ8nFl18LROX2fd9XnG2gO42Vkx5b4Ynb4Qb1YezCDU05FIHxeyiypI2JlMbIi3Xt/7G47ya0omCx+LxdpMQeG1WV0bCwUWCtNuu0+OGMDMz76lY3tfIoLasXLTHmrqlIwZoNsP73y6Sr90BEDy2SwKissI9feioLiMz9dsQaPVMGF0w9h88u0G+saE4eHiSHVtLZv2Hedo2nk+f+dvJo+f4NYQztdtsnTpUuLi4ho5XqBzvubPn09YWBgzZ87krbfeora2lgcffJAXX3zRIKH+//7v/7hy5QpPP/00UqmUZ555hgceeICyMt0Mh1QqZfXq1UyZMoWIiAhCQkJYtGgRAwYMuFv/qgGpGWd55pWp+s/zFy8BYPT9cbw34//umo74MG9KapR8vu80hVV1hLjZkfBwD5yvhR2vlNdw/UP0c707IJHAZ79lUFBZi6OlGbFBHrzc7/ZzgNTpiSit7FD0G4uZtT2agmxqv/8IqnXhIKmdE5obnswkTh7IfEOo+d/8xg1qNUjdfFFE9gULK7QVJagvnkK5dy2oTX9Cje8STEllDZ9vPERhRTUh3i4kTB6D87Ww45WSCoO3FJ+L744E+GzDQQrKKnG0sSQ2oj0vjzBcTPfQ6WyulFQwptetr5MW3ylIp23zEQrLr2l7foQ+UftKSaWhtvu66PbjpkQKyqp02jq24+VhDY5BhJ8bH0+MZ9HGwyzZegxvJ1v+ProPw7uYnts3tE8XSsoqSVi9kcLSCkICvPl8xkv6NbTyCosNZmuU9fV8+r8N5OYXYmVhTt/OHXl/ylPYWTeEnorLKpmx+BuulpRjY2VBcDtvvpg5mV7RpucsDe3XnZKyChJWraOwpJyQ9r58Pud1nK/NUuVdvUGfsp5PV/5Ebt5VrCws6Ns1kvffmISdTYO+gqISpn70H0rLq3C0t6VzeBArP3oHJxOXm4jvfO2423SYwvIqQnxcSXhxlP7lj0b7Nr6bbt9uPNRw3HUM4OURvfQ2Ee3c+XjSMBb9cpAlm4/g7WzH38f2Y3i3kEb931RfZDtKqmv5fGcyhZW1hHg4kvDkQJxtdC8VXCmrNtTXPwKJRMJnO5IpKK/B0dqc2BBvXh4crbdZc0T31uikr3YY9DXngZ6M7mR84dumGNq7EyXllSR8v5nC0nJC/L1JmP43fRJ+XmFJo2Pvs9WbyC0o0h17ncJ47+UnsLNueEmiuKySGZ+tunbsWRLczpPP3/kbvaJMH79W40/0pmJrINHeuJiU4C9PfaFpOS93G9X6hJsbtSGagqttLaFJpF1Mm5W469Q3nZ/4R0Da7vYW2r2jmLXsDcO2QnPxZFtLaJ5S05bJuJtIQrvd3KgNsYgedsf7qEvd1irtmEfcnRcbbheR8yUQCAQCgUBwFxFhR4FAIBAIBG3LPRZ2FM6XQCAQCASCNkWrFUtNCAQCgUAgEAjuEGLmSyAQCAQCQdvyJ1qjqzUQzpdAIBAIBIK2ReR8CQQCgUAgENxF7rGZL5HzJRAIBAKBQHAXETNfAoFAIBAI2pZ77Ie1hfMlEAgEAoGgbRFhR4FAIBAIBALBnULMfAkEAoFAIGhbxNuOAoFAIBAIBHeReyzsKJyvexDV+oS2ltAs8tGT21pCs1wZ+lxbS2gSp+LytpbQLNqKmraW0CyymIttLaFJtDmX21pCs0ijI9taQvNUV7W1gibRpuxvawnNEz2srRX85RDOl0AgEAgEgrZFhB0FAoFAIBAI7iL3mPMl3nYUCAQCgUAguIuImS+BQCAQCARtilYrFlkVCAQCgUAguHvcY2FH4XwJBAKBQCBoW+6xpSZEzpdAIBAIBALBXUTMfAkEAoFAIGhbRNhRIBAIBAKB4C4iwo4CgUAgEAgEgjuFmPkSCAQCgUDQtoiwo0AgEAgEAsFd5B4LOwrnqxWZMGECy5cvB0Aul+Pk5ERUVBSPPfYYEyZMQCr9c0Z5Vx+/yPLE8xRV1RHsZsfUuAgiPR2btF959AJrTmSSV1GDg6UZccGeTOkfhrlcdtc0Hz2Zwlff/kBaxjmuFhXzybyZDI7tfcf7tXl4NHZPPoLM2Qnl2fOU/GsxylOnjdpaj4jHefZbBmXaOiU5fe7Xf/Y7usNo3ZJP/kPFiu9N1qfofT+K/mOQ2DqguZJJ3bov0eScNWpr+cJcZIERjcpV6UepXfYeALKInih6xSPzDkRibUv1v19HcznTZF0Aiv4jMRvyEBI7RzS5F6j9LgFN5pmmK1haYz56AvJOfZBY2aAtLqB2zX9Qpx7RfS+RYjZiPIoeg5DYOaItK6L+4HaUm769JX3fncxi+bGLFFUpCXa1ZerAMCI8HIzaTlpzmGO5JY3K+wa4snhMFwCKqur4ZN9pDmYVUVlXT2dvJ94aGEY7R+tb0ifvEY+i3ygkNg5o8rJQbliGJvecUVuLZ2cja9+xUbnq9HHqvpkHUhmK+x5FHtwZiZMb2tpq1OdTqN+yCm1F4//rZqw+fJrl+9Ipqqwh2MORqcO7Eunj0qT9ygMZrEk8Q15ZNQ5W5sR19GPKfTGYK3TXkO8Tz7Am8SyXSysBCHRz4PkBEfQN9jZZm1G9xy6w/PC5hmvefVFEejVzzTtynjUnLpJXfu2aF+LFlAHhrXbNW33kHMsPnqGospZgd3umDu1EpLdT03oOn2XN0fPklV8bvzBvpgyK1OtZui+DHRmXyCyqwFwuI9rHmdcGR+LvYtsqegU3RzhfrczQoUP56quvUKvV5Ofns3nzZl599VV++OEHfv75Z+Ry04dcqVRiZmZ2B9TenC3pl1iwK413hkQS6enIqqMXmPz9YdZPGoiTtXkj+01puSzak87s+6OJ9nYiq7iSWZtOIpFIeHNQ44v9naKmppaQoPY8MHwIr03/513p0+q+ATi+/gLF8xZSl5qB3WNjcVv8IZcfnICmpNRoHU1lJZcfnNBQoDX8Pjf+IYPPlr274zTzTap3/mayPnl0H8xGTqRu7Reos89g1m8klpPepXr+y2iryhrZ1yz/EMl1x6vEyhbL1/+NKvlAQ5mZOeqL6aiS9mPx8Esma9Jr6xKL+UPPUfvtYjSZp1EMGoPVK+9RNXsS2orG2pDJsXp1HtqKUmqX/BNNaRFSJze01ZV6E7P4h1H0H07t1wvQXMlC1q4DFk+9gbamivpd603St+X0FRbszeCdwR2J8HDg2+OZTP7xKOsm9MPJqvF5sGBkJ+rVDTuzrEbJuJUHuK+DOwBarZbXfzmOXCpl4ajOWJvJWHk8kxfWHuHHp/tiqTDtOiGL7I3ZsKdRrl+COuccij7DsZjwDtX/fhWqyhvZ1377ERLZdX1Y2WD58keoUw7qPivMkXm1R7nrBzR5WUgsrTEbPhHzJ6dSm/C2Sdq2pGSy4NfjvDOqO5E+Lqw6mMHk5btY/+pInGwsGtlvSrrIom0nmD2mJ9F+rmQVVTDrx4NIJPDm/TrH1d3OiilDYvBztgUt/HziAq99u5fVL95PkLuDSfoa6U2/xIKdp3gnXudwrTpygcnfHWT984ONX/NO5bJodxqzh3XSXfNKKpm18bjumje48cOLyXpO5bBgWzLvDOtMpLcTqw6fZfK3v7F+cjxO1kbGLyWbRTtSmD2yK9G+zrrx+/koEiS8OSQagGPZVxnXLZCOno6oNVoW70rlxW9/48cXhmBp1kZuwT0WdvxzTsX8gTE3N8fDwwNvb286d+7M9OnTWb9+Pb/++itff/01ANnZ2YwePRobGxvs7Ox45JFHyM/P17cxe/ZsYmJi+PLLLwkICMDCQneCbd68mb59++Lg4ICzszMjRozg/Pnzd/T/WXH0AmOj/BgT6Uegiy0z4qOwUMhYl5Jt1D7pUgkx3k4MC/fB296K3gFuDA3zJvWK6U/Lt0O/Xt2Y8vzTxPXvc9f6tH3iISrXbaLqly2oLmZRPG8hmto6bEYNbbqSFjRFJQ1bseE4GXxXVIJl/z7UHT2J+tIVk/UpYkdRf3gbqqM70RbkUvfjF2jr65B3H2y8Qk0l2opS/SbrEA31daiSGpwv1fE91G//HvXZJJP1XI9Z3Fjq929GdXAbmivZ1H27GG19HYre8cb/l95DkFjbUPP5HNTn09AW5aM+m4Lm0kW9jax9OKqkQ6hTE9EW5aM6vg9V2nFk/iEm61t5PJOxEb6M7uhDoLMN78R1xEIuY13qJaP29hZmuFib67dD2UVYKKTcF+wBQHZpNSlXynhnUDgdPezxd7Jh+uCO1Kk0/JpxC/u2zwhUR3egOr4b7dVclOuXoK1XougyyHiFmkq0laX6TRYUpdu3qdecr7pqar+aizr1INrCy2hyzqL8ZaluhtO+6RkrY6w4kMHYrkGM6RxIoJs9M0Z2111Djhu/diXlFBLj58qw6AC8HW3oHeTJ0Mh2pOYW6W36h/rQL9ibds52tHOx45X7YrAyk5OSW2iSNqN6E88xNrodY6LaEehix4yh0Tq9yVnG9V4qJsbHiWEdffB2+P2a59Nq17wVh84wtlMAY2L8CXS1Y8bwzjo9JzON68ktIsbXmWGRfng7WNM70IOhEb6kXi7W2yQ83o/R0f4EudkT4uHAP0Z140pZNWl3+TptgEbTOtufBOF83QUGDRpEdHQ0P/74IxqNhtGjR1NcXMyePXvYtm0bFy5cYNy4cQZ1zp07x9q1a/nxxx85efIkAFVVVbzxxhscPXqUHTt2IJVKeeCBB9DcoQOuXq0hPa+MHv4NF1upREKPdi4kXzZ+kkZ7O5KWX0rKtZM4t7SKfRcK6Nve/Y5o/MMgl2MWGkzt4eMNZVottYnHMYsKb7KaxNISr1++xWvD/3BZ8A8U7ds1aSt1csSybw8q1/9quj6ZHKl3oKGTpNWiPpuMrF3LnBF59zhUJ/dBfZ3p/d9Mm18H1OknDLWln0DaPsy4luieqC9kYP7YS1jP/x9WM7/AbOg4kDRc0tQX0pCHxiBx04WipN4ByII6ojp1xCR59WoN6fnl9PBz1pdJJRJ6+DmTfKW0RW2sS80lPthTP6OlVOvOWbPrwlJSiQQzmZSTTZxbTSKTI/Vqj/pcckOZVov6XDJSv+AWNaHoMhhVyoHm962FFVqNBm1tVYul1avUpF8upkd7D32ZVCqhR6AHyTnGHaVoXxfSLhfrHanc4gr2nblM32Avo/ZqjYbNyZnUKFVE+bq2WJtRvfprXkM7UomEHv6uJF9q6prnRFpeKSmXr7/m5bfKNa9erSH9Sik9AtwM9QS4k3ydM2qgx8eZtCulpFzSOVu5JZXsO5tH3yAPo/YAlXX1ANhbtk2E5V5EhB3vEqGhoSQnJ7Njxw5SUlK4ePEivr6+AHzzzTd07NiRI0eO0K1bN0AXavzmm29wdW24CDz44IMGbS5btgxXV1fS0tKIiLj96e0bKalWotZqcb4hrOJsbU5mcaXROsPCfSitUTJx1X4AVBotD8e0Y1KvDq2u74+EzMEeiVyG+saZq+ISFP6+RuvUZ+VQPPdfKM9eQGpjjd34R3BftogrjzyLuqDxjcl6xBA0VdVU7zI95CixtkUik6GtNAzhaStLkbrdPE9G6tsBmWc76tZ8ZnLfN9VmY4dEJkNTXmqoraIUmYfxsZO4eCILcac+cRc1n85E6uqFxWMvg0yOcuMqAJRbvgcLK6xn/1eXzCuRoly/HFXiLpP0ldTozgMnK8Mbk7OVOZklN3dEUvNKOVdUyawhDeeov6M1HrYWLN53hhlxHbFU6MKO+ZW1FFaZ5txKrJrat2VIXVuwb32CkHr4UffT500byRWYxY9Hnbwf6mparK2kug61RovzDeFFZxsLMgsbh0MBhkUHUFpdx8Qvt4FWq7uGdOvApP6G17izeSU89d+tKFVqLM3kfPx4LIFu9i3W1qRerRZnayPXvKIK43o7+lBaU8fElbrzUqXR8nAnfyb1bpnj2yI9N46ftXnT4xfpp9Pz9a4GPV3aM6mv8QcZjVbLv7aeJMbXmaDbHL/bQiTcC+4EWq0WiURCeno6vr6+escLIDw8HAcHB9LT0/XOV7t27QwcL4CzZ8/y7rvvcvjwYQoLC/UzXtnZ2U06X3V1ddTVGV7MNfUqzE3MKWkpR7ILWXroHNPviyTSy5Gckirm70hlyYEzPN8KF6O/EsqUNJQpafrPV5NO4fnDV9iMHUHZF183srcZNZTqzTtAWX8XVepQdB+M+kpmk8n5dxuJRIK2opS6lZ+AVoMm+xx1Di6YDXlI73zJu8Si6D6I2mUformchdQ3EIuH/4amrAjVoe13Teu61Fw6uNgYJOcrZFIWjOzEnG2p9P98B7JrM2l9/F1uTPu748i7DEKTl9Vkcj5SGeaPvgESqPv5v3dcz5GL+Szde4rpI7oR6eNMTnEl8zcdZcmuFJ4fGKm383ex47vJw6isVbL9VDbvrj3Il8/ed9sOmMl6swpZevAs0+OjifR0JKekUnfN23+a5/uYHuK+bT2ZBSzdl8H0YZ2J9HLS6dlykiV703g+tvEs/LxfT3CuoJyvJwy461oN+BOFDFsD4XzdJdLT0wkICGixvbV14zeeRo4cSbt27fjvf/+Ll5cXGo2GiIgIlEplk+3MmzePOXPmGJRNH9mLGaNv/uafo5UZMomEompD562oqg4XI4mnAAn7TjM83Iex0brwWQdXO2rq1czdksSkXh2QSiQ37ffPiLq0DK1KjczJ8I0oqZMj6qLiJmrd2Iia+tPnkPs2nq0wj4lE4e9H4bS5t6RPW1WBVq1GYmN4Y5LYOKCtKG2+ssIceXRflFtX31LfN9VWWY5WrUZq58D1l1+JrQOacuOhHk1ZMajVBk/LmrxspPZOIJODWoX52Ekot3yP6uge3feXM1E6uWE2dJxJzpejpe48KK42PM+KqusazQrfSE29ii2n83ixV1Cj78Ld7flufB8q6uqpV+tm1p7830HC3U1zHrTVTe1be7SVpc1XVpgjj+qDcvt3xr+XyjB/7A0kDi7ULp1j0qwXgKOVOTKphKLKWoPyospaXGwsjdZJ2JHE8OgAxnbVjVkHD0dqlCrm/nyYSf0jkEp11xCFXKZLuAfCvZ05damYbw9mMHN0D5M0NtIrkVBUZeya1zi5HSDht3SGd/RtuOa5XbvmbU5iUu/g27rm6fXcOH5VdbgYeVkBIGH3KYZHtWNsJ939poO7vW78Nh5nUr8wAz3zfj3B3rNXWPbUANztrG5ZZ6twj818iZyvu8DOnTtJSUnhwQcfJCwsjJycHHJycvTfp6WlUVpaSnh407lBRUVFnD59mhkzZjB48GDCwsIoKbl5bsi0adMoKysz2P4+rHuLdCtkUsI87EnMagiBabRaErMKiWritevaejXSG641v5/s2rv9SH83UalQZpzBonunhjKJBItunVAmpzVd73qkUhRBAagLGztr1qPvpy7tNPVnL9yaPrUKzaXzusTq6/TJgiJRZxlfCuN35NG9Qa6g/vieW+u7JdqyzyILjTHUFhqD5kK68Srn05C6ecF1NxKpuzea0iJQq3RNmJk3vqBrNEhMvBkqZFLC3O04nNOQY6PRaknMKSLK06HZutvO5KFUaxgWZjxfCcDWXIGTlRlZJVWk5ZcxINCtSVujqFVoLl9AFtgwK4REgiwwEk12M0t1APKIXiCTozq5t/GX1xwvqbMHtcvmQo3xVIPmUMhlhHk5kXghT1+m0WhJvJBHlK/xxH3dNcRwH/3ucGmbmRfUaLX6XLpbRX/Ny7xq0G5i1lWivE245klb55qnkEkJ83QgMbPAUM/FAqJ8nI3Wqa1XN7qx36hHq9Uy79cT7Dx9iSXjY/G+xeVNBLeOmPlqZerq6sjLyzNYamLevHmMGDGCp556CqlUSmRkJE888QQLFy5EpVIxefJk+vfvT9euXZts19HREWdnZ5YsWYKnpyfZ2dm8/fbNX/k2NzfH3Nzw6bzGhJDjk13bM3PTScI9HIjwdGDV0QvU1KsZHekHwIyNJ3CzsWBKf10+QWygOyuPXiDU3Z5IT0eyS6tI2JdBbKAHshuvUHeQ6uoasnMv6z9fupxPxpnz2NvZ4ulh4s2thVSs+gHn2VNRpp2h7lQGto8/iNTSgspftgDgPGcqqoJCyj5bCoDdpCdRpqRRn3sZqY0Ndk89gszDncp1mwzalVhbYRUXS+nCL25LX/3enzEfNwVN7nnUOWcx6zcCiZkFqiO6tcTMH52CtqwY5a8rDeopusWhOnUYqo3kvFjaIHV0QWKnW3Po9xyj39+QbCnK7T9iMeFN1Flnry018QASMwvqD2wFwGLCm2hKi1Cu++ra/7IBswEjMX/kBZS7fkbq5o3Z0EcNlpBQpRzG7P5H0RRf1S014RuIIu4BfZumML6zP+9uSSHczZ4ID3u+PZGpOw866v7fGZuTcbMxZ0pfwzDTutRLDAh0w8FIIvO2M3k4WirwsLXkbFEF/9qdzoBAd3q1M+1tQoD6/Rswf/AlNJfOo849h6L3cCRm5tQf0+X9mD30MtryYuq3Gq5xJu86CHX6kcaOlVSG+eP/h9QzgLoVHyCRSsHGAQBtTaXewW0JT/YOZeaPBwn3dibC25lVBzOoUaoZ3bk9ADN+OICbnSVThugeXGJDvFl5IJ1QT0cifV3ILqogYUcSsSHeyK6tlbho6wn6BHvhYW9NdV09vyZncjQzn4Snmni70wSe7B7EzA3HCfd0IMLTkVVHz+v0Rl275v1yDDdbS6YM0D0sxwZ5sPLIed01z8uR7JIqEvZmEBvk3irXvCd7BjNz/RHCPR2J8HJiVeJZaupVjI721+lZl6jTM1jnfMcGe7Ly0FlCPRyJ9HYiu6SShN2niA321Ot5/9cT/Jqaw8JxvbE2V1B4bWbNxlyBheLurcdogAg7Cm6HzZs34+npiVwux9HRkejoaBYtWsTTTz+tX2R1/fr1vPLKK8TGxiKVShk6dCiLFy9utl2pVMrq1auZMmUKERERhISEsGjRIgYMGHBH/5/4MG9KapR8vu80hVV1hLjZkfBwD31C6pXymusnH3iudwckEvjstwwKKmtxtDQjNsiDl/uF3lGdN5KacZZnXpmq/zx/8RIARt8fx3sz/u+O9Fm9bTdSR3vsX5iAzNkR5ZnzFLzytn75CJmHG1pNw6Ow1M4Gpxn/h8zZEU15JcqMM+Q/OwXVRcNX2q2GDASJhKrNpiWK34gqaT8SazvM4h9FYuuI5vJFar78hz5RW+rgiuaGR3WJqxey9uEol8w22qa8Yzcsxk3Rf7YY/yYAyq2rUW5rIpRlTNuxvdTZ2mM+8kn9IqvVi2foHTiJkxvS67RpSwqpXjQDi4efx3rm52hLC6nfuQ7lljV6m9rVCZiPegqLx15CYuugW2T1t1/1OWGmEB/iqTsPDp6lqLqOEFc7Pnugq/48yKuoaTT7kVlcyYnLJXw+1vhD1dWqWhbsyaCoWhfGHxHuzfM9Ak3WBqBOOYDS2g7F4HGYXVtAt/br9+Da+m1Se5fG+9bFC5l/GDXLGoeyJXZOyMN0+aeWr3xk8F3Nl7PQXGzhbC4QH+lPSVUdn+9IorCylhBPRxKeGojztbDjlbIqJNcN3nP9I5AAn+1IoqC8Bkdrc2JDvHk5LkZvU1xVx4y1BymsqMHGQkGwuyMJTw2iV5Bni3U1qTfMm5LqOj7/LaPhmjeuJ87Xwo66a951evsE6655ezMoqKzB0cqc2CB3XjaSX3VLejr66vTsSdONn7s9CY/31SfhXymvNtTTLwwJEj7bnUpBxTU9wV68PLBhncU1x3Qz6JO+MZzNnjOqq96pu+vcY2FHiVb7lw4GCYxQs/TNtpbQLPLRk9taQrNcGfpcW0toEqeBdm0toVm0FablDN1tZDF3P0G6pWhzLt/cqA2RRkfe3KgtqTI9bHrXUCjaWkGzWI5/7473UfPj+63SjuXY6a3Szp1GzHwJBAKBQCBoW0TYUSAQCAQCgeAuco85X+JtR4FAIBAIBIK7iJj5EggEAoFA0LbcY+nnwvkSCAQCgUDQtoiwo0AgEAgEAoHgTiFmvgQCgUAgELQt99jMl3C+BAKBQCAQtC332CKrwvkSCAQCgUDQttxjM18i50sgEAgEAsE9y2effYa/vz8WFhb06NGDxMTEZu0XLlxISEgIlpaW+Pr68vrrr1NbW2tSn8L5EggEAoFA0LZota2zmch3333HG2+8waxZszh+/DjR0dHEx8dTUFBg1P7bb7/l7bffZtasWaSnp7N06VK+++47pk837WeNhPMlEAgEAoGgbdFoWmczkY8//pjnnnuOiRMnEh4ezhdffIGVlRXLli0zan/gwAH69OnD448/jr+/P0OGDOGxxx676WzZjQjnSyAQCAQCwV+Curo6ysvLDba6ujqjtkqlkmPHjhEXF6cvk0qlxMXFcfDgQaN1evfuzbFjx/TO1oULF9i0aRPDhg0zSadIuL8H0RRcbWsJzXJl6HNtLaFZPDf/t60lNIkqbW9bS2ie8uK2VtAsmpSktpbQJBIP17aW0CzqxGNtLaFZpK5ObS2hSbTllW0toe1ppYT7efPmMWfOHIOyWbNmMXv27Ea2hYWFqNVq3N3dDcrd3d3JyMgw2v7jjz9OYWEhffv2RavVolKpeOGFF0TYUSAQCAQCwZ8MraZVtmnTplFWVmawTZs2rdVk7t69m/fff5+EhASOHz/Ojz/+yMaNG5k7d65J7YiZL4FAIBAIBH8JzM3NMTc3b5Gti4sLMpmM/Px8g/L8/Hw8PDyM1pk5cyZPPvkkkyZNAiAyMpKqqiqef/553nnnHaTSls1piZkvgUAgEAgEbYpWo22VzRTMzMzo0qULO3bs0JdpNBp27NhBr169jNaprq5u5GDJZDLd/2DC25Zi5ksgEAgEAkHb0kaLrL7xxhs8/fTTdO3ale7du7Nw4UKqqqqYOHEiAE899RTe3t7MmzcPgJEjR/Lxxx/TqVMnevTowblz55g5cyYjR47UO2EtQThfAoFAIBAI7knGjRvH1atXeffdd8nLyyMmJobNmzfrk/Czs7MNZrpmzJiBRCJhxowZXLp0CVdXV0aOHMl7771nUr8SrSnzZIK/BFXznm5rCc1StDa3rSU0i3jb8TYQbzveMhIb67aW0CyarEttLaFZxNuOt471e2vueB/Vn7/SKu1Yvbi4Vdq504iZL4FAIBAIBG2Liflaf3aE8yUQCAQCgaBtET+sLRAIBAKBQCC4U4iZL4FAIBAIBG3LPTbzJZwvgUAgEAgEbcs99u6fCDu2kNmzZxMTE6P/PGHCBMaMGaP/PGDAAF577bU72qdAIBAIBII/P3/Jma8JEyawfPnyRuXx8fFs3rz5ltp88803eeWVpl+F/fHHH1EoFLfUdkv7PHXqFO+++y7Hjh0jKyuLf//7363u8AHIOw9G0eN+JDb2aApyUG5diebKBaO2Fo+/jaxdWKNy1bmT1K35NwBmwyehiOpn+P2FZOq+W2CyNpuHR2P35CPInJ1Qnj1Pyb8Wozx12qit9Yh4nGe/ZVCmrVOS0+d+/We/ozturAZAySf/oWLF9ybraylHT6bw1bc/kJZxjqtFxXwybyaDY3vfsf5+Z/WuYyzfcpiiskqCfd2Y+tgQIgO8mrRfuT2RNbtPkFdcjoONJXFdQpkydgDmCt2lo6q2js/W7WXXiTMUV1QT4ufOW+PiiGimzSa17Utl+e4kiipqCPZyZuoDfYj0c2ta295k1hxII6+kEgdrC+Ki2zNlWHe9NoD8sio+2XCI/Rk51CpV+LrYM+fRAXT0Nf1Hqv/I5wXAd8k5LD+RTVG1kmAXG6bGBhPhbm/UdtKPxzh2ubRRed92ziweGQNAtVLFooPn2XXhKmW19XjZWfBYtC8PR/iYrE3RexiKAWOQ2DqiuZJJ3U9L0OScNWpr+eI/kQVGNipXpR+ldqnu9/NkET1R9BqKzCcQibUd1R+/hubyRZN1/Y680yDkPe5HYm2PpiCb+u2r0Fwx3p75Y1OR+YU2KlefT6Luh4UAmA17FnlkX8PvL6RQt+bjW9PXIx5Fv1FIbBzQ5GWh3LAMTe45o7YWz85G1r5jo3LV6ePUfTMPpDIU9z2KPLgzEic3tLXVqM+nUL9lFdqKklvS1yqIsONfg6FDh/LVV18ZlLX0956MYWNjg42NTZPfOzm1/hoyN/ZZXV1N+/btefjhh3n99ddbvT8AWVh3zAY/hnLzctSXz6PoFo/FuDepXjIVqisa2df+uBiJ7LrDyNIGy2fnos44YmCnOp+McuOX+s9adb3J2qzuG4Dj6y9QPG8hdakZ2D02FrfFH3L5wQloSkqN1tFUVnL5wQkNBTfMbOfGP2Tw2bJ3d5xmvkn1zt9M1mcKNTW1hAS154HhQ3ht+j/vaF+/s+VIGgu+38E744cSGeDFqu1HmLzwO9bPfR4nu8ZrSG06fIpFa3cze8JwogO9ycovZtZXG5EAb46LA2DO8l85d+kq/3x2JK4ONmw8dIoX/r2atXOew93RtuXaTpxjwc8HeeehfkT6ubPqt2QmL9nI+qmP4mRr2Vjb8bMs2pjI7HH9ifb3IOtqKbNW79ZpG61zYsur65iweB3dgrz49LlhOFlbkFVYhp2lmclj90c+LwC2nM1nwb6zvDMglAgPO749mcPkn0+y7oleOFk1/n8XDIuiXt1wsyurrWfc6kTuC2pwdhfsO8uRSyW8d19HvOwsOJhdzLw9p3G1NmdAQMudV3l0X8xGPUPd2s9RZ5/BrN9ILJ+bTfX8yWgryxrZ13z9ARJ5w9hJrGyxfOMTVEn7G8rMLFBnpqNK2o/FIy+3WIsxZKHdUQx6FOXWb9BcvoCi632YP/J/1Px3mtF9W/fTp3DdSuYSSxssJv4D1Q37Vn0hmbpNSxsKVKpb0xfZG7NhT6NcvwR1zjkUfYZjMeEdqv/9KlSVN7Kv/fYjw2PPygbLlz9CnXJQ91lhjsyrPcpdP6DJy0JiaY3Z8ImYPzmV2oS3b0ljq3CPLTXxlw07mpub4+HhYbA5OjoCIJFI+M9//sOIESOwsrIiLCyMgwcPcu7cOQYMGIC1tTW9e/fm/Pnz+vZuFgK8Mey4YsUKunbtiq2tLR4eHjz++OMUFBTov9+9ezcSiYQdO3bQtWtXrKys6N27N6dPN8zi3Nhnt27d+Ne//sWjjz56W45kcyi6D0WVtAdVym9oiy6j3Pw1WpUSRVSs8Qq1VWiryvSbLKAj1CtRZSQa2qnrDeyorTZZm+0TD1G5bhNVv2xBdTGL4nkL0dTWYTNqaNOVtKApKmnYig2f7Ay+KyrBsn8f6o6eRH3pisn6TKFfr25Mef5p4vr3uaP9XM+KbYmM7RfNmD5RBHq5MGP8UCzM5Kzbn2zUPul8LjFBPgzr0RFvFwd6d2zP0O7hpGbqxqZWWc+O4xm89tBAugT74efmxIuj+uHr6sia3cdN07Y3hbE9wxjTPZRAD0dmPBiLhULOusQM49oy84nxd2dY5w54O9nSO8SXoZ2CSM2+qrf5audJPBxs+MejA4n0c8Pb2Y7eIb74uhifDWqOP/J5AbDyZDZjO3ozOtyLQCcb3hkYioVcxrr0y0bt7S0UuFib67dDOcVYyKXcF+Sut0nKK2NEqCddfRzxsrPkwQhvgl1sOJXf+IbfHIr+o6k/vBXVkR1o83OoW/s52vo65N3ijFeoqURbUarfZMExUF+HKrnB+VId3039tu9Qn739RXHl3YagStqLOmWfbt9u+QZtvRJ5ZD/jFWqrdE7PtU3mr9u36tOGzpdWpTKwo+7W9q2izwhUR3egOr4b7dVclOuXoK1XougyyHiFmkq0laX6TRYUpRu/1GvOV101tV/NRZ16EG3hZTQ5Z1H+shSZdyASe5db0igwnb+s83Uz5s6dy1NPPcXJkycJDQ3l8ccf529/+xvTpk3j6NGjaLVaXn751p+o6uvrmTt3LklJSaxbt47MzEwmTJjQyO6dd95hwYIFHD16FLlczjPPPHMb/9VtIpUh9fBHffHUdYVa1JmnkHoHtagJRVQsqrTDUK80KJf5hWI1ZTGWz3+AWfzTYGniat1yOWahwdQevu6mrtVSm3gcs6jwJqtJLC3x+uVbvDb8D5cF/0DRvl2TtlInRyz79qBy/a+mafsTUK9Sk56VR4+wAH2ZVCqhR5g/yeeNr0weHehDWlYeKRd1N/DcqyXsSzlP34hAANQaDWqN1iDMB2BuJufEuZb/SkG9Sk167lV6dPA21BbsQ3JWvnFt/u6k5RaSkq17oMktKmdfejZ9w3z1NnvSMgn3deXN5dsYOGs54xb8wNpD6S3W1SDmD3xeAPVqDekFFfTwbZh9l0ok9PBxJDmv8cySMdalXSa+gzuWioYZnWgPe/ZcvEpBZS1arZYjucVklVbT09eEWX6ZHKl3IOoz1zlJWi3qs0nI2oW0qAl59zhUJ38DZV3L+20p1/atJstw32oy01q8b+VRsajTje9by5c/wWLS+yiGPAkWt/ALBTI5Uq/2qM9d94Ck1aI+l4zUL7hFTSi6DEaVcgDqmxk/Cyu0Gg3a2irTNbYWWk3rbH8S/rJhxw0bNjQKE06fPp3p06cDMHHiRB555BEApk6dSq9evZg5cybx8fEAvPrqq/of1rwVrnei2rdvz6JFi+jWrRuVlZUGut577z369+8PwNtvv83w4cOpra3FwsLilvu+VSRWtkikMrTVhhdsbVUZUmfPm9aXerZH6uZL3aZlBuXqCymoTx9DU3YVqYMbZgMewuKRN6n95h8tfsNF5mCPRC5DfePMVXEJCn9fo3Xqs3IonvsvlGcvILWxxm78I7gvW8SVR55FXVDYyN56xBA0VdVU77qzIce2oKSyGrVGi7OdlUG5s501mXlFRusM69GR0spqJn64AgCVWsPD/TsxabgurGdtYU5UoDdLNuwnwNMZZztrNiemkXz+Er5uji3XVlWr03ZDeNHZxpLMglLj2jp3oLSqlomfrgctqDQaHu4VzqS4znqb3KIK1hxIY3z/SCYN7kRqTgHzf9qPQiZlVLeW3fjhj31eAJTU1KPWanG6IZzqbGVGZunNZ1tS88s4V1zFrMGGOWpT+4cwd2c68V/vRy6VIAFmDgqji3fL963E2g6JTIa2stSgXFtRitTt5rljUt8OyDz9qfv+0xb3aQr6fXtD+E5bXYbU2ePm+jwDkLr6oPz1hn17MQX1mWNoSguROrqiiH0Q6cNvULfynybtW4mV7bXxu+HYqyxD6urdRK3r9PkEIfXwo+6nz5s2kiswix+POnk/1NW0WFurc4+FHf+yztfAgQP5/HPDA+76vKyoqCj937//gGZkZKRBWW1tLeXl5djZ2Znc/7Fjx5g9ezZJSUmUlJSguZZMmJ2dTXh4w0zN9To8PXUX8oKCAvz8/Ezu0xh1dXXU1Rk+8ahUaszlLf/19ZYij45FU5DTKAlZnX644e+rudRezcHqxY+Q+oWhyUprdR2/o0xJQ5nS0P7VpFN4/vAVNmNHUPbF143sbUYNpXrzDlDeWt7NX40jp7NYuukg05+IJzLAi5yCEuZ/t50lG/bx/AhdMvF7z4xk9vKNDPn7p8ikEkL9PBjaPZz0rLw7q+3cZZbuOMH0sX2JbOdGTmE589cdYMm2Yzx/XxcANFot4T6uTBnWA4BQHxfO55Xww8E0k5yv2+WPdl7cyLq0y3RwtmmUnL86KYeU/HIWDo/C09aC45dL+eBazpdJs1+3gaJ7HOrLmU0m57c1sqjf961hcr46vSG8rC7MRVOQi+UL85H6haLJuoXZ11tE3mUQmrysJpPzkcowf/QNkEDdz3/c36z9K/KXdb6sra0JCmp62vj6NxMlEkmTZZpbeAOjqqqK+Ph44uPjWbVqFa6urmRnZxMfH49SaTg13Vp9NsW8efOYM2eOQdm0QVG8ExfTyFZbXYFWo0ZiZXgRlljbG02MNUBhhjysB8rffrypJm3pVbTV5Ugd3Vp8k1GXlqFVqZE5GT51S50cURe18Mea1WrqT59D7tv4idE8JhKFvx+F0+a2rK0/GY42VsikEorKDWdCisqrcLEz/iJJwrq9DO8Zwdh+MQB08HGjRlnP3BW/MmlYH6RSCb5ujiz9+3hq6pRU1ihxdbDhrf+sw9vVoeXarC102ioMn7qLKmtwMZJsD5Cw+QjDu3RgbE/dbE0HT2edtjW/MWlwZ6RSCa52VgS6Gx4vAe4ObE82/oZiU/yRzwsAR0sFMomE4hrDa0tRtRJnI8n211NTr2bL2Xxe7NHeoLxWpWbxofN8PCyKfv66PKBgF1tOF1ay4kRWi50vbVU5WrUaiY2DQbnE1gFt+U3erDMzRx7TD+WWb1vU162g37fWhg/YEiv7RrNhjVCYIQ/rTv1v627eT9lVtNUVSB3cTXK+tNUV18bvhmPPxr7RbGJjfebIo/qg3P6d8e+lMswfewOJgwu1S+e07awXoL3H3na8Z3O+7iQZGRkUFRXxwQcf0K9fP0JDQw2S7e8m06ZNo6yszGB7c0Dj17gB0KjR5GUi878+h0qCrF04mktNPDldQx7aHeRyVKcO3FSTxNYRLG1ufuO6HpUKZcYZLLp3uq4hCRbdOqFMbuGNSipFERSAurCxs2Y9+n7q0k5Tf9a0G/OfBYVcRlg7DxLTM/VlGo2WxPQsogKNhy9qlSqk1x4Ifuf3z9obXhu1NDfD1cGG8qoaDpy6wICYDqZp83El8WxD7plGoyXx7CWi2rkbrVNbb0yb1EBbtL8HmVdLDWyyrpbhacJbmDoxf+DzAlDIpIS52XI4p+G41mi1JOaWEOXR/MsF287lo1RrGRZsGD5VabSoNFpuGGJkEhOjQ2oVmkvnkXVomOFHIkEWFIU6y/gSMb8jj+oDcgX1x/eY0KGJXNu30naG+1bqH3bTfSsL6QYyhQn71hptValp+tQqNJcvGC69IZEgC4xEk32m2aryiF4gk6M6ubfxl9ccL6mzB7XL5kJNpWm67gQabetsfxL+sjNfdXV15OUZhj7kcjkuLnf+bQ4/Pz/MzMxYvHgxL7zwAqmpqcyde/szKkqlkrS0NP3fly5d4uTJk9jY2DQ5y2dubt7ozciqZkKO9YmbMR/xHJq8i6gvX0DRLR6Jwpz6ZF0elNmI59FWlFC/Z41BPXl0LOozx6HmhoRNhTmKvmNQnz6KtqoMiYMbZgPHoS0pQH0xxaT/v2LVDzjPnooy7Qx1pzKwffxBpJYWVP6yBQDnOVNRFRRS9pnu9W67SU+iTEmjPvcyUhsb7J56BJmHO5XrNhm0K7G2wioultKFX5ik53aorq4hO7fhTbRLl/PJOHMeeztbPD2aXtvqdnjyvu7MXLaBcH8PIq4tNVGjrGd0H92NccbSX3BztGXK2AEAxEYHsXJbIqF+7kQGeJF9tYSE9XuJjeqATKpzdA6kXkCLFn93Z7KvlvDvNTsJ8HBmdO+opmQY1xYbyczVuwn3dSXCz41Ve1N02rrrwoMzvt2Jm701U4brQoix4e1YuSeZUG8XIv3cyC4sJ2HzEWLD/fTaxsdGMmHxer7cfpwhMYGkZhew9lA6Mx9q4g3FZvgjnxcA42P8eHd7GuFudkS42/FtUjY1KjWjw3RO1Yxtp3CzNmdKb8PrxLq0ywxo74KDpeEahTZmcrp4ObBw/zksZDI87Sw4dqmEDRl5vNG35Y41QP2e9Zg/+iqa3HOos89i1m8kEjMLVEe2A2D+6Gtoy4pQ/rrCoJ6iexyq1MNGl3vA0gapoysSO90M3O/5T9qKErQVpSbpUx3ZitnwSWjyMtFcuYC86xAkCnNUKfsA3Xps2opS6vf+YFBPHhWL+uxx3duPBsLNUfQZjfrMUbSVZUgc3TAb8Mi1fZtqkjaA+v0bMH/wJTSXzqPOPYei93AkZubUH9ul0/fQy2jLi6nfajhDKO86CHX6kcaOlVSG+eP/h9QzgLoVHyCRSuHazKS2phLUt7Ykxm3zJ0qWbw3+ss7X5s2b9TlUvxMSEkJGhvFX11sTV1dXvv76a6ZPn86iRYvo3LkzH330EaNGjbqtdi9fvkynTg0zPx999BEfffQR/fv3Z/fu3bepWoc6PRGllR2KfmMxu7bgYO33H0G1bgpeaueE5oaTROLkgcw3hJr/zW/coFaD1M0XRWRf3Rs1FSWoL55CuXetySd59bbdSB3tsX9hAjJnR5RnzlPwytv65SNkHm5or3vykdrZ4DTj/5A5O6Ipr0SZcYb8Z6eguphl0K7VkIEgkVC1eZdJem6H1IyzPPPKVP3n+YuXADD6/jjem/F/d6TP+G7hlFRU8/n63ygsryLE142EVx/B+doaX1eKy/Whb4DnhvdBAny2bg8FpZU42loRGxXEyw/019tU1NSx+Kfd5JdUYG9tweDOIbw8pj8KE3MK4zsFUVJVy+dbjlJYXk2ItwsJzw3D2Vb3gsCV0kpDbXGdddp+PUJBWRWONpbEhvvx8rDuepsIPzc+njiERRsTWbLtON5Otvx9dG+GdzHNeYA/9nkBEN/BnZIaJZ8nXqCoqo4QV1s+GxmDs5XuwSuvorbRTGFmSRUnrpTx+agYo21+EB/B4oPnmb7tFOW19XjaWvBSz0Aejrh5ovf1qJL2IbGxwyz+cd0iq5cvUvPlHP0Mn9TRpfHYuXoja98R5X/eNdqmvGN3LB59Vf/Z4sm/A6Dc+j+UW1ebpE+dkUi9lS2KvmP0i6zWff+xft9K7JwbJcnr9m0wtd/9q3GD1/atPKKPbt9WlqK5mIryt59uad+qUw6gtLZDMXgcZrYOaK5kUvv1e1B1bfzsXdDcqM/FC5l/GDXLGj/0S+yckId1A8DylY8Mvqv5chaai3cv3/BeRqLV3mM/qCSgat7TbS2hWYrWtnyZgrbAc/MfNzFVlWYkxPBHoryF+XlthCbl9teNulNIbG5hqYK7iCbL+JIlfxSkrnfnJYFbQVv+Bwj7NYP1e2tubnSbVP3jiVZpx/rdVa3Szp3mLzvzJRAIBAKB4E+CSLgXCAQCgUAgENwpxMyXQCAQCASCtuVP9KZiayCcL4FAIBAIBG3LPfa2owg7CgQCgUAgENxFxMyXQCAQCASCtkWEHQUCgUAgEAjuHuLnhQQCgUAgEAgEdwwx8yUQCAQCgaBtEWFHgUAgEAgEgruIcL4EAoFAIBAI7iJiqQmBQCAQCAQCwZ1CzHwJBAKBQCBoW0TYUfBXR9qlR1tLaBan4vK2ltAsqrS9bS2hSeThsW0toVlUSdvbWkKzSDt3a2sJf1pkdnZtLaF5PHzaWkGTSCpK21pCm6O9x5wvEXYUCAQCgUAguIuImS+BQCAQCARtyz028yWcL4FAIBAIBG2LWOFeIBAIBAKBQHCnEDNfAoFAIBAI2hYRdhQIBAKBQCC4i9xjzpcIOwoEAoFAIBDcRcTMl0AgEAgEgjZFq723Zr6E8yUQCAQCgaBtucfCjsL5EggEAoFA0LbcY86XyPkSCAQCgUAguIsI56uFzJ49m5iYGP3nCRMmMGbMGP3nAQMG8Nprr93RPgUCgUAg+Cui1WhbZfuz8JcMO06YMIHly5c3Ko+Pj2fz5s231Oabb77JK6+80uT3P/74IwqF4pbabmmf//3vf/nmm29ITU0FoEuXLrz//vt07969VftdvTeJ5TuOUVReTbC3C1MfGkCkv0eT9it3nWDNvmTySipwsLYkLiaIKaP6YK7QHV73z1rGleKKRvUe6RfF9EcGmqRN0ft+FP3HILF1QHMlk7p1X6LJOWvU1vKFucgCIxqVq9KPUrvsPQBkET1R9IpH5h2IxNqW6n+/juZypkmarmf1rmMs33KYorJKgn3dmPrYECIDvJq0X7k9kTW7T5BXXI6DjSVxXUKZMnaAfuyqauv4bN1edp04Q3FFNSF+7rw1Lo6IZtq8XY6eTOGrb38gLeMcV4uK+WTeTAbH9r5j/f3O6j0nWL7tKEXlVQT7uDL1kUFE+ns2ab9y5zHW7E26dtxZENc5mCmj++nHTq3R8MXGg2xMTKOovBpXe2tG9ezIc/f3RCKRmK5vbzLLdx6/7ryIJbJdc+fFSdbsTzE8L0b2ajgvZn9t/LzoG8n0Rwa0uT6A/NJKPvn5APvTsqitr8fXxYE5Twymo5+7adqOXmD54bMUVdYS7G7P1CFRRHo5Na0t8Rxrjl8kr7waB0tz4kK9mDKwI+ZyGQDHsgtZfugs6XmlXK2s5eMHezAo5NbPiT/8vj10muW/naKosoZgD0emjuhOpK9L0/r2p7Mm8Qx5pVU4WJsT19GPKUM6Y66QNbJdtieVRVtP8HjvUN4a3oY/LP8ncpxag7+k8wUwdOhQvvrqK4Myc3PzW27PxsYGGxubJr93cmr6QtJafe7evZvHHnuM3r17Y2FhwYcffsiQIUM4deoU3t7erdLnlmNnWPDTb7wzbiCR7TxYtfskkxPWsX7mUzjZWjWy33Q0g0U/72f2E3FEB3iRVVDCrJXbkEgkvDk2FoBVbz6K5ro3Wc5dLuKFz37ivk4dTNImj+6D2ciJ1K39AnX2Gcz6jcRy0rtUz38ZbVVZI/ua5R8ikTcc4hIrWyxf/zeq5AMNZWbmqC+mo0raj8XDL5mk50a2HEljwfc7eGf8UCIDvFi1/QiTF37H+rnP42Rn3ch+0+FTLFq7m9kThhMd6E1WfjGzvtqIBHhzXBwAc5b/yrlLV/nnsyNxdbBh46FTvPDv1ayd8xzujra3pbcpampqCQlqzwPDh/Da9H/ekT5uZMvRDBas3cM7j8UR6e/Jqp3HmLx4LetnP2P8uDuSzqJ1vzH7yXii23uRlV/CrBWbkSDhzYcGAPDV1iOs2XuSfzx1P4FezqRl5TNrxWZsLM15fGBn0/Qdv+G82HOSyQk/s37G+CbOi9Ms+uUAsx8fTHSAJ1kFpcxatV23b8f2A2DV/41Do234SZVzV4p44bP13NcpyCRtd0pfeXUtExb+QLcOPnz64kicbCzJKijDztLCNG1puSzYkcI7Q2OI9HJk1ZHzTF59gPV/uw8n68bX5E2ncli06xSzR3Qm2tuJrOJKZm04jkQCb8ZFAVBTryLYzZ4x0e14Y+1hk8fLQN8ffd8mZ7Jg01HeGd2DSF8XVu1PZ/LXO1j/+iicbCwb60u6yKKtx5k9tjfRfq5kFZYza+0B3TV5WFcD29TcQn44coZgD0eTdQluj79s2NHc3BwPDw+DzdFRd4BJJBL+85//MGLECKysrAgLC+PgwYOcO3eOAQMGYG1tTe/evTl//ry+vZuFAG8MO65YsYKuXbtia2uLh4cHjz/+OAUFBfrvd+/ejUQiYceOHXTt2hUrKyt69+7N6dOnm+xz1apVTJ48mZiYGEJDQ/nyyy/RaDTs2LHj9gfsd927jjO2V0fG9OxIoKczM8YNwsJMzrqDp4zaJ124Qkx7T4Z1DcXb2Y7eYe0Y2iWY1Kw8vY2TrRUudtb6be+pi/i62NM1yDSHURE7ivrD21Ad3Ym2IJe6H79AW1+HvPtg4xVqKtFWlOo3WYdoqK9DldTgfKmO76F++/eozyaZpMUYK7YlMrZfNGP6RBHo5cKM8UN1Y7c/2ah90vlcYoJ8GNajI94uDvTu2J6h3cNJzbwCQK2ynh3HM3jtoYF0CfbDz82JF0f1w9fVkTW7j9+23qbo16sbU55/mrj+fe5YHzeyYucxxvaJZEyvCN1x99h9WJgpWHcgxah90oXLxAR6M6xbGN7O9vQO92do11BSs64Y2AyICiI2sj3ezvbc1zmYXmH+pGbmGW2zWX27TjK2d0fG9Awn0NOJGY8M1O3bQ2nG9V38/bwIuXZe+DG0SwdSs/P1Nk62lobnRWrmLZ0Xd0rfV9uP4eFgwz+eiCOynYdunMP88HW1N01b4jnGxvgzJrodga52zLg/Bgu5jHVJmca15RYT4+PMsI6+eDtY07u9O0PDfUi9XKK36RvowcsDwm9rtkuv74++b/enMbZrB8Z0CSLQzYEZo3tioZCx7th5o/ZJWVeJ8XNjWHQA3o429O7gxdAof1JzCw3squvqmf79Pt4d0wtbSzOTdbU6mlba/iT8ZZ2vmzF37lyeeuopTp48SWhoKI8//jh/+9vfmDZtGkePHkWr1fLyyy/fcvv19fXMnTuXpKQk1q1bR2ZmJhMmTGhk984777BgwQKOHj2KXC7nmWeeaXEf1dXV1NfXt9qsW71KTXpOAT1C/PRlUqmEHiF+JDdxw4pu70laTgEp177PLSxjX1omfcP9m+xj05EMRvcMNy30I5Mj9Q40dJK0WtRnk5G1C2lRE/LucahO7oP6upb320LqVWrSs/LoERagL5NKJfQI8yf5/CWjdaIDfUjLyiPl4mUAcq+WsC/lPH0jAgFd2Eyt0RqEgQDMzeScOJfb6v9DW1GvUpOend/4uAv1I/niFaN1ott7kZadT8o1RzW3sJR9qRfp27G9gc3h09lk5RcDcDq3gBPnL9GnY4DRNpvVl1NAjxBfQ30hviRfbOK8CLh2XmRdf15k0Te8XZN9bDp6mtE9w0wOid4pfXtSLhLu586by35l4PQvGffh/1h7INU0bWoN6VdK6eHv2qBNIqFHgCvJl4qNa/NxIi2vlJTLuu9zS6rYdz6PvoFNhwFvlT/Fvr1cTI+ghv9dKpXQI8iT5OyrxvW1cyXtchEpOTpnK7e4gn1nLtE32NDxe/+XRPqFeNMzqOnQ/t1E5Hz9RdiwYUOjMOH06dOZPn06ABMnTuSRRx4BYOrUqfTq1YuZM2cSHx8PwKuvvsrEiRNvuf/rnaj27duzaNEiunXrRmVlpYGu9957j/79+wPw9ttvM3z4cGpra7GwuPnU/tSpU/Hy8iIuLu6WdV5PSVUNao0WZzvDqXZnWysy841fKId1DaW0spaJC9eAFlQaDQ/3jWRSvPE8tJ3J56moqWNUz3CTtEmsbZHIZGgrDcOL2spSpG43f5qU+nZA5tmOujWfmdRvSymprDY+dnbWZOYVGa0zrEdHSiurmfjhCgBUag0P9+/EpOG6/CprC3OiAr1ZsmE/AZ7OONtZszkxjeTzl/B1++uECUoqfz/uDEOzzR533cIoraxh4oLVDcddv2gmDe2ht3lmSHeqausY84+vkEmkqLUaXh7Zl+Hdw0zT9/t5YWvsvCgxWmdY1xBKq2qZuHBtg74+EUwaYjynZmfyBd150cM0bXdSX25ROWv2pTB+YAyT7utKanY+89fuRSGTtVhnSXUdaq0W5xvCi87WFmQWVRrX1tGX0molE7/ZC4BKo+XhTgFM6tOyhyxT+MPv2+o6nb4bwovONhZkXm2cagEwLDpAp++/W0Cr1Y1f92AmDYjU22xOvkjG5WJWvTjMZE2C1uEv63wNHDiQzz//3KDs+hmiqKgo/d/u7rrk0cjISIOy2tpaysvLsbOzM7n/Y8eOMXv2bJKSkigpKUGj0c2HZmdnEx7e4Hhcr8PTU/cEUlBQgJ+fH83xwQcfsHr1anbv3t2so1ZXV0ddneFMj0ZZj7lZ67wccORsLku3HmH6IwOJ9Pcg52op89fuYcnmwzx/3Y3wd9YdPEWfcH/c7JvOn7sTKLoPRn0ls8nk/LbgyOkslm46yPQn4okM8CKnoIT5321nyYZ9PD+iLwDvPTOS2cs3MuTvnyKTSgj182Bo93DSs0wPnf2VOHImh6VbDjP90cFE+nvqjrs1u1iy6SDPD+sFwNbjp9mUmM68icMJ9HTmdO5V/vXDLlwdbBjVs+Od1Xc2l6VbjzL94QFE+ruTc7WM+T/uZcnmRJ4f2vjBZN2hNPqEtbtr50VL9Gm0WsJ93ZgyUvcwEOrryvkrRfywP/WWHIkWa8u6ytIDp5l+LUcsp6SK+duSWbIvg+f7ht6xflus74++by/ksXRPKtNH6pLyc4oqmL/xCEt2WvL8oCjySquYv+EoXzwTZzQBv834E81atQZ/WefL2tqaoKCmkxuvfzPx96lgY2W/O02mUFVVRXx8PPHx8axatQpXV1eys7OJj49HqVTeVMfN+vzoo4/44IMP2L59u4HzZox58+YxZ84cg7Lp44cx48nhjWwdrS2RSSUUlVcblBdVVONiJGEcIGHDQYZ3D2Vsb91bhR28XKhRqpj7vx1MGtIdqbRhmv1ycTmHT+ewYFLjvm+GtqoCrVqNxMYw30Ri44C2orT5ygpz5NF9UW5dbXK/LcXRxsr42JVX4WJn/KKbsG4vw3tGMLZfDAAdfNyoUdYzd8WvTBrWB6lUgq+bI0v/Pp6aOiWVNUpcHWx46z/r8HZ1uGP/y93G0eb3467KoLzZ4+6X/QzvHs7YPrrjv4O3KzV19cz9dhuThvZEKpXw7x/3MDG+O0O7huptrhSXs2zLYZOcL/15UWHkvDCSkA2QsPEQw7uFMLa3rh/deVHP3NW7mDSkm/Hz4tlbm4W4U/pc7awJ9DBMaQhwd2J7kvFcI6ParMyRSSQUVRk+ABZV1eJiJNkeIGFPOsMjfBkb46/T5mZPTb2KuZtOMqlPCNJbeFO1SX1/9H1rZa7TV1ljqK+yFhcjyfYACduTGB7TnrHddC80dfBw1I3fukNMGhBJ2uUiiqtqeeyzjfo6ao2W45n5fHfoNIlzHkcmbYOMpD9RvlZrcM/mfN1JMjIyKCoq4oMPPqBfv36EhoYaJNvfDvPnz2fu3Lls3ryZrl273tR+2rRplJWVGWx/HzfEqK1CLiPM143EMzn6Mo1GS+KZHKKaWGqitl7V6GL4+2cthk8y6w+l4WRrST8Tc24AUKvQXDqPLOg6Z1MiQRYUiTrrdNP1AHl0b5ArqD++x/R+W4hCLiOsnQeJ6Zn6Mo1GS2J6FlGBxsOitcqWj52luRmuDjaUV9Vw4NQFBsSY9qboHxmFXEaYnzuJp7P1ZRqNlsTT2UQFGM9HqVXWNx47qeHYNXVsmvqA3XBeNOTZ6fTlEBXQxHlhbN9eu6E1Pi/Sr50X/qYJu8P6ott7kllgGHrLulqKpwlv2SpkUsI8HUjMbMhP0mi1JGZeJcrbeK5qrUrd9HnRypMjf4p96+VE4vmGmW6NRkvi+Tyi/FyN1rnZNblHoCc/TBnBdy8P12/h3s4Miw7gu5eHt43jdQ/yl535qqurIy/PMDQjl8txcWl6bZTWws/PDzMzMxYvXswLL7xAamoqc+fOve12P/zwQ959912+/fZb/P399f9fc8tgmJubN1pio6aZkOOTAzszc+VWwv3ciGjnwardJ6ipq2f0tRytGd9swc3BhimjdG/CxUYEsHLXCUJ9XIls50F2YSkJGw8SGxFgcBJrNFp+PpTGyO5hyGW3dnLX7/0Z83FT0OSeR51zFrN+I5CYWaA6onvb0/zRKWjLilH+utKgnqJbHKpTh6G68bo7WNogdXRBYqe7EUhddY7S729ImsKT93Vn5rINhPt7EHFtqYkaZT2jr83OzFj6C26OtkwZOwCA2OggVm5LJNTPncgAL7KvlpCwfi+xUR30Y3cg9QJatPi7O5N9tYR/r9lJgIczo3s3P+N5O1RX15Cde1n/+dLlfDLOnMfezhZPD7c70ueTg7ow85vNhLfz0B13u47rjrteuhnVGV//qjvuxuhe5Y+NDGTlzmOE+roR6e+pG7sNB4iNbK8fu9jIQL7cfBgPRzsCvZw5nVPAyp3H9G2apG9gDDNXbifc142Idu6s2n2SGqWK0T2unRcrtuJmb8OUUboQncF54e9O9tUyEjYeIjbCv/F5cTidkd1Db/m8uFP6xg+IYcK/f+DLrUcY0qkDqVn5rD2Qysxxg0zT1j2Imb8cI9zTgQgvR1YlnqemXs3oKF2C+oyfj+Jma8mUgbqZpNggD1YmniPU3YFIb0eyS6pI2JtObAcPZNcc7GqliuyShpyxS2XVZOSXYm9hhqe98Rmruzl20Ir7tk84M9fuJ9zbmQgfF1YdSNfp66J7MWfGmv242VkyJV63fEpsqA8r96cT6uVIpI8L2cUVJGxPIjbUB5lUirW5lCB3w5xRSzM59lbmjcrvJn+mZPnW4C/rfG3evFmfQ/U7ISEhZGRk3PG+XV1d+frrr5k+fTqLFi2ic+fOfPTRR4waNeq22v38889RKpU89NBDBuWzZs1i9uzZt9X278R3CaaksobPNx6isKKaEG8XEiaP0SdDXympMHhj57n47kiAzzYcpKCsEkcbS2Ij2vPyCMNFOQ+dzuZKSQVjet16ro0qaT8SazvM4h9FYuuI5vJFar78hz4JX+rgarCeGIDE1QtZ+3CUS2YbbVPesRsW46boP1uMfxMA5dbVKLd9Z5K++G7hlFRU8/n63ygsryLE142EVx9pGLvicsOxG95HN3br9lBQWomjrRWxUUG8/EB/vU1FTR2Lf9pNfkkF9tYWDO4cwstj+qOQ37lcjdSMszzzylT95/mLlwAw+v443pvxf3ekz/iuobrjbsN+CsurCfFxJeHlB6877sqRXBfO0S2UCp/9sl83djaWxEa25+VRffU2bz8yiM9+2c+877ZTXFGDq701D/aN4m/XcsJM0tf52nmx6bBu3/q4kvDiKP0LFldKKm84L7rp9G081HBedAzg5RGGfR86naM7L0x8AeVu6Ito587Hk4ax6JeDLNl8BG9nO/4+th/Du5mW+B4f7kNJdR2f702nsKqOEHd7Esb1xtlGl6t6pbzGUFvfEJ22vWkUVNTgaGVObJBuaYnfOXWlhOdW7dN/XrBdtyTJyEg/5o7sYpq+P/q+jfKnpKqWz3ckUVhRQ4inIwkTBumT8K+UVXH9RNdzAyJ115VtSRSUV+NobU5sqA8v39fptnTcce6xsKNEq23tiVzBH52arQltLaFZ1Nu2tbWEZpGNHN3WEppEHh7b1hKaRZW0va0lNI9KeXMbgXHy/uDLn3j4tLWCpjFxlv1uY/nQjDveR/F1D523g9NPdy69pDURwV2BQCAQCASCu8hfNuwoEAgEAoHgT8I9FnYUzpdAIBAIBII2RXuPOV8i7CgQCAQCgUBwFxEzXwKBQCAQCNqWe2zmSzhfAoFAIBAI2hQRdhQIBAKBQCAQ3DHEzJdAIBAIBIK25R6b+RLOl0AgEAgEgjZFhB0FAoFAIBAI7hE+++wz/P39sbCwoEePHiQmJjZrX1payksvvYSnpyfm5uYEBwezadMmk/oUM18CgUAgEAjalLaa+fruu+944403+OKLL+jRowcLFy4kPj6e06dP4+bm1sheqVRy33334ebmxg8//IC3tzdZWVk4ODiY1K9wvgQCgUAgELQpbeV8ffzxxzz33HNMnDgRgC+++IKNGzeybNky3n777Ub2y5Yto7i4mAMHDqBQKADw9/c3uV8RdhQIBAKBQNC2aCWtstXV1VFeXm6w1dXVGe1SqVRy7Ngx4uLi9GVSqZS4uDgOHjxotM7PP/9Mr169eOmll3B3dyciIoL3338ftVpt0r8rZr7uReqVba2gWbQVNW0toXnKi9taQZOokra3tYRmkUfH3dyoDVHtXNnWEprGw6+tFTSLtqSkrSU0T0FBWytoEomXd1tL+Mswb9485syZY1A2a9YsZs+e3ci2sLAQtVqNu7u7Qbm7uzsZGRlG279w4QI7d+7kiSeeYNOmTZw7d47JkydTX1/PrFmzWqxTOF8CgUAgEAjalNYKO06bNo033njDoMzc3Lx1Ggc0Gg1ubm4sWbIEmUxGly5duHTpEv/617+E8yUQCAQCgeDPg1YjaZV2zM3NW+xsubi4IJPJyM/PNyjPz8/Hw8PDaB1PT08UCgUymUxfFhYWRl5eHkqlEjMzsxb1LXK+BAKBQCAQ3HOYmZnRpUsXduzYoS/TaDTs2LGDXr16Ga3Tp08fzp07h0bTMFV35swZPD09W+x4gXC+BAKBQCAQtDFaTetspvLGG2/w3//+l+XLl5Oens6LL75IVVWV/u3Hp556imnTpuntX3zxRYqLi3n11Vc5c+YMGzdu5P333+ell14yqV8RdhQIBAKBQNCmaLWtE3Y0lXHjxnH16lXeffdd8vLyiImJYfPmzfok/OzsbKTShnkqX19ftmzZwuuvv05UVBTe3t68+uqrTJ061aR+hfMlEAgEAoHgnuXll1/m5ZdfNvrd7t27G5X16tWLQ4cO3VafwvkSCAQCgUDQptxrv+0onC+BQCAQCARtSmu97fhnQSTcCwQCgUAgENxFxMyXQCAQCASCNkWrbWsFdxfhfAkEAoFAIGhTRNjxT46/vz8LFy5sk76//vprHBwcWq29zMxMJBIJJ0+ebLU2BQKBQCD4o6HVSFpl+7Nwx2e+8vLymDdvHhs3biQ3Nxd7e3uCgoIYP348Tz/9NFZWVndawi2ze/duBg4ciIODA1euXMHCwkL/3ZEjR+jevTsA2mvzpePGjWPYsGGt1r+vry9XrlzBxcWl1dq8Gav3pbJ810mKKqoJ9nJm6gN9iWzn3qT9yj1JrDlwirySShxsLIiLCmTK8B6YKxoOrfzSSj7ZcIj9GdnUKlX4utgz57GBdPR1M1mfov9IzIY8hMTOEU3uBWq/S0CTeabpCpbWmI+egLxTHyRWNmiLC6hd8x/UqUd030ukmI0Yj6LHICR2jmjLiqg/uB3lpm9N1gbXxm93EkUVNdfGrw+Rfk3/nyv3JrPmQJpu/KwtiItuz5Rh3Q3Hr6zq2vjlNIzfowPo6Otqur49J1i+7ShF5VUE+7gy9ZFBRPp7Nq1v5zHW7E0ir6RCp69zMFNG99PrU2s0fLHxIBsT0ygqr8bV3ppRPTvy3P09kUjuzIXw6MkUvvr2B9IyznG1qJhP5s1kcGzvO9LX9aw+fJrl+9Ipqqwh2MORqcO7EunT9Lm58kAGaxLPkFdWjYOVOXEd/ZhyXwzmCt3PknyfeIY1iWe5XFoJQKCbA88PiKBv8K39yPLqXcdYvuUwRWWVBPu6MfWxIUQGeDWtb3sia3afIK+4HAcbS+K6hDJl7AD9vq2qreOzdXvZdeIMxRXVhPi589a4OCKaabMp5FEDkHe9D4mVPZrCXOp3rUaTn2nU1vyhN5D5hDQqV19MoW79pwBYvfYfo3WVv61FdWyr6fo6DULebSgSa3s0BTnU71iFJu+icX3j3kLmF9pY3/kk6n78RP9Z4uSJov9DyHxDQCJDU3QZ5frP0FYUm6xv9ZGzLD9wmqLKWoLdHZh6fycivZ2btF956Axrjp2/duyZERfmw5TBUZjLdcfe0n3p7MjIJbOwAnO5jGhfZ14bHIW/i53J2gS3xh11vi5cuECfPn1wcHDg/fffJzIyEnNzc1JSUliyZAne3t6MGjXK5HbVajUSicRg4bM7ia2tLT/99BOPPfaYvmzp0qX4+fmRnZ2tL7O0tMTS0rLV+pXJZE3+vtSdYMuJcyxYv593Hu5PpJ8bq/YmM3nJBta//RhOto2d5E3HzrBo42FmjxtAdIAHWVfLmPW/nUgk8OboPgCUV9cxYfE6ugV58elzw3GysSSrsAw7S9N/6FTeJRbzh56j9tvFaDJPoxg0BqtX3qNq9iS0FWWNK8jkWL06D21FKbVL/ommtAipkxva6kq9iVn8wyj6D6f26wVormQha9cBi6feQFtTRf2u9Sbp23LiHAt+Psg7D/Uj0s+dVb8lM3nJRtZPfRQn28bHxabjZ1m0MZHZ4/oT7e9B1tVSZq3ejQR4c7TOmTAcv2E4WVtcG7+W/4yFXt/RDBas3cM7j8UR6e/Jqp3HmLx4LetnP2N8/x5JZ9G635j9ZDzR7b3Iyi9h1orNSJDw5kMDAPhq6xHW7D3JP566n0AvZ9Ky8pm1YjM2luY8PrCzyRpbQk1NLSFB7Xlg+BBem/7PO9LHjWxJyWTBr8d5Z1R3In1cWHUwg8nLd7H+1ZE42Vg0st+UdJFF204we0xPov1cySqqYNaPB3Xnxv1dAHC3s2LKkBj8nG1BCz+fuMBr3+5l9Yv3E+TuYJq+I2ks+H4H74wfSmSAF6u2H2Hywu9YP/d5nOysG+s7fIpFa3cze8JwogO9ycovZtZXG3XH3rg4AOYs/5Vzl67yz2dH4upgw8ZDp3jh36tZO+c53B1tW6xNFtwVRexDKHd+iybvIopOgzF/YAo1y2dBTUUj+7pfvgBZw61JYmGNxfiZqM4e05dVL/m7YR/+EZjd9yTqs8dbrEtfN6QbigHjUG5bgebKBRRd7sP84TeoWTodqo3oW/8ZXPe7fhILGywmzEF1+mhDmYMrFo9PQ5XyG7X714OyBqmzN1p1vcn6tpzKZsHWJN4Z3oVIbydWHT7L5FV7Wf/S/ThZGzn2UrJYtCOZ2aO6Ee3rojv21ifqztv4GACOZV1lXNcgOno5odZoWbwzhRdX7eXHF4diadY22Uj3Ws7XHfVeJk+ejFwu5+jRozzyyCOEhYXRvn17Ro8ezcaNGxk5ciQAH3/8MZGRkVhbW+Pr68vkyZOprGy4Qf4ezvv5558JDw/H3Nyc7OxsCgoKGDlyJJaWlgQEBLBq1apGGm7Wdkt4+umnWbZsmf5zTU0Nq1ev5umnnzawuzHsOHv2bGJiYlixYgX+/v7Y29vz6KOPUlHRcEJrNBrmz59PUFAQ5ubm+Pn58d577wHGw4579uyhe/fumJub4+npydtvv41KpTLp/2mKFXuSGNsznDHdQwn0cGLGQ/2xUChYl5hh1D4pM5+YAA+GdQnG28mO3iG+DO3UgdTsAr3NVztP4OFgzT8eG0RkO3e8nXV2vi72JuszixtL/f7NqA5uQ3Mlm7pvF6Otr0PRO96ovaL3ECTWNtR8Pgf1+TS0Rfmoz6agudTwRCtrH44q6RDq1ES0Rfmoju9DlXYcmX/jJ++bsWJvCmN7hl0bP0dmPBiLhULe/Pj5uzOscwe8nWyvjV8QqdlX9TZf7TyJh4MN/3h0IJF+brc1fit2HmNsn0jG9Iog0NOZGY/dh4WZgnUHUozru3CZmEBvhnULw9vZnt7h/gztGkpq1hUDmwFRQcRGtsfb2Z77OgfTK8yf1Mw8k/W1lH69ujHl+aeJ69/njvVxIysOZDC2axBjOgcS6GbPjJHdsVDIWHf8vFH7pJxCYvxcGRYdgLejDb2DPBka2Y7U3CK9Tf9QH/oFe9PO2Y52Lna8cl8MVmZyUnILTde3LZGx/aIZ0yeKQC8XZowfioWZnHX7k43rO59LTJAPw3p0xNvFgd4d2zO0ezipmbp9W6usZ8fxDF57aCBdgv3wc3PixVH98HV1ZM1u0xwceec4VKn7UKcdQFt8BeWOVWhVSuQdm5itrKuG6nL9JmsXDvVK1GcanK/rv6e6HFlgNJqcM2jLTR87edd4VMl7UafuQ1t0GeXWb9DWK5FH9DNeobYKqsr1m8y/4zV9R/Qmir5jUV9Ipn7PGrQF2WhLr6I+f9KoM3czVhw8w9jO7RkTE0Cgqz0zhnfRXVdOGJ+ZS8otIsbXhWGR7fB2sKZ3oAdDI/xIvdww45bwRCyjYwIIcrMnxMOBf4zuxpWyatKulJisr7W418KOd8z5KioqYuvWrbz00ktYWzd+8gL0YQmpVMqiRYs4deoUy5cvZ+fOnbz11lsGttXV1Xz44Yd8+eWXnDp1Cjc3NyZMmEBOTg67du3ihx9+ICEhgYKCAoN6LWn7Zjz55JP89ttv+lmutWvX4u/vT+fON3+yP3/+POvWrWPDhg1s2LCBPXv28MEHH+i/nzZtGh988AEzZ84kLS2Nb7/9Vv+zBjdy6dIlhg0bRrdu3UhKSuLzzz9n6dKl/POft//0X69Sk557lR7BPvoyqVRCj2BvkjPzjdaJ9ncnLecqKVm673OLytmXnkXfMD+9zZ5TmYT7uvHm8i0MfPcrxi1Yw9qDaaYLlMmR+nVAnX6ioUyrRZ1+Amn7MKNV5NE9UV/IwPyxl7Ce/z+sZn6B2dBxIGk47NUX0pCHxiBx04V6pN4ByII6ojp1xGibTaEfvw4NISPd+PmQnNXM+OUWknLNWdWNXzZ9w3z1NnvSMgn3deXN5dsYOGs54xb8wNpD6SZp0+vLzqdHSMO+kUol9Aj1I/niFaN1ott7kZadT8q1G3JuYSn7Ui/St2N7A5vDp7PJytdd2E/nFnDi/CX6dAwwWeMflXqVmvTLxfRo3zALLZVK6BHoQXKO8Zt9tK8LaZeL9Y5UbnEF+85cpm+w8ZCdWqNhc3ImNUoVUSaGk+tVatKz8ugR1jDmUqmEHmH+JJ+/ZFxfoA9pWXmkXLys03e1hH0p5+kbEajXo9ZoDcLfAOZmck6cy225OKkMqZsfmpzrj1ktmuwMpJ7tm6x2PfKOfVCfOQoqpXEDK1tk/pGoTu1rua7r9Xm0Q5N1/TVJiyYrDalXYMv0RfZDnZEI9b/rk+icwZJ8zB96A8vJCzF/YgayoE4my6tXq0m/UkKPgIZ7glQioUeAG8nXOfLXE+3jTNqVElIu6b7PLalk37kr9A1qOopSWaebkbO/hRl1wa1xx+YXz507h1arJSTEcAbBxcWF2tpaAF566SU+/PBDXnvtNf33/v7+/POf/+SFF14gISFBX15fX09CQgLR0dGA7lfEf/31VxITE+nWrRugCwWGhRneiFvS9s1wc3Pj/vvv5+uvv+bdd99l2bJlPPPMMy2qq9Fo+Prrr7G11U3TP/nkk+zYsYP33nuPiooKPvnkEz799FP9LFpgYCB9+/Y12lZCQgK+vr58+umnSCQSQkNDuXz5MlOnTuXdd981Goatq6ujrq7OUFO9qtFFtaSqFrVGi/MN4TFnWysyC0qN6hnWJZjSqlomfroOtKDSaHi4dziT4rrobXKLyllz4BTj+0cxaXBnUnOuMv+nfSjkUkZ1a5w30RQSGzskMhmackMt2opSZB6+xuu4eCILcac+cRc1n85E6uqFxWMvg0yOcqNullS55XuwsMJ69n91SyxLpCjXL0eVuKvF2qCZ8bOxbHr8One4Nn7rG8avVziT4hqc+tyiCtYcSGN8/0gmDe5Eak4B83/aj0ImZVS3ls/OlVTW6PTdEIJytrUiM994DsqwbmGUVtYwccHqBn39opk0tIfe5pkh3amqrWPMP75CJpGi1mp4eWRfhnc37hD/GSmprtON3Q3hRWcbCzILy43WGRYdQGl1HRO/3AZaLSqNloe7dWBS/wgDu7N5JTz1360oVWoszeR8/HgsgW6mzWqWVFZf27eGoWNnO2sy84zfoIf16EhpZTUTP1wBgEqt4eH+nZg0XDcbZW1hTlSgN0s27CfA0xlnO2s2J6aRfP4Svm6OLdYmsbRBIpWhvWHGR1tdjtTp5ikVUnd/pC7eKLd906SNPKwX1NeiPneiSZum9dle02e4H3X6ms6F1OvzCEDq6oNy81cNhda2SMwsUHQfRv2+H1HuXYPMPxKzMS9Rt3o+mtxmclRvoKRaiVqrxdnaME3D2dqCzELjs2jDItvpjr2vdgHXjr0ugUzqF27UXqPV8q8tJ4nxdSHIxGOvNWmr33ZsK+56cDcxMRGNRsMTTzyhdwq2b9/OvHnzyMjIoLy8HJVKRW1tLdXV1fqEfDMzM6KiovTtpKenI5fL6dKl4UYfGhra6G3DlrTdEp555hleffVVxo8fz8GDB1mzZg2//fbbTev5+/vrHS8AT09P/exceno6dXV1DB48uEUa0tPT6dWrl0Eic58+faisrCQ3Nxc/P79GdebNm8ecOXMMyqY/Fs+MJ4a2qM/mOHLuEkt3HGf6g7ocp5zCMuav28+SrUd5fkhXQHdih/u6MmV4TwBCfVw5f6WYHw6kmeR83QoSiQRtRSl1Kz8BrQZN9jnqHFwwG/KQ3vmSd4lF0X0Qtcs+RHM5C6lvIBYP/w1NWRGqQ9vvqL4j5y6zdMcJpo/tS2Q7N3IKy5m/7gBLth3j+ft0x7VGqyXcx5Upw3QOT6iPC+fzSvjhYJpJztct6TuTw9Ith5n+6GAi/T3JuVrK/DW7WLLpIM8P6wXA1uOn2ZSYzryJwwn0dOZ07lX+9cMuXB1sGNWz4x3V90fmyMV8lu49xfQR3Yj0cSanuJL5m46yZFcKzw+M1Nv5u9jx3eRhVNYq2X4qm3fXHuTLZ+8z2QEzWd/pLJZuOsj0J+KJDPAip6CE+d9tZ8mGfTw/Qvfw994zI5m9fCND/v4pMqmEUD8PhnYPJz3rzoWUb0QW0QfN1dwmk/NBNzOmykgEdeukX5iCLKofmqs5Bsn5kmsBJfW5E6iObQNAVZCD1DsQecxAlCY4X7fCkcwClu7LYPqwzkR6O5FTUsn8zSdZsvcUz8c2PifnbTrOuYIyvp446I7quhn32s8L3bGwY1BQEBKJhNOnTxuUt2/fnqCgIH1iemZmJiNGjCAqKoq1a9dy7NgxPvvsMwCUyoZpZktLS5Pfnmpp2y3h/vvvp6amhmeffZaRI0fi7Nz0mybXo1AoDD5LJBI0Gt1R1prJ+U0xbdo0ysrKDLa/PxLXyM7R2gKZVEJRRY1BeVFFNS5GkrEBEn5NZHiXYMb2DKeDlzODotrzyrAeLNtxAo1Glz3pamdFoLvhk3KAuwNXSkzLu9NWlqNVq5HaORiUS2wd0JQbz1PQlBWjyb9kcFZr8rKR2jvpE3rNx05CueV7VEf3oLmcierwDpQ7ftKFJ02gyfGrrMHFSLI9QMLmIwzv0oGxPcPo4OnMoMgAXhnWjWU7Trb6+DnaWOr0lVcZ6quoxsVIQjZAwi/7Gd49nLF9oujg7cqgmA68Mqovy7Yk6vX9+8c9TIzvztCuoXTwdmVEj3DGD+rCsi2HTdL3R8bRylw3dpW1BuVFlbW42DSxb3ckMTw6gLFdg+jg4cigcF9eiYth2W+n9GMHoJDL8HO2JdzbmSlDOhHs4ci3B43nCDapz8bq2r6tNtRXXoWLnY1xfev2MrxnBGP7xdDBx41BnUN45YH+LPv1oF6fr5sjS/8+noOf/h+bP3yZVe9MQKXW4O3q0GJt2ppKtBo1EivDBH2JlR3aKiMvyVyP3Ax5cDdUp/Y3aSL1CkLq5IEq9RZCjoC2puKaPsO3/FqkT2GGPLQ7qmTDh3BtTQVatQpN0WXD8qIrSOycTNLnaGWGTCKhqMowelFUVYuLkRc9ABJ2pTI8qh1jO7eng7sDg0J9eGVQJMv2ZaC5Iat93q/H2Xv2Ml8+NQB3u5ZPRghunzvmfDk7O3Pffffx6aefUlVV1aTdsWPH0Gg0LFiwgJ49exIcHMzly5ebtP+d0NBQVCoVx441JGGePn2a0tLS227bGHK5nKeeeordu3e3OOR4Mzp06IClpSU7duxokX1YWBgHDx7UL20BsH//fmxtbfHx8TFax9zcHDs7O4PtxpAj6G4CYT6uJJ5tyOfQaLQknr1ElL/xHLTaehXSGxxiqVT3WYtOY7S/R6OwW9bVMjydjN8UmkStQpN9FlloTEOZRIIsNAbNBeM5UOrzaUjdvOA6jVJ3bzSlRfqnZImZeeNHLo3GZEe/Yfwacmz049fEUh1Gx+9aPprB+F0tNbDJulqGpwlvm+n1+bmTeLrh7VyNRkvi6WyiAoyHV2qV9Tfdv8b/Bwkaw2v8nxqFXEaYlxOJFxpmfDQaLYkX8ojyNb7URG29+qZjZwyNVotSbdoUgEIuI6ydB4npmYb60rOICjS+bEWt0vh+M6bP0twMVwcbyqtqOHDqAgNiOrRcnEaNpiAbqe/1YWgJUt9QNFcuNFtVFtwFZHJUGU078vKIPqjzs9AWmpCHdqO+vCyk7W7Q1y4MzWXjL1M06OsGMgWqtING2sxsFFaVOHmgLTMeBm4KhUxGmKcjiRcb8kY1Wi2JFwuI8jE+AVCrUiO94fKlP/au3Tu0Wi3zfj3OzoxLLHlyAN6OJl6P7wAaraRVtj8Ld/Rtx4SEBFQqFV27duW7774jPT2d06dPs3LlSjIyMpDJZAQFBVFfX8/ixYu5cOECK1as4Isvvrhp2yEhIQwdOpS//e1vHD58mGPHjjFp0iSD2aRbbbsp5s6dy9WrV4mPN/52nalYWFgwdepU3nrrLb755hvOnz/PoUOHWLp0qVH7yZMnk5OTwyuvvEJGRgbr169n1qxZvPHGG62y7MaT/aP58VA6Px/J4EJ+Ce/9sJcaZT2ju+vCgzO+3cGiDYf09rHh/qw5cIrNJ85yqaicg6dzSPg1kdiO7ZBd0zO+fzQpWQV8uf0Y2VfL2HTsDGsPpTGuT4RRDc2h3P4jir73I+8Zh9TDF/PHXkFiZkH9Ad26PhYT3sRszES9ff3eDUisbDB/5AUkbt7IIrpjNvRR6vf8ordRpRzG7P5HkUV0R+LsjjymN4q4B6g/ecD08YuN5MfDGfx85LRu/Nb+dm38Qq6N304WbWy4kcSGt2PNgTQ2nzh3bfxySdh8hNhwv4bxi428Nn7HyS4sY9Pxs6w9lM64PqaH9J4c1IUf96fw86FTXLhSxHurt1NTV8/oXrp9MePrX1m0ruEpPjYykDW/JbH5aAaXCss4mJ5JwoYDxEa21+uLjQzky82H2ZtygUtFZew8eZaVO48xKDrIZH0tpbq6howz58k4o7s5XrqcT8aZ81zJK7hJzVvnyd6h/HjsHD+fuMCFgjLe+yWRGqWa0Z11SeMzfjjAoq0NOUexId6sOXKGzcmZXCqp5OC5KyTsSCI2xFs/dou2nuBYZj6XSio5m1fCoq0nOJqZz7Aof9P13dedH387yc8HkrlwpZD3Vm3WHXt9/p+9+w6PomobOPzb3fTeeyUhIT30HimBUAQiIrwWFARREVGxIE3AhqL4ojRfFKWLghh67z30GkINEEgI6T3Z9v2xsGHJJmQhEPk4N9deF5k9M/Ps7MzsmXOeOaNJ1Rg7ZxU/Ld9eEV9UIEt3HGF94hmu38pl35nLzFyxk5jI+tr49p66xJ5TF7XvD/5+Mf5ujvRqFakvhCopjmzGKLwNspAWSOzdMO74EhJjExRnNMeYSecBGLeOrzSfUVhrzR2CpVVcvJuYIavfGOUDtnpp4zu0AaPIZ5CFtdKMzdW5PxJjU21rmkm3wRi3fb5yfJFtNUNb6IlPcXA9sgbNkEXGILFzwahhB2QBUSiOGZZLCtC/ZRDLj1xi5fEULt3K56s1hymRK+gVrbnBYmzCAX7aUnFXa0x9d5Yeusj6U1c1+97FdGZuO0VMkIf2u/163RHWnLjCpOeaY2lqRGZhCZmFJZTKH3/X7R1qtaRWXk+KR5rzFRAQwNGjR/n6668ZNWoUqampmJqaEhoaykcffcTQoUOxsLDghx9+4Ntvv2XUqFHExMQwadIkXn311fsu//fff2fw4ME888wzuLq68uWXXzJu3Djt+1FRUQ+8bH1MTExqfcDTcePGYWRkxGeffcaNGzdwd3fnrbfe0lvW09OTtWvX8vHHHxMVFYWDgwODBg1i7NixtRJLXMNAcgpLmLX+IJn5xQR7OjFzyLM43u52TMsp1GkReqNTYyQSmLE2kYy8IuytzIkJ82VYt4qE7HAfF34YGMdPaw4we+NhPB2s+bhXa7o3DjI4PsXhnZRZ22Lao792kNXiaWNRF+QCIHFwQXpXq6A6J5Pin8Zi9sIQLMfNQp2biXxrAuUblmrLlC6ZiWnPVzF78R0k1naaQVZ3rdPmhBkirmEgOUWlzNpwqGL7vdGtYvvl3rP9YhshAWasO1ix/UJ9GNatmbaMZvt15qc1iczedOT29mtF98YGtD7cia9JA833u3qPJj4vZ2YOe16bhJ+Wk4/krktmzUCpMGPVHjJyCzXxRdRjWM+KG0I+7duBGav2MOnPzWQXlOBsa8nzbSJ583ZO2KNw6ux5Xn93pPbvydNmA9Crayxfjf3wkawzLsKPnKIyZm05TmZhKcHu9sx8tT2Ot7sd0/KKdLfdM+Ga73bLcTLyS7C3NCUm2JNhsdHaMtlFZYz9ex+ZBSVYmRkT5GrPzFc70DLw/oneleJrGkpOQTGzVuwiM7+IYG8XZr7Xt+K7zc7X3fe6t9bEl7BD891aWxATGciw557RlikoKWPaP9u5mVOAraUZHRsFMyz+GYyNZPeuvlrKc4eQm1th3LInEgsbVJmplCX8pB12QdMVp9vaJrF3ReZZn9LlU6tcriyoKSBBkZxoUDyV4ks+iNzCGuPW8dpBVsuW/VczjAUgsXao1DousXdD5hVE6V/f61/m+SOUb5yPcYvuSDq8hDonnfIVM1BdP29wfHFhPpp9b/spzb7nasfMl2K0N4Ck5RXrfrcxoUgkEmZsO0VGQQn2FqbEBLkzrENFruHSQ5oLl8Hzt+usa2LPptpKnfBoSdTqp21oM6FkzdS6DqFailXr6zqEahk927muQ6iaed13H1THKKpyvuG/iWLrwroOoWpulW+o+TdRH9l3/0J1SW74AKePi8TjwZ5q8LiYv/zFI1/H2aDaeTpMg3Nra2U5j5p4sLYgCIIgCHXqaWsG+n/3YG1DdO3aFSsrK72vr7/+uq7DEwRBEISnwtM2wv1T3fL166+/UlJSovc9BwfDbgkWBEEQBEGoiae68uXp+e/uZxcEQRCEp8GTNExEbXiqK1+CIAiCINS9J2mYiNrwVOd8CYIgCIIgPG6i5UsQBEEQhDr1tN3tKCpfgiAIgiDUqact50t0OwqCIAiCIDxGouVLEARBEIQ69bQl3IvKlyAIgiAIdeppy/kS3Y6CIAiCIAiPkWj5EgRBEAShTj1tCfei8vUUkvqG1XUI1ZJFX67rEKqlOnm8rkOokrRR07oOoVqKrQvrOoRqGXV4pa5DqJIyeV9dh1Ataae+dR1CtVQZ/97ziqx+87oOoc6JnC9BEARBEITH6Glr+RI5X4IgCIIgCI+RaPkSBEEQBKFOPWU3O4rKlyAIgiAIdUt0OwqCIAiCIAiPjGj5EgRBEAShTom7HQVBEARBEB4jVV0H8JiJbkdBEARBEITHSLR8CYIgCIJQp9SIbkdBEARBEITHRvWUjTUhuh0FQRAEQRAeoyey8uXn58fUqVPrOowqpaSkIJFIOHbsWF2HIgiCIAj/eioktfJ6Ujx0t+OAAQPIzc0lISGhFsL599u7dy9ffvkl+/bto6SkhPr16zNw4EDee+89ZDJZXYdXK5as28HcFVvIzM0nyM+TUYNeIKK+n96ycoWSOcs3snL7ATKyc/HzcOX9/r1o0zBUW+bP9bv4a8MubtzKBiDA2403X+hK20aGP+D7z2NXmHf4MllF5QQ5WzOyfQjhbnZ6yw5eeoDDqTmVprfxd2ZafGMAsorK+HF3MvuuZFFYJqeRpwOftA/B197S4NgAjBp1xLh5VyRWtqgyrlG+cSGqtEt6y5q99Cky35BK0xUXjlG29L8AmHQfjHFkW933L52g7M8pDxTfkp0nmLf1CFn5xQR5OjGyTwwRvm5Vll+47RhL95wkPacAO0tzYqMDGd6jJabGmlNH1wlzScsuqDRf3zYRjO7bzrDYDiQzb3cSWYUlBLnZM7J7EyK8nKqObe9ZliaeIz2vGDsLU2LDfBjeKRpTY81x+FfiOZYmnudGbiEAAS52DGkXTpsgT4PiMtShYyf5ffEyzpy9wK2sbH6cNI6OMa0e6Tr1WbLlIPPW7yUzr5Agb1c+fbkrEfX0f3a5QsmctbtZtecEGTn5+Lk58f4LHWkdEVg7sazbwdyETbfPKV6MGtz3PueUDazctv+uc0o8bao4X8xZvoEfF67g5e7tGTnohQeLb/sR5m08SFZ+EUFeLozs15EIf/cqyy/ccoilO4+Rnl2AnZU5sQ2DGP5cjPa4UKpU/Lx6L2sOnCErvwhnW0t6tgznjW4tkUgMryD8kbCOuX+tJDM7l+AAX0a9O4iIBvX1lpUrFPy6+B9WbtxORmY2ft4efPDGK7Rp1lBbRqlUMnP+X6zZvIvM7FycHe3pFdeON1/p80Dx1QaR8/X/lFwux9jY+KGW8c8//9C3b18GDhzItm3bsLOzY/PmzXzyySfs27ePv/76q8523Nqyfs9hvpv7D+Pe7EdEfT8Wrt7GW1/MYOW0z3C0ta5Ufvofq1iz8yDj33oJf09X9hxL4oPJvzD/qxGE1PMGwNXRjvdf6YWPuzNq1KzcdoD3vp3NX999SqBP1Se4e21ITmPKzrOM6RhGuJsdi4+kMHT5IRIGtMXBwrRS+Sk9GiJXViQS5JWU02/hXjrVdwVArVbzwaojGEmlTO3ZCEsTGQuPpPDW3wdZ/lobzI0NOzxkIc0w6fgi5evnobxxEeOmcZj1+4ji2SOhuHIFpXT5NCSyu9ZhboX5oC9Qnj2oU05x8QTla37V/q1Wyg2K644NR84x5Z9djOnXnghfNxbtOMbQmStZMfYVHKwtKpVfeyiZn1btZcJLHYnyd+dKRi7jF21GAnzUW1MhXPRhP1TqipvEL6Rl8daMFXRqaNiP9oaTKUxZd4QxPZsR4eXEon1nGTpvGyve64GDlVnl2I5f5qdNR5kQ34IoH2euZBUwfvk+JBL4qKumYu1qY8HwztH4OFqDGlYevcT7i3ey5O2uBLraGRSfIUpKSgkOrMdz3Tvz/ugvH9l6qrM+8TTf/7mRsf27E1HPk0WbDvD2D4tY8fU7ONpUvrCY/s821uw7yfgBz+Lv5sTe0xf5YPpfzBs9kBDfmh+jemPZfYjvfv+bcW++SESQHwtXb+Wtz6exctoEHO30nFMWr2TNzkTGv/0y/p5u7Dl2hg8mz2b+1x9pzyl3nDqfwtKNuwnyffAK9YZDZ5mybDtjXupEhJ87i7YeZui0payYMAgHPdtqbeIZfvpnJxNe7UJUPU+uZGQzft46zb73QgcAft+QyNIdx/h8QFcC3J04cyWd8fPXYWVuyksdGhsU3/pte/ju53mMe38IkQ3qs2D5Gt4c+SWr5v6Eo71tpfLTfvuDNZt3Mf7Dt/D39mTvoWO8P/47Fvz0JSH16wHw25IE/lq5ka9GDiPAz5vTyRcZ990MrC0teLl39wfYig9PDDVRi3744QciIiKwtLTE29uboUOHUlhYqH1/7ty52NnZsXr1aoKDg7GwsKBPnz4UFxczb948/Pz8sLe3Z/jw4SiVSp1lFxQU8OKLL2JpaYmnpyczZszQeV8ikTBr1ix69uyJpaUlX331FQCzZs0iICAAExMTgoODWbBgQY0+S1FREW+88QY9e/Zk9uzZREdH4+fnx+DBg5k3bx7Lli3jr7/+qnL+HTt20KxZM0xNTXF3d+fTTz9FoVBo32/Xrh3Dhw/nk08+wcHBATc3NyZMmGDQ9qwN81dt5fnYVsR3aEmAtzvj3vwP5qYmJGzZp7f86h2JDO7dmbaNw/Byc6Jfl7a0aRjK/FVbKz5b0wjaNg7D18MFPw9Xhr/cEwszU06cu2xQbAuPpNA73JteYV4EOFoxJjYMMyMZCaeu6y1va2aCk6Wp9rX/ahZmxlI6BWlaeq7mFnMyLY8xHUIJc7PFz8GK0R3DKFOoWHc2zaDYAIybdUFxfAeKk7tQZ92gfP1c1IpyjCNj9M9QWoS6KE/7kvmHgbwcxdlE3XJKuU45SosNjg1gwbZj9G4VRnyLUALcHRjbtz1mJkYk7D+jt/zxy2lE13OnW5NgPB1taBXiQ5fG9Tl19aa2jIO1OU42ltrXzlMpeDvZ0iTQsB/DBXvP0rtJIPGNAghwsWVsj2aYGctIOHJRf2zXMon2caZblD+e9la0CnSnS4Qvp1KztGWeaeBF2yBPfB1t8HWy4d1O0ViYGHEyNdOg2AzVtmVThg95jdhnWj/S9VRnwYZ99I5pRHzbaAI8nRn7anfMTIxJ2HVUb/k1e08wuHsb2kbWx8vFnr7tm9AmMpD5G/Y/dCzzV23l+U6tie9455zyouacsnWv3vKrdyQy+PkutG0cfvucEkObRmHMX7lZp1xxSSmjps5lwtsvY2NV+eKhphZsPkTv1pHEt4ogwMOJsS91xszYmIS9p/SWP37xBtEBnnRrFoqnky2tQv3p0jSEUynpFWUuXaddVCAxEQF4OtnSqXEwLUP9OJVi+Hll/rJVPN8tlue6dCDAz5vP3h+Cuakp/6zfqrf86s07GfzSc8Q0b4S3hyv9esbRtnlD5i1dpS1z7HQy7Vs1JaZFYzzdXOj8TEtaNYni5NkLBscnPJhHWvmSSqX89NNPnD59mnnz5rF161Y++eQTnTLFxcX89NNPLFmyhPXr17N9+3aee+451q5dy9q1a1mwYAH/+9//WLZsmc583333HVFRURw9epRPP/2U9957j02bNumUmTBhAs899xwnT57k9ddf559//uG9997jww8/5NSpU7z55pvaVqz72bhxI1lZWXz00UeV3uvRowdBQUH88ccfeue9fv063bp1o2nTphw/fpxZs2YxZ84cvvxS96p43rx5WFpacuDAASZPnsznn3+u85lqsj0fhlyuIOniNVpEBuuss3lkMMerqCiVyxWY3NOiaGZqwtEk/T+aSqWKdbsPUVJaTlSwf81jU6pIuplPcx/HitgkEpr7OHIiLbdGy0g4lUpckLu2RatcqbnWMjGq6C6WSiSYyKQcu1G5u7JaUhlSNz+Ul0/fNVGNMuU0Us+atQIZR8agOHMA5OU602U+DbAYPg3zId9gEvcamBveJSpXKEm6lkHz4IqWA6lUQvNgb05cTtc7T5S/O2euZXDyiub91Mw8dp+5QptQ3yrXsfZQMr1ahBjUAixXKEm6kU3zehXdn1KphOYBbpy4pr+iFOXtxJkb2dqKVGp2AbvP3aBNkIfe8kqVivUnUigpVxDp7Vzj2J5EcoWSpCtptAitOL6kUgktQv05cTFV7zzlCiUm97T0mhobc+z81YeLRa4g6eJVPeeUBhxPru6cohuLmYlxpXPKV7/8SdvG4bSIavDg8SmUJF1Np3lIxT4tlUpoHuLLiUs39M4TFeDBmas3OXlZU5FKvZXL7lOXaBNer6JMPU8OnL3ClZuaVIvk1AyOXrhO67B6epdZZXxyOWfOXaJFo8i74pPSolEEx88k652nvFyOqYmJzjRTExOOnjqr/Ts6LJgDR0+Sck3zGZMvpnDk5FmdrsnHTY2kVl5Pikfa7fj+++9r/+/n58eXX37JW2+9xcyZM7XT5XK5tjUKoE+fPixYsICbN29iZWVFaGgo7du3Z9u2bfTr1087X+vWrfn0008BCAoKYs+ePfz3v/+lU6dO2jIvvfQSAwcO1P794osvMmDAAIYOHQrAiBEj2L9/P99//z3t27ev9rOcO3cOgJCQyjk6AA0aNNCWudfMmTPx9vZm+vTpSCQSGjRowI0bNxg5ciSfffYZUqmmDhwZGcn48eMBqF+/PtOnT2fLli3az1ST7XmvsrIyysrKdCeWl1c6OAFyCgpRqlSVugIcbW24fP1mpfIAraJDWLBqK41DA/F2c+LAyWS27D+G8p77hs9duU7/0VMoL1dgYWbK1E/eIMC75t0ZOSXlKNVqHCx043a0MCUlp+i+859Kz+VCViHjO4drp/nZW+Jmbca03ecYGxuGubGm2/FmYSmZRWXVLK0yiYU1EqkMdXGeznR1UR5Sx/t/Tql7PaQu3pSt/U1nuvLSSZTJh1Hl3UJq54JJuz6Y9f2I0vmfg7rm92bnFJWgVKlxvKd70dHagpSb+iua3ZoEk1tUysCpf4MaFCoVL7QOZ3DnpnrLbz1xiYKSMno213+MVBlbcZkmtnu6Fx2tzEjJzNcfW5Q/ucVlDPx1E6jVKFRqXmhan8HPhOuUO5+ew6u/bKRcocTcxIgfXoohwKVyV83/JzkFxZrteU+XmaONJZfT9FdmW4UHsGDjfhoH++Dt7MCBpEtsPZJU6Tg2PJY75xQb3VjsrKs+pzS8c06przmnnKh8Tlm3+xBJl67xx+SRDxdf4e3jwkbPcZGerXeebs1CyS0sYeD3iyuOi5goBndtoS3zelxzikrLiJ8wB5lEilKtYlivtnRvHqp3mVXGl1eg2X73dC862ttx+Zr+Fv9WTaOZv2wVjSND8fZwZf+Rk2zZfQClqqJjb9CLz1FYXELPge8hk0pRqlQMf/1Fno2topX+MXjauh0faeVr8+bNTJo0ibNnz5Kfn49CoaC0tJTi4mIsLDQ7u4WFhbbiBeDq6oqfnx9WVlY60zIyMnSW3bJly0p/33sHZJMmTXT+TkpKYsiQITrTWrduzY8//ljjz6Q24Afv7vW2bKmbaNm6dWsKCwtJTU3Fx8cH0FS+7ubu7q7zuWuyPe81adIkJk6cqDNtzNuvMG7oqwZ/Dn1Gvt6HibP+oNd7XyBBgpebE706tCBhq253hb+HK0u/H0VhcQmb9h1l7PQF/Pb5ewZVwB5GwqlU6jtZ6STnG8ukTOnRkImbTvHMrC3IbrektfZz4nEPOWMUFYMq41ql5Hxl0oGK/99KpfTWNSze/h6pTwiqK/q7C2vLwfOpzNl4iNEvtCPCz5Vrt/KYvHwns9cnMqRLs0rlE/afoXWILy62VnqWVsuxXb7JnJ2nGf1sUyK8HLmWXcjktYeYve0kQ9pHaMv5Odnw59BuFJaWs/n0VT77ex+/Dur0/74CZqhPXozj83mriR89E4kEvJwd6NU6moTdxx57LCNff4GJsxbRa/jEu84pLUnYqkl9SM/M5ts5S5k9/l1MTR4uj/dBHEy+ypz1+xn9Yici/N25lpHD5L+2MnvNXoZ019xYsfHwWdYmJjHp9WcJ8HAi+VoG3y3dirOtFT1bht9nDQ/n03cGMmHKz/Qc+B4SwNvDjV5x7UlYX9HDs2H7XtZs2cW3o98jwM+b5IspfDvjd5wdHegV1+6RxidoPLLKV0pKCs8++yxvv/02X331FQ4ODuzevZtBgwZRXl6urSzcmwQvkUj0TlOpDK8XW1o+2B1r+gQFBQGailSrVpXvXEpKSiI01LCrmntV97lruj3vNWrUKEaMGKE78cIuvWXtra2QSaVk5eomh2fl5eN0z5XrHQ621vz46RDKyuXkFhTh4mDL1IUr8HJx1ClnbGyEj7umuyc0wIdTF66yaM12PnvrRf0b497YzE2QSSRkF+t2yWUVl+GoJ9n+biVyBRuS03m7ZeXuv1BXW/58pTUFZXLkSk3LWv8/9hHqatiPs7q4ALVKicRCdz6JpS3qwrwq5rrN2ASjkOaU71p+//Xk3kJdnI/U3sWgype9pTkyqYSsAt18sayCYpz0JNsDzFyzn+5Ng+ndSnOXWX0PJ0rK5XyxZBuDOzdFKq24mLiRnc+B5GtMGdStxjFpY7Mw1cRWWKobW2EpTlbm+mPbcpzuUf70bqL5Tuu72VNSruCLlQcY/Ey4NjZjI5km4R4I9XTk9PVsFu87y7hezQ2O80lhb22h2Z75ui3CWflFOFVRMXawsWTqu/0okyvILSzGxc6aqcu24Ols/5Cx3Dmn6LZgZuUW3Oec8pbuOWVBAl6umjtfz1y8SnZeAf0++kY7j1Kl4vCZCyxZt4NDf/6ETFazjBp7q9vHRb6e40JPsj3AzFW76d48jN5tNBfL9T2dNcfFwo0M7toSqVTCf5fvYGBcM7o0DdGWScvO57f1BwyqfNnbWmu2X47uOSQrJxdHBzu98zjY2fLTFyMpKy8nN68AFycH/vvLQrzcXbRlpsxewKD/xNO1QxsAgur5cuPmLX79Y3mdVb6etpavR5bzdfjwYVQqFVOmTKFFixYEBQVx44b+PvQHsX///kp/V9UleEdISAh79uzRmbZnz54aVZo6d+6Mg4MDU6ZUvsV/5cqVnD9/nhdf1F+RCAkJYd++fTqtZnv27MHa2hovL6/7rhsefHuamppiY2Oj89LX5QiaClJIgDcHTlbkEqhUKg6cOEdUUPX5WaYmxrg62qFQqti8/xjtmkVWW16lVlMuV1RbRic2mZQQVxsOXKtIqFap1SReyyLS3a7aeTedS6dcqaJbiP58IABrU2McLEy4klPEmZt5tAtwqbKsXiolqvQUZH5370sSZL6hqK5Xn8Rq1KAZGBmhOK0/AfluEmt7MLe6f4XuHsZGMkK8XUg8V5Hzo1KpSUy+RqS//qEmSssVSO/J3brTRa6+p21wxf4kHKzNaRvmZ1Bc2tg8HEi8VJF7plKpSbyUTqS3/qEmSuVKPbFJ9MZ2N5Varc31+//K2EhGiK87B5IqcqpUKjUHki4TGVD9+cbU2AhXexsUShVbDifRvmHQw8VibERIgA8HTtx7Tkm+b85npXNKU805pXlkA/7+71j+mjJa+woL8KF7TFP+mjK6xhUvuL2tfNxIPHvlrvjUJJ69QmQ9/eeLmhwXpeVyvfunysCeE2NjY0KD6nHg6Mm74lOx/+hJokKDq5lTk+fl6uyIQqlk864DtG9VkS5QWlqmjfkOmVSKug6HmRc5Xw8gLy+v0oCiTk5OyOVypk2bRo8ePdizZw8///xzbawO0FReJk+eTHx8PJs2bWLp0qWsWbOm2nk+/vhj+vbtS8OGDYmNjWXVqlUsX76czZs3VzsfaFrR/ve///Gf//yHIUOGMGzYMGxsbNiyZQsff/wxffr0oW/fvnrnHTp0KFOnTuXdd99l2LBhJCcnM378eEaMGFHpAKhKYGDgI92ed7zaowNjpy0gNMBHO9RESVkZ8R00+Qyjf5qPq4Mt773SC4AT51LIyM6lgZ8XN7NzmfXXWlQqNQPjY7XL/HHhClo3DMPd2Z6iklLW7TrEodPn+XncUINie6WRH59tOEmoiy3hbrYsPppCiVxJrzDNnXVj15/AxcqU4W10T0oJp67TLsAFO/PKlc5N59KxNzfGzdqc81kFfLc9iXYBrrT0rXp8qarIE9dj+uwbqNIvo7xxCeOmcUiMTZGf0LQ0mjw7BHVBDvIdS3XmM4qKQXnuCJTck7tmbIpxm3iUyYdQF+UhsXPBpH0/1DkZKC+fxFD920czbuFmQr1dCPd1ZdH2Y5SUK+h1Ow9l7IKNuNhaMbynpmU3JtyfhduO0sDLmQg/V67eymPmmv3EhPshu2u/VanUrDyQRI9mDTAy4IdPJ7ZWDRi3fB+hno6EezqyaN9ZSsqV9GqkSVAeu2wvLjbmDO+sSQiOCfZk4d4kGrjbE+HtxNWsAmZuOU5MsKc2tp82HqV1kAdutpYUl8lZdyKFQyk3mflqhweKsaaKi0u4mlpxYXT9xk3OnruIrY017m4GVuofUP+4loz7NYEwPw/C/T1YuOkAJWVy4ttEAzDmlwRc7K15r09HAE5cTCUjt4AG3m5k5OYza8UOVCo1A7o+/B2bmnPKfEIDfYmo78vCVXfOKZrUkdE/zsXV0Y73XonXxHLu8u1zirfmnPLnGlRqFQOf0+S+WpqbUd9Xt2JkbmaKrZVlpek10T+2CePmriXU141wP3cWbT1ESbmcXq00LVRjf1+Di501w5/T5EPFRASwcMshGni7EOHvztWMXGau3E1MZIB234uJCODXdftxc7AhwN2J5Gs3Wbj5EL1aRVQZR5Xbr08Pxnw7nbCgACIaBLLg7zWUlJYRH6fJUx79zU+4ODny/uCXNdsv6RwZmdkEB/iTkZnFrPl/abbff+K1y3ymZRNmL/obdxcnAvy8OXvhMvOXrSa+S/W5z0LtqZXK1/bt22nYUPcuiUGDBvHDDz/w7bffMmrUKGJiYpg0aRKvvlo7uUYffvghhw4dYuLEidjY2PDDDz8QFxdX7Tzx8fH8+OOPfP/997z33nv4+/vz+++/065duxqts0+fPmzbto2vvvqKtm3bUlpaSv369RkzZgzvv/9+lXd4eXp6snbtWj7++GOioqJwcHBg0KBBjB07tsafNyoq6pFuzzu6tG5MTl4hM5esITO3gGB/T2aNfUebMJuema1zRVculzP9j9Wk3szEwsyUNo3C+Hr4q9hYVnRlZecVMnbafG7l5GNlYUaQryc/jxtKyyjDErPjgt3JKSln1r7zZBWXEexsw4znmuBoqel2TC8oQXrPV5CSXcjRGznM6t1EzxLhVlEpU3acJau4DCdLU54N9WRI8wC9Ze9HmZRIuYUNxm17Y2JpiyrjKqV/fQ/Fmi4XqY2DzphYABIHN2TewZT8MbnyAtUqpC7eGEe0ATML1AU5KC+fpnzn36CseavhHXGNgsgpLGHW2gNk5hcR7OXMzLd7apON03IKdfbhN+KaIpHAjDX7ycgrxN7KnJgwf4Y9q5tvuT/5Gmk5BcS3ePBu97gIP3KKypi15TiZhaUEu9sz89X2ON7udkzLK0Jy15f7xjPhSIAZW46TkV+CvaUpMcGeDIuN1pbJLipj7N/7yCwowcrMmCBXe2a+2oGWgY82z/DU2fO8/m5FIvjkabMB6NU1lq/GfvhI131Hl2Zh5BQUMTNhO5l5hQR7uzLzg5dwvN3tmJ6dp9NtXK5QMGP5NlJv5WBhZkKbiPp8Nfg5bCwqj7FmcCxtmpCTX8jMP1aTmZtPsL8Xs8YNu+uckqNzEVoulzN98Srdc8p7r+mcU2pTXJMG5BQUM2vVntvHhQsz3+2jvWEhLbtA97jo1lJzXKzcTUbu7eMiMoBhvSoGQ/70P7HMWLmbSX9sJrugGGdbS55vG8Wb3Q0fbLdL+9Zk5+UzY+4SMnNyaRDgx8/fjMHpdrdjWkYmEknF9isrlzPttyWkpt3EwtyMts0b8vWnw7GxquhGHf3uIKb/voQvf/yF7Nx8nB3t6fNsJ97u38fg+GqL6slptKoVEvWDZJALT7SyU5vuX6gOKXevrusQqqXOya3rEKokbaT/TsR/jTz9d5D9Wxh1eKWuQ6iSMln/WHv/FhK7qp+U8G+gyjBsXMHHSVb/352DaOJleIudoVa4vVQry+mVvrhWlvOoPZHPdhQEQRAEQXhSicrXbYsWLcLKykrvKyzM8GcQCoIgCIJQM+paej0pnppnO95Pz549ad5cf9Pvwz4TUhAEQRCEqv3/vge5MlH5us3a2hpr68oPeRUEQRAE4dFSGfBIsv8PRLejIAiCIAjCYyRavgRBEARBqFNPUr5WbRCVL0EQBEEQ6tTTlvMluh0FQRAEQRAeI9HyJQiCIAhCnXraRrgXLV+CIAiCINQpFZJaeT2IGTNm4Ofnh5mZGc2bNycxMbFG8y1ZsgSJREJ8fLzB6xSVL0EQBEEQnkp//vknI0aMYPz48Rw5coSoqCji4uLIyMiodr6UlBQ++ugj2rZtW225qojKlyAIgiAIdaquRrj/4YcfeOONNxg4cCChoaH8/PPPWFhY8Ntvv1U5j1Kp5OWXX2bixInUq1fvAdYqKl+CIAiCINQxlaR2XmVlZeTn5+u8ysrK9K6zvLycw4cPExsbq50mlUqJjY1l376qH2T/+eef4+LiwqBBgx7484qE+6eRiXldR1At9bUbdR1CtSRuznUdwpPLzaeuI6iWMrnqE25dkwW3rOsQqqXYNK+uQ6iWOvNWXYdQJaXqXz7QgldEXUdQY5MmTWLixIk608aPH8+ECRMqlc3MzESpVOLq6qoz3dXVlbNnz+pd/u7du5kzZw7Hjh17qDhF5UsQBEEQhDpVW9XPUaNGMWLECJ1ppqamtbLsgoIC+vfvzy+//IKTk9NDLUtUvgRBEARBqFO1NcK9qalpjStbTk5OyGQybt68qTP95s2buLm5VSp/8eJFUlJS6NGjh3aa6narpZGREcnJyQQEBNRo3SLnSxAEQRCEOlVbOV+GMDExoXHjxmzZsqUiDpWKLVu20LJl5W7+Bg0acPLkSY4dO6Z99ezZk/bt23Ps2DG8vb1rvG7R8iUIgiAIwlNpxIgRvPbaazRp0oRmzZoxdepUioqKGDhwIACvvvoqnp6eTJo0CTMzM8LDw3Xmt7OzA6g0/X5E5UsQBEEQhDpVV7cc9OvXj1u3bvHZZ5+Rnp5OdHQ069ev1ybhX716Fam09jsJReVLEARBEIQ6VZf3ew4bNoxhw4bpfW/79u3Vzjt37twHWqfI+RIEQRAEQXiMRMuXIAiCIAh1Sv2UPVhbVL4EQRAEQahT//JhZmud6HYUBEEQBEF4jETLlyAIgiAIdUq0fD2FJBIJCQkJAKSkpCCRSB76uU2CIAiCINSMupZeT4onuuXr2rVrjB8/nvXr15OZmYm7uzvx8fF89tlnODo6PtAyvb29SUtLe+jnNt0xYMAAcnNztZW7J8GSNVuZu3w9mTl5BPl7M+rNl4gIqqe3rFyhYM7StazcupeMrBz8PN14f0Af2jSueBDrzMUr+PmPlTrz+Xm6sfLnrwyOzah5HMZteyKxskOVfoXy1b+hSr2gt6zZoAnI6oVVmq5IPkLZ/EkglWHc6T8YBTVC4uCCurQY5cWTyDcsQl2QY3BsAH+euMa8o1fJKi4nyMmKkTFBhLva6i07ePlhDt/IrTS9ja8j03pEA1BcruCnfRfZdukWeaVyPGzMeDHKmxfCvR4oviU7TzBv6xGy8osJ8nRiZJ8YInwrP0bjjoXbjrF0z0nScwqwszQnNjqQ4T1aYmpcceq4mVvIjyv3sufMFUrlcryd7Jj4ckfCfFyrXK7e2LYdZt6GA2TlFRLk7cLIFzsT4e9RdWybE1m6/Sjp2fnYWZkT27gBw3u308ZWVFrGjISdbDt6juyCYoJ9XPmkXyzh1SzToHi3HGTe+r1k5hUS5O3Kpy93JaKep96ycoWSOWt3s2rPCTJy8vFzc+L9FzrSOiKwVmKpqUPHTvL74mWcOXuBW1nZ/DhpHB1jWj3y9S5JPM+8PUlkFZYS5GbHyK6NifCq+hy9cF8ySw9dID2vGDsLE2JDvRneMQpTYxkAc3adYUtSKimZ+ZgayYjyduL9TlH4Odk8UHz/+uN2x1HmbTpEVn4RQV7OjOzbgQg/9yrLL9x6mKU7j98+bs2IbRTE8F5ttceGUqXi5zX7WJN4hqz8YpxtLenZIow3urZAInnKMt/ryBNb+bp06RItW7YkKCiIP/74A39/f06fPs3HH3/MunXr2L9/Pw4ODgYvVyaT6X2m09Ni/a5Evvv1T8a905+IoHosXLmJtz77Lyt//gpHu8ontukL/2HNtv2Mf/c1/L3c2XPkFB98PYP5k0cREuCrLRfg48EvX36k/Vv2AIPWySJaYdLtNcpXzEZ57QLGrbtjNmAMxf99D4ryK5UvXfw9Etldu7iFFebDvkd5cp/mb2NTZB71KN+2DFX6FSTmlph0H4hp/5GUzvzU4Pg2nL/JlN3nGdOuAeFuNiw+do2hK4+R8HJLHCxMKpWf0i0SubKisT2vVE6/JYl0CnSpKLP7PAev5/BVpzA8bMzYdzWbSTuScbY0pZ2/s2HxHTnHlH92MaZfeyJ83Vi04xhDZ65kxdhXcLC2qFR+7aFkflq1lwkvdSTK350rGbmMX7QZCfBR77YA5BeXMmDqMprW92L62z1wsDLnSkYeNuZmhsV28AxT/trCmFe6EOHvwaLNBxk69U9WfDEEBxvLyrEdOM1Pf29nwoDuRAV4cuVmNuN/X6OJrV8sABPnrePC9Vt8OagHznZWrNl/mrf+u4S/J76Bq721QfHda33iab7/cyNj+3cnop4nizYd4O0fFrHi63dw1BPv9H+2sWbfScYPeBZ/Nyf2nr7IB9P/Yt7ogYT4Vv0jWttKSkoJDqzHc9078/7oLx/LOjecusqUDUcZ82wTIjwdWbQ/maELt7NiWHccrCrvJ2tPpPDT5uNM6NWMKG8nrmQVMD7hABIkfNSlIQCHUzLo1zSQME9HlCoV07ac4O0F21n+TjfMTQz7WfvXH7eHzjLl7x2MeTGWCD93Fm09zNBpf7Niwuv6j9uDSfyUsIsJ/eOIqufBlZs5jF+wXrP9+rQD4PeNB1m68xifv9qVAA9Hzly5yfgF67EyN+Wl9o0Miq+2GPpooCfdE9vt+M4772BiYsLGjRt55pln8PHxoWvXrmzevJnr168zZswYANLS0ujevTvm5ub4+/uzePFi/Pz8mDp1qt7l6ut23LFjB82aNcPU1BR3d3c+/fRTFArFA8W9bNkyIiIiMDc3x9HRkdjYWIqKirTv//rrr4SEhGBmZkaDBg2YOXOmzvwnT56kQ4cO2vmHDBlCYWHhA8Wiz/yEjTwfF0N8bBsCfDwYN7Q/5qYmJGzarbf86m37GNy3O22bROLl5ky/bu1p0ziC+QkbdcoZyWQ42dtqX/a2hv/4Gbd+FsWhLSiObEd9K5XyFbNRy8sxbtxB/wwlhagLc7UvWWAkyMtQnLpd+SorpvT3L1Ce2oc68waqa+cpXzUHmWcAElvDWz4XHrtK7zBPeoV6EOBgxZj2DTAzkpGQdENveVszY5wsTbWv/deyMTOS0imwosXoeHoezzZwp4mXPR425jwf7kmQkxWnb1aubN7Pgm3H6N0qjPgWoQS4OzC2b3vMTIxI2H9Gb/njl9OIrudOtybBeDra0CrEhy6N63PqasVDaH/ffBg3Oys+fzmWCF83PB1taRXig7ez/laDKmPblEjvtlHEt44kwMOJsa900cS254T+2C6mEh3oRbfmYXg62dEqrB5dmoVyKiUNgNJyOVuOnOX9Pu1pHOSDj4sDb/dsi7ezPUu3HzEoNr3xbthH75hGxLeNJsDTmbGvdsfMxJiEXUf1ll+z9wSDu7ehbWR9vFzs6du+CW0iA5m/Yf9Dx2KIti2bMnzIa8Q+0/qxrXPBvrP0bhRAfMN6BLjYMvbZppgZG5Fw9JLe8sevZRHt40S3SD887a1oFehOlwhfTl3P0paZ2b8dvRrWI9DFlmA3ez6Pb05aXjFnbmQbHN+//rjdepjerSOIbxlOgLsjY1/spNnX9p7UW/74pRtEB3jSrWmI5ngM9aNLkwacupKmU6ZdZCAxEfXwdLSlU6MgWob4cSol3eD4aouqll5Piiey8pWdnc2GDRsYOnQo5ubmOu+5ubnx8ssv8+eff6JWq3n11Ve5ceMG27dv5++//2b27NlkZGTUeF3Xr1+nW7duNG3alOPHjzNr1izmzJnDl18aftWYlpbGiy++yOuvv05SUhLbt2+nd+/eqNWanupFixbx2Wef8dVXX5GUlMTXX3/NuHHjmDdvHgBFRUXExcVhb2/PwYMHWbp0KZs3b65yZF5DyeUKki5coUVUiHaaVCqleXQox5Mv6p2nXK7AxNhYZ5qZqQlHz5zXmXblxk06vjaCroNH8un3s0nLyMIgMiOkHvVQXrjrx1itRnnhBFKfoBotwrhxRxQn94K8rOpCZhaoVSrUpUVVl9FDrlSRlFFAc++K1lapREJzL3tOpOfVaBkJZ24QV98V89tdKwBRbrbsuHyLjMJS1Go1B1OzuZJbTAtvw1p15QolSdcyaB5c8eBXqVRC82BvTlzWf8KN8nfnzLUMTl7RvJ+amcfuM1doE1rRornj5GVCfVz56Ld1tB/9K/2+/YO/954yPLYr6TQP8deNLcSPExev648twIszV9I5eVnzA5l6K4fdJy/SJjwA0HSrKFVqne5RAFMTI45eSDUoPv3xptEiVDfeFqH+nLiof9nlCiUm98ZibMyx81cfKpZ/O7lCSdKNHJrXq6iYSKUSmtdz5USq/nNAlLcjZ27kcPL2+6nZhew+n0ab+lW3EBaWygGwNa/cUlVtfE/CcXv1Js2DfSrik0po3sCHE5fT9M4TVc+DM1dvcvL2hUhqZi67T12mTVg9nTIHkq9y5aamspqcmsHRi9dpHeavd5mPw9NW+Xoiux3Pnz+PWq0mJCRE7/shISHk5OSwa9cuNm/ezMGDB2nSpAmgaVmqX79+jdc1c+ZMvL29mT59OhKJhAYNGnDjxg1GjhzJZ599ZtAzn9LS0lAoFPTu3RtfX80PWERERW7U+PHjmTJlCr179wbA39+fM2fO8L///Y/XXnuNxYsXU1payvz587G01HRtTJ8+nR49evDtt99qn0V1t7KyMsrK7qlslJdjalL5JJWTX4BSpcLRXrd70dHOhsup+g/0Vg3DWZCwkcbhQXi7OXPgeBJb9h5Bqao4DCKC6vHl+6/j5+nGrZw8fv5jJQM+/Ybl0z/H0sJc73LvJbGwRiKToS7UPSGqC/OQOuvPs7mb1CsQqZsPZf/MqrqQkTEmca+gPLEHykpqFNcdOSVylGo1Dvec/B0tTEjJLb7v/Kdu5nEhu4jxHXX36ZHPBPPF1iTi5u7BSCpBAozrEEJjT3vD4isqQalS43hPN4WjtQUpN/Xnt3VrEkxuUSkDp/4NalCoVLzQOpzBnZtqy6Rm5bN090leaR/N4E5NOHX1JpP/3omxTEbP5vqPz0qxFRZrYrO5JzYbS1LS9f9Ad2seRm5hMQO/XQCAQqnihWcaMri7Jn/J0syUyABPZq/eg7+7I442lqxPPMOJi9fxdjFs21WKt+BOvLrdi442llxOy9Q7T6vwABZs3E/jYB+8nR04kHSJrUeSUKqepBRhw+UUl6NUq3G8p3vR0dKMlEz9rUDdIv3ILS5n4G9bADUKlZoXmgQyOKZy/iaASqXmu/VHifZ2ItDVzrD4/u3HbWGJ/n3N2oKUm/pb+bo1DSG3sISBU5ZUHLdtoxjcpbm2zOudm1FUWkb8578jk0hRqlUM69GG7s1qdswKD++JrHzdcafFqCqXL1/GyMiIRo0q+rADAwOxt6/5AZCUlETLli11khBbt25NYWEhqamp+Pj4VDO3rqioKDp27EhERARxcXF07tyZPn36YG9vT1FRERcvXmTQoEG88cYb2nkUCgW2trbaWKKiorQVrzuxqFQqkpOT9Va+Jk2axMSJE3WmjRk2kHHvvl7juKszcsiLTJw2l15vj0GCBC93Z3rFtiZhc0U3ZdsmFRXMIH9vIoLq0WXQJ2zYfYjendvWShz3Y9S4A6r0K1Um5yOVYfqfESCBspW/PJaY7pZw5gb1Ha0qJfkuOX6Nkzfzmdo9EndrM47cyOWb27kjhl5FG+rg+VTmbDzE6BfaEeHnyrVbeUxevpPZ6xMZ0qUZACq1mlBvF4b30FR6Gng7czEti2V7TtW48vVAsSVfYc7afYx+OY4Ifw+uZeQw+c/NzF69myHPtgHgq9d7MGHeGjp/PB2ZVEIDHze6NAsl6crj71r55MU4Pp+3mvjRM5FIwMvZgV6to0nYfeyxx/Jvd/DyTebsOsPo7pqk/GvZhUxed4TZO04x5JnwSuUnrT3MhYxc5r4e+9hj/Vcet+euMWfDAUb/pyMRfu5cu5XL5KXbmL12H0O6tQRg45Fk1iYmMWlgdwLcHUlOvcV3y7bhbGdFzxb6K7mP2v/vy5DKnsjKV2BgIBKJhKSkJJ577rlK7yclJWFvb4+dnd3jD64aMpmMTZs2sXfvXjZu3Mi0adMYM2YMBw4cwMJCc9X/yy+/0Lx580rzPahRo0YxYsQI3YlXD+kta29jjUwqJStH94o0KzcfJ3v9OTwOttb8OPZdysrl5BYU4uJgx9R5y/ByrTqp1MbKAl8PV66l1bz7V11cgFqpRGKlG4fEyhZ1YW71MxubYhTZmvLNf+p/XyrD9MURSOycKJ0z0eBWLwB7c2NkEgnZJeU607OKy3HUk7R7txK5kg3nb/J2c907SksVSqbtv8gP3SJp66fJQQtysiY5s5AFR68YdBK3tzRHJpWQVaB7NZ9VUIyTnqRdgJlr9tO9aTC9W2lOxvU9nCgpl/PFkm0M7twUqVSCs40lAW66cfi7OrD5uP5uar2xWVloYsu/J7b8IpxsrPTHlrCT7i3C6d02WhObl4smtgXrGNytNVKpBG8Xe+Z8/AolZeUUlpTjbGfFJ/9LwNPZrsax6Y3X+k68ul3TWflFONnqj9fBxpKp7/ajTK4gt7AYFztrpi7bgqfzw7XC/dvZW5ggk0jIKizVmZ5VVIqTlf5W75nbTtI9yo/ejTVdyPVd7SgpV/DFqoMMbhuGVFpxITxpzWF2nrvObwM74mqrfz+uNr5/+3FrZa5/XysoxknPjR0AM1ftoXuzUHq3jgSgvqczJWVyvli8icFdWiCVSvjv8h0MjGtGlyYNtGXSsvP5bcOBOqt8iYT7J4CjoyOdOnVi5syZlJTo/lCmp6ezaNEi+vXrR3BwMAqFgqNHK5JgL1y4QE5OzYcRCAkJYd++fTqtbHv27MHa2hovL8NvG5ZIJLRu3ZqJEydy9OhRTExM+Oeff3B1dcXDw4NLly4RGBio8/L399fGcvz4cZ0E/T179iCVSgkODta7PlNTU2xsbHRe+rocAYyNjQgJ9OXAiSTtNJVKxYHjSUQFB1T7uUxNjHF1tEehVLJ57xHatYiusmxxSSnX0jOqrNDppVSgunEJWUBFKxoSCbKACFRXz1U7q1F4S5AZoTi2s/KbtyteUkc3Sn/7Akoe7OYFY5mUEBdrDlyr6ApQqdUkpuYQ6Vb959x04SblSjXdgnRzWhQqTZfLvXd+yyRgaG+VsZGMEG8XEs9V5CSpVGoSk68R6a//7t7ScgXSe1Z+p5tdffs6NaqeOykZusfTlVu5uBtwN6GxkYwQXzcSk1J0Y0u6QmSA/i5lvbHd/lt9zzW0uakJznZW5BeVsPf0JdpF1zztoOp43TmQdFkn3gNJl4kMqP6cYGpshKu9DQqlii2Hk2jfsGb5ik8qYyMZIR72JF6uuElDpVKTeOkmkVUMNVEqVyK9Z5+/U+G6892q1WomrTnM1rOpzH6tA572+iu9943vSThufVxJTK7IDdQct1eJ9NefA1daLtdz3Opuv1K5/uPn/3kv+L/KE9nyBZpcp1atWhEXF8eXX36pM9SEp6cnX331FQ4ODsTGxjJkyBBmzZqFsbExH374Iebm5jUey2To0KFMnTqVd999l2HDhpGcnMz48eMZMWKEQfleAAcOHGDLli107twZFxcXDhw4wK1bt7S5axMnTmT48OHY2trSpUsXysrKOHToEDk5OYwYMYKXX36Z8ePH89prrzFhwgRu3brFu+++S//+/fV2OT6IV+M7M/a/cwgN9CMiyJ+FKzZTUlpGfKzm7qjRP/yKq6M97732PAAnki+RkZVDg3o+3MzKYdbiFahUKgb27qpd5vdz/qRds2jcXRy5lZ3LzMUrkEmldH2mud4YqiLfsxrT599Bdf0iytQLGLfqjsTEFPnhbQCY9BmGOj8b+cbFOvMZNemAMulg5YqVVIbpSx8idfenbME3SKRSsLIDQF1SCErD7mh9JdqHzzafIdTFhnBXGxYfv0qJQkmvEM1Jcuym07hYmjK8le7YTglnbtCunhN25ro3LliZGNHYw46pey5gJpPhbmPG4es5rD6bzog2hlcg+rePZtzCzYR6uxDu68qi7ccoKVfQq3moJr4FG3GxtWJ4T00XYky4Pwu3HaWBlzMRfq5cvZXHzDX7iQn30w4V8kq7aAb8dxm/bjxI54b1OXXlJn/vPcW4flXcgVpVbJ2aMe631YT6uRF+e6iJknI5vW5fvY+dswoXe2uG926niS0qkIWbEmng40qEvwdXb+Uwc8VOYiLra2Pbe+oSatT4uTpy9VYO/126FX83R3q1ijR421WKN64l435NIMzPg3B/DxZuOkBJmZz4NtEAjPklARd7a97r0xGAExdTycgtoIG3Gxm5+cxasQOVSs2Aro/vrkOA4uISrqZW3MV3/cZNzp67iK2NNe5uLtXM+eD6t2zAuH/2E+rhQLinA4v2n6NErqBXQ02L0djl+3GxMWd4bBQAMUEeLNyXTAM3eyK8HLmaXcjMrSeJCfbQfrdfrznMupNXmPpiWyxNjMgs0FyEW5kZY2Zs2M/av/647dCYcfPXE+rrRrivG4u2HaGkTE6vlpou2LFz1+FiZ8XweE0KR0xEAAu3HqaBtwsRfu6aY2P1XmIi6mm3X0xEAL+uP4CbvQ0BHo4kX8tg4dbD2mXWhScpWb42PLGVr/r163Po0CHGjx9P3759yc7Oxs3Njfj4eMaPH68d42v+/PkMGjSImJgY3NzcmDRpEqdPn8bMrGbjEHl6erJ27Vo+/vhjoqKicHBwYNCgQYwdO9bgmG1sbNi5cydTp04lPz8fX19fpkyZQteumorK4MGDsbCw4LvvvuPjjz/G0tKSiIgI3n//fQAsLCzYsGED7733Hk2bNsXCwoLnn3+eH374weBYqtKlbTNy8gqYuSiBzJx8gut5M2viBzjebqVKv5Wtc8VUXi5n+sJ/SE2/hYWZGW2aRPD1iMHYWFV0AWRk5TDy+/+Rm1+Eva01jUIDWfj9GBwMHG5CeXIv5ZY2GHfsh4m1Haq0FErnfgVFmiR8qa0TqnvyACVOHsj8Qij57YtKy5PYOGAUokkeN3/3e533Sn4dj+qy/iEYqhJX35WcknJmJV4iq6iMYGdrZvSIxtHCFID0gtJKV5spOUUcTctjVs9ovcv8Ji6cafsuMnrTafJL5bhbm/FOiwBeCL//TQaV4msURE5hCbPWHiAzv4hgL2dmvt1Tm+iellOoc1HyRlxTJBKYsWY/GXmF2FuZExPmz7BnW2rLhPu68sPgbvy0ah+z1x/E09GGj3u3pXtT/S2xVcbWNJScgmJmrdilic3bhZnv9dUmGqdl5+vG1r01EmBGwg4ycguxt7YgJjKQYc89oy1TUFLGtH+2czOnAFtLMzo2CmZY/DMYGz14N/4dXZqFkVNQxMyE7WTmFRLs7crMD17C8Xa3Y3p2nk73WLlCwYzl20i9lYOFmQltIurz1eDnsLEwbDy0h3Xq7Hlef3ek9u/J02YD0KtrLF+N/fCRrDMu3IecolJmbTtJZmEpwW52zHylnTYJPy2vSKeV6I2YMCQSCTO2niSjoAR7C1Nigj0Y1qGi0rz0kCZ3c/DcrTrrmtirmbZSV+P4/u3HbZMGmuN29R4y84s1x+2w5yuOjZx8JHfta5qBUmHGqj2aY8PKnJiIegzr2UZb5tO+HZixag+T/txMdkEJzraWPN8mkje7tay0/sflaWt0k6jvl7X+/0xqaire3t5s3ryZjh071nU4daLsnP4xu/4tFPN+rOsQqiVxM2yQxMdJEhRa1yFUz/zBuoceF4nM+P6F6ogsuO5+GGtCsWleXYdQLXXmrboOoUqS0Oi6DqFa5h2HPPJ1TPJ9pVaWM+rKwlpZzqP2xLZ81dTWrVspLCwkIiKCtLQ0PvnkE/z8/IiJianr0ARBEARBAFRPWdvX//vKl1wuZ/To0Vy6dAlra2tatWrFokWLMDZ++Cvcq1evEhpadUvDmTNnDBqKQhAEQRCeRiLn6/+ZuLg44uLiHsmyPTw8dB5DpO99QRAEQRCEu/2/r3w9SkZGRgQGBt6/oCAIgiAIVXq6Oh1F5UsQBEEQhDomuh0FQRAEQRAeIzHCvSAIgiAIgvDIiJYvQRAEQRDqlBhqQhAEQRAE4TF6uqpeottREARBEAThsRItX4IgCIIg1Clxt6MgCIIgCMJj9LTlfIluR0EQBEEQhMdItHw9hVSXj9V1CNWSRkXUdQjVUiYerusQqiSzsanrEKqlzsmp6xCqJe3Ut65DqJJi07y6DqFaRp1eq+sQqqVM3lfXIVTNyr6uI6hzT1e7l6h8CYIgCIJQx0TOlyAIgiAIwmMkcr4EQRAEQRCER0a0fAmCIAiCUKeernYvUfkSBEEQBKGOPW05X6LbURAEQRAE4TESLV+CIAiCINQp9VPW8SgqX4IgCIIg1CnR7SgIgiAIgiA8MqLlSxAEQRCEOvW0jfMlKl+CIAiCINSpp6vqVYvdjgMGDCA+Pr62FifUQEpKChKJhGPHjtV1KIIgCIIg1JBBLV8DBgxg3jzNw12NjY3x8fHh1VdfZfTo0fz444+o1U9G3XXChAkkJCTUaqVl7ty5DBw4kLi4ONavX6+dnpubi729Pdu2baNdu3a1tr5HZcnOE8zbeoSs/GKCPJ0Y2SeGCF+3Kssv3HaMpXtOkp5TgJ2lObHRgQzv0RJT44pd62ZuIT+u3MueM1colcvxdrJj4ssdCfNxNTy+A8nM251EVmEJQW72jOzehAgvp6rj23uWpYnnSM8rxs7ClNgwH4Z3isbUWAbAX4nnWJp4nhu5hQAEuNgxpF04bYI8DY4NwLhVN4zbxSOxtkeVlkLZP7NRXTuvt6z5218iC6j8EHFF0iFK53wBgCy8BcYtuyDzCkBiaUPxD++junH5gWIDWHLoEvMOnCersJQgV1tGdo4kwsOhyvILEy+w9Mhl0vOLsTM3JbaBB8Pbh2FqpNl+h69mMm//eZLSc7lVWMoPzzenQ7DHA8VmFNkOoyadkFjYospMRb5tCaqbKXrLmvYZgcwruNJ05eWTlK2YDoDF+//TO2/5rr9RHN5ocHxL1u1gbsImMnPzCfLzYtTgvkTU99NbVq5QMmf5BlZu209Gdi5+Hq683z+eNo3C9Jafs3wDPy5cwcvd2zNy0AsGxwawJPE88/Ykab5bNztGdm1MhJdjleUX7ktm6aELt48NE2JDvRneMUp7bMzZdYYtSamkZOZjaiQjytuJ9ztF4ef06B7efujYSX5fvIwzZy9wKyubHyeNo2NMq0e2vqos2XKQeev3kplXSJC3K5++3JWIevrPCXKFkjlrd7NqzwkycvLxc3Pi/Rc60joisPbiWb+beau2kplbQJCvB5++3puIQN+q40nYzKodB8nIzsPPw4X3X36W1tEh2jJ/bdzDXxv3cONWNgABXm682SeONg1D9C7zcRDdjvfRpUsXfv/9d8rKyli7di3vvPMOxsbGjBo16lHE90QxMjJi8+bNbNu2jfbt29facsvLyzExMam15VVlw5FzTPlnF2P6tSfC141FO44xdOZKVox9BQdri0rl1x5K5qdVe5nwUkei/N25kpHL+EWbkQAf9W4LQH5xKQOmLqNpfS+mv90DBytzrmTkYWNuZnh8J1OYsu4IY3o2I8LLiUX7zjJ03jZWvNcDB6vKy1t7/DI/bTrKhPgWRPk4cyWrgPHL9yGRwEddGwPgamPB8M7R+DhagxpWHr3E+4t3suTtrgS62hkUn1FUG0x6vk7Z37NQXj2HSdsemL8xgeLJQ1EX5lUqXzL3GyRGFYegxMIa8xE/oji+p2KaiRnKlCQUx/dg1neYQfHca8OZVKZsOcmYLtFEeNiz6OBFhi7Zy4o3O+FgaVqp/NrT1/hp22kmPNuIKE8HrmQXMn71Ec32i43UfAa5giAXW+KjfBnx94EHjk0W1ATjmD6Ub12MKv0yxg07YvrccErmjYeSgkrly1b9DLK7tp2ZJWavjENx/rB2WvHsj3XX4ReOSaf+KM8fMTi+9bsP8d3vfzPuzReJCPJj4eqtvPX5NFZOm4CjnXWl8tMXr2TNzkTGv/0y/p5u7Dl2hg8mz2b+1x8RUs9bp+yp8yks3bibIN8Hq/ADbDh1lSkbjjLm2SZEeDqyaH8yQxduZ8Ww7vqPjRMp/LT5OBN6NSPK20lzbCQcQIKEj7o0BOBwSgb9mgYS5umIUqVi2pYTvL1gO8vf6Ya5yaPJWCkpKSU4sB7Pde/M+6O/fCTruJ/1iaf5/s+NjO3fnYh6nizadIC3f1jEiq/fwdHGslL56f9sY82+k4wf8Cz+bk7sPX2RD6b/xbzRAwnxdX/4ePYe5fv5CYx94wUi6vuyaM0O3v7qf6yYOgpHWz373pK1rNl1mPFv9sXf04W9x5P54LvfmfflcEL8vQBwcbDlvZeexcfdGbVazaodB3lv8hz+nPwhgd4PH/ODEHc73oepqSlubm74+vry9ttvExsby8qVKyt1O6pUKiZNmoS/vz/m5uZERUWxbNky7fvbt29HIpGwYcMGGjZsiLm5OR06dCAjI4N169YREhKCjY0NL730EsXFxdr5ysrKGD58OC4uLpiZmdGmTRsOHjxYablbtmyhSZMmWFhY0KpVK5KTkwFNC9XEiRM5fvw4EokEiUTC3LlzAU0r1eDBg3F2dsbGxoYOHTpw/PjxGm8bS0tLXn/9dT799NNqy508eZIOHTpgbm6Oo6MjQ4YMobCwUPv+nW351Vdf4eHhQXCw5go/MTGRhg0bYmZmRpMmTTh69GiNY6uJBduO0btVGPEtQglwd2Bs3/aYmRiRsP+M3vLHL6cRXc+dbk2C8XS0oVWID10a1+fU1ZvaMr9vPoybnRWfvxxLhK8bno62tArxwdvZ1vD49p6ld5NA4hsFEOBiy9gezTAzlpFw5KL++K5lEu3jTLcofzztrWgV6E6XCF9OpWZpyzzTwIu2QZ74Otrg62TDu52isTAx4mRqpsHxGT/TC/mBjSgObkF98xplf89CLS/DqGms/hlKClEX5GpfsqBokJehOFFR+VIc2Y58058oz9d8P6zKgsQL9I72Iz7KlwBnG8Z2jcbMSEbC8RS95Y+nZhPt5Ui3MG887SxpVc+VLqFenLqRoy3TJsCNYe1CH7i16w6jRrEoTu1GeWYv6uw0yrcsQq0oxyisilaPsmIozte+ZL6hIC9Hea6i8nX3+xTnIwuIQnXtHOp8w7/b+au28nyn1sR3bEmAtzvj3nwRc1MTErbu1Vt+9Y5EBj/fhbaNw/Fyc6JflxjaNApj/srNOuWKS0oZNXUuE95+GRuryhc4NbVg31l6NwogvmE9zbHxbFPMjI1IOHpJb/nj17KI9nGiW6Sf7rFxveLYmNm/Hb0a1iPQxZZgN3s+j29OWl4xZ25kP3Cc99O2ZVOGD3mN2GdaP7J13M+CDfvoHdOI+LbRBHg6M/bV7piZGJOwS//5ds3eEwzu3oa2kfXxcrGnb/smtIkMZP6G/bUTz+rt9O7Ykvj2zQnwcmPsGy9gZmJCwjb9Fztrdh1i8HOxtG0UiperE307t6ZNwxDmr9quLdOuSThtG4Xi6+6Mn4cL777YHQszU06cv1IrMT8IdS39e1I8dM6Xubk55eXllaZPmjSJ+fPn8/PPP3P69Gk++OADXnnlFXbs2KFTbsKECUyfPp29e/dy7do1+vbty9SpU1m8eDFr1qxh48aNTJs2TVv+k08+4e+//2bevHkcOXKEwMBA4uLiyM7WPSGMGTOGKVOmcOjQIYyMjHj99dcB6NevHx9++CFhYWGkpaWRlpZGv379AHjhhRe0lb/Dhw/TqFEjOnbsWGnZ1ZkwYQInT57UqWjeraioiLi4OOzt7Tl48CBLly5l8+bNDBum26qxZcsWkpOT2bRpE6tXr6awsJBnn32W0NBQDh8+zIQJE/joo49qHNf9yBVKkq5l0Dy44qpcKpXQPNibE5fT9c4T5e/OmWsZnLyieT81M4/dZ67QJrSiOXzHycuE+rjy0W/raD/6V/p9+wd/7z31YPHdyKZ5vYouUKlUQvMAN05c0/9jGuXtxJkb2dqKVGp2AbvP3aBNkP6KglKlYv2JFErKFUR6OxsWoMwIqWcAynN3VZLUapTnjyPzrdw9po9Rs1gUx3ZBeZlh664BuVJFUlouzf0qPpdUIqG5vzMnruvfv6O8HDiTnsvJ2z+2qTlF7L6YTpuAqruhH4hUhtTFB9W1pLsmqlFdPYvUvV6NFmEU1hrluUOgqHwuAsDCGplfBIrTuw0OTy5XkHTxKi0iK75HqVRK88gGHE/W3wVcLldgYqzbOmRmYszRJN0Lha9++ZO2jcNpEdXA4Li08SmUJN3IoXm9im58qVRC83qunLjrQuNuUd6OnLmRw8nb76dmF7L7fBpt6lfd6lFYKgfA1vzRt8LXFblCSdKVNFqE+munSaUSWoT6c+Jiqt55yhXKSt+1qbExx85frYV4FCRdSqVFRNBd8UhpEVGfE+f0V5TK5QpM7mmZNDUx5liy/oq4UqVi3Z4jlJSVERXk99AxCzXzwG3HarWaLVu2sGHDBt59911u3bqlfa+srIyvv/6azZs307JlSwDq1avH7t27+d///sczzzyjLfvll1/SurXmKmfQoEGMGjWKixcvUq+e5qTbp08ftm3bxsiRIykqKmLWrFnMnTuXrl27AvDLL7+wadMm5syZw8cfV3QzfPXVV9r1fPrpp3Tv3p3S0lLMzc2xsrLCyMgIN7eKH5Hdu3eTmJhIRkYGpqaaLpjvv/+ehIQEli1bxpAhQ2q0XTw8PHjvvfcYM2aM3hsQFi9eTGlpKfPnz8fSUtOEPX36dHr06MG3336Lq6vmBGppacmvv/6q7W6cPXs2KpWKOXPmYGZmRlhYGKmpqbz99tvVxlNWVkZZme6PuapcjqmJsc60nKISlCo1jvd0LzpaW5ByMwd9ujUJJreolIFT/wY1KFQqXmgdzuDOTbVlUrPyWbr7JK+0j2ZwpyacunqTyX/vxFgmo2fzmucX5BSXaeK7pwvF0cqMlMx8/fFF+ZNbXMbAXzeBWo1CpeaFpvUZ/Ey4Trnz6Tm8+stGyhVKzE2M+OGlGAJcDGuZk1jaIJHJUBfm6kxXF+QidfG67/xS7/rI3P0o+2u6QeutqZziMpRqNY73dC86WpqRklWod55uYd7kFpczcP5OAM32a+jP4NY1q0zWlMTcColUhrpYt3tRXZyP1OH+FT2pqx9SJ0/KN82vsoxRSEuQl6K8YHhrcU5BIUqVCkc73VwnRztrLl+/qXeeVg1DWLBqK41D6+Pt5sSBE8ls2X8Mpariynzd7kMkXbrGH5NHGhyTTnzF5Zrv9t5jw7KaYyPST/Pd/rYFuH1sNAlkcIz+nDSVSs13648S7e1kcHf8kySnoFhznrmne9HRxpLLafov8lqFB7Bg434aB/vg7ezAgaRLbD2SpPNdP3A8+UW39z3d7kVHO2su38jQH09UAxas3k7jkAC8XR05cOo8WxNPoFTpduydv3qD/mN+pFyuwMLMhP9+9DoBXrV8YWUA0e14H6tXr8bKygozMzO6du1Kv379mDBhgk6ZCxcuUFxcTKdOnbCystK+5s+fz8WLuld+kZGR2v+7urpiYWGhrXjdmZaRodnJLl68iFwu11bWQJP436xZM5KS7r5q1l2uu7vmau7OcvQ5fvw4hYWFODo66sR8+fLlSjHfz8iRI7l16xa//fZbpfeSkpKIiorSVrwAWrdujUql0naNAkREROjkeSUlJREZGYmZWcUJ9k7FtjqTJk3C1tZW5/Xdn5sM+jxVOXg+lTkbDzH6hXb88Uk/fhjUjV1nUpi9PlFbRqVW08DLmeE9WtHA25k+rcPp3TKMZXsMb/0yOL7LN5mz8zSjn23KH2935YcXY9h17jqzt53UKefnZMOfQ7uxYEgcfZvW57O/93Exo3KO1qNk3CwW5Y2UKpPz68LBK7eYszeZ0V2i+eP19vzwfHN2XUxn9u6zdR2aDll4a1S3UqtMzgdNy5jibCIoFY8lppGvv4CPuzO9hk+kcd/hfP3rn/Tq0BKpVAJAemY2385ZyjfvD6h0IfQ4HLx8kzm7zjC6e2P+eDOOH/q1Yde5G8zeof+4nLT2MBcycvm2z+NPfv+3++TFOHxdHYgfPZMmQ75k0sL19GodjVQiqZt4Bj6Hr5sz8e9PoslLHzNpzt/0atcMqUT3597Pw4W/vvuIhV+/zwudWzNuxmIupurv5XgcnrZuR4Nbvtq3b8+sWbMwMTHBw8MDI6PKi7iTv7RmzRo8PXWTSO+0Kt1hbFxx4pFIJDp/35mmUhleJ753uUC1yyksLMTd3Z3t27dXes/Ozs6gddvZ2TFq1CgmTpzIs88+a9C8d9xdOXsYo0aNYsSIETrTVDvmVCpnb2mOTCohq6BYZ3pWQTFOepLtAWau2U/3psH0bqW5Wq7v4URJuZwvlmxjcOemSKUSnG0sCXDTvZvO39WBzccNq9DaW5hq4iss1Y2vsBQnK3P98W05Tvcof3o30dx1VN/NnpJyBV+sPMDgZ8K1P4TGRjJNwj0Q6unI6evZLN53lnG9mtc4PnVRPmqlEomVnc50ibUd6nz9LYdaJqYYRbelfMPiGq/PUPYWpsgkErKKdFtBs4pKcdKTbA8wc0cS3cO96R3tB0B9F1tK5Aq+WHuMwa2Da+3HRV1SiFqlRGKhe3UvsbBBXXSfSrCRCUZBTZHvW1llEalHIFIHN8rW/vJA8dlbWyGTSsnK1W1FysotwMlO/51/DrbW/PjpW5SVy8ktKMLFwZapCxLwctXcmXvm4lWy8wro99E32nmUKhWHz1xgybodHPrzJ2Syml0b21uYaL7be4+NomqOjW0n6R7lR+/GAQDUd7XTHBurDjK4bZj22ACYtOYwO89d57eBHXG1ffC8tCeBvbWF5jyTX6QzPSu/CCdbK73zONhYMvXdfpTJFeQWFuNiZ83UZVvwdLZ/+HhsLG/ve7qtwtXuezZWTP1kkGbfKyzCxd6WqYtW4+mqex42NjLCx02ThhBaz5vTF6+yaO1OPhvS96HjFu7P4JYvS0tLAgMD8fHx0VvxAggNDcXU1JSrV68SGBio8/L29tY7T00EBARgYmLCnj0VCclyuZyDBw8SGhpa4+WYmJigVCp1pjVq1Ij09HSMjIwqxezkVPVQBlV59913kUql/PjjjzrTQ0JCOH78OEVFFQf3nj17kEql2sR6fUJCQjhx4gSlpRUn2P3775/QaWpqio2Njc5L35W2sZGMEG8XEs9V5DWoVGoSk68R6a+/Kbq0XFHpB1gq1exSd65Aouq5k5KhW/m4cisXd/vKd+lUx9hIRoiHA4mXKq7MVCo1iZfSifTW//2UypV64pPoxKePSq2mXGlghV+pQHX9IrL6FS2uSCTIAiNRXkmuej7AKLI1GBkjP7Kj2nIPw1gmJcTdjsSUivQAlVpNYsotIj31DzVRqtCz/W7/XaujyqiUqDKuIvW+uxtagtS7Aao0/Xkqd8iCGoPMCMXZqu+0NApvjfLmFdSZ+nN27sfY2IiQAB8OnKj4HlUqFQdOJBMV7F/NnJpcG1dHOxRKFZv3H6NdU83+0TyyAX//dyx/TRmtfYUF+NA9pil/TRld44oX3Dk27Em8XNEFqjk2bhJZxVATmmNDd9q9x4ZarWbSmsNsPZvK7Nc64Gmvv/Lx/4mxkYwQX3cOJFXk8qlUag4kXSYyoPr0AVNjI1ztbVAoVWw5nET7hkHVlq9ZPEaE1PPiwKlzd8Wj4sCp80QG6R9qQhuPiTGuDpp9b8uBE7RvUnlYm7upVGrk8sfTMqx3/bX0elI8kvuFra2t+eijj/jggw9QqVS0adOGvLw89uzZg42NDa+99toDLdfS0pK3336bjz/+GAcHB3x8fJg8eTLFxcUMGjSoxsvx8/Pj8uXLHDt2DC8vL6ytrYmNjaVly5bEx8czefJkgoKCuHHjBmvWrOG5556jSZMmBsVqZmbGxIkTeeedd3Smv/zyy4wfP57XXnuNCRMmcOvWLd5991369++vzffS56WXXmLMmDG88cYbjBo1ipSUFL7//nuDYrqf/u2jGbdwM6HeLoT7urJo+zFKyhX0aq6p2I5dsBEXWyuG99R0PcSE+7Nw21EaeDkT4efK1Vt5zFyzn5hwP2S3K2GvtItmwH+X8evGg3RuWJ9TV27y995TjOvXwfD4WjVg3PJ9hHo6Eu7pyKJ9ZykpV9KrkaabeuyyvbjYmDO8s+ZW+ZhgTxbuTaKBuz0R3k5czSpg5pbjxAR7auP7aeNRWgd54GZrSXGZnHUnUjiUcpOZrxoen3zHCkz/8x6q1Asor57HpG0PJCZmKA5q7nAz/c/7qPOyKF+3QGc+42axKE4dgOLKQypgboXU3hmJjaaCJHXWtCSrC3JQF+QaFF//ZoGMW3WYUHc7wj3sWZR4kRK5kl6RmpP42JWHcLE2Z3h7TUtmTKAbCxMv0MDVjghPe67mFDFzZxIx9d2Q3f6hLi5XcDWnImfsel4xZ2/mYmtmgrsBrSSKI5sx6TwA1c0UVOkpGDXqiMTYBMUZzd2EJp0HoC7KRb4nQWc+o7DWKC8eg9KiygsFMDFDVr8x8p36b4CpqVd7dGDstPmEBvoSUd+Xhau2UVJWRnwHTdf/6B/n4upox3uvxANw4txlMrJzaeDnzc3sXGb9uQaVWsXA5zoBYGluRn1f3Rs/zM1MsbWyrDS9Jvq3bMC4f/YT6uFAuKcDi/afo0SuoFfD28fG8v2aYyM2CoCYIA8W7kumgZs9EV6OXM0uZObWk8QEe2iPja/XHGbdyStMfbEtliZGZBaUAGBlZoyZ8aMZaqK4uISrqTe0f1+/cZOz5y5ia2ONu5vLI1nnvfrHtWTcrwmE+XkQ7u/Bwk0HKCmTE98mGoAxvyTgYm/Ne306AnDiYioZuQU08HYjIzefWSt2oFKpGdC1du7Y7P9sO8bNWExYPW/CA31ZuHYHJWXlxLfTtMyPmb5IO3QEwInzV8jIzqOBnwcZ2XnMWroBlVrFgF4V57QfF6+mTXQIbk72FJeWsnb3EQ6ducisMW/WSswPQvWEjBNaWx7Z44W++OILnJ2dmTRpEpcuXcLOzo5GjRoxevToh1ruN998g0qlon///hQUFNCkSRM2bNiAvX3Nm3iff/55li9fTvv27cnNzeX3339nwIABrF27ljFjxjBw4EBu3bqFm5sbMTEx1VaKqvPaa68xZcoUzpypGKrBwsKCDRs28N5779G0aVMsLCx4/vnn+eGHH6pdlpWVFatWreKtt96iYcOGhIaG8u233/L8888/UGz6xDUKIqewhFlrD5CZX0SwlzMz3+6Jo43mRzQtp1DbhQvwRlxTJBKYsWY/GXmF2FuZExPmz7BnK3LRwn1d+WFwN35atY/Z6w/i6WjDx73b0r2p4UnbcRF+5BSVMWvLcTILSwl2t2fmq+1xvN21kpZXhOSuy/k3nglHAszYcpyM/BLsLU2JCfZkWGy0tkx2URlj/95HZkEJVmbGBLnaM/PVDrQMNHysG8Xx3UisbDCJe0kzyOqNy5T8OlE7xpfU3gmVWvfaTOLsiaxeGOX/+0zvMo3CmmH2n/e0f5v119xUUr7xD8o3LjEovrhQL3KKy5i1M4nMojKCXW2Z2a+VNlE7Lb9E9/ttE6z5fneeIaOgBHsLU2ICNUNL3HE6LYc3FlXcQThlsyafrkeED1/0aFzj2JTnDiE3t8K4ZU8kFjaoMlMpS/hJWyHVVD51T84Se1dknvUpXT61yuXKgpoCEhTJiVWWqYkubZqQk1/IzD9Wk5mbT7C/F7PGDdMm4adn5mhbfQHK5XKmL15F6s1MLMxMadMojK/few0by0fTbRcX7kNOUSmztp3UHBtudsx8pV3Fd5tXxN2NmG/EhCGRSJix9WTFdxvswbAOFS23Sw9dAGDw3K0665rYq5m2UlfbTp09z+vvVtyAMHnabAB6dY3lq7EfPpJ13qtLszByCoqYmbCdzLxCgr1dmfnBSzje7nZMz87T6ZYtVyiYsXwbqbdysDAzoU1Efb4a/Bw2FoaPZag3nlYNNfveX+s1+56fJzNHv6lNwk/PzNFpoS6Xy5mxZC2pGVmafa9hCF8Nexkby4ou6Oy8QsbOWMStnHysLMwJ8nVn1pg3aRlZuzfTCFWTqJ+UYemFWlOy4dHcUVdr8h7dOEK1QZl4+P6F6ogsou5GqK4Jdc598t/qmKzTvzffRXViZ12HUC2jTg/Wo/G4KJP31XUIVbN6+PywR8ksqtsjX8crvr1rZTkLryyvleU8auLB2oIgCIIg1Kmn7fFCtfZg7f/vwsLCdIaguPu1aNGiug5PEARBEIQnhGj5qqG1a9cil8v1vvegOWGCIAiCIFR/B/r/R6LyVUO+vtXf1isIgiAIwoN5koaJqA2i8iUIgiAIQp0SOV+CIAiCIAjCIyNavgRBEARBqFMi50sQBEEQBOExetpyvkS3oyAIgiAIwmMkKl+CIAiCINQptVpdK68HMWPGDPz8/DAzM6N58+YkJlb9OLJffvmFtm3bYm9vj729PbGxsdWWr4qofAmCIAiCUKdUqGvlZag///yTESNGMH78eI4cOUJUVBRxcXFkZGToLb99+3ZefPFFtm3bxr59+/D29qZz585cv37doPWKypcgCIIgCE+lH374gTfeeIOBAwcSGhrKzz//jIWFBb/99pve8osWLWLo0KFER0fToEEDfv31V1QqFVu2bDFovSLhXhAEQRCEOlVbCfdlZWWUlZXpTDM1NcXU1LRS2fLycg4fPsyoUaO006RSKbGxsezbV7MHsRcXFyOXy3FwcDAoTlH5ehrlZtV1BNUrLqrrCKoldTbsIHus3LzqOoLqVdGU/2+hyrhc1yFUSZ15q65DqJYyuWY/VnVFFtyyrkOokmJ/Ql2HUL2obo98FbU11MSkSZOYOHGizrTx48czYcKESmUzMzNRKpWVHhHo6urK2bNna7S+kSNH4uHhQWxsrEFxisqXIAiCIAj/L4waNYoRI0boTNPX6lUbvvnmG5YsWcL27dsxMzMzaF5R+RIEQRAEoU7V1uOFqupi1MfJyQmZTMbNmzd1pt+8eRM3N7dq5/3+++/55ptv2Lx5M5GRkQbHKRLuBUEQBEGoU3Ux1ISJiQmNGzfWSZa/kzzfsmXV3dSTJ0/miy++YP369TRp0uSBPq9o+RIEQRAEoU7V1Qj3I0aM4LXXXqNJkyY0a9aMqVOnUlRUxMCBAwF49dVX8fT0ZNKkSQB8++23fPbZZyxevBg/Pz/S09MBsLKywsrKqsbrFZUvQRAEQRCeSv369ePWrVt89tlnpKenEx0dzfr167VJ+FevXkUqregknDVrFuXl5fTp00dnOVUl9VdFVL4EQRAEQahTdflg7WHDhjFs2DC9723fvl3n75SUlFpZp6h8CYIgCIJQp2or4f5JIRLuBUEQBEEQHiPR8iUIgiAIQp160IdiP6lE5UsQBEEQhDoluh0FQRAEQRCER+axVL4GDBhAfHz841jVU0cikZCQkFDXYQiCIAjCA1PX0r8nRa11Ow4YMIB58+YBYGxsjI+PD6+++iqjR4/mxx9/fGL6cydMmEBCQgLHjh2rtWUqlUq+++475s6dy5UrVzA3N6d+/fq88cYbDB48uNbWU1uWHDjHvD1JZBWWEORqz8jujYnwcqqy/MK9Z1l68DzpecXYWZgSG+bN8NhoTI1lAMzZeZotZ66RkpmPqbGMKG9n3u8cjZ+TTe3Ee/gS8w5cIKuojCAXG0Z2iiTCw77qeA9eZOnRy6Tnl2BnbkJssAfD24ViaiR76FiMGnbAqHlXJJa2qDKuIt+8CFWa/oc1m744EplPg0rTlRePU7ZsKgAm3QZhFNFG9/1LJylb+sMDxbdk5wnmbT1CVn4xQZ5OjOwTQ4Rv1Y/RWLjtGEv3nCQ9pwA7S3NiowMZ3qMlpsaaU0fXCXNJyy6oNF/fNhGM7tvOoNiMGnbAqGmX29vuGvIti1ClV7Ht+n1S9bZb/qP2b4mDO8bP9EHmHQwSGaqsG5SvmIG6INug2ACWbD/CvI0HycovIsjLhZH9OhLh715l+YVbDrF05zHSswuwszIntmEQw5+L0W47pUrFz6v3subAGbLyi3C2taRny3De6NYSiURicHx/nrjGvKNXySouJ8jJipExQYS72uotO3j5YQ7fyK00vY2vI9N6RANQXK7gp30X2XbpFnmlcjxszHgxypsXwmvn4e1Lthxk3vq9ZOYVEuTtyqcvdyWinqfesnKFkjlrd7NqzwkycvLxc3Pi/Rc60joisFZiqalDx07y++JlnDl7gVtZ2fw4aRwdY1o98vUu2X2KeduPk1VQQpCHIyOfa02Ej0uV5RfuPMHSvWdIzynEztKM2Kh6DO/WTLvvAdzMK+LH1fvZc/YapeUKvJ1smfifdoR5Oz/yz6OP6gmpI9SWWs356tKlC7///jtlZWWsXbuWd955B2NjY0aNGlWbq3niTJw4kf/9739Mnz6dJk2akJ+fz6FDh8jJyanr0CrZcPIKU9YfYUyPpkR4ObFo31mGzt/GiuE9cLCq/ODQtSdS+GnzMSbEtyDK24krWQWM/2c/EuCjro0BOJySQb/mQYR5OqBUqZm26Thvz9vK8nefxdzk4XbBDUnXmbL1NGPiNBWuRQcvMfTPfawY0hEHy8rP91p7OpWftp9hQreGRHk6cCWnkPFrjiCRSPioY/hDxSJr0AzjDv+hfON8VDcuYdykE6Z9P6Tkl1FQXLmCUvbPdJBVVPgk5laYDfwcxdmDOuWUl05QtnZOxQSF4oHi23DkHFP+2cWYfu2J8HVj0Y5jDJ25khVjX8HB2qJS+bWHkvlp1V4mvNSRKH93rmTkMn7RZs1327stAIs+7IdKXTE29YW0LN6asYJODQ37UZQFN8W4XT/KNy1AlXYJ48adMH1hBCVzRuvfditm6G47MyvMBkxEkXyoYpqdM2YvjUJxchele1ZAeQlSR0/USrlBsQFsOHSWKcu2M+alTkT4ubNo62GGTlvKigmDcLCxrFR+beIZfvpnJxNe7UJUPU+uZGQzft46JBL46IUOAPy+IZGlO47x+YCuBLg7ceZKOuPnr8PK3JSXOjQ2LL7zN5my+zxj2jUg3M2GxceuMXTlMRJebomDhUml8lO6RSJXVnxveaVy+i1JpFNgxQ/6lN3nOXg9h686heFhY8a+q9lM2pGMs6Up7fwf7gd6feJpvv9zI2P7dyeinieLNh3g7R8WseLrd3DUsz2n/7ONNftOMn7As/i7ObH39EU+mP4X80YPJMS36gpwbSspKSU4sB7Pde/M+6O/fCzr3HD0AlNW7mNMn7ZE+LiyaNcJhs5ew4qR/8HB2rxS+bVHzvPTmkQm9HuGKD83rtzKZfyS7ZrjtpemophfXMaAaQk0DfRg+hvdcLA040pmHjbmlfcV4dGo1W5HU1NT3Nzc8PX15e233yY2NpaVK1dW6nZUqVRMmjQJf39/zM3NiYqKYtmyZdr3t2/fjkQiYcOGDTRs2BBzc3M6dOhARkYG69atIyQkBBsbG1566SWKi4u185WVlTF8+HBcXFwwMzOjTZs2HDx4sNJyt2zZQpMmTbCwsKBVq1YkJycDMHfuXCZOnMjx48eRSCRIJBLmzp0LQG5uLoMHD8bZ2RkbGxs6dOjA8ePHa7RdVq5cydChQ3nhhRfw9/cnKiqKQYMG8dFHH2nL+Pn5MXXqVJ35oqOjdUbMPX/+PDExMZiZmREaGsqmTZtqtH5DLNh7lt6NA4hvFECAiy1jezTDzNiIhCMX9ZY/fvUW0d7OdIv0w9PeilaB7nSJ8OXU9YqWhZmvtqdXw3oEutgR7GbP571bkJZXzJkbhrc+VIo38QK9o3yJj/QlwMmGsV2iMDOWkXDiiv54r2cT7eVAtzAvPO0saOXvQpcQL06lPXxF2KhpZxTHd6I8uRt11g3KN8xHLS/HKKKt/hlKi6AoX/uS+YWBvBxlsm7lS61Q6JSjrFj/8u5jwbZj9G4VRnyLUALcHRjbtz1mJkYk7D+jt/zxy2lE13OnW5NgPB1taBXiQ5fG9Tl1teIhtA7W5jjZWGpfO0+l4O1kS5NA/S0YVTFqEofixE6Up25vu423t124gdvuXMW2M27TG+WlE8h3LEWdcRV17i2UF4/prczdz4LNh+jdOpL4VhEEeDgx9qXOmBkbk7D3lN7yxy/eIDrAk27NQvF0sqVVqD9dmoZwKiW9osyl67SLCiQmIgBPJ1s6NQ6mZagfp1LSDI5v4bGr9A7zpFeoBwEOVoxp3wAzIxkJSTf0lrc1M8bJ0lT72n8tGzMjKZ0CXSviS8/j2QbuNPGyx8PGnOfDPQlysuL0zXyD47vXgg376B3TiPi20QR4OjP21e6YmRiTsOuo3vJr9p5gcPc2tI2sj5eLPX3bN6FNZCDzN+x/6FgM0bZlU4YPeY3YZ1o/tnUu2HmS3i1CiG/WgAA3e8Y+H6M5Jyee1Vv+eMpNov1c6daoPp4O1rQK9qZLw0BOXb2lLfP71mO42Vnx+X/aE+Hjojm+g73xdtLfUvo4qGvp9aR4pDlf5ubmlJeXV5o+adIk5s+fz88//8zp06f54IMPeOWVV9ixY4dOuQkTJjB9+nT27t3LtWvX6Nu3L1OnTmXx4sWsWbOGjRs3Mm3aNG35Tz75hL///pt58+Zx5MgRAgMDiYuLIztb90d+zJgxTJkyhUOHDmFkZMTrr78OaB4z8OGHHxIWFkZaWhppaWn069cPgBdeeEFb+Tt8+DCNGjWiY8eOlZatj5ubG1u3buXWrVv3LVsVlUpF7969MTEx4cCBA/z888+MHDnygZenj1yhJCktm+YBFd1QUqmE5gFunEjN1DtPlI8zZ9KyOXn7/dTsQnafu0Gb+h5VrqewVNPyYPuQV1lypYqk9Dya+1VchUslEpr7OXPiuv7KVJSnA2fSczl5Q/N+am4Ruy/dpE09V73la0wqQ+rmh+rK6bsmqlGlnEHqWbNWIKPIGJRJB0Cue8zIfBpgPuxHzAZ/jXHn/mBWuWXgfuQKJUnXMmge7F0RslRC82BvTlxO1ztPlL87Z65lcPKK5v3UzDx2n7lCm1DfKtex9lAyvVqEGNZtJpUhdfNFdeXuSqAa1ZUzSD0CarQIo4i2KM8m3rXtJMgColDl3MS0zwjMh07F9OWxyAIb1jyu2+QKJUlX02keUvG5pVIJzUN8OXFJf+UmKsCDM1dvcvKypiKVeiuX3acu0Sa8XkWZep4cOHuFKzc155Dk1AyOXrhO67B6epdZZXxKFUkZBTT3dqiITyKhuZc9J9LzarSMhDM3iKvvirlxRWtilJstOy7fIqOwFLVazcHUbK7kFtPirvU8CLlCSdKVNFqE+lfEK5XQItSfExdT9c5TrlBiYqzbSm5qbMyx81cfKpZ/O7lCSVLqLZrXr7iYkUolNA/y4sSVm3rnifJz5UxqJievZgCQmpXP7qSrtAmpOPZ3nEkh1NuZj+Ztov34efSbsoy/9yc92g9zHyrUtfJ6UjySoSbUajVbtmxhw4YNvPvuuzqVjrKyMr7++ms2b96sfWp4vXr12L17N//73/945plntGW//PJLWrfWXGEMGjSIUaNGcfHiRerV05yc+vTpw7Zt2xg5ciRFRUXMmjWLuXPn0rVrVwB++eUXNm3axJw5c/j444+1y/3qq6+06/n000/p3r07paWlmJubY2VlhZGREW5uFRWQ3bt3k5iYSEZGBqammq6s77//noSEBJYtW8aQIUOq3R4//PADffr0wc3NjbCwMFq1akWvXr20cdbE5s2bOXv2LBs2bMDDQ1Ox+frrr++7jLKyMsrKynSmqeQKnb7/O3KKy1Cq1Dha6nYvOlqakXJL/9Vut0g/covLGDhnM6jVKFRqXmgayOBnwvSWV6nUfLfuMNE+zgS62lUb+/3kFJehVKtxvKd70dHSlJQs/a0b3cK8yC0pY+DCXQCaeBv6MbhV0EPFIrGwRiKVoS7S3U7q4jykjlXnVN0hdfdH6uxF+brfdKYrL59Eee4wqtxMpPbOGMc8j/SFEZQt/BIMyJHIKSrRfLf3dC86WluQclN/RbVbk2Byi0oZOPVvUINCpeKF1uEM7txUb/mtJy5RUFJGz+YhNY4LQGJ+e9sV37vt8pE63L9LSep2e9ut/71ioqU1EhMzjJt1Q757OeU7lyLzi8Ak/h3KlkxGlXquxvHlFN7edjZ6tl26/ouvbs1CyS0sYeD3iyu2XUwUg7u20JZ5Pa45RaVlxE+Yg0wiRalWMaxXW7o3D61xbAA5JXKUajUO91zMOFqYkJJ7/1bSUzfzuJBdxPiOut/byGeC+WJrEnFz92AklSABxnUIobFn1fmUNYq3oPj29tS9iHC0seRymv6LvFbhASzYuJ/GwT54OztwIOkSW48koVQ9OT+2DyKnqPT2cavbvehoZU5KRq7eebo1qq85bqevqNj3WoYyOLaRtkxqVgFL957hlWciGNyxIaeuZTD5nz0Yy6T0bBr8KD9SlZ6kilNtqNXK1+rVq7GyskIul6NSqXjppZeYMGEC77zzjrbMhQsXKC4uplOnTjrzlpeX07Ch7lVpZGSk9v+urq5YWFhoK153piUmJgJw8eJF5HK5trIGmsT/Zs2akZSkW6O/e7nu7pqTe0ZGBj4+Pno/1/HjxyksLMTR0VFneklJCRcv6u+Ou1toaCinTp3i8OHD7Nmzh507d9KjRw8GDBjAr7/+et/5AZKSkvD29tZWvABt5bU6kyZNYuLEiTrTRj//DGNfaF+j9d7Pwcs3mbPzNKOfbUKElxPXsgqYvO4ws7efZEi7iMrxrDnIhYw85g7qpGdpj97BK5nM2Xee0XFRRLjbcy2nkMlbTjF7TzJDWtfNSQdAFhmDKuNapeR8ZVJixf8zU1FlpGL+1mSkPg1QXXm0V6oHz6cyZ+MhRr/Qjgg/V67dymPy8p3MXp/IkC7NKpVP2H+G1iG+uNhaPdK47iWLbIvq1jWd5HzJ7UZ95YWjKA5ruucVGdeQegZgFN2ecgMqXw/iYPJV5qzfz+gXOxHh7861jBwm/7WV2Wv2MqS7Ju9m4+GzrE1MYtLrzxLg4UTytQy+W7oVZ1srerZ8uPxDQyScuUF9R6tKyflLjl/j5M18pnaPxN3ajCM3cvnmds7Xw7Z+GeqTF+P4fN5q4kfPRCIBL2cHerWOJmH3sccax5Pg4IUbzNlylNG92xDh68K1zHwmJ+xl9qbDDOmkySVUqdWEejkzvFtzABp4OXExPYdl+87UWeXraVOrla/27dsza9YsTExM8PDwwMio8uILCwsBWLNmDZ6eunkhd1qV7jA2Ntb+XyKR6Px9Z5pKpcJQ9y4XqHY5hYWFuLu7V3rAJoCdnV2N1imVSmnatClNmzbl/fffZ+HChfTv358xY8bg7++PVCqtdEeoXG54YvC9Ro0axYgRI3SmqVZ+p7esvYUpMqmErKJSnelZRaU4WVdOtgeYueUE3aP86d1Y07VW39WOErmCL1YmMjgmHKm0ovtp0uqD7Ey+wW+DYnG1rZzgbSh7C1NkEglZRbote1lFZThZVhHvriS6h3nTO0rThVTfxYYSuZIv1h9ncKsgpA9wlxmAurgAtUqJxFL3Dk6JhW2l1rBKjE0wCmmGfFfC/deTdwt1cQFSO1eDKl/2luaa77ZAtyUkq6AYJz3J9gAz1+yne9NgerfStGLW93CipFzOF0u2MbhzU53v9kZ2PgeSrzFlULcax6T9TCW3t53FvdvOBnXRfbrNjE0watAM+e6EystUKlBl6XYLqrPSkHrVNyg+e6vb2y5fz7bTkxwOMHPVbro3D6N3G82FXn1PZ822W7iRwV1bIpVK+O/yHQyMa0aXpiHaMmnZ+fy2/oBBlS97c2NkEgnZJbrd1VnF5TjqSba/W4lcyYbzN3m7uW5XZ6lCybT9F/mhWyRt/TR3Ogc5WZOcWciCo1ceqvJlb21xe3sW6cabX4RTFRV3BxtLpr7bjzK5gtzCYlzsrJm6bAuezg/XCvdvZ29pdvu4LdGZnlVYgpOeZHuAmesP0r1xfXq3uL1fuTtq9r2luxjcsRFSqQRnGwsCXHW3nb+rHZtPXHo0H6QGnpQREWpLreZ8WVpaEhgYiI+Pj96KF2hagUxNTbl69SqBgYE6L29vb73z1ERAQAAmJibs2bNHO00ul3Pw4EFCQ2vejG9iYoJSqdSZ1qhRI9LT0zEyMqoUs5NT1UMwVOdOTEVFmhOQs7MzaWkVibb5+flcvlxxJR8SEsK1a9d0yuzff/9kU1NTU2xsbHRe+rocAYyNZIS4O5B4qSKXQKVSk3gpncgqhpoolSuQ3lNfuVOBuTPmilqtZtLqg2xNSmX2wA542tdOy4ixTEqImy2JKRXd2iq1msQrt4isomukVK6sHO/tCQ917KuUqNJTkPreva9JkPqFoLp+odpZZcFNQWaM4vTe+65GYm0P5paoi3INCs/YSEaItwuJ5ypyalQqNYnJ14j0198tWlquqFQZlUo1p4x7x9NZsT8JB2tz2ob5GRSXJhAlqvQrSH3v7vaSIPUNQXWj+pZlWdDtbXdmn55lpiB10P1sEgc31HlZBoVnbCQjxMeNxLMVN3GoVGoSz14hsp7+3MaabLvScrmeMhKDb7k3lkkJcbHmwLWKLlCVWk1iag6RbtUnUG+6cJNypZpuQbrduwqVJoXg3msRmQQetqfP2EhGiK87B5Iqzm8qlZoDSZeJDKh+GAtTYyNc7W1QKFVsOZxE+4YPly7wb2dsJCPEy5nE89e101QqNYnnrxPpqz9PVXNOvme/kujue1F+bqTcytUpc+VWHu721rUYvWFEztcjZm1tzUcffcQHH3yASqWiTZs25OXlsWfPHmxsbHjttdceaLmWlpa8/fbbfPzxxzg4OODj48PkyZMpLi5m0KBBNV6On58fly9f5tixY3h5eWFtbU1sbCwtW7YkPj6eyZMnExQUxI0bN1izZg3PPfccTZo0qXaZffr0oXXr1rRq1Qo3NzcuX77MqFGjCAoKokEDzVhFHTp0YO7cufTo0QM7Ozs+++wzZHfdSh8bG0tQUBCvvfYa3333Hfn5+YwZM+aBtlV1+rdqwLh/9hHq4UC4lyOL9iVTUq6gVyPNlfHYv/fiYmPB8E7RAMQEe7Jw31kauNsT4eXE1awCZm49QUywJ7LbPzZfrz7EupMpTH0xBksTYzJvX8VZmRljVkVFsMbxNgtk3OojhLrbEe5uz6JDFykpV9IrUtOFPHbVYVyszRneTlMpigl0Y+HBizRwtSXCw56rOUXM3HmWmEBXZPfWygykOLgRk+6DUaWnoEq7hFGTzkiMTVGc3A2ASffBqAtyke9cpjOfUWQMyvNHNHfw3c3YFOPWvVCeO4S6MA+JvQsm7fqizslAeVn/XXbV6d8+mnELNxPq7UK4ryuLth/TfLe3c4zGLtiIi60Vw3tqusViwv1ZuO0oDbycifBz5eqtPGau2U9MuJ/2uwXNj8HKA0n0aNYAI9mDXc8pDm3ApNudbXcZoyadNNvu1O1t120w6oIc5Lv+1pnPKLKt/m0HKA6ux6THW8hSz6G6ehaZfziygCjKlkw2OL7+sU0YN3ctob5uhPu5s2jrIUrK5fRqpWmhGvv7GlzsrBn+XAwAMREBLNxyiAbeLkT4u3M1I5eZK3cTExmg3XYxv236jgAAUSFJREFUEQH8um4/bg42BLg7kXztJgs3H6JXq8rd9ffzSrQPn20+Q6iLDeGuNiw+fpUShZJeIZpK1dhNp3GxNGV4K92bPxLO3KBdPSfszHV7FaxMjGjsYcfUPRcwk8lwtzHj8PUcVp9NZ0Qbw1oO9ekf15JxvyYQ5udBuL8HCzcdoKRMTnybaADG/JKAi7017/XpCMCJi6lk5BbQwNuNjNx8Zq3YgUqlZkDXx3fXIUBxcQlXUytaU6/fuMnZcxextbHG3a3qcbceRv+YCMYt2U6otzPhPi4s2nlSs+8103QPjl28FRdbS4Z313QhxoT6snDHCRp4OhHh48LVzHxmrj9ITKiPdt97JSaCAdNW8OvmI3SODuDU1Qz+3p/EuD4xj+QzCJXVybMdv/jiC5ydnZk0aRKXLl3Czs6ORo0aMXr06Ida7jfffINKpaJ///4UFBTQpEkTNmzYgL19zZumn3/+eZYvX0779u3Jzc3l999/Z8CAAaxdu5YxY8YwcOBAbt26hZubGzExMbi63v8uubi4OP744w8mTZpEXl4ebm5udOjQgQkTJmhbCEeNGsXly5d59tlnsbW15YsvvtBp+ZJKpfzzzz8MGjSIZs2a4efnx08//USXLl0M31DVxRrhS05xKbO2niCzsJRgN3tm9m+Po5WmiTstr1jnTrY3nglHIpEwY8sJMvJLsLc0JSbYk2Edo7Rllh48D8Dg37forGvicy3o1dCwO7sqxRviSU5xGbN2nSWzqIxgFxtm9muhvWkgLb9EN97WQUgkMGPnWTIKS7C3MCUm0JVhMYYlOeujPJuI3MIa4zbx2kFWy/76AW4nkktsHCs1r0kc3JB5B1H6p56uYLUKqYs3RuGtwcwCdWEuqsunKN/1DygNH+srrlEQOYUlzFp7gMz8IoK9nJn5dk9tInlaTqHutoprqtlWa/aTkVeIvZU5MWH+DHtWN9dwf/I10nIKiG/x4NtQmXxQs+1ax2sHWS1b9t+KbWftAGrd1ACJvRsyryBK//pe/zLPH6F843yMW3RH0uEl1DnplK+Yger6eYPji2vSgJyCYmat2nN727kw890+2qTxtOwC3W3XraVm263cTUbu7W0XGcCwXhVDZ3z6n1hmrNzNpD82k11QjLOtJc+3jeLN7oYP2hlX35WcknJmJV4iq6iMYGdrZvSIxtFCk8qRXlBaqTUkJaeIo2l5zOoZrXeZ38SFM23fRUZvOk1+qRx3azPeaRHAC+GGDSOiT5dmYeQUFDEzYTuZeYUEe7sy84OXcLzd7ZienafTrV2uUDBj+TZSb+VgYWZCm4j6fDX4OWws9KcXPCqnzp7n9Xcr7jKfPG02AL26xvLV2A8fyTrjGgaSU1TKrA2HyMwvJtjTiZlvdNPePJOWe89xG9sICTBj3UEy8oo0+16oD8O6VeRphvu48MPAzvy0JpHZm47g6WDNx71a0b3xw1esH9STNDp9bZCon7aOVoGSPyfev1BdKq7civFvos548CFDHjVJtGGDcz5u6hNH6jqEakmaPPrRyh+U+tS/e9tJGz3eVihDyYLvf4NSXVHsT6jrEKpl/uyI+xd6SE3cqxjTz0CH0nbVynIeNfFgbUEQBEEQhMdIVL5qQVhYGFZWVnpfixYtquvwBEEQBOFfTSTcCwZbu3ZtlcNC1CQnTBAEQRCeZk9bBpSofNUCX1/9j1sRBEEQBEG4l6h8CYIgCIJQp56kLsPaICpfgiAIgiDUqadtqAlR+RIEQRAEoU4Z+mSHJ52421EQBEEQBOExEi1fgiAIgiDUKdHtKAiCIAiC8BiJbkdBEARBEAThkREtX4IgCIIg1CnR7SgIgiAIgvAYPW3djqLy9RSSNGha1yFUS31yT12HUC11fmFdh1AlSUFuXYdQLYmHZ12HUC1Z/eZ1HUKVlCpVXYdQPSv7uo6gWor9CXUdQpWMWsTXdQjCYyYqX4IgCIIg1CnR7SgIgiAIgvAYPW3djuJuR0EQBEEQhMdItHwJgiAIglCnRLejIAiCIAjCY6RW/8tvKKllovIlCIIgCEKdUj1lLV8i50sQBEEQBOExEi1fgiAIgiDUKfVTdrejqHwJgiAIglCnRLejIAiCIAiC8MiIli9BEARBEOrU09btKFq+atmAAQOIj4+vUdmUlBQkEgnHjh17pDEJgiAIwr+ZSq2uldeTQrR8GUAikVT7/vjx4/nxxx9rXIP39vYmLS0NJyen2giv1ixZv5t5q7aSmVtAkK8Hn77em4hAX71l5QolcxI2s2rHQTKy8/DzcOH9l5+ldXSItsxfG/fw18Y93LiVDUCAlxtv9omjTcMQvcusNraDF5i37xxZhaUEudoysktDIjwdqiy/8MB5lh66SHp+MXYWpsSGeDK8QwSmRjIA5uw+y5az10nJKsDUSEaUlyPvd4zAz8na4NgAjJrHYdy2JxIrO1TpVyhf/Ruq1At6y5oNmoCsXlil6YrkI5TNnwRSGcad/oNRUCMkDi6oS4tRXjyJfMMi1AU5DxTfkv3JzNt1mqzCEoLc7Bn5bDMivKve/xbuSWJp4jnSc4uwszQlNsyH4Z0bYWosq1T2tx2n+GnjUV5q1YBPuhv+8PYlB88zb2/y7e/WjpFdGxLh6Vh1bPvPsfTwRdLzirGzMCE2xIvhHSPv+m6T2HI2lZTM29+ttyPvd4zEz8nG4NgA/khYx9y/VpKZnUtwgC+j3h1ERIP6esvKFQp+XfwPKzduJyMzGz9vDz544xXaNGuoLaNUKpk5/y/WbN5FZnYuzo729Iprx5uv9LnvuUafJTuOMm/TIbLyiwjycmZk3w5E+LlXWX7h1sMs3Xmc9JwC7CzNiG0UxPBebTE11vwsKFUqfl6zjzWJZ8jKL8bZ1pKeLcJ4o2sLg+P7N59TAJbsPsW87cfJKighyMORkc+1JsLHpcryC3eeYOneM6TnFGq2XVQ9hndrpt12/9fefYc1dbZhAL8T9t57D2UI4kAt4taKlbrQOutAratWrdZRF3Vb6yhWXJ8girPuvUBFxYGCotQBAg5UFEWw7PV+f6RGYoISqzkn9fldF1fl5ITczSHJw3ve87wA8DSvAKEHLyLu9kMUl5bDztQAs3q3Qh07sw/K+D5Xrt3A+i07cfP2XWS/yEHoghlo26LpJ3ks8u9R8SWHJ0+eiP+9fft2zJw5E3fu3BFv09XVha6ubo1/noqKCiwtLT9qxn/r6PmrWLxxL6Z/9w28azlg86FYjJy3Bvt+/xkmBtIFyYpth3HobAJChveEk405zifdwY+/rceGuWPg4WQLADA3NsDYvl/D3soMjDEciL2MsYvCsX3RBLjaVf/h8LZjfz3EkhPXMa1jA3jbGGPzpVSM2nIW+0YFwFhHU2r/wzceYHnMDfzSyRc+dia4/+JvhOy/AgEE+Km9DwAg4UE2ejVyQR0rI1RUMvxxKhkjt5zF7hHtoaUu38tDxbsp1DsOROm+tah4eBdq/oHQHDQNhcvGAgWvpPYv3rIYApUqj6GtC63Ri1Fx44LoezUNqFg7o/TUTlRm3YdASwfqgcHQ6D8ZxSunyJUNAI5dv4clh69gWpcm8LYzxea4WxgVGYN9P3aGsa6W1P6HkzKw/HgifglqCh97M9x//gohu85DIBDgp46+EvsmZz7HzsspqG1pJHcuADj21wMsOZ6EaYEN3xzbzWew7/uvqjm297E85jp+6dwIPnamomO7L150bAPqAQAS7mejl68r6lgbi47tyRsYufkMdo/sIPexPXoqDr+t3oAZ44ahrnstRO0+hOGT5+JA5HKYGBlI7f9HxFYcij6LkAkj4GRng/NXrmFcyG+IWj4XHrWcAQAR2/biz/3HMW/yaLg42uGvO2mY8VsY9HS00S8oUL7n78ptLNkVi2l92sHb0QqbTyZg1B+7sO+XwTDW05Z+/i7fwvK9Z/FL/wD4OFvj/tOXCIk6Knr+erQCAKw/fhk7zlzD7AFfwcXaBDfvP0VI1FHoammgb+sGNX/uePyeAgDHrt7Fkv0XMK1Hc3jbW2Dz2esYtfYQ9k3uDWM9Ga+LxFQsPxSPX3q1hI+jJe5n5yJk22kIAPzURVTsvCoswaA/9qKRqzVWfNcRxjqauP88D/pa6nJlk0dRUTHcXJ3RLbA9xk2d+8ke51P53Drc02lHOVhaWoq/DAwMIBAIJLbp6upKnXasrKzEokWL4OrqCg0NDdjb22PevHkApE87nj59GgKBADExMfD19YW2tjaaNm0qUeABwKpVq+Di4gJ1dXW4ubkhKirqo/0/Rh08jaC2fujauglcbC0x/btvoKmujr2nLsnc/9DZKxjarR2aN/CErYUperb3R7P6Hth44LR4n1a+XmjewBMOVmZwtDbHD30Coa2pgeup9+XLdjEFQfWd0LWeI1zM9DE9sAE01VSw99o9mfsnZb5APTsTdPS2h42hDpq6WKKDlx2SH+eI91nZtzm6+DjC1dwAbpaGmN25EZ7kFeLmE/lHltT8v0b5lRiUJ54Gy85E6b61YGWlUGvYRvYdivLB8nPFXyqudYGyEpQn/1N8lRSieP0cVCRfAHv+GJUPU1F6IBwqNi4QGMg/WhoVdxNBvrXQtaErXMwNMb3LF6LnLyFN5v5J97NRz94cHX2cYGOki6a1rNGhriOSM59L7FdYUoapf57DzK5+0PvAD5eoCykIauCMrvWc4GJmgOmBDaGppoq9VzNkZ8t8gXp2pujo7VDl2NpLHtt+LdClntObY9vlw4/txp0H0L1jO3Tr0AYujnaYOW4YtDQ0sOfoSZn7H4w+g6F9u6FFkwaws7ZAr84BaN6kPjbsOCDe59pfd9C6aSO0+KIhbCzN0b6lH5r6+uDGbdkjpe8SdTIBQf7e6OrnBRcrE0zv8yU01dWw9/wNmfsnpT9GPRcbdGzkARsTAzT1dEQHX3ck338isU+ruq5o4e0MGxMDfNmgNvw8HJF8L0u+bDx+TwGAqDM3EPSFB7o2doeLpRGmd28h+t2Lvy1z/6R7T1HP0QIdG9SCjbEemrrZoUN9VyQ/yBbvs/7kNVga6mJ279bwtjeHjYk+mrrZwc5UulD/WJr7NcKYYQPRrqX/J3uMT4kx9lG+lAUVX5/Yzz//jIULF2LGjBm4efMmtmzZAgsLi3feZ9q0aViyZAmuXLkCVVVVDB48WHzbnj17MHbsWEyYMAHJyckYPnw4goODcerUqX+dtay8HLfSM/GFd23xNqFQiC+8a+F6iuw3tdKycqi/NYqgoa6Ga3fSZe5fUVmJI3GJKCopgU9tx5pnq6jErSe5aOL05lSAUCBAEycLXM98IfM+PrYmuPkkFzceiT6QM1/m41xqFpq5Vj/amF9SBgAwkLeIUFGF0NoZFXevv9nGGCruXofQvnb196tCrWFblN84D5SVVL+TpjZYZSVYcYFc8crKK3DrcQ6aVPl/FwoFaOJqhetVPjSq8nEww83HL3DjoajYysz5G+dSHqFZbRuJ/eYfiEdzNxt84SrfiIM4W0UFbj15iSZOb14XomNr/p5j+xI3Holuz3yZj3N3n3ySY1tWVoabKen4okHdN/mEQnzRwBtJN+/IvE9paRk01CUfR0NdHVeT33yg16vjhktXb+Dew8cAgDtp95B447bEqcka5SuvwK0HT9HEzb5KPgGauNvjesYTmffxcbbGzQdPceOe6PbM57k4l5yBZnWcJfa5dOcB7j8VvX7uZD7D1bRH8K/jJEc2/r6niPJV4FZmNprUevM7LRQK0KS2La7ffyrzPj6OFriZ+Rw3HjwDAGS+eIVztx6gmYedeJ/Ym/fgaWeGnzacQOuQDei1ZCd2XbwlVzby30anHT+hv//+G6GhoVixYgUGDhwIAHBxcUGzZs3eeb958+ahZcuWAIApU6YgMDAQxcXF0NTUxOLFizFo0CCMGjUKADB+/HhcvHgRixcvRuvWraV+VklJCUpKJD/MWWkZNNTVpPZ9+aoAFZWVMDGUPBVgYqiHjMfPZGZt6uOOqIOn0dDDBXYWJriUnIqT8ddRUSm5Tlfqg8foPy0UpWXl0NZUx7KfBsPFtuanXF8WlqCCMZjoSp6CMtHRwL3n0qf0AKCjtz1yi0oQHCkqTMsrGb5p6IyhzWTPC6lkDL8dv4Z6diZwNZfvL1SBth4EKipg+XkS21l+HoRmNtXc6w2hrSuElvYo2bOq+p1U1aAe8C0qrscBJUVy5XtZWIKKSgaTt04vmuhq4l52nsz7dPRxQm5BMYL/dwxgTPT8Na6Noa28xfscvZ6B249zsHlkR7nySGYrFR1bHQ3JbDqauPf8b9nZvB2QW1iC4PWnAPyTraELhjb3lLl/JWP47dg11LMzlfvYvsz7W/S6eOv0oomRITIePpJ5n6aN6mHjzgNoWNcTdtYWuJh4AzHnLkm8Lob06Yb8wiJ0Dh4LFaEQFZWVGDO4D75u10K+fPlFomOrryOZT08b957myLxPx0YeyM0vQvCSbQADyisr8U1zHwzt0ES8z+D2jVFQXIKus9dDRSBEBavE6E7NENi45vOq+PyeAgAvC4pFz53e268LLdx7livzPh0b1BK9Llbse/Pc+XliaLs3p2IzX/yNHedv4tuW3hjatj6SHz7Doj1xUFMRonMjN7kyfi4+tz5fVHx9Qrdu3UJJSQnatm0r1/3q1n3zF7aVlWg04dmzZ7C3t8etW7cwbNgwif39/f0RGhoq82ctWLAAs2bNktg2bXhfTB/ZT65M1ZkU3A2zV29H13ELIBAIYGthgi6tGmPvqXiJ/RytzfHnbz8hv7AYJy4mYUbYFoTPGi33m6U8Lt97hvBztzG1YwN4Wxvj4ct8LDp2DWvP3MSwFtIf0guOXMXdZ68QOajVJ8tUHdWGbVCZdb/ayfkQqkCj93hAAJTs/59CMl1Oz0J4bDKmdhJNyn/44m8sOnQZa09qYVibusjKLcCig1ewenA7mRPwP2m2qsfW5p9je/Qa1p75C8NaSF/EsOBwIu4+y0NkcDWngD+yKd8H45clq9E5eCwEAOysLdEloDX2Hn0zQn3s9HkcijmLX6eOhYujHe6k3cOvYethZmKMLgGtPmm+yykPEX7sEqb2bgtvRys8zM7Foh2nsPbwBQzr6AcAOJ54B4fjb2FBcCBcrExwJzMbv+08BTNDXXT+Qvo5/lj4/J4CAJfvPkZ4zFVMDWoGbwdzPHz+Cov2nsfaEwkY9mVDAKJi39PWDGM6iopZd1tTpGW9xM4LN6n4qoYynTL8GKj4+oS0tKQna9aEmtqbUanXVxVVVn7Yiu8///wzxo8fL7GN3ZF9itJIXwcqQiFe5EqONrzI/RumhrKvEDPW18Xvk4agpLQMufkFMDcywO+bD8LGQvIKRDVVVdhbiq7y8XS2w19pD7D58BnMHNazRv8fRtoaUBEI8CK/WDJbQQlMdaUnZAPAytN/IbCuA4Lqi06T1LIwQFFpOeYcSsTQ5h4QVrlia8GRqziT+gQRA1rBQl96gvL7sMK/wSoqINCVHB0R6BqA5ee++85qGlCt64/S6O2ybxeqQKPPeAgMTVEcPkvuUS/gn+dPKMCLfMn7vsgvhqmMyfYAsDI6CYH1nBHUSHRFXy1LIxSVlWPO3osY2sobNx+/QE5BMfqEHRLfp6KSIfHeU2y/eAfxs/pCRfj+mQ1G2uqiY1sgOUL7oqC4+mN7Kll0bBuITpPVsjBEUWkF5hy8gqHNPd86tok4k/oYEQNbf9CxNTLQE70uXkqOEL54mQsTY0OZ9zE2NMDyOZNRUlqK3Ly/YW5qjGX/2wRbqzenzZesjcKQ3l3xVRvRSHhtZwc8fpqNdVt3y1V8GelqiY7tK8lT0S/+LoTpW6Nhr608EIfAxp4I8hf9oVfLxgxFJWWYs+UEhnb4AkKhAMt2xyI4oDE6+LqL93mS8woRxy7VuPji83sKABjpaIqeu7/ffl0UwVTGZHsAWHn0MgIb1kLQF6IRwFpWJigqLcOcHWcxtG0DCIUCmOlrw8VC8uITJwtDRF+XfeqUQKnaRHwMNOfrE6pVqxa0tLQQExPz0X6mh4cH4uLiJLbFxcXB01P26RYNDQ3o6+tLfMk65QiI3sw8nG1xKTlFvK2yshKXklNRt7bsy8LFj6OuBgtjQ5RXVCLm0nW09vV+5/6VlQxlZeXv3Ecim4oQHlaGiL/35lRFJWOIz3iGuray2xEUl1VI/YILhaIP5devc8YYFhy5ipN3HmHtty1gYyT7w+q9KspR+TgdKi5V/r8FAqi4eKPyQUr19wOg6uUHqKii/NoZ6Rv/KbyEJpYojpgDFOV/UDw1VRV4WBsjPu3NZOnKSob4tCzUtZd96XtxWblEEQNA/D0DQxMXK+wc8zW2jw4Uf3namKCjjxO2jw6sUeEFAGoqKvCwMkJ8xps5Nu89tuUVEL7V7eDNsWXi/y44koiTtx9hbf9WsDGq+ZXIEvnU1OBZ2xmXrr6ZvF5ZWYmLV2/Ax/Pdoxga6uqwMDNBeUUFos9eQuumb1pwFBeXQPjWc6QiFIJVyvchpKaqAg97C8TfeVAlH0P8nQeo6yR7Hl5xaZn0sRW+ObZA9cdfnnh8fk8R5VOBh60Z4lPfnD6urGSIT32Eug6y5+bKfl5Ex/H1c+fjaIl72bkS+9zPzoOV0Ye1sCH/PTTy9Qlpampi8uTJmDRpEtTV1eHv74/s7Gz89ddfGDJkyAf9zIkTJ6Jnz56oX78+2rVrhwMHDmD37t2Ijo7+KJn7f90KM8K2oI6zHbxcHbDpcCyKSkrRtZVo+Hzais3iy7wB4HrqfTzLyYO7ozWe5eRh1Y5jqGSVGNTlzemd0C0H0ayeByxNjVBYXIzD5xJx5WYaVk0bLl+2L2pjxr7L8LQygpe1MTbHp6KorBxdfBwBANP3xsNcTwtj2orepFvUtsKmi6lwtzSCt40xHrzMx8rTf6FFbSuo/PNBM//IVRxJfojfezWFjoYanv8zsqaroQZNOU+llcUdhEb371H5KA0VmXeh1jQQAnUNlCWIRhrVe4wGe5WDsuNbJO6n6tsGFbcuSxdWQhVo9J0AoZUTSqIWQiAUArqGAABWlA9UyPdB09/fEzN2xcHTxgRetqbYfP4WikrL0aWhi+j52xEHc30tjAkQzV1p4W6LTXG34G5tBG9bUzzI+Rsro5PQwt0WKkIhdDSEcH3rr3stdVUYaGtIbX9vNr/amLE3Hp7WxqJjeylFdGzriUYtp++99M+xFY3UtKhlhU0XU94c25x8rDyVjBa1rcVF3/wjiThy4wF+7+UPHQ1VPP9n1E90bOV76xvQoxOm/boCdWq7wNvdFVG7DqGouARdA0TzLKcuXA5zUxOMGyo6nX/9VgqePc+Bm4sTnj1/gVUb/0Qlq0Rw767in9nSzxdrN++ClbkpXBztcPtuBjbuPIiuHaTnbr73+WvTEDM2HoWngyW8HCyx+VQiikrK0MXPS/T8RR6BuaEuxnRtLnr+vF2w6WQC3O3M4e1ohQfZL7Hy4Hm08HYWP38tvF2w7uglWBrpw8XaBHcePsOmkwnin1njbDx+TwGA/i28MWPbaXjamcHL3hybz9xAUWkZujQWFdbTt5yEuYEOxgSK8rbwdMCm2OtwtzGFt705Hjx/hZVHL6OFp734ufu2hTcG/bEP66IT0b6eC5IfPMOui7cwo4d88/nkUVhYhAeZj8XfP3r8FLdT0mCgrwcry+p7lvEFnXYkH9WMGTOgqqqKmTNn4vHjx7CyssKIESM++Od17doVoaGhWLx4McaOHQsnJyesX78erVq1+ih5OzStj5ev8rHyz6N4nvsKbo42WDl1uHjCbNbzlxJ/9ZWWlSFs22FkPnsBbU0NNKvvgXmj+0Ff582QfU5ePqaHbUb2y1fQ1dZCbQcrrJo2HH515Zv7EFDHDi8LS7Aq9iae5xfDzcIAK/s2E0/Cf/KqUKL543fNPSCAAGGnk/Hs7yIYaWugRW1rjG795pTJjgTRaYChG2MlHmtWZ19xUVdTFTfOo1RHH2pte0FdzxCVT+6hOHIeUCA6XSU0MJUaWheYWkPF0QNFEXOkfp5A3xiqHqKREq0fFkvcVrQuBJUZN+XKF1DXES8LirEqJgnP/y6Cm5URVg5qI56E/ySvAFX/oP+ulTcEAMJOJOHZq0IY6WighbstRn8p39V4NcpWxx4vC0qw6nTyP8fWECv7tnhzbPPeOrYtPCEQCBB2quqxtcLoNm9GR3ZcEbXQGLrxtMRjzercSFzU1VSH1v7IyXuFsMhteP4yF+4ujli9cBpM/znt+OTZcwgEb0axSkrL8EfENmQ+eQptLU00b1If86eMgb7um5HVqT8MwYr12zA39H/IyX0FMxMj9Pj6S4zs30OubAAQ4OuOl/lFWHUwDs9fFcLN1gwrR3cXT8J/8vIVBFWGCkWNUoGwA3F4lpsPI10ttPB2xujOby4GmtKzDcIOxGHB9mjk/F0EMwMddG9WF8P/mRNW4+eOx+8pABBQ31X0ujh2RfTc2Zhi5XcdYfJPf7QnufmSv3vtGoheF0cu41legei587TH6I6Nxft42ZtjaXB7LD8Uj7UnEmFjrIeJXZoisKHsprwfQ/LtVAz+YbL4+0V/rAUAdPmqHeZNn/DJHvdj+dwm3AvY51ZuEhQnHeY6wjuxG3Hv34lDlbfefRqRS8L6PlxHeLeSd7TR4AGVljWfL6RoFXcucB3hnQSmtlxHeCf2UHbfLj5Q/aIr1xHeSc3U+f07/UsGui4f5efk5cvuW8g3NPJFCCGEEE59buNAVHwRQgghhFN0tSMhhBBCCPlkaOSLEEIIIZz63BbWpuKLEEIIIZyi046EEEIIIeSToZEvQgghhHCKrnYkhBBCCFEgmvNFCCGEEKJAn9vIF835IoQQQshnKywsDI6OjtDU1ESTJk0QHx//zv137NgBd3d3aGpqwtvbG4cPy79qDBVfhBBCCOEUY+yjfMlr+/btGD9+PEJCQpCYmAgfHx8EBATg2bNnMvc/f/48+vTpgyFDhuDq1avo2rUrunbtiuTkZLkel4ovQgghhHCKfaQveS1duhTfffcdgoOD4enpidWrV0NbWxsREREy9w8NDUWHDh0wceJEeHh4YM6cOWjQoAFWrFgh1+NS8UUIIYSQ/4SSkhK8evVK4qukpETmvqWlpUhISEC7du3E24RCIdq1a4cLF2QvZH/hwgWJ/QEgICCg2v2rxQj5F4qLi1lISAgrLi7mOopMfM7H52yMUb5/g8/ZGKN8/xaf8/E5myKEhIRIDYiFhITI3PfRo0cMADt//rzE9okTJ7LGjRvLvI+amhrbsmWLxLawsDBmbm4uV04BY5/ZJQbko3r16hUMDAyQl5cHfX19ruNI4XM+PmcDKN+/wedsAOX7t/icj8/ZFKGkpERqpEtDQwMaGhpS+z5+/Bg2NjY4f/48/Pz8xNsnTZqE2NhYXLp0Seo+6urq2LBhA/r06SPetnLlSsyaNQtPnz6tcU5qNUEIIYSQ/4TqCi1ZTE1NoaKiIlU0PX36FJaWljLvY2lpKdf+1aE5X4QQQgj57Kirq6Nhw4aIiYkRb6usrERMTIzESFhVfn5+EvsDwIkTJ6rdvzo08kUIIYSQz9L48eMxcOBA+Pr6onHjxvj9999RUFCA4OBgAMCAAQNgY2ODBQsWAADGjh2Lli1bYsmSJQgMDMS2bdtw5coVrF27Vq7HpeKL/CsaGhoICQmp8TCvovE5H5+zAZTv3+BzNoDy/Vt8zsfnbHzUq1cvZGdnY+bMmcjKykK9evVw9OhRWFhYAAAePHgAofDNScKmTZtiy5YtmD59OqZOnYpatWph79698PLykutxacI9IYQQQogC0ZwvQgghhBAFouKLEEIIIUSBqPgihBBCCFEgKr4IIYQQQhSIii9CCCGEEAWiVhPkg9y8eRMPHjxAaWmpxPbOnTtzlIh8bjIzMwEAtra2HCdRLtnZ2bhz5w4AwM3NDWZmZhwnIv9WbGwsFi9ejFu3bgEAPD09MXHiRDRv3pzjZKQ61GqCyCU9PR3dunXDjRs3IBAI8PrXRyAQAAAqKiq4jCeBCsT/nsrKSsydOxdLlixBfn4+AEBPTw8TJkzAtGnTJPrxcK24uFjqd4/LtfYKCgrwww8/ICoqSvw6VVFRwYABA/DHH39AW1tb4ZmuX79e433r1q37CZPItn///hrvy9X7yqZNmxAcHIygoCD4+/sDAOLi4rBnzx5ERkaib9++nOQi7yHXMtzks/f111+zLl26sOzsbKarq8tu3rzJzp49yxo3bszOnDnDdTzGGGNpaWmsbt26TCAQMKFQyAQCgfjfQqGQ63jVunv3LmvdujVnj//48WMWFRXFDh06xEpKSiRuy8/PZ7NmzeIo2RtTpkxhZmZmbOXKlSwpKYklJSWxsLAwZmZmxqZOncp1PFZQUMC+//57ZmZmJv59q/rFpWHDhjFnZ2d2+PBhlpeXx/Ly8tihQ4eYi4sLGzFiBCeZqr5GZT1fXD93r987qr6HvP0918fW3d2dLV26VGr7kiVLmLu7OweJSE1Q8UXkYmJiwpKSkhhjjOnr67Pbt28zxhiLiYlh9erV4zKamDIUiLJcu3aNszfx+Ph4ZmhoyPT19ZmWlhZzdXVlycnJ4tuzsrI4Lx4YY8zKyort27dPavvevXuZtbU1B4kkjRo1inl4eLCdO3cyLS0tFhERwebMmcNsbW3Zpk2bOM1mYmLCTp06JbX95MmTzNTUVPGBGGP37t0Tf+3Zs4e5uLiw1atXiwvr1atXs1q1arE9e/Zwkq+qEydOsAYNGrCjR4+Ki9ejR48yX19fdvz4cc5yqaurs9TUVKntqampTENDg4NEpCZozheRS0VFBfT09ACIVoR//Pgx3Nzc4ODgIJ5HwrULFy7g5MmTMDU1hVAohFAoRLNmzbBgwQKMGTMGV69e5STX8uXL33n7o0ePFJRE2tSpU9GtWzesW7cOBQUFmDx5Mlq2bIkTJ06gfv36nOV6W05ODtzd3aW2u7u7Iycnh4NEkg4cOICNGzeiVatWCA4ORvPmzeHq6goHBwds3rwZ/fr14yxbYWGheMmUqszNzVFYWMhBIsDBwUH872+++QbLly9Hx44dxdvq1q0LOzs7zJgxA127duUg4Rvjxo3D6tWr0axZM/G2gIAAaGtrY9iwYeL5VopmZ2eHmJgYuLq6SmyPjo6GnZ0dJ5nI+1HxReTi5eWFpKQkODk5oUmTJli0aBHU1dWxdu1aODs7cx0PAH8LxHHjxsHKygrq6uoyb397fpAiJSQkICwsDEKhEHp6eli5ciXs7e3Rtm1bHDt2DPb29pxlq8rHxwcrVqyQKmRXrFgBHx8fjlK9kZOTI34d6OvriwvCZs2aYeTIkVxGg5+fH0JCQrBx40ZoamoCAIqKijBr1iz4+flxmg0Abty4AScnJ6ntTk5OuHnzJgeJJKWlpcHQ0FBqu4GBAe7du6fwPK9NmDABY8aMwbVr19C0aVMAojlfkZGRCA0N5SwXeQ+uh96Icjl69CjbtWsXY0w0rO3m5sYEAgEzNTVlMTExHKcTadasmfg0RZ8+fViHDh3YuXPn2IABA1idOnU4y+Xo6Mi2b99e7e1Xr17l7NSekZGR+HRyVb/99hszNDRku3fv5sVpx9OnTzMdHR3m4eHBBg8ezAYPHsw8PDyYrq4uL04pe3t7s9OnTzPGGGvbti2bMGECY4yx0NBQZmNjw2U0duPGDWZtbc1MTExYmzZtWJs2bZiJiQmzsbGROMXMlfr167P+/ftLzDcsKSlh/fv3Z/Xr1+cwmUjz5s3Zl19+ybKyssTbsrKyWPv27VmLFi04TMbY7t27mb+/PzM2NmbGxsbM39+f7d27l9NM5N3oakfyr+Xk5MDIyEh8xSPXjh07hoKCAgQFBeHu3bv4+uuvkZKSAhMTE2zfvh1t2rThJFePHj3g4uKCX3/9VebtSUlJqF+/PiorKxWcDGjRogX69u2LESNGSN22aNEizJw5E2VlZby4mvXx48cICwvD7du3AQAeHh4YNWoUrK2tOU4GLFu2DCoqKhgzZgyio6PRqVMnMMZQVlaGpUuXYuzYsZzmKywsxObNmyWeu379+kFLS4vTXAAQHx8vfr5eX9l4/fp1CAQCHDhwAI0bN+Y03927d9GtWzekpKSIT+c9fPgQtWrVwt69e6VO+xHyLlR8kc8CHwrEmzdvorCwEL6+vjJvLysrw+PHjyXmwSjKunXrEBsbi6ioKJm3//rrr1i9ejUyMjIUnEy53b9/HwkJCXB1deWkVYKyKSgokCoO+/btCx0dHY6TiTDGcOLECYl87dq148UfnqWlpXj27JnUH298mTJAJFHxRd4rKCioxvvu3r37EyZ5v7KyMmhpaeHatWvw8vLiNAv5OK5fvw4vLy8IhcL39oWiAufdoqKisGbNGqSnp+PChQtwcHDAsmXL4OzsjC5dunCWq6ysDO7u7jh48CA8PDw4y6GMUlNTMXjwYJw/f15iO2MMAoGAF6PVRBpNuCfvZWBgIP43Ywx79uyBgYGBeAQnISEBubm5chVpn4qamhrs7e3pDec/pF69esjKyoK5uTnq1asn0dy3Kr580MTExCAmJkbmKERERARHqYBVq1Zh5syZGDduHObOnSt+royMjPD7779zWnypqamhuLiYs8evidmzZ7/z9pkzZyooiaRBgwZBVVUVBw8ehJWVFS9G4cj70cgXkcvkyZORk5OD1atXQ0VFBYDo6sJRo0ZBX18fv/32G8cJgfDwcOzevRtRUVEwNjbmOg4AoEGDBoiJiYGRkRHq16//zjfIxMREBSbjdzZAdOrO3t4eAoEA9+/ff+e+XJyyrWrWrFmYPXs2fH19ZX4Q7tmzh6NkoiVn5s+fj65du0JPTw9JSUlwdnZGcnIyWrVqhefPn3OWDQDmz5+PlJQUrFu3Dqqq/BsXeLvlSllZGTIyMqCqqgoXFxdOXhsAoKOjg4SEBJktWAh/8e83nPBaREQEzp07Jy68ANESJePHj0fTpk15UXytWLECd+/ehbW1NRwcHKTmi3DxJtmlSxdoaGgAAOf9it7G52yAZEHFdXH1PqtXr0ZkZCT69+/PdRQpGRkZMnu2aWhooKCggINEki5fvoyYmBgcP34c3t7eUq9brqc0yOoP+OrVKwwaNAjdunXjIJGIp6cn54UzkR8VX0Qu5eXluH37Ntzc3CS23759m5Or9GThYwEREhIi8998wOdsb1uwYAEsLCwwePBgie0RERHIzs7G5MmTOUomUlpaKu61xDdOTk64du2aVAF79OhRXsyzMjQ0RPfu3bmOIRd9fX3MmjULnTp14qzg/vXXXzFp0iTMnz8f3t7eUFNTk8pI+IeKLyKX4OBgDBkyBGlpaeJLvy9duoSFCxciODiY43QifC8gXuPz1Ul8zbZmzRps2bJFanudOnXQu3dvzouvoUOHYsuWLZgxYwanOWQZP348vv/+exQXF4Mxhvj4eGzduhULFizAunXruI6H9evXcx3hg+Tl5SEvL4+zx2/Xrh0AoG3bthLbacI9v1HxReSyePFiWFpaYsmSJXjy5AkAwMrKChMnTsSECRM4TicpISFBvORHnTp1eLNMTkpKCoYMGcLLq5P4nA0AsrKyYGVlJbXdzMxM/PvIpeLiYqxduxbR0dGoW7eu1CjE0qVLOUomKgy1tLQwffp0FBYWom/fvrC2tkZoaCh69+7NWa63ZWdni1eicHNzg5mZGceJRN5eVYExhidPniAqKgpfffUVR6mAU6dOcfbY5MPRhHvywV69egWAf8Paz549Q+/evXH69GnxciC5ublo3bo1tm3bxvmbub+/P1RVVTFlyhSZk7K5XCaHz9kAoFatWggJCcG3334rsT0qKgohISFIT0/nKJlI69atq71NIBDg5MmTCkxTvcLCQuTn58Pc3JzrKGIFBQX44YcfsHHjRvGIq4qKCgYMGIA//vgD2tranOZ7e+kjoVAIMzMztGnTBj///LN4STNCaoKKL/Kf06tXL6Snp2Pjxo3iuSw3b97EwIED4erqiq1bt3Kaj89XJ/E5GyDqtr9o0SL89ttv4pUKYmJiMGnSJEyYMAE///wzxwn5q6ioCIwxcRFz//597NmzB56enmjfvj3H6YDhw4cjOjoaK1asgL+/PwDg3LlzGDNmDL788kusWrWK44T8Qb3vlB8VX+S93td+oCquLreuysDAANHR0WjUqJHE9vj4eLRv3x65ubncBPtHo0aNsGzZMjRr1ozTHLLwORsgOtUzZcoULF++XLwQuaamJiZPnsxZn6XqZGZmAgBsbW05TiLSvn17BAUFYcSIEcjNzYWbmxvU1dXx/PlzLF26lPOFv01NTbFz5060atVKYvupU6fQs2dPZGdncxOsGvfv30dBQQHc3d0hFAoV+thCoVDc+04oFPK+9x2RptjfGKKUunbtii5duqBLly4ICAhAWloaNDQ00KpVK7Rq1QqamppIS0tDQEAA11EBAJWVlVJzbQBRI0c+XJH5+uqk06dP48WLF3j16pXEF2WrnkAgwK+//ors7GxcvHgRSUlJyMnJ4U3hVVlZidmzZ8PAwAAODg5wcHCAoaEh5syZw/nvXmJiIpo3bw4A2LlzJywtLXH//n1s3LhRaj4TFwoLC2FhYSG13dzcHIWFhRwkEomIiJCaqzds2DA4OzvD29sbXl5eePjwoUIzZWRkiKdPZGRkID09HRkZGVJfXJ+GJ++gmPW7yX/FkCFD2PTp06W2z5w5kwUHB3OQSFrnzp1ZixYt2KNHj8TbMjMzWcuWLVnXrl05TCYiEAiYQCBgQqFQ4uv1NsqmvKZMmcLMzMzYypUrWVJSEktKSmJhYWHMzMyMTZ06ldNsWlpa7P79+4wxxr755hv2yy+/MMYYe/DgAdPS0uIyGmOMsTZt2rBvvvmGFRUVibcVFhayb775hrVt25azXE2aNGERERHi748cOcJUVVXZpk2bWEJCAvPz82NDhgzhLB9RTnTakcjFwMAAV65cQa1atSS2p6amwtfXl9NLrl97+PAhOnfujL/++gt2dnbibV5eXti/fz/np4FiY2PfeXvLli0VlEQan7MBoknZCxcurHb5Hq7/0re2tsbq1avRuXNnie379u3DqFGj8OjRI46Sieb+DB06FN26dYOXlxeOHj0KPz8/JCQkIDAwEFlZWZxlA4Dk5GQEBASgpKREfGFHUlISNDU1cezYMdSpU4eTXCYmJjh9+jS8vb0BACNHjkR2djZ27twJADh9+jSCg4M5W3Se773viGzUaoLIRUtLC3FxcVLFV1xcHDQ1NTlKJcnOzg6JiYmIiYkRt5rw8PAQ98PhGtcFzLvwORsgapcQGxuL/v3783Idu5ycHJkXK7i7uyMnJ4eDRG/MnDkTffv2xY8//oi2bdvCz88PAHD8+HFetGHx8vJCamoqNm/ejNu3bwMA+vTpg379+kFLS4uzXEVFRRJXdJ8/fx5DhgwRf+/s7Mxp4cr33ndENiq+iFzGjRuHkSNHIjExUaLJanh4OC/m3VRWViIyMhK7d+/GvXv3IBAI4OTkBAMDA3GvKr4oLCzEgwcPxBPHX+PD1Ul8zXbkyBEcOnRIfDUc3/j4+GDFihVSc6hWrFjBeZuOHj16oFmzZnjy5IlElrZt23K6PE5V2tra+O6777iOIcHBwQEJCQlwcHDA8+fP8ddff0n8/mVlZcHAwICzfHzvfUdko+KLyGXKlClwdnZGaGgoNm3aBEC0ttiGDRs4X6KEMYbOnTvj8OHD8PHxgbe3NxhjuHXrFgYNGoTdu3dj7969nGYERE0kg4ODceTIEZm3c3l1Ep+zAYCRkRFvFkuXZdGiRQgMDER0dLR4ZOnChQt4+PAhDh8+zHE6wNLSEpaWlhLbXv8RxZUzZ87UaL8WLVp84iSyDRw4EN9//z3++usvnDx5Eu7u7mjYsKH49vPnz8PLy4uTbIBopD8uLk6qD1lcXBysra05SkXeh4ovIreePXuiZ8+eAESNVrdu3YrffvsNCQkJnH44R0ZG4syZM4iJiZFqdnny5El07doVGzduxIABAzhKKDJu3Djk5ubi0qVLaNWqFfbs2YOnT59i7ty5WLJkCWV7hzlz5mDmzJnYsGED5003ZWnZsiVSUlIQFhYmPnUWFBSEUaNGcfZBGBQUVKP9uFq4+u3WElW9HqkWCAQoLy9XUCJJkyZNQmFhIXbv3g1LS0vs2LFD4va4uDj06dOHk2wA8N1332HcuHEoKyuT2fuO8BNNuCcf5MyZMwgPD8euXbtgbW2NoKAgdO/eXaq3liK1b98ebdq0wZQpU2TePn/+fMTGxuLYsWMKTibJysoK+/btQ+PGjaGvr48rV66gdu3a2L9/PxYtWoRz585RtmrUr18faWlpYIzB0dFRqqUIH/rM8U1N11zlam3F6i7SKSwsRGhoKJYvXw5nZ2ckJycrONmH2bp1Kzp37gwdHR2FPB5Tot535A0a+SI1lpWVhcjISISHh+PVq1fo2bMnSkpKsHfvXnh6enIdD9evX8eiRYuqvf2rr77iRT+jgoIC8bIuRkZGyM7ORu3ateHt7c158cDnbICo5xzfvK/DeFVczJmTt6jKzMyEtbW1whqHvj1fqrKyEhEREZg1axaEQiHCwsIwcOBAhWT5GIYPH44mTZrA2dlZIY/3uvfdjBkzcOvWLWhpaaFWrVrQ0NBQyOOTD0PFF6mRTp064cyZMwgMDMTvv/+ODh06QEVFBatXr+Y6mlhOTo7MJo2vWVhY4OXLlwpMJJubmxvu3LkDR0dH+Pj4YM2aNXB0dMTq1atlTpylbG+EhIRwHUFKvXr1qu0wXpWydBv39PTEtWvXFFY8VLV7925MnToV2dnZ+Pnnn/HDDz8oXRHB1ckkXV1dTs88EPlQ8UVq5MiRIxgzZgxGjhwp1WaCLyoqKqCqWv2vtIqKCmfzRqoaO3as+CqkkJAQdOjQAZs3b4a6ujoiIyMpm5Lhqr/Tp8JF8RAbG4vJkyfjxo0bGDt2LCZPnszpFYR8FxQUhMjISOjr6793Th9Xc/nIu1HxRWrk3LlzCA8PR8OGDeHh4YH+/fujd+/eXMeSwBjDoEGDqv1LuaSkRMGJZPv222/F/27YsCHu37+P27dvw97eHqamphwm42c2Y2NjpKSkwNTUFEZGRu9sF8JFLy0HBweFP+Z/SceOHREdHY3Bgwdj7969UldjEmkGBgbi1wEVqcqJJtwTuRQUFGD79u2IiIhAfHw8KioqsHTpUgwePBh6enqcZuP7xGLyYTZs2IDevXtDQ0MDGzZseOe+XM8N2rFjB7Zu3YqUlBQAQO3atdG3b1/06NGD01zy0NPTQ1JSksJOOwqFQqiqqkJHR4d3hfWHUNTzN3v2bPz000+8vOqXvB8VX+SD3blzB+Hh4YiKikJubi6+/PJL7N+/n+tYvDR+/HjMmTMHOjo6GD9+/Dv3fXsR30+Nz9mURWVlJfr06YMdO3agdu3a4i73t27dwt27d/HNN99g69atvGryWx1FF1/vK6hf47qwrilFPX8qKip48uSJ+AIZolzotCP5YG5ubli0aBEWLFiAAwcOICIigutIvHX16lWUlZWJ/10dLj6c+ZxNWYSGhiI6Ohr79+/H119/LXHb/v37ERwcjNDQUIwbN46bgHJQ9HGWt6hSdCsHeTk4OEi1QPkUaNxEudHIFyGE91RUVGq0H1dXE9atWxfjxo2TWtz4tfDwcISGhsrVloIrih75kpe+vj5nV2Pm5uZi586dSEtLw8SJE2FsbIzExERYWFjAxsZGoVmEQiGePn0KMzMzhT4u+Tho5IsQwnuMMTg4OGDgwIG8WAT6bampqe9cuL1du3YYPXq0AhO9W2ZmJgDA1tZW6rabN2/yelkarsYLrl+/jnbt2sHAwAD37t3Dd999B2NjY+zevRsPHjzAxo0bFZ6pdu3a7x2pVJa5cp8bKr4IUYCaLvECKP7ScD5ney0+Pl48euTk5ITBgwejX79+MDIy4iTP27S0tJCbmwt7e3uZt7969QqampoKTiWpsrJSvExUfn4+ANEo14QJEzBt2jRxU1U7OzsuY/LW+PHjMWjQICxatEji4qKOHTuib9++nGSaNWsWXe2opKj4IkQB+PwGyedsr/n6+sLX1xfLli3Dzp07sX79ekyePBmdOnXCkCFD8OWXX3Kaz8/PD6tWrcKqVatk3h4WFiZeaJsr06ZNQ3h4OBYuXAh/f38AohYyv/zyC4qLizFv3jxO8/Hd5cuXsWbNGqntNjY2yMrK4iAR0Lt3b5pwr6wYIYQoofT0dNa6dWsmFArZixcvOM0SFxfH1NTU2DfffMMuXbrE8vLyWG5uLrtw4QLr0aMHU1NTY+fOneM0o5WVFdu3b5/U9r179zJra2sOEn0YXV1dlpaWpvDHNTMzY4mJiVIZjh8/zmxtbRWeRygUsqdPnyr8ccnHQSNfhBClkpmZicjISERGRqKwsBATJ06Evr4+p5maNm2K7du3Y9iwYdi1a5fEbUZGRti6dat4tIkrOTk54hYYVbm7u9O8oBro3LkzZs+ejT///BOA6KrQBw8eYPLkyejevbvC8zC6Vk6p0dWOhChAgwYNEBMTAyMjI9SvX/+dk2QVvYA1n7O9Vlpaij179iA8PBxnz57FV199hcGDB+Orr76q8ZWQilBYWIhjx44hNTUVgGhCdPv27XnRCLNJkyZo0qSJ1OLyP/zwAy5fvoyLFy9ylEw+Xl5eOHLkiMLnpuXl5aFHjx64cuUK/v77b1hbWyMrKwt+fn44fPgwb1tfEH6ikS9CFKBLly7iZY+6du3KbZi38Dnba1ZWVtDT08PAgQOxcuVK8TyXgoICif24HgHT1tZGt27d3ruft7c3Dh8+rNACYtGiRQgMDER0dLR4/tmFCxfw8OFDHD58WGE53qUmrRySk5M5yWZgYIATJ04gLi4OSUlJyM/PR4MGDd55lSsh1aGRL0II772+Eg+Q3QSUMQaBQMBZny95cdVL6/HjxwgLC8Pt27cBAB4eHhg1ahQvWku83crhzp07cHZ2xvTp0zlr5VDVxo0b0atXL6m1Y0tLS7Ft2zYMGDCAo2REGVHxRQiH8vPzUVlZKbGN69Gb1/iULTY2tkb7tWzZ8hMn+Tj43siUC+3atUODBg3ErRxePz/nz59H3759ce/ePU7zVbecz4sXL2Bubq40hT/hBzrtSIiCZWRkYPTo0Th9+jSKi4vF2/kwesPXbPIWVQsXLsSIESNgaGj4aQIpievXr8PLywtCofC93fXr1q2roFSy8bGVQ1WvXwNvy8zMVIp2LYRfqPgiRMG+/fZbMMYQEREBCwsLXq2ZyOds8pg/fz569uz52Rdf9erVQ1ZWFszNzVGvXj0IBAKZV8lxXfQDgIaGBl69eiW1PSUlhdMldF5fhCIQCNC2bVuoqr752KyoqEBGRgY6dOjAWT6inKj4IkTBkpKSkJCQADc3N66jSOFzNnnQbAqRjIwMceGSkZHBcZp341srh9deX4Ry7do1BAQEQFdXV3yburo6HB0dOc1HlBMVX4QoWKNGjfDw4UNeFjh8zkbk5+DgIPPffLRkyRL06NED5ubmKCoqQsuWLcWtHLjsvh8SEgIAcHR0RK9evThfJor8N9CEe0IULC0tDSNGjMC3334LLy8vqKmpSdzO5dwbPmeTB98ntG/ZsgVdunT55L2h9u/fX+N9O3fu/AmT1BzfWzmUlpbi2bNnUhejVLeuJyGyUPFFiIJdvHhR6uqt13NxuJ57w+ds8uCy+IqNjcXixYtx69YtAICnpycmTpyI5s2bKzxL1RYd78KHY8v3Vg6pqakYPHgwzp8/L7Fd2V4bhB+o+CJEwTw9PeHh4YFJkybJnNTO5ekhPmeTB1fF16ZNmxAcHIygoCDxckJxcXHYs2cPIiMj0bdvX4XmUSZ8b+Xg7+8PVVVVTJkyBVZWVlKvDR8fH46SEWVExRchCqajo4OkpCS4urpyHUUKn7PJo2PHjggPD4eVlZVCH9fDwwPDhg3Djz/+KLF96dKl+N///iceDSPShEIhnj59KnVlY1JSElq3bs35+pM6OjpISEiQuT4mIfKiCfeEKFibNm14W+DwOdvbiouLUVpaKrHtdRNYrpbLSU9PR6dOnaS2d+7cGVOnTuUg0Rtvr+n4mkAggKamJlxdXdGiRQuFr5WpLK0cPD098fz5c65jkP8IKr4IUbBOnTrhxx9/xI0bN+Dt7S01qZ3Lic98zgaIFq6eNGkS/vzzT7x48ULqdq5PTdnZ2SEmJkaqeI2Ojlb4QtBvW7ZsGbKzs1FYWAgjIyMAwMuXL6GtrQ1dXV08e/YMzs7OOHXqlEKzKksrh19//RWTJk3C/PnzZb42+LIyBVEOdNqREAV71yRorifu8jkbAHz//fc4deoU5syZg/79+yMsLAyPHj3CmjVrsHDhQvTr14/TfKtWrcK4ceMwePBgNG3aFIBozldkZCRCQ0MxfPhwzrJt3boVa9euxbp16+Di4gIAuHv3LoYPH45hw4bB398fvXv3hqWlJXbu3KnwfBs2bOB1K4fXr42353rRhHvyIaj4IoQoDXt7e2zcuBGtWrWCvr4+EhMT4erqiqioKGzdupWz041V7dmzB0uWLBHP7/Lw8MDEiRPRpUsXTnO5uLhg165dqFevnsT2q1evonv37khPT8f58+fRvXt3PHnyhJuQ4G8rh/etL6os64oSnmCEEIX46quvWG5urvj7BQsWsJcvX4q/f/78OfPw8OAgGb+zVaWjo8Pu37/PGGPMxsaGXbp0iTHGWHp6OtPR0eEyGisrK2OzZs1iDx8+5DRHdbS0tNjly5eltsfHxzMtLS3GGGMZGRmcPY8pKSmsWbNmTCgUSnwJBAImFAo5yUTIp1KzJjCEkH/t2LFjKCkpEX8/f/58iSu4ysvLcefOHS6i8TpbVc7OzuJlctzd3cVL0Rw4cIDzdRxVVVWxaNEilJeXc5qjOq1bt8bw4cNx9epV8barV69i5MiRaNOmDQDgxo0bcHJy4iTfoEGDIBQKcfDgQSQkJCAxMRGJiYm4evUqEhMTOcn0ttzcXCxZsgRDhw7F0KFDsWzZMuTl5XEdiyghmnBPiIKwt87wv/09l/icrarg4GAkJSWhZcuWmDJlCjp16oQVK1agrKwMS5cu5Toe2rZti9jYWDg6OnIdRUp4eDj69++Phg0biieLl5WVoV27dggPDwcA6OrqYsmSJZzku3btGq9bOVy5cgUBAQHQ0tJC48aNAYhaiMybNw/Hjx9HgwYNOE5IlAkVX4QQpVG1f1a7du1w+/ZtJCQkwNXVlRdLH3311VeYMmUKbty4gYYNG0otH8Tl1aKWlpY4ceIEzp49i4yMDBgaGsLNzU1iHc/WrVtzlo/vrRx+/PFHdO7cGf/73//E7TDKy8sxdOhQjBs3DmfOnOE4IVEmNOGeEAVRUVFBVlaWuImknp4erl+/Lj7N8/TpU1hbW3Ny1RSfsykTvl4tmpubi2nTpmH79u14+fIlAMDIyAi9e/fG3LlzOT9lCwAnT57E9OnTedvKQUtLC1evXpUambt58yZ8fX1RWFjIUTKijGjkixAFYYxh0KBB4rXriouLMWLECPHoSNU5V5Ttjeqag8oyZsyYT5jk/d6+Qo8PcnJy4Ofnh0ePHqFfv37w8PAAICoaIiMjERMTg/Pnz4t7f3Hl9QLabdu2ldjOeNLKQV9fHw8ePJAqvh4+fAg9PT2OUhFlRSNfhChIcHBwjfZbv379J04ijc/Z3p4A/rpR6OvRmtzcXGhra8Pc3Bzp6ekKz8d348aNQ0xMDKKjo2FhYSFxW1ZWFtq3b4+2bdti2bJlHCUU4XsrhzFjxmDPnj1YvHixRA+3iRMnonv37vj99985zUeUDEdXWRJCiNw2b97M/P392e3bt8Xbbt++zZo3b842bdrEYbI3oqOjWWBgIHN2dmbOzs4sMDCQnThxgrM8Dg4O7OjRo9XefuTIEebg4KC4QEqqpKSEjRkzhqmrq4vbYGhoaLBx48ax4uJiruMRJUMjX4QQpeHi4oKdO3eifv36EtsTEhLQo0cPcRsKrqxcuRJjx45Fjx494OfnBwC4ePEidu7ciWXLluH7779XeCYNDQ2kpaXB1tZW5u2ZmZlwdXVFcXGxgpNJy83NRXh4uLhBbZ06dTB48GAYGBhwnOyNwsJCpKWlARD9Pmpra3OciCgjKr4IIUpDW1sbsbGxaNSokcT2+Ph4tGrVivNJz7a2tpgyZQpGjx4tsT0sLAzz58/Ho0ePFJ7JxsYG27dvR7NmzWTefvbsWfTq1QuPHz9WcDJJslo5XL58GUVFRdTKgfznUPFFCFEanTp1wqNHj7Bu3Trxh3FCQgKGDRsGGxsb7N+/n9N8urq6uHbtmtTC2qmpqahfvz7y8/MVnmnw4MFIS0vDiRMnoK6uLnFbSUkJAgIC4OzsjIiICIVnq6p58+ZwdXWV2cohPT2d81YOxcXF+OOPP3Dq1CmZyx/xpREsUQ5UfBFClEZ2djYGDhyIo0ePilsRlJeXIyAgAJGRkTA3N+c0X9++fVG/fn1MnDhRYvvixYtx5coVbNu2TeGZMjMz4evrCw0NDXz//fdwd3cHYwy3bt3CypUrUVJSgitXrsDOzk7h2arieyuHfv364fjx4+jRowcsLCykFtgOCQnhKBlRRtRqghCiFBhjKCoqwq5du5CZmSmeF+Tu7o7atWtzlqtqKwxPT0/MmzcPp0+flpjzFRcXhwkTJnCSz9bWFhcuXMCoUaPw888/i1cvEAgE+PLLL7FixQrOCy+A/60cDh48iMOHD8Pf35/rKOQ/gEa+CCFKobKyEpqamvjrr79Qq1YtruOI1XQtRIFAwHkrjJcvXyI1NRUA4OrqCmNjY07zVMX3Vg6enp7Ytm0bL1ZSIMqPii9CiNKoU6cOwsPD8cUXX3AdhXxkpaWlmDhxIlavXi1enFxNTQ0jR47EwoULxQ2AuXLkyBEsX74cq1evhoODA6dZiPKj4osQojQOHDiARYsWYdWqVfDy8uI6DvkE+NrKITs7Gz179sSZM2egra0ttfxRTk4OR8mIMqLiixCiNIyMjFBYWIjy8nKoq6tDS0tL4nauPwAZY9i5c2e1V8Tt3r2bo2Tk32rXrh0ePHiAIUOGyJxwP3DgQI6SEWVEE+4JIUqD63k/7zNu3DisWbMGrVu3lvkBTarH91YO58+fx4ULF+Dj48NpDvLfQMUXIURp8H10ISoqCrt370bHjh25jqJ0hgwZIm7l0LhxY94Vru7u7igqKuI6BvmPoNOOhBClVFxcjNLSUolt+vr6HKURcXJywpEjR6TaJZD3MzAw4HUrh+PHj2PWrFmYN28evL29peZ8cf27R5QLFV+EEKVRUFCAyZMn488//8SLFy+kbq+oqOAg1RsbNmzA0aNHERERITUfjbwb31s5CIVCAJAakWOMQSAQcP67R5QLnXYkhCiNSZMm4dSpU1i1ahX69++PsLAwPHr0CGvWrMHChQu5joeePXti69atMDc3h6Ojo9ToCNfzlvhsyZIlmDx5Mm9bOZw6dYrrCOQ/hIovQojSOHDgADZu3IhWrVohODhYvB6gg4MDNm/ejH79+nGab+DAgUhISMC3335LE+7l5Ovri+LiYjg7O/OylUPLli05fXzy30LFFyFEaeTk5MDZ2RmAaI7N6w/kZs2aYeTIkVxGAwAcOnQIx44dQ7NmzbiOonT69OmDR48eYf78+bwtXM+ePYs1a9YgPT0dO3bsgI2NDaKiouDk5ETHnMiFii9CiNJwdnZGRkYG7O3t4e7ujj///BONGzfGgQMHYGhoyHU82NnZ0cTrD8T3Vg67du1C//790a9fPyQmJqKkpAQAkJeXh/nz5+Pw4cMcJyTKRMh1AEIIqang4GAkJSUBAKZMmYKwsDBoamrixx9/xMSJEzlOJ5q3NGnSJNy7d4/rKEqH760c5s6di9WrV+N///ufxClRf39/mstH5EZXOxJClNb9+/eRkJAAV1dXXlwlV7UDPx/nLfEZ31s5aGtr4+bNm3B0dISenh6SkpLg7OyM9PR0eHp6ori4mNN8RLnQaUdCCO8VFRUhJiYGX3/9NQDg559/Fp/2AYCLFy9i9uzZ0NTU5CoiAP534OezDh06AADatm0rsZ0vrRwsLS1x9+5dODo6Smw/d+6ceB4iITVFxRchhPc2bNiAQ4cOiYuvFStWoE6dOuJeWrdv34aVlRV+/PFHLmPyvgM/n/G9lcN3332HsWPHIiIiAgKBAI8fP8aFCxfw008/YcaMGVzHI0qGTjsSQnivefPmmDRpEjp16gQAEqd9AGDTpk0ICwvDhQsXuIwpgY8d+MmHY4xh/vz5WLBgAQoLCwEAGhoa+OmnnzBnzhyO0xFlQ8UXIYT3rKyscOHCBfEpHzMzM1y+fFn8fUpKCho1aoS8vDzuQoL/Hfj5ThlaOZSWluLu3bvIz8+Hp6cndHV1uY5ElBBd7UgI4b3c3FyJOV7Z2dkSc28qKyslbufKpEmTcPLkSaxatQoaGhpYt24dZs2aBWtra2zcuJHreLy2a9cuBAQEQEtLS2YrB75QV1eHp6cnGjduTIUX+WA054sQwnu2trZITk6Gm5ubzNuvX78OW1tbBaeSxvcO/Hz2upXDgAEDsG3bNvF2f39/zJ07l5NMQUFBiIyMhL6+Prp16/bOxq+7d+9WYDKi7GjkixDCex07dsTMmTNlXs5fVFSEWbNmITAwkINkkt7Vgf/MmTNcRuO9O3fuoEWLFlLbDQwMkJubq/hA/zz264LL0NAQhoaGMDAwkPlFiDxo5IsQwntTp07Fn3/+CTc3N4wePRq1a9cGIPrAXrFiBcrLyzF16lSOU767Az99QL8bH1s5rF+/HhUVFfj111+RkpKC0tJStGnTBr/88ov4SltCPggjhBAlkJ6ezgICAphQKGQCgYAJBAImFApZQEAAS0tL4zoeY4yxpUuXstDQUMYYYydOnGCamppMQ0ODCYVC9vvvv3Ocjt/mz5/PPD092cWLF5menh47e/Ys27RpEzMzM2PLly/nLNfs2bOZUChk7du3Z126dGGamposODiYszzkv4GudiSEKJWcnBzcvXsXAODq6gpjY2OOE1XvdQd+U1NTbNq0CWvXruU6Em8xnrZyqFWrFn766ScMHz4cABAdHY3AwEAUFRVBKKSZO+TDUPFFCCGfWFJSEho0aECtJmqAb60cNDQ0cPfuXdjZ2Ym3aWpq4u7du7y4yIMoJ5rzRQghhDdet3Lgi/Lycqllq9TU1FBWVsZRIvJfQMUXIYQQTihDKwfGGAYNGgQNDQ3xtuLiYowYMQI6OjribdRqgsiDii9CCCGceLuVg0AgAN9mwshar/Pbb7/lIAn5L6E5X4QQ8i8FBQW98/bc3FzExsbSnC8ZKioqsHjxYuzfv59aOZDPBo18EULIv/S+Hl4GBgYYMGCAgtIol/nz5+OXX35Bu3btoKWlheXLlyM7OxsRERFcRyPkk6GRL0IIIZyhVg7kc0TFFyGEEM5QKwfyOaI/KwghhHCGWjmQzxHN+SKEEMIZauVAPkdUfBFCCOEMtXIgnyOa80UIIYQQokA054sQQgghRIGo+CKEEEIIUSAqvgghhBBCFIiKL0IIIYQQBaLiixBCCCFEgaj4IoQQQghRICq+CCGEEEIUiIovQgghhBAF+j/c00Hf2VnA6gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sb\n",
    "from sklearn.cluster import KMeans\n",
    "dataplot = sb.heatmap(targets_df_trainVal.corr(), annot=True,vmin=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "479a468a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 1, 1, 2, 2, 0, 0, 2], dtype=int32)"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clust = KMeans(n_clusters=3)\n",
    "classes = clust.fit_predict(np.transpose(targets_df_trainVal))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "7452d751",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dora' 'Piemonte_Nord' 'Piemonte_Sud']\n",
      "['Emiliani1' 'Emiliani2' 'Garda_Mincio']\n",
      "['Adda' 'Lambro_Olona' 'Oglio_Iseo' 'Ticino']\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(targets_df_trainVal.loc[:,classes==i].columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "084537a5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 1, 0, 2, 0, 2, 2, 2], dtype=int32)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clust = KMeans(n_clusters=4)\n",
    "classes = clust.fit_predict(np.transpose(targets_df_trainVal))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "7437ffa1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adda' 'Garda_Mincio' 'Oglio_Iseo']\n",
      "['Emiliani1' 'Emiliani2']\n",
      "['Lambro_Olona' 'Piemonte_Nord' 'Piemonte_Sud' 'Ticino']\n",
      "['Dora']\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    print(targets_df_trainVal.loc[:,classes==i].columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aeb9a2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## features loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea7f48f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### wrapper best 5 features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "best5_wrapper_fulldf_train = pd.DataFrame()\n",
    "best5_wrapper_fulldf_val = pd.DataFrame()\n",
    "best5_wrapper_fulldf_test = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    best5_wrapper_train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_train.csv')\n",
    "    best5_wrapper_val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_val.csv')\n",
    "    best5_wrapper_test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_wrapper_best5_test.csv')\n",
    "    best5_wrapper_fulldf_train[basin+'_'+best5_wrapper_train_temp.columns.values] = best5_wrapper_train_temp\n",
    "    best5_wrapper_fulldf_val[basin+'_'+best5_wrapper_val_temp.columns.values] = best5_wrapper_val_temp\n",
    "    best5_wrapper_fulldf_test[basin+'_'+best5_wrapper_test_temp.columns.values] = best5_wrapper_test_temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a786a60",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CMI features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "CMI_fulldf_train = pd.DataFrame()\n",
    "CMI_fulldf_val = pd.DataFrame()\n",
    "CMI_fulldf_test = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_train.csv')\n",
    "    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_val.csv')\n",
    "    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_CMI_test.csv')\n",
    "    CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n",
    "    CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n",
    "    CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5900737",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### CMI best5 features\n",
    "path_features = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "\n",
    "best5_CMI_fulldf_train = pd.DataFrame()\n",
    "best5_CMI_fulldf_val = pd.DataFrame()\n",
    "best5_CMI_fulldf_test = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    train_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_train.csv')\n",
    "    val_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_val.csv')\n",
    "    test_temp = pd.read_csv(path_features+basin+'_nonLinCFA_best5_CMI_test.csv')\n",
    "    best5_CMI_fulldf_train[basin+'_'+train_temp.columns.values] = train_temp\n",
    "    best5_CMI_fulldf_val[basin+'_'+val_temp.columns.values] = val_temp\n",
    "    best5_CMI_fulldf_test[basin+'_'+test_temp.columns.values] = test_temp\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c317fc60",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Full model - Wrapper best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "796a6f58",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best5_wrapper_fulldf_train_withClass = pd.DataFrame()\n",
    "best5_wrapper_fulldf_val_withClass = pd.DataFrame()\n",
    "best5_wrapper_fulldf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "    best5_wrapper_fulldf_train_withClass = pd.concat((best5_wrapper_fulldf_train_withClass,pd.concat((best5_wrapper_fulldf_train,pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_fulldf_val_withClass = pd.concat((best5_wrapper_fulldf_val_withClass,pd.concat((best5_wrapper_fulldf_val,pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_fulldf_test_withClass = pd.concat((best5_wrapper_fulldf_test_withClass,pd.concat((best5_wrapper_fulldf_test,pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "d9c7fef5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "ac175a72",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### senza one-hot encoding\n",
    "model_full = LinearRegression()\n",
    "model_full.fit(pd.concat((best5_wrapper_fulldf_train_withClass,best5_wrapper_fulldf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "883b97db",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5491554759619361\n",
      "-1.0423450950191295\n",
      "-0.6594175746250646\n",
      "-0.7279030457484599\n",
      "-0.3240293352193375\n",
      "-0.7789305558620834\n",
      "-0.586276530759325\n",
      "-0.625783137074384\n",
      "-0.825757489868459\n",
      "-0.6676428068629505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    res = model_full.predict(best5_wrapper_fulldf_test_withClass.loc[best5_wrapper_fulldf_test_withClass.basin==i+1].values)\n",
    "    print(r2_score(targets_df_test[basins[i]].values, res))\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "69d7ab54",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### con OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "0bf66abe",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    best5_wrapper_fulldf_train_withClass[basins[i]] = best5_wrapper_fulldf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_fulldf_val_withClass[basins[i]] = best5_wrapper_fulldf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_fulldf_test_withClass[basins[i]] = best5_wrapper_fulldf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "bb15b566",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_6</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_5</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_1w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_2</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_1w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_1w_2</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Adda</th>\n",
       "      <th>Dora</th>\n",
       "      <th>Emiliani1</th>\n",
       "      <th>Emiliani2</th>\n",
       "      <th>Garda_Mincio</th>\n",
       "      <th>Lambro_Olona</th>\n",
       "      <th>Oglio_Iseo</th>\n",
       "      <th>Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud</th>\n",
       "      <th>Ticino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>-1.709060</td>\n",
       "      <td>-1.866687</td>\n",
       "      <td>1.001341</td>\n",
       "      <td>-3.062159</td>\n",
       "      <td>-0.858428</td>\n",
       "      <td>0.569944</td>\n",
       "      <td>-0.645734</td>\n",
       "      <td>-0.958059</td>\n",
       "      <td>-1.179177</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>-0.490888</td>\n",
       "      <td>-1.024977</td>\n",
       "      <td>1.976018</td>\n",
       "      <td>-1.604230</td>\n",
       "      <td>-0.144075</td>\n",
       "      <td>2.777501</td>\n",
       "      <td>-0.040254</td>\n",
       "      <td>0.064877</td>\n",
       "      <td>-0.154668</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>-0.923993</td>\n",
       "      <td>-0.954945</td>\n",
       "      <td>1.350939</td>\n",
       "      <td>-2.492491</td>\n",
       "      <td>-0.543433</td>\n",
       "      <td>1.425829</td>\n",
       "      <td>-0.727940</td>\n",
       "      <td>-1.002116</td>\n",
       "      <td>-0.919496</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>-1.171925</td>\n",
       "      <td>-1.039569</td>\n",
       "      <td>0.464342</td>\n",
       "      <td>-1.901370</td>\n",
       "      <td>-0.723360</td>\n",
       "      <td>1.785519</td>\n",
       "      <td>-0.924722</td>\n",
       "      <td>-0.601101</td>\n",
       "      <td>-0.594848</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>-0.855241</td>\n",
       "      <td>-1.185594</td>\n",
       "      <td>0.406680</td>\n",
       "      <td>-2.302021</td>\n",
       "      <td>-0.540293</td>\n",
       "      <td>1.524603</td>\n",
       "      <td>-0.569035</td>\n",
       "      <td>-0.789653</td>\n",
       "      <td>-0.843317</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>1.778381</td>\n",
       "      <td>1.494928</td>\n",
       "      <td>-1.208471</td>\n",
       "      <td>1.138232</td>\n",
       "      <td>1.462830</td>\n",
       "      <td>-0.520256</td>\n",
       "      <td>1.585661</td>\n",
       "      <td>0.807565</td>\n",
       "      <td>0.577376</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>1.051617</td>\n",
       "      <td>0.843470</td>\n",
       "      <td>0.824414</td>\n",
       "      <td>1.152253</td>\n",
       "      <td>0.599620</td>\n",
       "      <td>-0.530550</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>1.020805</td>\n",
       "      <td>0.776516</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>0.470849</td>\n",
       "      <td>0.404951</td>\n",
       "      <td>1.236207</td>\n",
       "      <td>1.253158</td>\n",
       "      <td>0.344849</td>\n",
       "      <td>0.031726</td>\n",
       "      <td>0.422436</td>\n",
       "      <td>0.910086</td>\n",
       "      <td>0.715672</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-1.195756</td>\n",
       "      <td>-1.026883</td>\n",
       "      <td>-0.159932</td>\n",
       "      <td>0.874675</td>\n",
       "      <td>-1.130239</td>\n",
       "      <td>-0.154282</td>\n",
       "      <td>-1.116372</td>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.083901</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-1.470946</td>\n",
       "      <td>-1.326713</td>\n",
       "      <td>0.209276</td>\n",
       "      <td>0.821070</td>\n",
       "      <td>-1.598190</td>\n",
       "      <td>0.583732</td>\n",
       "      <td>-1.711036</td>\n",
       "      <td>-0.182408</td>\n",
       "      <td>-0.229108</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4110 rows  61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_tg_1w_6  \\\n",
       "0                            -0.862899                          -1.709060   \n",
       "1                            -0.093639                          -0.490888   \n",
       "2                            -0.524505                          -0.923993   \n",
       "3                            -0.666293                          -1.171925   \n",
       "4                            -0.416695                          -0.855241   \n",
       "..                                 ...                                ...   \n",
       "406                           1.568770                           1.778381   \n",
       "407                           0.812306                           1.051617   \n",
       "408                           0.876968                           0.470849   \n",
       "409                          -0.723696                          -1.195756   \n",
       "410                          -1.413870                          -1.470946   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_1w_5  Adda_cyclostationary_mean_rr_1w_0  \\\n",
       "0                            -1.866687                           1.001341   \n",
       "1                            -1.024977                           1.976018   \n",
       "2                            -0.954945                           1.350939   \n",
       "3                            -1.039569                           0.464342   \n",
       "4                            -1.185594                           0.406680   \n",
       "..                                 ...                                ...   \n",
       "406                           1.494928                          -1.208471   \n",
       "407                           0.843470                           0.824414   \n",
       "408                           0.404951                           1.236207   \n",
       "409                          -1.026883                          -0.159932   \n",
       "410                          -1.326713                           0.209276   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_2  Dora_cyclostationary_mean_tg_1w_0  \\\n",
       "0                             -3.062159                          -0.858428   \n",
       "1                             -1.604230                          -0.144075   \n",
       "2                             -2.492491                          -0.543433   \n",
       "3                             -1.901370                          -0.723360   \n",
       "4                             -2.302021                          -0.540293   \n",
       "..                                  ...                                ...   \n",
       "406                            1.138232                           1.462830   \n",
       "407                            1.152253                           0.599620   \n",
       "408                            1.253158                           0.344849   \n",
       "409                            0.874675                          -1.130239   \n",
       "410                            0.821070                          -1.598190   \n",
       "\n",
       "     Dora_cyclostationary_mean_rr_4w_1  Dora_cyclostationary_mean_tg_1w_2  \\\n",
       "0                             0.569944                          -0.645734   \n",
       "1                             2.777501                          -0.040254   \n",
       "2                             1.425829                          -0.727940   \n",
       "3                             1.785519                          -0.924722   \n",
       "4                             1.524603                          -0.569035   \n",
       "..                                 ...                                ...   \n",
       "406                          -0.520256                           1.585661   \n",
       "407                          -0.530550                           0.724000   \n",
       "408                           0.031726                           0.422436   \n",
       "409                          -0.154282                          -1.116372   \n",
       "410                           0.583732                          -1.711036   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_4w_1  Dora_cyclostationary_mean_tg_4w_0  \\\n",
       "0                            -0.958059                          -1.179177   \n",
       "1                             0.064877                          -0.154668   \n",
       "2                            -1.002116                          -0.919496   \n",
       "3                            -0.601101                          -0.594848   \n",
       "4                            -0.789653                          -0.843317   \n",
       "..                                 ...                                ...   \n",
       "406                           0.807565                           0.577376   \n",
       "407                           1.020805                           0.776516   \n",
       "408                           0.910086                           0.715672   \n",
       "409                           0.237759                           0.083901   \n",
       "410                          -0.182408                          -0.229108   \n",
       "\n",
       "     ...  Adda  Dora  Emiliani1  Emiliani2  Garda_Mincio  Lambro_Olona  \\\n",
       "0    ...     1     0          0          0             0             0   \n",
       "1    ...     1     0          0          0             0             0   \n",
       "2    ...     1     0          0          0             0             0   \n",
       "3    ...     1     0          0          0             0             0   \n",
       "4    ...     1     0          0          0             0             0   \n",
       "..   ...   ...   ...        ...        ...           ...           ...   \n",
       "406  ...     0     0          0          0             0             0   \n",
       "407  ...     0     0          0          0             0             0   \n",
       "408  ...     0     0          0          0             0             0   \n",
       "409  ...     0     0          0          0             0             0   \n",
       "410  ...     0     0          0          0             0             0   \n",
       "\n",
       "     Oglio_Iseo  Piemonte_Nord  Piemonte_Sud  Ticino  \n",
       "0             0              0             0       0  \n",
       "1             0              0             0       0  \n",
       "2             0              0             0       0  \n",
       "3             0              0             0       0  \n",
       "4             0              0             0       0  \n",
       "..          ...            ...           ...     ...  \n",
       "406           0              0             0       1  \n",
       "407           0              0             0       1  \n",
       "408           0              0             0       1  \n",
       "409           0              0             0       1  \n",
       "410           0              0             0       1  \n",
       "\n",
       "[4110 rows x 61 columns]"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best5_wrapper_fulldf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "11259b11",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_full_ohe = LinearRegression()\n",
    "model_full_ohe.fit(pd.concat((best5_wrapper_fulldf_train_withClass,best5_wrapper_fulldf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "2b1fbc59",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5415005337955616\n",
      "-1.0338308669146623\n",
      "-0.6131189863744742\n",
      "-0.7083968352300551\n",
      "-0.39181095113804565\n",
      "-0.7874150404941778\n",
      "-0.5603225748543441\n",
      "-0.6433379917406741\n",
      "-0.8360326699741558\n",
      "-0.6155985316411592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    res = model_full_ohe.predict(best5_wrapper_fulldf_test_withClass.loc[best5_wrapper_fulldf_test_withClass.basin==i+1].values)\n",
    "    print(r2_score(targets_df_test[basins[i]].values, res))\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ef7cf5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Full model - CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "3c8e73b8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fulldf_train_withClass = pd.DataFrame()\n",
    "fulldf_val_withClass = pd.DataFrame()\n",
    "fulldf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "    fulldf_train_withClass = pd.concat((fulldf_train_withClass,pd.concat((CMI_fulldf_train,pd.DataFrame(1+i*np.ones(len(CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    fulldf_val_withClass = pd.concat((fulldf_val_withClass,pd.concat((CMI_fulldf_val,pd.DataFrame(1+i*np.ones(len(CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    fulldf_test_withClass = pd.concat((fulldf_test_withClass,pd.concat((CMI_fulldf_test,pd.DataFrame(1+i*np.ones(len(CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "1bfd3a8a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "d6f7b3f4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### senza one-hot encoding\n",
    "model_full = LinearRegression()\n",
    "model_full.fit(pd.concat((fulldf_train_withClass,fulldf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "4fcdaab0",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.32432543674993175\n",
      "-0.8338333508633748\n",
      "-0.5346654436935785\n",
      "-0.6156751999424308\n",
      "-0.29797616991576814\n",
      "-0.6914126013197579\n",
      "-0.43343408191227617\n",
      "-0.6440930744307678\n",
      "-0.8875935087066893\n",
      "-0.5576540694126282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    res = model_full.predict(fulldf_test_withClass.loc[fulldf_test_withClass.basin==i+1].values)\n",
    "    print(r2_score(targets_df_test[basins[i]].values, res))\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "f9675873",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### con OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "2154e4f5",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    fulldf_train_withClass[basins[i]] = fulldf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    fulldf_val_withClass[basins[i]] = fulldf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    fulldf_test_withClass[basins[i]] = fulldf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "27528dd1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_full_ohe = LinearRegression()\n",
    "model_full_ohe.fit(pd.concat((fulldf_train_withClass,fulldf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "44ebbb8e",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3343247368017468\n",
      "-0.8408703888186033\n",
      "-0.522049414451657\n",
      "-0.6268155983314645\n",
      "-0.3506464522126824\n",
      "-0.6975832864306979\n",
      "-0.4271381098033764\n",
      "-0.683697356646664\n",
      "-0.922163317963026\n",
      "-0.5326480209316058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    res = model_full_ohe.predict(fulldf_test_withClass.loc[fulldf_test_withClass.basin==i+1].values)\n",
    "    print(r2_score(targets_df_test[basins[i]].values, res))\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec7ac38",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Full model - CMI best5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "8ac427aa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fulldf_train_withClass = pd.DataFrame()\n",
    "fulldf_val_withClass = pd.DataFrame()\n",
    "fulldf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(10):\n",
    "    fulldf_train_withClass = pd.concat((fulldf_train_withClass,pd.concat((best5_CMI_fulldf_train,pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    fulldf_val_withClass = pd.concat((fulldf_val_withClass,pd.concat((best5_CMI_fulldf_val,pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    fulldf_test_withClass = pd.concat((fulldf_test_withClass,pd.concat((best5_CMI_fulldf_test,pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "7ed966df",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "35ee6441",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" checked><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### senza one-hot encoding\n",
    "model_full = LinearRegression()\n",
    "model_full.fit(pd.concat((fulldf_train_withClass,fulldf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "e4b5bedf",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07074209099490547\n",
      "-0.3400251166748527\n",
      "0.021472147689631682\n",
      "-0.018948230897721796\n",
      "0.1079367225647263\n",
      "-0.10209848606072591\n",
      "0.040766556111391794\n",
      "-0.09174830928989253\n",
      "-0.25051627456874725\n",
      "-0.05702704585485252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    res = model_full.predict(fulldf_test_withClass.loc[fulldf_test_withClass.basin==i+1].values)\n",
    "    print(r2_score(targets_df_test[basins[i]].values, res))\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "619f1dff",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### con OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "da6d08fc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    fulldf_train_withClass[basins[i]] = fulldf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    fulldf_val_withClass[basins[i]] = fulldf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    fulldf_test_withClass[basins[i]] = fulldf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "2cbfbaca",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_full_ohe = LinearRegression()\n",
    "model_full_ohe.fit(pd.concat((fulldf_train_withClass,fulldf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "a810b111",
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07483055333995814\n",
      "-0.33438354490326283\n",
      "0.04241445328655613\n",
      "-0.01150395664153292\n",
      "0.10141628406867964\n",
      "-0.10104147267469954\n",
      "0.05616066638937134\n",
      "-0.10050670963023434\n",
      "-0.2571160595620916\n",
      "-0.02778105022402344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    res = model_full_ohe.predict(fulldf_test_withClass.loc[fulldf_test_withClass.basin==i+1].values)\n",
    "    print(r2_score(targets_df_test[basins[i]].values, res))\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843bde20",
   "metadata": {},
   "source": [
    "## Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b028bfc",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Emiliani1 - Emiliani2 - Garda_Mincio: wrapper best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "d9b4bbde",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### prova con Emiliani1 e 2 e Garda_Mincio\n",
    "clust_basins = ['Emiliani1','Emiliani2','Garda_Mincio']\n",
    "colnames = [x for x in best5_wrapper_fulldf_train.columns if x.startswith('Emiliani1') or x.startswith('Emiliani2') or x.startswith('Garda_Mincio')]\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass = pd.DataFrame()\n",
    "best5_wrapper_clusterdf_val_withClass = pd.DataFrame()\n",
    "best5_wrapper_clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(3):\n",
    "    best5_wrapper_clusterdf_train_withClass = pd.concat((best5_wrapper_clusterdf_train_withClass,pd.concat((best5_wrapper_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_clusterdf_val_withClass = pd.concat((best5_wrapper_clusterdf_val_withClass,pd.concat((best5_wrapper_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_clusterdf_test_withClass = pd.concat((best5_wrapper_clusterdf_test_withClass,pd.concat((best5_wrapper_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(3):\n",
    "    best5_wrapper_clusterdf_train_withClass[clust_basins[i]] = best5_wrapper_clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_clusterdf_val_withClass[clust_basins[i]] = best5_wrapper_clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_clusterdf_test_withClass[clust_basins[i]] = best5_wrapper_clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass = best5_wrapper_clusterdf_train_withClass.loc[:,best5_wrapper_clusterdf_train_withClass.columns != 'basin']\n",
    "best5_wrapper_clusterdf_val_withClass = best5_wrapper_clusterdf_val_withClass.loc[:,best5_wrapper_clusterdf_val_withClass.columns != 'basin']\n",
    "best5_wrapper_clusterdf_test_withClass = best5_wrapper_clusterdf_test_withClass.loc[:,best5_wrapper_clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "15f27ff6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_0</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_16w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_12w_2</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_1w_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_1w_5</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_8w_3</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_8w_1</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_16w_2</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_1w_6</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_0</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_4</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_6</th>\n",
       "      <th>Emiliani1</th>\n",
       "      <th>Emiliani2</th>\n",
       "      <th>Garda_Mincio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.563762</td>\n",
       "      <td>0.702658</td>\n",
       "      <td>2.356915</td>\n",
       "      <td>4.551719</td>\n",
       "      <td>0.733057</td>\n",
       "      <td>-0.890461</td>\n",
       "      <td>1.715033</td>\n",
       "      <td>0.451434</td>\n",
       "      <td>5.057234</td>\n",
       "      <td>0.839851</td>\n",
       "      <td>1.758769</td>\n",
       "      <td>0.309939</td>\n",
       "      <td>1.937637</td>\n",
       "      <td>2.719823</td>\n",
       "      <td>2.154612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.725573</td>\n",
       "      <td>1.770284</td>\n",
       "      <td>2.298396</td>\n",
       "      <td>1.893610</td>\n",
       "      <td>0.688605</td>\n",
       "      <td>-0.266454</td>\n",
       "      <td>0.884643</td>\n",
       "      <td>1.266314</td>\n",
       "      <td>3.825332</td>\n",
       "      <td>1.871824</td>\n",
       "      <td>1.121893</td>\n",
       "      <td>1.158323</td>\n",
       "      <td>1.850264</td>\n",
       "      <td>4.725401</td>\n",
       "      <td>4.547085</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.426653</td>\n",
       "      <td>-0.294432</td>\n",
       "      <td>1.655602</td>\n",
       "      <td>1.912331</td>\n",
       "      <td>0.400704</td>\n",
       "      <td>-0.541753</td>\n",
       "      <td>0.397911</td>\n",
       "      <td>0.262699</td>\n",
       "      <td>2.978955</td>\n",
       "      <td>2.175787</td>\n",
       "      <td>0.598275</td>\n",
       "      <td>-0.747849</td>\n",
       "      <td>1.614353</td>\n",
       "      <td>2.989650</td>\n",
       "      <td>3.013864</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.048203</td>\n",
       "      <td>1.312823</td>\n",
       "      <td>0.788894</td>\n",
       "      <td>1.822362</td>\n",
       "      <td>0.740061</td>\n",
       "      <td>-0.679603</td>\n",
       "      <td>0.054424</td>\n",
       "      <td>0.396038</td>\n",
       "      <td>2.665933</td>\n",
       "      <td>2.151856</td>\n",
       "      <td>0.310672</td>\n",
       "      <td>0.618235</td>\n",
       "      <td>1.102825</td>\n",
       "      <td>2.877711</td>\n",
       "      <td>2.874078</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.795649</td>\n",
       "      <td>0.083310</td>\n",
       "      <td>4.072560</td>\n",
       "      <td>2.039331</td>\n",
       "      <td>1.203853</td>\n",
       "      <td>-0.500179</td>\n",
       "      <td>0.103811</td>\n",
       "      <td>0.302639</td>\n",
       "      <td>2.141665</td>\n",
       "      <td>2.644978</td>\n",
       "      <td>0.314132</td>\n",
       "      <td>-0.197356</td>\n",
       "      <td>1.639373</td>\n",
       "      <td>1.887482</td>\n",
       "      <td>2.011651</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.549183</td>\n",
       "      <td>1.068315</td>\n",
       "      <td>-0.544373</td>\n",
       "      <td>-0.687935</td>\n",
       "      <td>-1.495602</td>\n",
       "      <td>0.805732</td>\n",
       "      <td>-0.293248</td>\n",
       "      <td>0.661497</td>\n",
       "      <td>-0.655689</td>\n",
       "      <td>1.600522</td>\n",
       "      <td>0.030398</td>\n",
       "      <td>1.386827</td>\n",
       "      <td>-1.000215</td>\n",
       "      <td>-0.832783</td>\n",
       "      <td>-0.872908</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.481985</td>\n",
       "      <td>0.560944</td>\n",
       "      <td>-0.518064</td>\n",
       "      <td>-0.626884</td>\n",
       "      <td>-0.968744</td>\n",
       "      <td>0.306776</td>\n",
       "      <td>-0.156714</td>\n",
       "      <td>0.689496</td>\n",
       "      <td>-0.459704</td>\n",
       "      <td>1.017618</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>0.600403</td>\n",
       "      <td>-0.657988</td>\n",
       "      <td>-0.534876</td>\n",
       "      <td>-0.467096</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.402054</td>\n",
       "      <td>0.350446</td>\n",
       "      <td>-0.616373</td>\n",
       "      <td>-0.606093</td>\n",
       "      <td>-0.646526</td>\n",
       "      <td>0.503166</td>\n",
       "      <td>0.174464</td>\n",
       "      <td>0.605186</td>\n",
       "      <td>-0.408143</td>\n",
       "      <td>0.542851</td>\n",
       "      <td>0.643723</td>\n",
       "      <td>0.382350</td>\n",
       "      <td>-0.459207</td>\n",
       "      <td>-0.351997</td>\n",
       "      <td>-0.249248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.146823</td>\n",
       "      <td>-1.792820</td>\n",
       "      <td>-0.325116</td>\n",
       "      <td>-0.462663</td>\n",
       "      <td>-0.400672</td>\n",
       "      <td>-1.067879</td>\n",
       "      <td>0.229314</td>\n",
       "      <td>0.030515</td>\n",
       "      <td>-0.452395</td>\n",
       "      <td>-0.750222</td>\n",
       "      <td>-0.102080</td>\n",
       "      <td>-1.910985</td>\n",
       "      <td>-0.487928</td>\n",
       "      <td>-0.312771</td>\n",
       "      <td>-0.184850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.051540</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.236889</td>\n",
       "      <td>-0.568468</td>\n",
       "      <td>1.556927</td>\n",
       "      <td>-1.709317</td>\n",
       "      <td>0.223387</td>\n",
       "      <td>0.115353</td>\n",
       "      <td>-0.222063</td>\n",
       "      <td>-0.857548</td>\n",
       "      <td>0.187242</td>\n",
       "      <td>-0.460368</td>\n",
       "      <td>-0.433529</td>\n",
       "      <td>-0.297669</td>\n",
       "      <td>0.028905</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emiliani1_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                  2.563762   \n",
       "1                                  1.725573   \n",
       "2                                  1.426653   \n",
       "3                                  1.048203   \n",
       "4                                  1.795649   \n",
       "..                                      ...   \n",
       "406                               -0.549183   \n",
       "407                               -0.481985   \n",
       "408                               -0.402054   \n",
       "409                               -0.146823   \n",
       "410                               -0.051540   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_0  \\\n",
       "0                               0.702658   \n",
       "1                               1.770284   \n",
       "2                              -0.294432   \n",
       "3                               1.312823   \n",
       "4                               0.083310   \n",
       "..                                   ...   \n",
       "406                             1.068315   \n",
       "407                             0.560944   \n",
       "408                             0.350446   \n",
       "409                            -1.792820   \n",
       "410                            -0.120537   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_16w_1  \\\n",
       "0                                   2.356915   \n",
       "1                                   2.298396   \n",
       "2                                   1.655602   \n",
       "3                                   0.788894   \n",
       "4                                   4.072560   \n",
       "..                                       ...   \n",
       "406                                -0.544373   \n",
       "407                                -0.518064   \n",
       "408                                -0.616373   \n",
       "409                                -0.325116   \n",
       "410                                -0.236889   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_12w_2  \\\n",
       "0                                   4.551719   \n",
       "1                                   1.893610   \n",
       "2                                   1.912331   \n",
       "3                                   1.822362   \n",
       "4                                   2.039331   \n",
       "..                                       ...   \n",
       "406                                -0.687935   \n",
       "407                                -0.626884   \n",
       "408                                -0.606093   \n",
       "409                                -0.462663   \n",
       "410                                -0.568468   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_1w_4  \\\n",
       "0                                  0.733057   \n",
       "1                                  0.688605   \n",
       "2                                  0.400704   \n",
       "3                                  0.740061   \n",
       "4                                  1.203853   \n",
       "..                                      ...   \n",
       "406                               -1.495602   \n",
       "407                               -0.968744   \n",
       "408                               -0.646526   \n",
       "409                               -0.400672   \n",
       "410                                1.556927   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_1w_5  \\\n",
       "0                                 -0.890461   \n",
       "1                                 -0.266454   \n",
       "2                                 -0.541753   \n",
       "3                                 -0.679603   \n",
       "4                                 -0.500179   \n",
       "..                                      ...   \n",
       "406                                0.805732   \n",
       "407                                0.306776   \n",
       "408                                0.503166   \n",
       "409                               -1.067879   \n",
       "410                               -1.709317   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_8w_3  \\\n",
       "0                                  1.715033   \n",
       "1                                  0.884643   \n",
       "2                                  0.397911   \n",
       "3                                  0.054424   \n",
       "4                                  0.103811   \n",
       "..                                      ...   \n",
       "406                               -0.293248   \n",
       "407                               -0.156714   \n",
       "408                                0.174464   \n",
       "409                                0.229314   \n",
       "410                                0.223387   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_8w_1  \\\n",
       "0                                  0.451434   \n",
       "1                                  1.266314   \n",
       "2                                  0.262699   \n",
       "3                                  0.396038   \n",
       "4                                  0.302639   \n",
       "..                                      ...   \n",
       "406                                0.661497   \n",
       "407                                0.689496   \n",
       "408                                0.605186   \n",
       "409                                0.030515   \n",
       "410                                0.115353   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_16w_2  \\\n",
       "0                                   5.057234   \n",
       "1                                   3.825332   \n",
       "2                                   2.978955   \n",
       "3                                   2.665933   \n",
       "4                                   2.141665   \n",
       "..                                       ...   \n",
       "406                                -0.655689   \n",
       "407                                -0.459704   \n",
       "408                                -0.408143   \n",
       "409                                -0.452395   \n",
       "410                                -0.222063   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_1w_6  \\\n",
       "0                                  0.839851   \n",
       "1                                  1.871824   \n",
       "2                                  2.175787   \n",
       "3                                  2.151856   \n",
       "4                                  2.644978   \n",
       "..                                      ...   \n",
       "406                                1.600522   \n",
       "407                                1.017618   \n",
       "408                                0.542851   \n",
       "409                               -0.750222   \n",
       "410                               -0.857548   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_4w_1  \\\n",
       "0                                     1.758769   \n",
       "1                                     1.121893   \n",
       "2                                     0.598275   \n",
       "3                                     0.310672   \n",
       "4                                     0.314132   \n",
       "..                                         ...   \n",
       "406                                   0.030398   \n",
       "407                                   0.377049   \n",
       "408                                   0.643723   \n",
       "409                                  -0.102080   \n",
       "410                                   0.187242   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_0  \\\n",
       "0                                  0.309939   \n",
       "1                                  1.158323   \n",
       "2                                 -0.747849   \n",
       "3                                  0.618235   \n",
       "4                                 -0.197356   \n",
       "..                                      ...   \n",
       "406                                1.386827   \n",
       "407                                0.600403   \n",
       "408                                0.382350   \n",
       "409                               -1.910985   \n",
       "410                               -0.460368   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_1  \\\n",
       "0                                      1.937637   \n",
       "1                                      1.850264   \n",
       "2                                      1.614353   \n",
       "3                                      1.102825   \n",
       "4                                      1.639373   \n",
       "..                                          ...   \n",
       "406                                   -1.000215   \n",
       "407                                   -0.657988   \n",
       "408                                   -0.459207   \n",
       "409                                   -0.487928   \n",
       "410                                   -0.433529   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_4  \\\n",
       "0                                      2.719823   \n",
       "1                                      4.725401   \n",
       "2                                      2.989650   \n",
       "3                                      2.877711   \n",
       "4                                      1.887482   \n",
       "..                                          ...   \n",
       "406                                   -0.832783   \n",
       "407                                   -0.534876   \n",
       "408                                   -0.351997   \n",
       "409                                   -0.312771   \n",
       "410                                   -0.297669   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_6  Emiliani1  Emiliani2  \\\n",
       "0                                      2.154612          1          0   \n",
       "1                                      4.547085          1          0   \n",
       "2                                      3.013864          1          0   \n",
       "3                                      2.874078          1          0   \n",
       "4                                      2.011651          1          0   \n",
       "..                                          ...        ...        ...   \n",
       "406                                   -0.872908          0          0   \n",
       "407                                   -0.467096          0          0   \n",
       "408                                   -0.249248          0          0   \n",
       "409                                   -0.184850          0          0   \n",
       "410                                    0.028905          0          0   \n",
       "\n",
       "     Garda_Mincio  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "406             1  \n",
       "407             1  \n",
       "408             1  \n",
       "409             1  \n",
       "410             1  \n",
       "\n",
       "[1233 rows x 18 columns]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best5_wrapper_clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "e1e62dcc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in ['Emiliani1','Emiliani2','Garda_Mincio']:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "22593ca2",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.382765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.319215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.548542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.010351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.402030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>0.032299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>0.132804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>-0.214182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>-2.409204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>-2.673294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    -0.382765\n",
       "1     0.319215\n",
       "2     0.548542\n",
       "3    -0.010351\n",
       "4     0.402030\n",
       "...        ...\n",
       "1228  0.032299\n",
       "1229  0.132804\n",
       "1230 -0.214182\n",
       "1231 -2.409204\n",
       "1232 -2.673294\n",
       "\n",
       "[1233 rows x 1 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_train_unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "2e2eb590",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31486223593225293\n",
      "0.2084530199165946\n",
      "0.24633777765773346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_E1E2GM_ohe = LinearRegression()\n",
    "model_E1E2GM_ohe.fit(pd.concat((best5_wrapper_clusterdf_train_withClass,best5_wrapper_clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_E1E2GM_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Emiliani1==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani1'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Emiliani2==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani2'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Garda_Mincio==1].values)\n",
    "print(r2_score(targets_df_test['Garda_Mincio'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "51451691",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_0</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_16w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_12w_2</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_1w_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_1w_5</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_8w_3</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_8w_1</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_16w_2</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_1w_6</th>\n",
       "      <th>...</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_0_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_1_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_1_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_1_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_4_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_4_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_4_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_6_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_6_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_24w_6_Garda_Mincio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.563762</td>\n",
       "      <td>0.702658</td>\n",
       "      <td>2.356915</td>\n",
       "      <td>4.551719</td>\n",
       "      <td>0.733057</td>\n",
       "      <td>-0.890461</td>\n",
       "      <td>1.715033</td>\n",
       "      <td>0.451434</td>\n",
       "      <td>5.057234</td>\n",
       "      <td>0.839851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.937637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.719823</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.154612</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.725573</td>\n",
       "      <td>1.770284</td>\n",
       "      <td>2.298396</td>\n",
       "      <td>1.893610</td>\n",
       "      <td>0.688605</td>\n",
       "      <td>-0.266454</td>\n",
       "      <td>0.884643</td>\n",
       "      <td>1.266314</td>\n",
       "      <td>3.825332</td>\n",
       "      <td>1.871824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.850264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.725401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.547085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.426653</td>\n",
       "      <td>-0.294432</td>\n",
       "      <td>1.655602</td>\n",
       "      <td>1.912331</td>\n",
       "      <td>0.400704</td>\n",
       "      <td>-0.541753</td>\n",
       "      <td>0.397911</td>\n",
       "      <td>0.262699</td>\n",
       "      <td>2.978955</td>\n",
       "      <td>2.175787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.614353</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.989650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.013864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.048203</td>\n",
       "      <td>1.312823</td>\n",
       "      <td>0.788894</td>\n",
       "      <td>1.822362</td>\n",
       "      <td>0.740061</td>\n",
       "      <td>-0.679603</td>\n",
       "      <td>0.054424</td>\n",
       "      <td>0.396038</td>\n",
       "      <td>2.665933</td>\n",
       "      <td>2.151856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.102825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.877711</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.874078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.795649</td>\n",
       "      <td>0.083310</td>\n",
       "      <td>4.072560</td>\n",
       "      <td>2.039331</td>\n",
       "      <td>1.203853</td>\n",
       "      <td>-0.500179</td>\n",
       "      <td>0.103811</td>\n",
       "      <td>0.302639</td>\n",
       "      <td>2.141665</td>\n",
       "      <td>2.644978</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.639373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.887482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.011651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.549183</td>\n",
       "      <td>1.068315</td>\n",
       "      <td>-0.544373</td>\n",
       "      <td>-0.687935</td>\n",
       "      <td>-1.495602</td>\n",
       "      <td>0.805732</td>\n",
       "      <td>-0.293248</td>\n",
       "      <td>0.661497</td>\n",
       "      <td>-0.655689</td>\n",
       "      <td>1.600522</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386827</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.000215</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.832783</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.872908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.481985</td>\n",
       "      <td>0.560944</td>\n",
       "      <td>-0.518064</td>\n",
       "      <td>-0.626884</td>\n",
       "      <td>-0.968744</td>\n",
       "      <td>0.306776</td>\n",
       "      <td>-0.156714</td>\n",
       "      <td>0.689496</td>\n",
       "      <td>-0.459704</td>\n",
       "      <td>1.017618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600403</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.657988</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.534876</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.467096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.402054</td>\n",
       "      <td>0.350446</td>\n",
       "      <td>-0.616373</td>\n",
       "      <td>-0.606093</td>\n",
       "      <td>-0.646526</td>\n",
       "      <td>0.503166</td>\n",
       "      <td>0.174464</td>\n",
       "      <td>0.605186</td>\n",
       "      <td>-0.408143</td>\n",
       "      <td>0.542851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382350</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.459207</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.351997</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.249248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.146823</td>\n",
       "      <td>-1.792820</td>\n",
       "      <td>-0.325116</td>\n",
       "      <td>-0.462663</td>\n",
       "      <td>-0.400672</td>\n",
       "      <td>-1.067879</td>\n",
       "      <td>0.229314</td>\n",
       "      <td>0.030515</td>\n",
       "      <td>-0.452395</td>\n",
       "      <td>-0.750222</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.910985</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.487928</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.312771</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.184850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.051540</td>\n",
       "      <td>-0.120537</td>\n",
       "      <td>-0.236889</td>\n",
       "      <td>-0.568468</td>\n",
       "      <td>1.556927</td>\n",
       "      <td>-1.709317</td>\n",
       "      <td>0.223387</td>\n",
       "      <td>0.115353</td>\n",
       "      <td>-0.222063</td>\n",
       "      <td>-0.857548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.460368</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.433529</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.297669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows  63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emiliani1_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                  2.563762   \n",
       "1                                  1.725573   \n",
       "2                                  1.426653   \n",
       "3                                  1.048203   \n",
       "4                                  1.795649   \n",
       "..                                      ...   \n",
       "406                               -0.549183   \n",
       "407                               -0.481985   \n",
       "408                               -0.402054   \n",
       "409                               -0.146823   \n",
       "410                               -0.051540   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_0  \\\n",
       "0                               0.702658   \n",
       "1                               1.770284   \n",
       "2                              -0.294432   \n",
       "3                               1.312823   \n",
       "4                               0.083310   \n",
       "..                                   ...   \n",
       "406                             1.068315   \n",
       "407                             0.560944   \n",
       "408                             0.350446   \n",
       "409                            -1.792820   \n",
       "410                            -0.120537   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_16w_1  \\\n",
       "0                                   2.356915   \n",
       "1                                   2.298396   \n",
       "2                                   1.655602   \n",
       "3                                   0.788894   \n",
       "4                                   4.072560   \n",
       "..                                       ...   \n",
       "406                                -0.544373   \n",
       "407                                -0.518064   \n",
       "408                                -0.616373   \n",
       "409                                -0.325116   \n",
       "410                                -0.236889   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_12w_2  \\\n",
       "0                                   4.551719   \n",
       "1                                   1.893610   \n",
       "2                                   1.912331   \n",
       "3                                   1.822362   \n",
       "4                                   2.039331   \n",
       "..                                       ...   \n",
       "406                                -0.687935   \n",
       "407                                -0.626884   \n",
       "408                                -0.606093   \n",
       "409                                -0.462663   \n",
       "410                                -0.568468   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_1w_4  \\\n",
       "0                                  0.733057   \n",
       "1                                  0.688605   \n",
       "2                                  0.400704   \n",
       "3                                  0.740061   \n",
       "4                                  1.203853   \n",
       "..                                      ...   \n",
       "406                               -1.495602   \n",
       "407                               -0.968744   \n",
       "408                               -0.646526   \n",
       "409                               -0.400672   \n",
       "410                                1.556927   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_1w_5  \\\n",
       "0                                 -0.890461   \n",
       "1                                 -0.266454   \n",
       "2                                 -0.541753   \n",
       "3                                 -0.679603   \n",
       "4                                 -0.500179   \n",
       "..                                      ...   \n",
       "406                                0.805732   \n",
       "407                                0.306776   \n",
       "408                                0.503166   \n",
       "409                               -1.067879   \n",
       "410                               -1.709317   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_8w_3  \\\n",
       "0                                  1.715033   \n",
       "1                                  0.884643   \n",
       "2                                  0.397911   \n",
       "3                                  0.054424   \n",
       "4                                  0.103811   \n",
       "..                                      ...   \n",
       "406                               -0.293248   \n",
       "407                               -0.156714   \n",
       "408                                0.174464   \n",
       "409                                0.229314   \n",
       "410                                0.223387   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_8w_1  \\\n",
       "0                                  0.451434   \n",
       "1                                  1.266314   \n",
       "2                                  0.262699   \n",
       "3                                  0.396038   \n",
       "4                                  0.302639   \n",
       "..                                      ...   \n",
       "406                                0.661497   \n",
       "407                                0.689496   \n",
       "408                                0.605186   \n",
       "409                                0.030515   \n",
       "410                                0.115353   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_16w_2  \\\n",
       "0                                   5.057234   \n",
       "1                                   3.825332   \n",
       "2                                   2.978955   \n",
       "3                                   2.665933   \n",
       "4                                   2.141665   \n",
       "..                                       ...   \n",
       "406                                -0.655689   \n",
       "407                                -0.459704   \n",
       "408                                -0.408143   \n",
       "409                                -0.452395   \n",
       "410                                -0.222063   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_1w_6  ...  \\\n",
       "0                                  0.839851  ...   \n",
       "1                                  1.871824  ...   \n",
       "2                                  2.175787  ...   \n",
       "3                                  2.151856  ...   \n",
       "4                                  2.644978  ...   \n",
       "..                                      ...  ...   \n",
       "406                                1.600522  ...   \n",
       "407                                1.017618  ...   \n",
       "408                                0.542851  ...   \n",
       "409                               -0.750222  ...   \n",
       "410                               -0.857548  ...   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_0_Garda_Mincio  \\\n",
       "0                                             0.000000     \n",
       "1                                             0.000000     \n",
       "2                                            -0.000000     \n",
       "3                                             0.000000     \n",
       "4                                            -0.000000     \n",
       "..                                                 ...     \n",
       "406                                           1.386827     \n",
       "407                                           0.600403     \n",
       "408                                           0.382350     \n",
       "409                                          -1.910985     \n",
       "410                                          -0.460368     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_1_Emiliani1  \\\n",
       "0                                             1.937637      \n",
       "1                                             1.850264      \n",
       "2                                             1.614353      \n",
       "3                                             1.102825      \n",
       "4                                             1.639373      \n",
       "..                                                 ...      \n",
       "406                                          -0.000000      \n",
       "407                                          -0.000000      \n",
       "408                                          -0.000000      \n",
       "409                                          -0.000000      \n",
       "410                                          -0.000000      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_1_Emiliani2  \\\n",
       "0                                                  0.0      \n",
       "1                                                  0.0      \n",
       "2                                                  0.0      \n",
       "3                                                  0.0      \n",
       "4                                                  0.0      \n",
       "..                                                 ...      \n",
       "406                                               -0.0      \n",
       "407                                               -0.0      \n",
       "408                                               -0.0      \n",
       "409                                               -0.0      \n",
       "410                                               -0.0      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_1_Garda_Mincio  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -1.000215         \n",
       "407                                          -0.657988         \n",
       "408                                          -0.459207         \n",
       "409                                          -0.487928         \n",
       "410                                          -0.433529         \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_4_Emiliani1  \\\n",
       "0                                             2.719823      \n",
       "1                                             4.725401      \n",
       "2                                             2.989650      \n",
       "3                                             2.877711      \n",
       "4                                             1.887482      \n",
       "..                                                 ...      \n",
       "406                                          -0.000000      \n",
       "407                                          -0.000000      \n",
       "408                                          -0.000000      \n",
       "409                                          -0.000000      \n",
       "410                                          -0.000000      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_4_Emiliani2  \\\n",
       "0                                                  0.0      \n",
       "1                                                  0.0      \n",
       "2                                                  0.0      \n",
       "3                                                  0.0      \n",
       "4                                                  0.0      \n",
       "..                                                 ...      \n",
       "406                                               -0.0      \n",
       "407                                               -0.0      \n",
       "408                                               -0.0      \n",
       "409                                               -0.0      \n",
       "410                                               -0.0      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_4_Garda_Mincio  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.832783         \n",
       "407                                          -0.534876         \n",
       "408                                          -0.351997         \n",
       "409                                          -0.312771         \n",
       "410                                          -0.297669         \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_6_Emiliani1  \\\n",
       "0                                             2.154612      \n",
       "1                                             4.547085      \n",
       "2                                             3.013864      \n",
       "3                                             2.874078      \n",
       "4                                             2.011651      \n",
       "..                                                 ...      \n",
       "406                                          -0.000000      \n",
       "407                                          -0.000000      \n",
       "408                                          -0.000000      \n",
       "409                                          -0.000000      \n",
       "410                                           0.000000      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_6_Emiliani2  \\\n",
       "0                                                  0.0      \n",
       "1                                                  0.0      \n",
       "2                                                  0.0      \n",
       "3                                                  0.0      \n",
       "4                                                  0.0      \n",
       "..                                                 ...      \n",
       "406                                               -0.0      \n",
       "407                                               -0.0      \n",
       "408                                               -0.0      \n",
       "409                                               -0.0      \n",
       "410                                                0.0      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_24w_6_Garda_Mincio  \n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                             0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                          -0.872908        \n",
       "407                                          -0.467096        \n",
       "408                                          -0.249248        \n",
       "409                                          -0.184850        \n",
       "410                                           0.028905        \n",
       "\n",
       "[1233 rows x 63 columns]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(best5_wrapper_clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        best5_wrapper_clusterdf_train_withClass[best5_wrapper_clusterdf_train_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        best5_wrapper_clusterdf_val_withClass[best5_wrapper_clusterdf_val_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        best5_wrapper_clusterdf_test_withClass[best5_wrapper_clusterdf_test_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "e1247120",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2983574252239063\n",
      "0.2060983834314577\n",
      "0.23368544966756366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_E1E2GM_ohe = LinearRegression()\n",
    "model_E1E2GM_ohe.fit(pd.concat((best5_wrapper_clusterdf_train_withClass,best5_wrapper_clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_E1E2GM_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Emiliani1==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani1'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Emiliani2==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani2'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Garda_Mincio==1].values)\n",
    "print(r2_score(targets_df_test['Garda_Mincio'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a932b5de",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Emiliani1 - Emiliani2 - Garda_Mincio: CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "b2245869",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### prova con Emiliani1 e 2 e Garda_Mincio\n",
    "clust_basins = ['Emiliani1','Emiliani2','Garda_Mincio']\n",
    "colnames = [x for x in CMI_fulldf_train.columns if x.startswith('Emiliani1') or x.startswith('Emiliani2') or x.startswith('Garda_Mincio')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(3):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(3):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "5ae0ff20",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_8w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_9</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_4w_3</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_12w_0</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_0</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_12w_2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_8w_0</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Emiliani1</th>\n",
       "      <th>Emiliani2</th>\n",
       "      <th>Garda_Mincio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.112078</td>\n",
       "      <td>0.345989</td>\n",
       "      <td>1.690770</td>\n",
       "      <td>3.965287</td>\n",
       "      <td>0.268224</td>\n",
       "      <td>2.563762</td>\n",
       "      <td>-0.415835</td>\n",
       "      <td>0.733822</td>\n",
       "      <td>-0.736407</td>\n",
       "      <td>2.581050</td>\n",
       "      <td>...</td>\n",
       "      <td>2.601327</td>\n",
       "      <td>1.154090</td>\n",
       "      <td>0.309939</td>\n",
       "      <td>1.365733</td>\n",
       "      <td>1.718220</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>1.758769</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.404523</td>\n",
       "      <td>1.128851</td>\n",
       "      <td>1.865833</td>\n",
       "      <td>1.655892</td>\n",
       "      <td>0.977612</td>\n",
       "      <td>1.725573</td>\n",
       "      <td>0.237307</td>\n",
       "      <td>0.849889</td>\n",
       "      <td>0.294888</td>\n",
       "      <td>2.460299</td>\n",
       "      <td>...</td>\n",
       "      <td>2.248295</td>\n",
       "      <td>1.494420</td>\n",
       "      <td>1.158323</td>\n",
       "      <td>1.161450</td>\n",
       "      <td>3.292752</td>\n",
       "      <td>1.350980</td>\n",
       "      <td>1.121893</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.162736</td>\n",
       "      <td>0.786460</td>\n",
       "      <td>1.429151</td>\n",
       "      <td>1.672157</td>\n",
       "      <td>-0.780151</td>\n",
       "      <td>1.426653</td>\n",
       "      <td>-0.259989</td>\n",
       "      <td>0.518355</td>\n",
       "      <td>-1.191392</td>\n",
       "      <td>1.657472</td>\n",
       "      <td>...</td>\n",
       "      <td>1.476876</td>\n",
       "      <td>0.992024</td>\n",
       "      <td>-0.747849</td>\n",
       "      <td>0.765542</td>\n",
       "      <td>2.143920</td>\n",
       "      <td>0.395851</td>\n",
       "      <td>0.598275</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861999</td>\n",
       "      <td>0.564161</td>\n",
       "      <td>0.611897</td>\n",
       "      <td>1.593990</td>\n",
       "      <td>0.408553</td>\n",
       "      <td>1.048203</td>\n",
       "      <td>-0.565851</td>\n",
       "      <td>0.239497</td>\n",
       "      <td>0.067063</td>\n",
       "      <td>1.600489</td>\n",
       "      <td>...</td>\n",
       "      <td>1.354389</td>\n",
       "      <td>0.831685</td>\n",
       "      <td>0.618235</td>\n",
       "      <td>0.486500</td>\n",
       "      <td>2.057757</td>\n",
       "      <td>0.584992</td>\n",
       "      <td>0.310672</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.461930</td>\n",
       "      <td>0.604584</td>\n",
       "      <td>4.150391</td>\n",
       "      <td>1.782496</td>\n",
       "      <td>-0.260577</td>\n",
       "      <td>1.795649</td>\n",
       "      <td>-0.187005</td>\n",
       "      <td>0.696217</td>\n",
       "      <td>-0.894857</td>\n",
       "      <td>1.249495</td>\n",
       "      <td>...</td>\n",
       "      <td>1.149851</td>\n",
       "      <td>0.648410</td>\n",
       "      <td>-0.197356</td>\n",
       "      <td>0.471393</td>\n",
       "      <td>1.411145</td>\n",
       "      <td>0.375705</td>\n",
       "      <td>0.314132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.211596</td>\n",
       "      <td>0.739113</td>\n",
       "      <td>-0.281990</td>\n",
       "      <td>-0.636426</td>\n",
       "      <td>1.599630</td>\n",
       "      <td>-0.549183</td>\n",
       "      <td>1.352614</td>\n",
       "      <td>-0.220555</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>-0.187672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.500492</td>\n",
       "      <td>-0.325559</td>\n",
       "      <td>1.386827</td>\n",
       "      <td>-0.243007</td>\n",
       "      <td>-0.779607</td>\n",
       "      <td>0.784844</td>\n",
       "      <td>0.030398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.765747</td>\n",
       "      <td>0.855313</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-1.204469</td>\n",
       "      <td>0.920235</td>\n",
       "      <td>-0.481985</td>\n",
       "      <td>1.040390</td>\n",
       "      <td>0.346445</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>-0.358316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168721</td>\n",
       "      <td>-0.048154</td>\n",
       "      <td>0.600403</td>\n",
       "      <td>-0.089677</td>\n",
       "      <td>-0.282528</td>\n",
       "      <td>0.689576</td>\n",
       "      <td>0.377049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.609296</td>\n",
       "      <td>0.697286</td>\n",
       "      <td>-0.562017</td>\n",
       "      <td>-1.089158</td>\n",
       "      <td>0.341994</td>\n",
       "      <td>-0.402054</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>0.429694</td>\n",
       "      <td>0.796373</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094182</td>\n",
       "      <td>0.392946</td>\n",
       "      <td>0.382350</td>\n",
       "      <td>0.196236</td>\n",
       "      <td>-0.211020</td>\n",
       "      <td>0.473678</td>\n",
       "      <td>0.643723</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.836849</td>\n",
       "      <td>-0.719738</td>\n",
       "      <td>-0.028118</td>\n",
       "      <td>-0.925439</td>\n",
       "      <td>-1.523290</td>\n",
       "      <td>-0.146823</td>\n",
       "      <td>-0.631908</td>\n",
       "      <td>-0.434877</td>\n",
       "      <td>-2.562406</td>\n",
       "      <td>-0.028237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027915</td>\n",
       "      <td>-0.140998</td>\n",
       "      <td>-1.910985</td>\n",
       "      <td>0.283754</td>\n",
       "      <td>-0.190893</td>\n",
       "      <td>-0.254712</td>\n",
       "      <td>-0.102080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.283715</td>\n",
       "      <td>-1.078052</td>\n",
       "      <td>0.226971</td>\n",
       "      <td>-0.799403</td>\n",
       "      <td>-0.625862</td>\n",
       "      <td>-0.051540</td>\n",
       "      <td>-1.226069</td>\n",
       "      <td>0.334461</td>\n",
       "      <td>-0.263730</td>\n",
       "      <td>0.344734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228144</td>\n",
       "      <td>0.297361</td>\n",
       "      <td>-0.460368</td>\n",
       "      <td>0.250722</td>\n",
       "      <td>0.025355</td>\n",
       "      <td>-0.180499</td>\n",
       "      <td>0.187242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emiliani1_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                  2.112078   \n",
       "1                                  1.404523   \n",
       "2                                  1.162736   \n",
       "3                                  0.861999   \n",
       "4                                  1.461930   \n",
       "..                                      ...   \n",
       "406                               -0.211596   \n",
       "407                               -0.765747   \n",
       "408                               -0.609296   \n",
       "409                               -0.836849   \n",
       "410                               -0.283715   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                  0.345989   \n",
       "1                                  1.128851   \n",
       "2                                  0.786460   \n",
       "3                                  0.564161   \n",
       "4                                  0.604584   \n",
       "..                                      ...   \n",
       "406                                0.739113   \n",
       "407                                0.855313   \n",
       "408                                0.697286   \n",
       "409                               -0.719738   \n",
       "410                               -1.078052   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_12w_1  \\\n",
       "0                                   1.690770   \n",
       "1                                   1.865833   \n",
       "2                                   1.429151   \n",
       "3                                   0.611897   \n",
       "4                                   4.150391   \n",
       "..                                       ...   \n",
       "406                                -0.281990   \n",
       "407                                -0.234571   \n",
       "408                                -0.562017   \n",
       "409                                -0.028118   \n",
       "410                                 0.226971   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_8w_1  \\\n",
       "0                                  3.965287   \n",
       "1                                  1.655892   \n",
       "2                                  1.672157   \n",
       "3                                  1.593990   \n",
       "4                                  1.782496   \n",
       "..                                      ...   \n",
       "406                               -0.636426   \n",
       "407                               -1.204469   \n",
       "408                               -1.089158   \n",
       "409                               -0.925439   \n",
       "410                               -0.799403   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_9  \\\n",
       "0                               0.268224   \n",
       "1                               0.977612   \n",
       "2                              -0.780151   \n",
       "3                               0.408553   \n",
       "4                              -0.260577   \n",
       "..                                   ...   \n",
       "406                             1.599630   \n",
       "407                             0.920235   \n",
       "408                             0.341994   \n",
       "409                            -1.523290   \n",
       "410                            -0.625862   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                  2.563762   \n",
       "1                                  1.725573   \n",
       "2                                  1.426653   \n",
       "3                                  1.048203   \n",
       "4                                  1.795649   \n",
       "..                                      ...   \n",
       "406                               -0.549183   \n",
       "407                               -0.481985   \n",
       "408                               -0.402054   \n",
       "409                               -0.146823   \n",
       "410                               -0.051540   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                 -0.415835   \n",
       "1                                  0.237307   \n",
       "2                                 -0.259989   \n",
       "3                                 -0.565851   \n",
       "4                                 -0.187005   \n",
       "..                                      ...   \n",
       "406                                1.352614   \n",
       "407                                1.040390   \n",
       "408                                0.830698   \n",
       "409                               -0.631908   \n",
       "410                               -1.226069   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_4w_3  \\\n",
       "0                                  0.733822   \n",
       "1                                  0.849889   \n",
       "2                                  0.518355   \n",
       "3                                  0.239497   \n",
       "4                                  0.696217   \n",
       "..                                      ...   \n",
       "406                               -0.220555   \n",
       "407                                0.346445   \n",
       "408                                0.429694   \n",
       "409                               -0.434877   \n",
       "410                                0.334461   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_4  \\\n",
       "0                              -0.736407   \n",
       "1                               0.294888   \n",
       "2                              -1.191392   \n",
       "3                               0.067063   \n",
       "4                              -0.894857   \n",
       "..                                   ...   \n",
       "406                             0.471800   \n",
       "407                             0.034058   \n",
       "408                             0.796373   \n",
       "409                            -2.562406   \n",
       "410                            -0.263730   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_8w_0  ...  \\\n",
       "0                                  2.581050  ...   \n",
       "1                                  2.460299  ...   \n",
       "2                                  1.657472  ...   \n",
       "3                                  1.600489  ...   \n",
       "4                                  1.249495  ...   \n",
       "..                                      ...  ...   \n",
       "406                               -0.187672  ...   \n",
       "407                               -0.358316  ...   \n",
       "408                               -0.106524  ...   \n",
       "409                               -0.028237  ...   \n",
       "410                                0.344734  ...   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_12w_0  \\\n",
       "0                                   2.601327   \n",
       "1                                   2.248295   \n",
       "2                                   1.476876   \n",
       "3                                   1.354389   \n",
       "4                                   1.149851   \n",
       "..                                       ...   \n",
       "406                                -0.500492   \n",
       "407                                -0.168721   \n",
       "408                                -0.094182   \n",
       "409                                 0.027915   \n",
       "410                                 0.228144   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                     1.154090   \n",
       "1                                     1.494420   \n",
       "2                                     0.992024   \n",
       "3                                     0.831685   \n",
       "4                                     0.648410   \n",
       "..                                         ...   \n",
       "406                                  -0.325559   \n",
       "407                                  -0.048154   \n",
       "408                                   0.392946   \n",
       "409                                  -0.140998   \n",
       "410                                   0.297361   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_0  \\\n",
       "0                                  0.309939   \n",
       "1                                  1.158323   \n",
       "2                                 -0.747849   \n",
       "3                                  0.618235   \n",
       "4                                 -0.197356   \n",
       "..                                      ...   \n",
       "406                                1.386827   \n",
       "407                                0.600403   \n",
       "408                                0.382350   \n",
       "409                               -1.910985   \n",
       "410                               -0.460368   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                     1.365733   \n",
       "1                                     1.161450   \n",
       "2                                     0.765542   \n",
       "3                                     0.486500   \n",
       "4                                     0.471393   \n",
       "..                                         ...   \n",
       "406                                  -0.243007   \n",
       "407                                  -0.089677   \n",
       "408                                   0.196236   \n",
       "409                                   0.283754   \n",
       "410                                   0.250722   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_12w_2  \\\n",
       "0                                      1.718220   \n",
       "1                                      3.292752   \n",
       "2                                      2.143920   \n",
       "3                                      2.057757   \n",
       "4                                      1.411145   \n",
       "..                                          ...   \n",
       "406                                   -0.779607   \n",
       "407                                   -0.282528   \n",
       "408                                   -0.211020   \n",
       "409                                   -0.190893   \n",
       "410                                    0.025355   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_8w_0  \\\n",
       "0                                     0.523659   \n",
       "1                                     1.350980   \n",
       "2                                     0.395851   \n",
       "3                                     0.584992   \n",
       "4                                     0.375705   \n",
       "..                                         ...   \n",
       "406                                   0.784844   \n",
       "407                                   0.689576   \n",
       "408                                   0.473678   \n",
       "409                                  -0.254712   \n",
       "410                                  -0.180499   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_4w_1  Emiliani1  Emiliani2  \\\n",
       "0                                     1.758769          1          0   \n",
       "1                                     1.121893          1          0   \n",
       "2                                     0.598275          1          0   \n",
       "3                                     0.310672          1          0   \n",
       "4                                     0.314132          1          0   \n",
       "..                                         ...        ...        ...   \n",
       "406                                   0.030398          0          0   \n",
       "407                                   0.377049          0          0   \n",
       "408                                   0.643723          0          0   \n",
       "409                                  -0.102080          0          0   \n",
       "410                                   0.187242          0          0   \n",
       "\n",
       "     Garda_Mincio  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "406             1  \n",
       "407             1  \n",
       "408             1  \n",
       "409             1  \n",
       "410             1  \n",
       "\n",
       "[1233 rows x 27 columns]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "1168cfe6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in ['Emiliani1','Emiliani2','Garda_Mincio']:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "076285b1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.382765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.319215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.548542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.010351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.402030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>0.032299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>0.132804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>-0.214182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>-2.409204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>-2.673294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    -0.382765\n",
       "1     0.319215\n",
       "2     0.548542\n",
       "3    -0.010351\n",
       "4     0.402030\n",
       "...        ...\n",
       "1228  0.032299\n",
       "1229  0.132804\n",
       "1230 -0.214182\n",
       "1231 -2.409204\n",
       "1232 -2.673294\n",
       "\n",
       "[1233 rows x 1 columns]"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_train_unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "ca3e4ad6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24672638409672598\n",
      "0.13606766610694088\n",
      "0.22388038233882868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_E1E2GM_ohe = LinearRegression()\n",
    "model_E1E2GM_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Emiliani1==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani1'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Emiliani2==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani2'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Garda_Mincio==1].values)\n",
    "print(r2_score(targets_df_test['Garda_Mincio'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "01635641",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_8w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_9</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_4w_3</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_8w_0_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_12w_2_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_12w_2_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_12w_2_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_8w_0_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_8w_0_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_8w_0_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_4w_1_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_4w_1_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_4w_1_Garda_Mincio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.112078</td>\n",
       "      <td>0.345989</td>\n",
       "      <td>1.690770</td>\n",
       "      <td>3.965287</td>\n",
       "      <td>0.268224</td>\n",
       "      <td>2.563762</td>\n",
       "      <td>-0.415835</td>\n",
       "      <td>0.733822</td>\n",
       "      <td>-0.736407</td>\n",
       "      <td>2.581050</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.718220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.758769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.404523</td>\n",
       "      <td>1.128851</td>\n",
       "      <td>1.865833</td>\n",
       "      <td>1.655892</td>\n",
       "      <td>0.977612</td>\n",
       "      <td>1.725573</td>\n",
       "      <td>0.237307</td>\n",
       "      <td>0.849889</td>\n",
       "      <td>0.294888</td>\n",
       "      <td>2.460299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.292752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.350980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.121893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.162736</td>\n",
       "      <td>0.786460</td>\n",
       "      <td>1.429151</td>\n",
       "      <td>1.672157</td>\n",
       "      <td>-0.780151</td>\n",
       "      <td>1.426653</td>\n",
       "      <td>-0.259989</td>\n",
       "      <td>0.518355</td>\n",
       "      <td>-1.191392</td>\n",
       "      <td>1.657472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.143920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.598275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861999</td>\n",
       "      <td>0.564161</td>\n",
       "      <td>0.611897</td>\n",
       "      <td>1.593990</td>\n",
       "      <td>0.408553</td>\n",
       "      <td>1.048203</td>\n",
       "      <td>-0.565851</td>\n",
       "      <td>0.239497</td>\n",
       "      <td>0.067063</td>\n",
       "      <td>1.600489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.057757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.461930</td>\n",
       "      <td>0.604584</td>\n",
       "      <td>4.150391</td>\n",
       "      <td>1.782496</td>\n",
       "      <td>-0.260577</td>\n",
       "      <td>1.795649</td>\n",
       "      <td>-0.187005</td>\n",
       "      <td>0.696217</td>\n",
       "      <td>-0.894857</td>\n",
       "      <td>1.249495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.411145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.211596</td>\n",
       "      <td>0.739113</td>\n",
       "      <td>-0.281990</td>\n",
       "      <td>-0.636426</td>\n",
       "      <td>1.599630</td>\n",
       "      <td>-0.549183</td>\n",
       "      <td>1.352614</td>\n",
       "      <td>-0.220555</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>-0.187672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.243007</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.779607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.784844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.765747</td>\n",
       "      <td>0.855313</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-1.204469</td>\n",
       "      <td>0.920235</td>\n",
       "      <td>-0.481985</td>\n",
       "      <td>1.040390</td>\n",
       "      <td>0.346445</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>-0.358316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089677</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.282528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.609296</td>\n",
       "      <td>0.697286</td>\n",
       "      <td>-0.562017</td>\n",
       "      <td>-1.089158</td>\n",
       "      <td>0.341994</td>\n",
       "      <td>-0.402054</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>0.429694</td>\n",
       "      <td>0.796373</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196236</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.211020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.643723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.836849</td>\n",
       "      <td>-0.719738</td>\n",
       "      <td>-0.028118</td>\n",
       "      <td>-0.925439</td>\n",
       "      <td>-1.523290</td>\n",
       "      <td>-0.146823</td>\n",
       "      <td>-0.631908</td>\n",
       "      <td>-0.434877</td>\n",
       "      <td>-2.562406</td>\n",
       "      <td>-0.028237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283754</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.190893</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.254712</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.102080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.283715</td>\n",
       "      <td>-1.078052</td>\n",
       "      <td>0.226971</td>\n",
       "      <td>-0.799403</td>\n",
       "      <td>-0.625862</td>\n",
       "      <td>-0.051540</td>\n",
       "      <td>-1.226069</td>\n",
       "      <td>0.334461</td>\n",
       "      <td>-0.263730</td>\n",
       "      <td>0.344734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025355</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.180499</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows  99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emiliani1_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                  2.112078   \n",
       "1                                  1.404523   \n",
       "2                                  1.162736   \n",
       "3                                  0.861999   \n",
       "4                                  1.461930   \n",
       "..                                      ...   \n",
       "406                               -0.211596   \n",
       "407                               -0.765747   \n",
       "408                               -0.609296   \n",
       "409                               -0.836849   \n",
       "410                               -0.283715   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                  0.345989   \n",
       "1                                  1.128851   \n",
       "2                                  0.786460   \n",
       "3                                  0.564161   \n",
       "4                                  0.604584   \n",
       "..                                      ...   \n",
       "406                                0.739113   \n",
       "407                                0.855313   \n",
       "408                                0.697286   \n",
       "409                               -0.719738   \n",
       "410                               -1.078052   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_12w_1  \\\n",
       "0                                   1.690770   \n",
       "1                                   1.865833   \n",
       "2                                   1.429151   \n",
       "3                                   0.611897   \n",
       "4                                   4.150391   \n",
       "..                                       ...   \n",
       "406                                -0.281990   \n",
       "407                                -0.234571   \n",
       "408                                -0.562017   \n",
       "409                                -0.028118   \n",
       "410                                 0.226971   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_8w_1  \\\n",
       "0                                  3.965287   \n",
       "1                                  1.655892   \n",
       "2                                  1.672157   \n",
       "3                                  1.593990   \n",
       "4                                  1.782496   \n",
       "..                                      ...   \n",
       "406                               -0.636426   \n",
       "407                               -1.204469   \n",
       "408                               -1.089158   \n",
       "409                               -0.925439   \n",
       "410                               -0.799403   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_9  \\\n",
       "0                               0.268224   \n",
       "1                               0.977612   \n",
       "2                              -0.780151   \n",
       "3                               0.408553   \n",
       "4                              -0.260577   \n",
       "..                                   ...   \n",
       "406                             1.599630   \n",
       "407                             0.920235   \n",
       "408                             0.341994   \n",
       "409                            -1.523290   \n",
       "410                            -0.625862   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                  2.563762   \n",
       "1                                  1.725573   \n",
       "2                                  1.426653   \n",
       "3                                  1.048203   \n",
       "4                                  1.795649   \n",
       "..                                      ...   \n",
       "406                               -0.549183   \n",
       "407                               -0.481985   \n",
       "408                               -0.402054   \n",
       "409                               -0.146823   \n",
       "410                               -0.051540   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                 -0.415835   \n",
       "1                                  0.237307   \n",
       "2                                 -0.259989   \n",
       "3                                 -0.565851   \n",
       "4                                 -0.187005   \n",
       "..                                      ...   \n",
       "406                                1.352614   \n",
       "407                                1.040390   \n",
       "408                                0.830698   \n",
       "409                               -0.631908   \n",
       "410                               -1.226069   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_4w_3  \\\n",
       "0                                  0.733822   \n",
       "1                                  0.849889   \n",
       "2                                  0.518355   \n",
       "3                                  0.239497   \n",
       "4                                  0.696217   \n",
       "..                                      ...   \n",
       "406                               -0.220555   \n",
       "407                                0.346445   \n",
       "408                                0.429694   \n",
       "409                               -0.434877   \n",
       "410                                0.334461   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_4  \\\n",
       "0                              -0.736407   \n",
       "1                               0.294888   \n",
       "2                              -1.191392   \n",
       "3                               0.067063   \n",
       "4                              -0.894857   \n",
       "..                                   ...   \n",
       "406                             0.471800   \n",
       "407                             0.034058   \n",
       "408                             0.796373   \n",
       "409                            -2.562406   \n",
       "410                            -0.263730   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_8w_0  ...  \\\n",
       "0                                  2.581050  ...   \n",
       "1                                  2.460299  ...   \n",
       "2                                  1.657472  ...   \n",
       "3                                  1.600489  ...   \n",
       "4                                  1.249495  ...   \n",
       "..                                      ...  ...   \n",
       "406                               -0.187672  ...   \n",
       "407                               -0.358316  ...   \n",
       "408                               -0.106524  ...   \n",
       "409                               -0.028237  ...   \n",
       "410                                0.344734  ...   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_8w_0_Garda_Mincio  \\\n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                             0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                          -0.243007        \n",
       "407                                          -0.089677        \n",
       "408                                           0.196236        \n",
       "409                                           0.283754        \n",
       "410                                           0.250722        \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_12w_2_Emiliani1  \\\n",
       "0                                             1.718220      \n",
       "1                                             3.292752      \n",
       "2                                             2.143920      \n",
       "3                                             2.057757      \n",
       "4                                             1.411145      \n",
       "..                                                 ...      \n",
       "406                                          -0.000000      \n",
       "407                                          -0.000000      \n",
       "408                                          -0.000000      \n",
       "409                                          -0.000000      \n",
       "410                                           0.000000      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_12w_2_Emiliani2  \\\n",
       "0                                                  0.0      \n",
       "1                                                  0.0      \n",
       "2                                                  0.0      \n",
       "3                                                  0.0      \n",
       "4                                                  0.0      \n",
       "..                                                 ...      \n",
       "406                                               -0.0      \n",
       "407                                               -0.0      \n",
       "408                                               -0.0      \n",
       "409                                               -0.0      \n",
       "410                                                0.0      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_12w_2_Garda_Mincio  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.779607         \n",
       "407                                          -0.282528         \n",
       "408                                          -0.211020         \n",
       "409                                          -0.190893         \n",
       "410                                           0.025355         \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_8w_0_Emiliani1  \\\n",
       "0                                             0.523659     \n",
       "1                                             1.350980     \n",
       "2                                             0.395851     \n",
       "3                                             0.584992     \n",
       "4                                             0.375705     \n",
       "..                                                 ...     \n",
       "406                                           0.000000     \n",
       "407                                           0.000000     \n",
       "408                                           0.000000     \n",
       "409                                          -0.000000     \n",
       "410                                          -0.000000     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_8w_0_Emiliani2  \\\n",
       "0                                                  0.0     \n",
       "1                                                  0.0     \n",
       "2                                                  0.0     \n",
       "3                                                  0.0     \n",
       "4                                                  0.0     \n",
       "..                                                 ...     \n",
       "406                                                0.0     \n",
       "407                                                0.0     \n",
       "408                                                0.0     \n",
       "409                                               -0.0     \n",
       "410                                               -0.0     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_8w_0_Garda_Mincio  \\\n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                             0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                           0.784844        \n",
       "407                                           0.689576        \n",
       "408                                           0.473678        \n",
       "409                                          -0.254712        \n",
       "410                                          -0.180499        \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_4w_1_Emiliani1  \\\n",
       "0                                             1.758769     \n",
       "1                                             1.121893     \n",
       "2                                             0.598275     \n",
       "3                                             0.310672     \n",
       "4                                             0.314132     \n",
       "..                                                 ...     \n",
       "406                                           0.000000     \n",
       "407                                           0.000000     \n",
       "408                                           0.000000     \n",
       "409                                          -0.000000     \n",
       "410                                           0.000000     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_4w_1_Emiliani2  \\\n",
       "0                                                  0.0     \n",
       "1                                                  0.0     \n",
       "2                                                  0.0     \n",
       "3                                                  0.0     \n",
       "4                                                  0.0     \n",
       "..                                                 ...     \n",
       "406                                                0.0     \n",
       "407                                                0.0     \n",
       "408                                                0.0     \n",
       "409                                               -0.0     \n",
       "410                                                0.0     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_4w_1_Garda_Mincio  \n",
       "0                                             0.000000       \n",
       "1                                             0.000000       \n",
       "2                                             0.000000       \n",
       "3                                             0.000000       \n",
       "4                                             0.000000       \n",
       "..                                                 ...       \n",
       "406                                           0.030398       \n",
       "407                                           0.377049       \n",
       "408                                           0.643723       \n",
       "409                                          -0.102080       \n",
       "410                                           0.187242       \n",
       "\n",
       "[1233 rows x 99 columns]"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        clusterdf_train_withClass[clusterdf_train_withClass.columns[i]+'_'+j] = clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_val_withClass[clusterdf_val_withClass.columns[i]+'_'+j] = clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_test_withClass[clusterdf_test_withClass.columns[i]+'_'+j] = clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "d07bdd76",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27369143203190605\n",
      "0.1317049349915349\n",
      "0.2036432280102406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_E1E2GM_ohe = LinearRegression()\n",
    "model_E1E2GM_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Emiliani1==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani1'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Emiliani2==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani2'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Garda_Mincio==1].values)\n",
    "print(r2_score(targets_df_test['Garda_Mincio'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b92661",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Emiliani1 - Emiliani2 - Garda_Mincio: CMI best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55da185e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### prova con Emiliani1 e 2 e Garda_Mincio\n",
    "clust_basins = ['Emiliani1','Emiliani2','Garda_Mincio']\n",
    "colnames = [x for x in best5_CMI_fulldf_train.columns if x.startswith('Emiliani1') or x.startswith('Emiliani2') or x.startswith('Garda_Mincio')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(3):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((best5_CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((best5_CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((best5_CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(3):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "597c5252",
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emiliani1_rr_4w_0</th>\n",
       "      <th>Emiliani2_tg_1w_4</th>\n",
       "      <th>Garda_tg_8w_0</th>\n",
       "      <th>Emiliani1</th>\n",
       "      <th>Emiliani2</th>\n",
       "      <th>Garda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.112078</td>\n",
       "      <td>-0.415835</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.404523</td>\n",
       "      <td>0.237307</td>\n",
       "      <td>1.350980</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.162736</td>\n",
       "      <td>-0.259989</td>\n",
       "      <td>0.395851</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861999</td>\n",
       "      <td>-0.565851</td>\n",
       "      <td>0.584992</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.461930</td>\n",
       "      <td>-0.187005</td>\n",
       "      <td>0.375705</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.211596</td>\n",
       "      <td>1.352614</td>\n",
       "      <td>0.784844</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.765747</td>\n",
       "      <td>1.040390</td>\n",
       "      <td>0.689576</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.609296</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>0.473678</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.836849</td>\n",
       "      <td>-0.631908</td>\n",
       "      <td>-0.254712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.283715</td>\n",
       "      <td>-1.226069</td>\n",
       "      <td>-0.180499</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emiliani1_rr_4w_0  Emiliani2_tg_1w_4  Garda_tg_8w_0  Emiliani1  \\\n",
       "0             2.112078          -0.415835       0.523659          1   \n",
       "1             1.404523           0.237307       1.350980          1   \n",
       "2             1.162736          -0.259989       0.395851          1   \n",
       "3             0.861999          -0.565851       0.584992          1   \n",
       "4             1.461930          -0.187005       0.375705          1   \n",
       "..                 ...                ...            ...        ...   \n",
       "406          -0.211596           1.352614       0.784844          0   \n",
       "407          -0.765747           1.040390       0.689576          0   \n",
       "408          -0.609296           0.830698       0.473678          0   \n",
       "409          -0.836849          -0.631908      -0.254712          0   \n",
       "410          -0.283715          -1.226069      -0.180499          0   \n",
       "\n",
       "     Emiliani2  Garda  \n",
       "0            0      0  \n",
       "1            0      0  \n",
       "2            0      0  \n",
       "3            0      0  \n",
       "4            0      0  \n",
       "..         ...    ...  \n",
       "406          0      1  \n",
       "407          0      1  \n",
       "408          0      1  \n",
       "409          0      1  \n",
       "410          0      1  \n",
       "\n",
       "[1233 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdf_train_withClass[['Emiliani1_cyclostationary_mean_rr_4w_0','Emiliani2_cyclostationary_mean_tg_1w_4','Garda_Mincio_cyclostationary_mean_tg_8w_0','Emiliani1','Emiliani2','Garda_Mincio']].rename(columns={\"Garda_Mincio\": \"Garda\",\"Emiliani1_cyclostationary_mean_rr_4w_0\":\"Emiliani1_rr_4w_0\",\"Emiliani2_cyclostationary_mean_tg_1w_4\":\"Emiliani2_tg_1w_4\",\"Garda_Mincio_cyclostationary_mean_tg_8w_0\":\"Garda_tg_8w_0\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72780992",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "b48b19df",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in ['Emiliani1','Emiliani2','Garda_Mincio']:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "61c3ffd8",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.382765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.319215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.548542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.010351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.402030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>0.032299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>0.132804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>-0.214182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>-2.409204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>-2.673294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    -0.382765\n",
       "1     0.319215\n",
       "2     0.548542\n",
       "3    -0.010351\n",
       "4     0.402030\n",
       "...        ...\n",
       "1228  0.032299\n",
       "1229  0.132804\n",
       "1230 -0.214182\n",
       "1231 -2.409204\n",
       "1232 -2.673294\n",
       "\n",
       "[1233 rows x 1 columns]"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_train_unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "714f56e5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4031090822249198\n",
      "0.3100764945337038\n",
      "0.28477623168379684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_E1E2GM_ohe = LinearRegression()\n",
    "model_E1E2GM_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Emiliani1==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani1'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Emiliani2==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani2'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Garda_Mincio==1].values)\n",
    "print(r2_score(targets_df_test['Garda_Mincio'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "f5d2a8ea",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.15359654 -0.08367787  0.18876555 -0.08755932 -0.12342461 -0.00735284\n",
      "   0.12504554 -0.11491597 -0.04351746 -0.02367721 -0.03127354 -0.03282753\n",
      "   0.24373819 -0.07772121  0.11412778 -0.05248622 -0.02688542  0.07937163]] [0.0245803]\n"
     ]
    }
   ],
   "source": [
    "print(model_E1E2GM_ohe.coef_,model_E1E2GM_ohe.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "aa9c82bf",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_rr_8w_1</th>\n",
       "      <th>Emiliani1_cyclostationary_mean_tg_9</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_4w_3</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_tg_4</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Emiliani2_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_0_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_8w_0_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_8w_0_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_8w_0_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_12w_2_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_12w_2_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_rr_12w_2_Garda_Mincio</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_8w_0_Emiliani1</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_8w_0_Emiliani2</th>\n",
       "      <th>Garda_Mincio_cyclostationary_mean_tg_8w_0_Garda_Mincio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.112078</td>\n",
       "      <td>0.345989</td>\n",
       "      <td>1.690770</td>\n",
       "      <td>3.965287</td>\n",
       "      <td>0.268224</td>\n",
       "      <td>-0.415835</td>\n",
       "      <td>0.733822</td>\n",
       "      <td>-0.736407</td>\n",
       "      <td>2.581050</td>\n",
       "      <td>1.579481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.365733</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.718220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.404523</td>\n",
       "      <td>1.128851</td>\n",
       "      <td>1.865833</td>\n",
       "      <td>1.655892</td>\n",
       "      <td>0.977612</td>\n",
       "      <td>0.237307</td>\n",
       "      <td>0.849889</td>\n",
       "      <td>0.294888</td>\n",
       "      <td>2.460299</td>\n",
       "      <td>1.146518</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.161450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.292752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.350980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.162736</td>\n",
       "      <td>0.786460</td>\n",
       "      <td>1.429151</td>\n",
       "      <td>1.672157</td>\n",
       "      <td>-0.780151</td>\n",
       "      <td>-0.259989</td>\n",
       "      <td>0.518355</td>\n",
       "      <td>-1.191392</td>\n",
       "      <td>1.657472</td>\n",
       "      <td>0.697926</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.765542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.143920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.395851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.861999</td>\n",
       "      <td>0.564161</td>\n",
       "      <td>0.611897</td>\n",
       "      <td>1.593990</td>\n",
       "      <td>0.408553</td>\n",
       "      <td>-0.565851</td>\n",
       "      <td>0.239497</td>\n",
       "      <td>0.067063</td>\n",
       "      <td>1.600489</td>\n",
       "      <td>0.578318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.486500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.057757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.461930</td>\n",
       "      <td>0.604584</td>\n",
       "      <td>4.150391</td>\n",
       "      <td>1.782496</td>\n",
       "      <td>-0.260577</td>\n",
       "      <td>-0.187005</td>\n",
       "      <td>0.696217</td>\n",
       "      <td>-0.894857</td>\n",
       "      <td>1.249495</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.471393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.411145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-0.211596</td>\n",
       "      <td>0.739113</td>\n",
       "      <td>-0.281990</td>\n",
       "      <td>-0.636426</td>\n",
       "      <td>1.599630</td>\n",
       "      <td>1.352614</td>\n",
       "      <td>-0.220555</td>\n",
       "      <td>0.471800</td>\n",
       "      <td>-0.187672</td>\n",
       "      <td>-0.422427</td>\n",
       "      <td>...</td>\n",
       "      <td>1.386827</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.243007</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.779607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.784844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.765747</td>\n",
       "      <td>0.855313</td>\n",
       "      <td>-0.234571</td>\n",
       "      <td>-1.204469</td>\n",
       "      <td>0.920235</td>\n",
       "      <td>1.040390</td>\n",
       "      <td>0.346445</td>\n",
       "      <td>0.034058</td>\n",
       "      <td>-0.358316</td>\n",
       "      <td>-0.518833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600403</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.089677</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.282528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-0.609296</td>\n",
       "      <td>0.697286</td>\n",
       "      <td>-0.562017</td>\n",
       "      <td>-1.089158</td>\n",
       "      <td>0.341994</td>\n",
       "      <td>0.830698</td>\n",
       "      <td>0.429694</td>\n",
       "      <td>0.796373</td>\n",
       "      <td>-0.106524</td>\n",
       "      <td>-0.588942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196236</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.211020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.473678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.836849</td>\n",
       "      <td>-0.719738</td>\n",
       "      <td>-0.028118</td>\n",
       "      <td>-0.925439</td>\n",
       "      <td>-1.523290</td>\n",
       "      <td>-0.631908</td>\n",
       "      <td>-0.434877</td>\n",
       "      <td>-2.562406</td>\n",
       "      <td>-0.028237</td>\n",
       "      <td>-0.468533</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.910985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283754</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.190893</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.254712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.283715</td>\n",
       "      <td>-1.078052</td>\n",
       "      <td>0.226971</td>\n",
       "      <td>-0.799403</td>\n",
       "      <td>-0.625862</td>\n",
       "      <td>-1.226069</td>\n",
       "      <td>0.334461</td>\n",
       "      <td>-0.263730</td>\n",
       "      <td>0.344734</td>\n",
       "      <td>-0.241170</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.460368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025355</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.180499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows  63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emiliani1_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                  2.112078   \n",
       "1                                  1.404523   \n",
       "2                                  1.162736   \n",
       "3                                  0.861999   \n",
       "4                                  1.461930   \n",
       "..                                      ...   \n",
       "406                               -0.211596   \n",
       "407                               -0.765747   \n",
       "408                               -0.609296   \n",
       "409                               -0.836849   \n",
       "410                               -0.283715   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                  0.345989   \n",
       "1                                  1.128851   \n",
       "2                                  0.786460   \n",
       "3                                  0.564161   \n",
       "4                                  0.604584   \n",
       "..                                      ...   \n",
       "406                                0.739113   \n",
       "407                                0.855313   \n",
       "408                                0.697286   \n",
       "409                               -0.719738   \n",
       "410                               -1.078052   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_12w_1  \\\n",
       "0                                   1.690770   \n",
       "1                                   1.865833   \n",
       "2                                   1.429151   \n",
       "3                                   0.611897   \n",
       "4                                   4.150391   \n",
       "..                                       ...   \n",
       "406                                -0.281990   \n",
       "407                                -0.234571   \n",
       "408                                -0.562017   \n",
       "409                                -0.028118   \n",
       "410                                 0.226971   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_rr_8w_1  \\\n",
       "0                                  3.965287   \n",
       "1                                  1.655892   \n",
       "2                                  1.672157   \n",
       "3                                  1.593990   \n",
       "4                                  1.782496   \n",
       "..                                      ...   \n",
       "406                               -0.636426   \n",
       "407                               -1.204469   \n",
       "408                               -1.089158   \n",
       "409                               -0.925439   \n",
       "410                               -0.799403   \n",
       "\n",
       "     Emiliani1_cyclostationary_mean_tg_9  \\\n",
       "0                               0.268224   \n",
       "1                               0.977612   \n",
       "2                              -0.780151   \n",
       "3                               0.408553   \n",
       "4                              -0.260577   \n",
       "..                                   ...   \n",
       "406                             1.599630   \n",
       "407                             0.920235   \n",
       "408                             0.341994   \n",
       "409                            -1.523290   \n",
       "410                            -0.625862   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                 -0.415835   \n",
       "1                                  0.237307   \n",
       "2                                 -0.259989   \n",
       "3                                 -0.565851   \n",
       "4                                 -0.187005   \n",
       "..                                      ...   \n",
       "406                                1.352614   \n",
       "407                                1.040390   \n",
       "408                                0.830698   \n",
       "409                               -0.631908   \n",
       "410                               -1.226069   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_4w_3  \\\n",
       "0                                  0.733822   \n",
       "1                                  0.849889   \n",
       "2                                  0.518355   \n",
       "3                                  0.239497   \n",
       "4                                  0.696217   \n",
       "..                                      ...   \n",
       "406                               -0.220555   \n",
       "407                                0.346445   \n",
       "408                                0.429694   \n",
       "409                               -0.434877   \n",
       "410                                0.334461   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_tg_4  \\\n",
       "0                              -0.736407   \n",
       "1                               0.294888   \n",
       "2                              -1.191392   \n",
       "3                               0.067063   \n",
       "4                              -0.894857   \n",
       "..                                   ...   \n",
       "406                             0.471800   \n",
       "407                             0.034058   \n",
       "408                             0.796373   \n",
       "409                            -2.562406   \n",
       "410                            -0.263730   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                  2.581050   \n",
       "1                                  2.460299   \n",
       "2                                  1.657472   \n",
       "3                                  1.600489   \n",
       "4                                  1.249495   \n",
       "..                                      ...   \n",
       "406                               -0.187672   \n",
       "407                               -0.358316   \n",
       "408                               -0.106524   \n",
       "409                               -0.028237   \n",
       "410                                0.344734   \n",
       "\n",
       "     Emiliani2_cyclostationary_mean_rr_12w_1  ...  \\\n",
       "0                                   1.579481  ...   \n",
       "1                                   1.146518  ...   \n",
       "2                                   0.697926  ...   \n",
       "3                                   0.578318  ...   \n",
       "4                                   0.843396  ...   \n",
       "..                                       ...  ...   \n",
       "406                                -0.422427  ...   \n",
       "407                                -0.518833  ...   \n",
       "408                                -0.588942  ...   \n",
       "409                                -0.468533  ...   \n",
       "410                                -0.241170  ...   \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_0_Garda_Mincio  \\\n",
       "0                                             0.000000     \n",
       "1                                             0.000000     \n",
       "2                                            -0.000000     \n",
       "3                                             0.000000     \n",
       "4                                            -0.000000     \n",
       "..                                                 ...     \n",
       "406                                           1.386827     \n",
       "407                                           0.600403     \n",
       "408                                           0.382350     \n",
       "409                                          -1.910985     \n",
       "410                                          -0.460368     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_8w_0_Emiliani1  \\\n",
       "0                                             1.365733     \n",
       "1                                             1.161450     \n",
       "2                                             0.765542     \n",
       "3                                             0.486500     \n",
       "4                                             0.471393     \n",
       "..                                                 ...     \n",
       "406                                          -0.000000     \n",
       "407                                          -0.000000     \n",
       "408                                           0.000000     \n",
       "409                                           0.000000     \n",
       "410                                           0.000000     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_8w_0_Emiliani2  \\\n",
       "0                                                  0.0     \n",
       "1                                                  0.0     \n",
       "2                                                  0.0     \n",
       "3                                                  0.0     \n",
       "4                                                  0.0     \n",
       "..                                                 ...     \n",
       "406                                               -0.0     \n",
       "407                                               -0.0     \n",
       "408                                                0.0     \n",
       "409                                                0.0     \n",
       "410                                                0.0     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_8w_0_Garda_Mincio  \\\n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                             0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                          -0.243007        \n",
       "407                                          -0.089677        \n",
       "408                                           0.196236        \n",
       "409                                           0.283754        \n",
       "410                                           0.250722        \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_12w_2_Emiliani1  \\\n",
       "0                                             1.718220      \n",
       "1                                             3.292752      \n",
       "2                                             2.143920      \n",
       "3                                             2.057757      \n",
       "4                                             1.411145      \n",
       "..                                                 ...      \n",
       "406                                          -0.000000      \n",
       "407                                          -0.000000      \n",
       "408                                          -0.000000      \n",
       "409                                          -0.000000      \n",
       "410                                           0.000000      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_12w_2_Emiliani2  \\\n",
       "0                                                  0.0      \n",
       "1                                                  0.0      \n",
       "2                                                  0.0      \n",
       "3                                                  0.0      \n",
       "4                                                  0.0      \n",
       "..                                                 ...      \n",
       "406                                               -0.0      \n",
       "407                                               -0.0      \n",
       "408                                               -0.0      \n",
       "409                                               -0.0      \n",
       "410                                                0.0      \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_rr_12w_2_Garda_Mincio  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.779607         \n",
       "407                                          -0.282528         \n",
       "408                                          -0.211020         \n",
       "409                                          -0.190893         \n",
       "410                                           0.025355         \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_8w_0_Emiliani1  \\\n",
       "0                                             0.523659     \n",
       "1                                             1.350980     \n",
       "2                                             0.395851     \n",
       "3                                             0.584992     \n",
       "4                                             0.375705     \n",
       "..                                                 ...     \n",
       "406                                           0.000000     \n",
       "407                                           0.000000     \n",
       "408                                           0.000000     \n",
       "409                                          -0.000000     \n",
       "410                                          -0.000000     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_8w_0_Emiliani2  \\\n",
       "0                                                  0.0     \n",
       "1                                                  0.0     \n",
       "2                                                  0.0     \n",
       "3                                                  0.0     \n",
       "4                                                  0.0     \n",
       "..                                                 ...     \n",
       "406                                                0.0     \n",
       "407                                                0.0     \n",
       "408                                                0.0     \n",
       "409                                               -0.0     \n",
       "410                                               -0.0     \n",
       "\n",
       "     Garda_Mincio_cyclostationary_mean_tg_8w_0_Garda_Mincio  \n",
       "0                                             0.000000       \n",
       "1                                             0.000000       \n",
       "2                                             0.000000       \n",
       "3                                             0.000000       \n",
       "4                                             0.000000       \n",
       "..                                                 ...       \n",
       "406                                           0.784844       \n",
       "407                                           0.689576       \n",
       "408                                           0.473678       \n",
       "409                                          -0.254712       \n",
       "410                                          -0.180499       \n",
       "\n",
       "[1233 rows x 63 columns]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        clusterdf_train_withClass[clusterdf_train_withClass.columns[i]+'_'+j] = clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_val_withClass[clusterdf_val_withClass.columns[i]+'_'+j] = clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_test_withClass[clusterdf_test_withClass.columns[i]+'_'+j] = clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "d1baa779",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4159901109016101\n",
      "0.31316188469641604\n",
      "0.24666673132732686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_E1E2GM_ohe = LinearRegression()\n",
    "model_E1E2GM_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Emiliani1==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani1'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Emiliani2==1].values)\n",
    "print(r2_score(targets_df_test['Emiliani2'].values, res))\n",
    "res = model_E1E2GM_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Garda_Mincio==1].values)\n",
    "print(r2_score(targets_df_test['Garda_Mincio'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b157c7c1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cea06c6a",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Adda - Lambro_Olona - Oglio_Iseo - Ticino: wrapper best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "88e7f00e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino']\n",
    "colnames = [x for x in best5_wrapper_fulldf_train.columns if x.startswith('Adda') or x.startswith('Lambro_Olona') or x.startswith('Oglio_Iseo') or x.startswith('Ticino')]\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass = pd.DataFrame()\n",
    "best5_wrapper_clusterdf_val_withClass = pd.DataFrame()\n",
    "best5_wrapper_clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    best5_wrapper_clusterdf_train_withClass = pd.concat((best5_wrapper_clusterdf_train_withClass,pd.concat((best5_wrapper_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_clusterdf_val_withClass = pd.concat((best5_wrapper_clusterdf_val_withClass,pd.concat((best5_wrapper_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_clusterdf_test_withClass = pd.concat((best5_wrapper_clusterdf_test_withClass,pd.concat((best5_wrapper_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    best5_wrapper_clusterdf_train_withClass[clust_basins[i]] = best5_wrapper_clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_clusterdf_val_withClass[clust_basins[i]] = best5_wrapper_clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_clusterdf_test_withClass[clust_basins[i]] = best5_wrapper_clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass = best5_wrapper_clusterdf_train_withClass.loc[:,best5_wrapper_clusterdf_train_withClass.columns != 'basin']\n",
    "best5_wrapper_clusterdf_val_withClass = best5_wrapper_clusterdf_val_withClass.loc[:,best5_wrapper_clusterdf_val_withClass.columns != 'basin']\n",
    "best5_wrapper_clusterdf_test_withClass = best5_wrapper_clusterdf_test_withClass.loc[:,best5_wrapper_clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "abc5431f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_6</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_5</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_1w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_2</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_1w_2</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_rr_1w_1</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_1w_5</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_24w_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Oglio_Iseo_cyclostationary_mean_tg_1w_2</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_1w_1</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_16w_3</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_0</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_1</th>\n",
       "      <th>Adda</th>\n",
       "      <th>Lambro_Olona</th>\n",
       "      <th>Oglio_Iseo</th>\n",
       "      <th>Ticino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>-1.709060</td>\n",
       "      <td>-1.866687</td>\n",
       "      <td>1.001341</td>\n",
       "      <td>-3.062159</td>\n",
       "      <td>-0.016453</td>\n",
       "      <td>1.139294</td>\n",
       "      <td>0.598277</td>\n",
       "      <td>-0.325450</td>\n",
       "      <td>0.326942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.633924</td>\n",
       "      <td>-0.093720</td>\n",
       "      <td>0.367163</td>\n",
       "      <td>-2.519366</td>\n",
       "      <td>1.086902</td>\n",
       "      <td>0.923555</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>-0.490888</td>\n",
       "      <td>-1.024977</td>\n",
       "      <td>1.976018</td>\n",
       "      <td>-1.604230</td>\n",
       "      <td>0.588844</td>\n",
       "      <td>1.558519</td>\n",
       "      <td>1.327611</td>\n",
       "      <td>0.401314</td>\n",
       "      <td>1.779921</td>\n",
       "      <td>...</td>\n",
       "      <td>1.150367</td>\n",
       "      <td>0.660804</td>\n",
       "      <td>1.109746</td>\n",
       "      <td>-1.279902</td>\n",
       "      <td>2.955987</td>\n",
       "      <td>3.878325</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>-0.923993</td>\n",
       "      <td>-0.954945</td>\n",
       "      <td>1.350939</td>\n",
       "      <td>-2.492491</td>\n",
       "      <td>0.354168</td>\n",
       "      <td>0.824111</td>\n",
       "      <td>1.123972</td>\n",
       "      <td>0.373232</td>\n",
       "      <td>0.816023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.652153</td>\n",
       "      <td>0.398414</td>\n",
       "      <td>0.745952</td>\n",
       "      <td>-1.931105</td>\n",
       "      <td>1.397907</td>\n",
       "      <td>2.009521</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>-1.171925</td>\n",
       "      <td>-1.039569</td>\n",
       "      <td>0.464342</td>\n",
       "      <td>-1.901370</td>\n",
       "      <td>0.207584</td>\n",
       "      <td>0.400613</td>\n",
       "      <td>0.838592</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>1.160471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280106</td>\n",
       "      <td>0.123697</td>\n",
       "      <td>0.265868</td>\n",
       "      <td>-1.487132</td>\n",
       "      <td>1.452206</td>\n",
       "      <td>2.031725</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>-0.855241</td>\n",
       "      <td>-1.185594</td>\n",
       "      <td>0.406680</td>\n",
       "      <td>-2.302021</td>\n",
       "      <td>0.395861</td>\n",
       "      <td>0.313123</td>\n",
       "      <td>0.990957</td>\n",
       "      <td>0.484058</td>\n",
       "      <td>0.876454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.659749</td>\n",
       "      <td>0.385859</td>\n",
       "      <td>0.489741</td>\n",
       "      <td>-1.755441</td>\n",
       "      <td>1.059559</td>\n",
       "      <td>1.666844</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>1.778381</td>\n",
       "      <td>1.494928</td>\n",
       "      <td>-1.208471</td>\n",
       "      <td>1.138232</td>\n",
       "      <td>1.284746</td>\n",
       "      <td>-1.204774</td>\n",
       "      <td>1.292422</td>\n",
       "      <td>1.757969</td>\n",
       "      <td>0.987092</td>\n",
       "      <td>...</td>\n",
       "      <td>1.451391</td>\n",
       "      <td>1.365035</td>\n",
       "      <td>-0.995021</td>\n",
       "      <td>1.029462</td>\n",
       "      <td>-0.889708</td>\n",
       "      <td>-1.175881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>1.051617</td>\n",
       "      <td>0.843470</td>\n",
       "      <td>0.824414</td>\n",
       "      <td>1.152253</td>\n",
       "      <td>1.022290</td>\n",
       "      <td>0.454118</td>\n",
       "      <td>1.054859</td>\n",
       "      <td>1.437956</td>\n",
       "      <td>0.978438</td>\n",
       "      <td>...</td>\n",
       "      <td>1.312351</td>\n",
       "      <td>0.754469</td>\n",
       "      <td>0.937092</td>\n",
       "      <td>1.054968</td>\n",
       "      <td>-0.475943</td>\n",
       "      <td>-0.744283</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>0.470849</td>\n",
       "      <td>0.404951</td>\n",
       "      <td>1.236207</td>\n",
       "      <td>1.253158</td>\n",
       "      <td>0.881454</td>\n",
       "      <td>0.935050</td>\n",
       "      <td>0.963252</td>\n",
       "      <td>0.693918</td>\n",
       "      <td>0.832314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.945694</td>\n",
       "      <td>0.700923</td>\n",
       "      <td>1.093168</td>\n",
       "      <td>1.164702</td>\n",
       "      <td>-0.394052</td>\n",
       "      <td>-0.658232</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-1.195756</td>\n",
       "      <td>-1.026883</td>\n",
       "      <td>-0.159932</td>\n",
       "      <td>0.874675</td>\n",
       "      <td>-0.485089</td>\n",
       "      <td>-0.092682</td>\n",
       "      <td>-0.604243</td>\n",
       "      <td>-0.416388</td>\n",
       "      <td>0.627521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.424773</td>\n",
       "      <td>-0.742700</td>\n",
       "      <td>-0.315473</td>\n",
       "      <td>0.830063</td>\n",
       "      <td>-0.260074</td>\n",
       "      <td>-0.519229</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-1.470946</td>\n",
       "      <td>-1.326713</td>\n",
       "      <td>0.209276</td>\n",
       "      <td>0.821070</td>\n",
       "      <td>-1.329610</td>\n",
       "      <td>0.113361</td>\n",
       "      <td>-1.328723</td>\n",
       "      <td>-0.822069</td>\n",
       "      <td>0.628527</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.361463</td>\n",
       "      <td>-1.265944</td>\n",
       "      <td>0.131009</td>\n",
       "      <td>0.771344</td>\n",
       "      <td>-0.397287</td>\n",
       "      <td>-0.805547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_tg_1w_6  \\\n",
       "0                            -0.862899                          -1.709060   \n",
       "1                            -0.093639                          -0.490888   \n",
       "2                            -0.524505                          -0.923993   \n",
       "3                            -0.666293                          -1.171925   \n",
       "4                            -0.416695                          -0.855241   \n",
       "..                                 ...                                ...   \n",
       "406                           1.568770                           1.778381   \n",
       "407                           0.812306                           1.051617   \n",
       "408                           0.876968                           0.470849   \n",
       "409                          -0.723696                          -1.195756   \n",
       "410                          -1.413870                          -1.470946   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_1w_5  Adda_cyclostationary_mean_rr_1w_0  \\\n",
       "0                            -1.866687                           1.001341   \n",
       "1                            -1.024977                           1.976018   \n",
       "2                            -0.954945                           1.350939   \n",
       "3                            -1.039569                           0.464342   \n",
       "4                            -1.185594                           0.406680   \n",
       "..                                 ...                                ...   \n",
       "406                           1.494928                          -1.208471   \n",
       "407                           0.843470                           0.824414   \n",
       "408                           0.404951                           1.236207   \n",
       "409                          -1.026883                          -0.159932   \n",
       "410                          -1.326713                           0.209276   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_2  \\\n",
       "0                             -3.062159   \n",
       "1                             -1.604230   \n",
       "2                             -2.492491   \n",
       "3                             -1.901370   \n",
       "4                             -2.302021   \n",
       "..                                  ...   \n",
       "406                            1.138232   \n",
       "407                            1.152253   \n",
       "408                            1.253158   \n",
       "409                            0.874675   \n",
       "410                            0.821070   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_1w_2  \\\n",
       "0                                    -0.016453   \n",
       "1                                     0.588844   \n",
       "2                                     0.354168   \n",
       "3                                     0.207584   \n",
       "4                                     0.395861   \n",
       "..                                         ...   \n",
       "406                                   1.284746   \n",
       "407                                   1.022290   \n",
       "408                                   0.881454   \n",
       "409                                  -0.485089   \n",
       "410                                  -1.329610   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_rr_1w_1  \\\n",
       "0                                     1.139294   \n",
       "1                                     1.558519   \n",
       "2                                     0.824111   \n",
       "3                                     0.400613   \n",
       "4                                     0.313123   \n",
       "..                                         ...   \n",
       "406                                  -1.204774   \n",
       "407                                   0.454118   \n",
       "408                                   0.935050   \n",
       "409                                  -0.092682   \n",
       "410                                   0.113361   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_1w_5  \\\n",
       "0                                     0.598277   \n",
       "1                                     1.327611   \n",
       "2                                     1.123972   \n",
       "3                                     0.838592   \n",
       "4                                     0.990957   \n",
       "..                                         ...   \n",
       "406                                   1.292422   \n",
       "407                                   1.054859   \n",
       "408                                   0.963252   \n",
       "409                                  -0.604243   \n",
       "410                                  -1.328723   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                    -0.325450   \n",
       "1                                     0.401314   \n",
       "2                                     0.373232   \n",
       "3                                     0.208962   \n",
       "4                                     0.484058   \n",
       "..                                         ...   \n",
       "406                                   1.757969   \n",
       "407                                   1.437956   \n",
       "408                                   0.693918   \n",
       "409                                  -0.416388   \n",
       "410                                  -0.822069   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_24w_1  ...  \\\n",
       "0                                      0.326942  ...   \n",
       "1                                      1.779921  ...   \n",
       "2                                      0.816023  ...   \n",
       "3                                      1.160471  ...   \n",
       "4                                      0.876454  ...   \n",
       "..                                          ...  ...   \n",
       "406                                    0.987092  ...   \n",
       "407                                    0.978438  ...   \n",
       "408                                    0.832314  ...   \n",
       "409                                    0.627521  ...   \n",
       "410                                    0.628527  ...   \n",
       "\n",
       "     Oglio_Iseo_cyclostationary_mean_tg_1w_2  \\\n",
       "0                                   0.633924   \n",
       "1                                   1.150367   \n",
       "2                                   0.652153   \n",
       "3                                   0.280106   \n",
       "4                                   0.659749   \n",
       "..                                       ...   \n",
       "406                                 1.451391   \n",
       "407                                 1.312351   \n",
       "408                                 0.945694   \n",
       "409                                -0.424773   \n",
       "410                                -1.361463   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1w_3  Ticino_cyclostationary_mean_rr_1w_1  \\\n",
       "0                              -0.093720                             0.367163   \n",
       "1                               0.660804                             1.109746   \n",
       "2                               0.398414                             0.745952   \n",
       "3                               0.123697                             0.265868   \n",
       "4                               0.385859                             0.489741   \n",
       "..                                   ...                                  ...   \n",
       "406                             1.365035                            -0.995021   \n",
       "407                             0.754469                             0.937092   \n",
       "408                             0.700923                             1.093168   \n",
       "409                            -0.742700                            -0.315473   \n",
       "410                            -1.265944                             0.131009   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_16w_3  \\\n",
       "0                               -2.519366   \n",
       "1                               -1.279902   \n",
       "2                               -1.931105   \n",
       "3                               -1.487132   \n",
       "4                               -1.755441   \n",
       "..                                    ...   \n",
       "406                              1.029462   \n",
       "407                              1.054968   \n",
       "408                              1.164702   \n",
       "409                              0.830063   \n",
       "410                              0.771344   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_0  \\\n",
       "0                                1.086902   \n",
       "1                                2.955987   \n",
       "2                                1.397907   \n",
       "3                                1.452206   \n",
       "4                                1.059559   \n",
       "..                                    ...   \n",
       "406                             -0.889708   \n",
       "407                             -0.475943   \n",
       "408                             -0.394052   \n",
       "409                             -0.260074   \n",
       "410                             -0.397287   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_1  Adda  Lambro_Olona  Oglio_Iseo  \\\n",
       "0                                0.923555     1             0           0   \n",
       "1                                3.878325     1             0           0   \n",
       "2                                2.009521     1             0           0   \n",
       "3                                2.031725     1             0           0   \n",
       "4                                1.666844     1             0           0   \n",
       "..                                    ...   ...           ...         ...   \n",
       "406                             -1.175881     0             0           0   \n",
       "407                             -0.744283     0             0           0   \n",
       "408                             -0.658232     0             0           0   \n",
       "409                             -0.519229     0             0           0   \n",
       "410                             -0.805547     0             0           0   \n",
       "\n",
       "     Ticino  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "406       1  \n",
       "407       1  \n",
       "408       1  \n",
       "409       1  \n",
       "410       1  \n",
       "\n",
       "[1644 rows x 24 columns]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best5_wrapper_clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "18021e90",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "be3993e9",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.546951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.277191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.534156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.447894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>-0.563495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>-0.291984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>0.770822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>-0.412164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>-1.081585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    -2.546951\n",
       "1    -0.277191\n",
       "2    -0.534156\n",
       "3    -0.666789\n",
       "4    -0.447894\n",
       "...        ...\n",
       "1639 -0.563495\n",
       "1640 -0.291984\n",
       "1641  0.770822\n",
       "1642 -0.412164\n",
       "1643 -1.081585\n",
       "\n",
       "[1644 rows x 1 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_train_unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "24012160",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.035985702392081764\n",
      "-0.022537911682852352\n",
      "-0.01660417154567484\n",
      "-0.003059224965991536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((best5_wrapper_clusterdf_train_withClass,best5_wrapper_clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "d5ef023f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_6</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_5</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_1w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_2</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_1w_2</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_rr_1w_1</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_1w_5</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_24w_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_16w_3_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_16w_3_Ticino</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_0_Adda</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_0_Lambro_Olona</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_0_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_0_Ticino</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_1_Adda</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_1_Lambro_Olona</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_1_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_24w_1_Ticino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>-1.709060</td>\n",
       "      <td>-1.866687</td>\n",
       "      <td>1.001341</td>\n",
       "      <td>-3.062159</td>\n",
       "      <td>-0.016453</td>\n",
       "      <td>1.139294</td>\n",
       "      <td>0.598277</td>\n",
       "      <td>-0.325450</td>\n",
       "      <td>0.326942</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.086902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.923555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>-0.490888</td>\n",
       "      <td>-1.024977</td>\n",
       "      <td>1.976018</td>\n",
       "      <td>-1.604230</td>\n",
       "      <td>0.588844</td>\n",
       "      <td>1.558519</td>\n",
       "      <td>1.327611</td>\n",
       "      <td>0.401314</td>\n",
       "      <td>1.779921</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.955987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.878325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>-0.923993</td>\n",
       "      <td>-0.954945</td>\n",
       "      <td>1.350939</td>\n",
       "      <td>-2.492491</td>\n",
       "      <td>0.354168</td>\n",
       "      <td>0.824111</td>\n",
       "      <td>1.123972</td>\n",
       "      <td>0.373232</td>\n",
       "      <td>0.816023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.397907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.009521</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>-1.171925</td>\n",
       "      <td>-1.039569</td>\n",
       "      <td>0.464342</td>\n",
       "      <td>-1.901370</td>\n",
       "      <td>0.207584</td>\n",
       "      <td>0.400613</td>\n",
       "      <td>0.838592</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>1.160471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.452206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.031725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>-0.855241</td>\n",
       "      <td>-1.185594</td>\n",
       "      <td>0.406680</td>\n",
       "      <td>-2.302021</td>\n",
       "      <td>0.395861</td>\n",
       "      <td>0.313123</td>\n",
       "      <td>0.990957</td>\n",
       "      <td>0.484058</td>\n",
       "      <td>0.876454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.059559</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.666844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>1.778381</td>\n",
       "      <td>1.494928</td>\n",
       "      <td>-1.208471</td>\n",
       "      <td>1.138232</td>\n",
       "      <td>1.284746</td>\n",
       "      <td>-1.204774</td>\n",
       "      <td>1.292422</td>\n",
       "      <td>1.757969</td>\n",
       "      <td>0.987092</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.029462</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.889708</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.175881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>1.051617</td>\n",
       "      <td>0.843470</td>\n",
       "      <td>0.824414</td>\n",
       "      <td>1.152253</td>\n",
       "      <td>1.022290</td>\n",
       "      <td>0.454118</td>\n",
       "      <td>1.054859</td>\n",
       "      <td>1.437956</td>\n",
       "      <td>0.978438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.054968</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.475943</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.744283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>0.470849</td>\n",
       "      <td>0.404951</td>\n",
       "      <td>1.236207</td>\n",
       "      <td>1.253158</td>\n",
       "      <td>0.881454</td>\n",
       "      <td>0.935050</td>\n",
       "      <td>0.963252</td>\n",
       "      <td>0.693918</td>\n",
       "      <td>0.832314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.164702</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.394052</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.658232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-1.195756</td>\n",
       "      <td>-1.026883</td>\n",
       "      <td>-0.159932</td>\n",
       "      <td>0.874675</td>\n",
       "      <td>-0.485089</td>\n",
       "      <td>-0.092682</td>\n",
       "      <td>-0.604243</td>\n",
       "      <td>-0.416388</td>\n",
       "      <td>0.627521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.830063</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.260074</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.519229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-1.470946</td>\n",
       "      <td>-1.326713</td>\n",
       "      <td>0.209276</td>\n",
       "      <td>0.821070</td>\n",
       "      <td>-1.329610</td>\n",
       "      <td>0.113361</td>\n",
       "      <td>-1.328723</td>\n",
       "      <td>-0.822069</td>\n",
       "      <td>0.628527</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.771344</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.397287</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.805547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows  104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_tg_1w_6  \\\n",
       "0                            -0.862899                          -1.709060   \n",
       "1                            -0.093639                          -0.490888   \n",
       "2                            -0.524505                          -0.923993   \n",
       "3                            -0.666293                          -1.171925   \n",
       "4                            -0.416695                          -0.855241   \n",
       "..                                 ...                                ...   \n",
       "406                           1.568770                           1.778381   \n",
       "407                           0.812306                           1.051617   \n",
       "408                           0.876968                           0.470849   \n",
       "409                          -0.723696                          -1.195756   \n",
       "410                          -1.413870                          -1.470946   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_1w_5  Adda_cyclostationary_mean_rr_1w_0  \\\n",
       "0                            -1.866687                           1.001341   \n",
       "1                            -1.024977                           1.976018   \n",
       "2                            -0.954945                           1.350939   \n",
       "3                            -1.039569                           0.464342   \n",
       "4                            -1.185594                           0.406680   \n",
       "..                                 ...                                ...   \n",
       "406                           1.494928                          -1.208471   \n",
       "407                           0.843470                           0.824414   \n",
       "408                           0.404951                           1.236207   \n",
       "409                          -1.026883                          -0.159932   \n",
       "410                          -1.326713                           0.209276   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_2  \\\n",
       "0                             -3.062159   \n",
       "1                             -1.604230   \n",
       "2                             -2.492491   \n",
       "3                             -1.901370   \n",
       "4                             -2.302021   \n",
       "..                                  ...   \n",
       "406                            1.138232   \n",
       "407                            1.152253   \n",
       "408                            1.253158   \n",
       "409                            0.874675   \n",
       "410                            0.821070   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_1w_2  \\\n",
       "0                                    -0.016453   \n",
       "1                                     0.588844   \n",
       "2                                     0.354168   \n",
       "3                                     0.207584   \n",
       "4                                     0.395861   \n",
       "..                                         ...   \n",
       "406                                   1.284746   \n",
       "407                                   1.022290   \n",
       "408                                   0.881454   \n",
       "409                                  -0.485089   \n",
       "410                                  -1.329610   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_rr_1w_1  \\\n",
       "0                                     1.139294   \n",
       "1                                     1.558519   \n",
       "2                                     0.824111   \n",
       "3                                     0.400613   \n",
       "4                                     0.313123   \n",
       "..                                         ...   \n",
       "406                                  -1.204774   \n",
       "407                                   0.454118   \n",
       "408                                   0.935050   \n",
       "409                                  -0.092682   \n",
       "410                                   0.113361   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_1w_5  \\\n",
       "0                                     0.598277   \n",
       "1                                     1.327611   \n",
       "2                                     1.123972   \n",
       "3                                     0.838592   \n",
       "4                                     0.990957   \n",
       "..                                         ...   \n",
       "406                                   1.292422   \n",
       "407                                   1.054859   \n",
       "408                                   0.963252   \n",
       "409                                  -0.604243   \n",
       "410                                  -1.328723   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                    -0.325450   \n",
       "1                                     0.401314   \n",
       "2                                     0.373232   \n",
       "3                                     0.208962   \n",
       "4                                     0.484058   \n",
       "..                                         ...   \n",
       "406                                   1.757969   \n",
       "407                                   1.437956   \n",
       "408                                   0.693918   \n",
       "409                                  -0.416388   \n",
       "410                                  -0.822069   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_24w_1  ...  \\\n",
       "0                                      0.326942  ...   \n",
       "1                                      1.779921  ...   \n",
       "2                                      0.816023  ...   \n",
       "3                                      1.160471  ...   \n",
       "4                                      0.876454  ...   \n",
       "..                                          ...  ...   \n",
       "406                                    0.987092  ...   \n",
       "407                                    0.978438  ...   \n",
       "408                                    0.832314  ...   \n",
       "409                                    0.627521  ...   \n",
       "410                                    0.628527  ...   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_16w_3_Oglio_Iseo  \\\n",
       "0                                               -0.0   \n",
       "1                                               -0.0   \n",
       "2                                               -0.0   \n",
       "3                                               -0.0   \n",
       "4                                               -0.0   \n",
       "..                                               ...   \n",
       "406                                              0.0   \n",
       "407                                              0.0   \n",
       "408                                              0.0   \n",
       "409                                              0.0   \n",
       "410                                              0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_16w_3_Ticino  \\\n",
       "0                                      -0.000000   \n",
       "1                                      -0.000000   \n",
       "2                                      -0.000000   \n",
       "3                                      -0.000000   \n",
       "4                                      -0.000000   \n",
       "..                                           ...   \n",
       "406                                     1.029462   \n",
       "407                                     1.054968   \n",
       "408                                     1.164702   \n",
       "409                                     0.830063   \n",
       "410                                     0.771344   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_0_Adda  \\\n",
       "0                                     1.086902   \n",
       "1                                     2.955987   \n",
       "2                                     1.397907   \n",
       "3                                     1.452206   \n",
       "4                                     1.059559   \n",
       "..                                         ...   \n",
       "406                                  -0.000000   \n",
       "407                                  -0.000000   \n",
       "408                                  -0.000000   \n",
       "409                                  -0.000000   \n",
       "410                                  -0.000000   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_0_Lambro_Olona  \\\n",
       "0                                                  0.0   \n",
       "1                                                  0.0   \n",
       "2                                                  0.0   \n",
       "3                                                  0.0   \n",
       "4                                                  0.0   \n",
       "..                                                 ...   \n",
       "406                                               -0.0   \n",
       "407                                               -0.0   \n",
       "408                                               -0.0   \n",
       "409                                               -0.0   \n",
       "410                                               -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_0_Oglio_Iseo  \\\n",
       "0                                                0.0   \n",
       "1                                                0.0   \n",
       "2                                                0.0   \n",
       "3                                                0.0   \n",
       "4                                                0.0   \n",
       "..                                               ...   \n",
       "406                                             -0.0   \n",
       "407                                             -0.0   \n",
       "408                                             -0.0   \n",
       "409                                             -0.0   \n",
       "410                                             -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_0_Ticino  \\\n",
       "0                                       0.000000   \n",
       "1                                       0.000000   \n",
       "2                                       0.000000   \n",
       "3                                       0.000000   \n",
       "4                                       0.000000   \n",
       "..                                           ...   \n",
       "406                                    -0.889708   \n",
       "407                                    -0.475943   \n",
       "408                                    -0.394052   \n",
       "409                                    -0.260074   \n",
       "410                                    -0.397287   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_1_Adda  \\\n",
       "0                                     0.923555   \n",
       "1                                     3.878325   \n",
       "2                                     2.009521   \n",
       "3                                     2.031725   \n",
       "4                                     1.666844   \n",
       "..                                         ...   \n",
       "406                                  -0.000000   \n",
       "407                                  -0.000000   \n",
       "408                                  -0.000000   \n",
       "409                                  -0.000000   \n",
       "410                                  -0.000000   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_1_Lambro_Olona  \\\n",
       "0                                                  0.0   \n",
       "1                                                  0.0   \n",
       "2                                                  0.0   \n",
       "3                                                  0.0   \n",
       "4                                                  0.0   \n",
       "..                                                 ...   \n",
       "406                                               -0.0   \n",
       "407                                               -0.0   \n",
       "408                                               -0.0   \n",
       "409                                               -0.0   \n",
       "410                                               -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_1_Oglio_Iseo  \\\n",
       "0                                                0.0   \n",
       "1                                                0.0   \n",
       "2                                                0.0   \n",
       "3                                                0.0   \n",
       "4                                                0.0   \n",
       "..                                               ...   \n",
       "406                                             -0.0   \n",
       "407                                             -0.0   \n",
       "408                                             -0.0   \n",
       "409                                             -0.0   \n",
       "410                                             -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_24w_1_Ticino  \n",
       "0                                       0.000000  \n",
       "1                                       0.000000  \n",
       "2                                       0.000000  \n",
       "3                                       0.000000  \n",
       "4                                       0.000000  \n",
       "..                                           ...  \n",
       "406                                    -1.175881  \n",
       "407                                    -0.744283  \n",
       "408                                    -0.658232  \n",
       "409                                    -0.519229  \n",
       "410                                    -0.805547  \n",
       "\n",
       "[1644 rows x 104 columns]"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(best5_wrapper_clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        best5_wrapper_clusterdf_train_withClass[best5_wrapper_clusterdf_train_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        best5_wrapper_clusterdf_val_withClass[best5_wrapper_clusterdf_val_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        best5_wrapper_clusterdf_test_withClass[best5_wrapper_clusterdf_test_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "bb7d3b55",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.025485091324654707\n",
      "-0.040504606273706\n",
      "-0.19022139049651954\n",
      "0.10691584689345834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((best5_wrapper_clusterdf_train_withClass,best5_wrapper_clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035694ac",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Adda - Lambro_Olona - Oglio_Iseo - Ticino: CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b6fb31d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino']\n",
    "colnames = [x for x in CMI_fulldf_train.columns if x.startswith('Adda') or x.startswith('Lambro_Olona') or x.startswith('Oglio_Iseo') or x.startswith('Ticino')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccc316ce",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_24w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_8w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_12w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Oglio_Iseo_cyclostationary_mean_tg_1w_1</th>\n",
       "      <th>Oglio_Iseo_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Oglio_Iseo_cyclostationary_mean_tg_8w_2</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1</th>\n",
       "      <th>Adda</th>\n",
       "      <th>Lambro_Olona</th>\n",
       "      <th>Oglio_Iseo</th>\n",
       "      <th>Ticino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>1.560382</td>\n",
       "      <td>1.711682</td>\n",
       "      <td>-2.770704</td>\n",
       "      <td>1.914831</td>\n",
       "      <td>1.558385</td>\n",
       "      <td>-3.062159</td>\n",
       "      <td>-2.717835</td>\n",
       "      <td>-2.894908</td>\n",
       "      <td>-1.573558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354242</td>\n",
       "      <td>-0.437988</td>\n",
       "      <td>-1.562524</td>\n",
       "      <td>-0.432799</td>\n",
       "      <td>0.611605</td>\n",
       "      <td>-0.442197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>5.036114</td>\n",
       "      <td>2.547788</td>\n",
       "      <td>-0.879312</td>\n",
       "      <td>2.856614</td>\n",
       "      <td>5.651050</td>\n",
       "      <td>-1.604230</td>\n",
       "      <td>-0.773323</td>\n",
       "      <td>-1.521259</td>\n",
       "      <td>-0.081890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.814679</td>\n",
       "      <td>0.943677</td>\n",
       "      <td>-0.432666</td>\n",
       "      <td>0.776085</td>\n",
       "      <td>1.691336</td>\n",
       "      <td>0.807518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>3.177144</td>\n",
       "      <td>1.634451</td>\n",
       "      <td>-2.052028</td>\n",
       "      <td>1.827839</td>\n",
       "      <td>3.585398</td>\n",
       "      <td>-2.492491</td>\n",
       "      <td>-1.882391</td>\n",
       "      <td>-2.358171</td>\n",
       "      <td>-1.022712</td>\n",
       "      <td>...</td>\n",
       "      <td>0.209296</td>\n",
       "      <td>-0.174601</td>\n",
       "      <td>-1.152962</td>\n",
       "      <td>-0.906320</td>\n",
       "      <td>0.832271</td>\n",
       "      <td>-1.081813</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>3.205993</td>\n",
       "      <td>1.836713</td>\n",
       "      <td>-1.425685</td>\n",
       "      <td>2.055666</td>\n",
       "      <td>3.473244</td>\n",
       "      <td>-1.901370</td>\n",
       "      <td>-1.316877</td>\n",
       "      <td>-1.801222</td>\n",
       "      <td>-0.568594</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056410</td>\n",
       "      <td>0.195684</td>\n",
       "      <td>-0.862380</td>\n",
       "      <td>0.529173</td>\n",
       "      <td>0.859041</td>\n",
       "      <td>0.324392</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>2.498195</td>\n",
       "      <td>1.795310</td>\n",
       "      <td>-1.994518</td>\n",
       "      <td>2.009029</td>\n",
       "      <td>2.635690</td>\n",
       "      <td>-2.302021</td>\n",
       "      <td>-1.671404</td>\n",
       "      <td>-2.178712</td>\n",
       "      <td>-0.939871</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188935</td>\n",
       "      <td>-0.108776</td>\n",
       "      <td>-1.137538</td>\n",
       "      <td>-0.687667</td>\n",
       "      <td>0.647203</td>\n",
       "      <td>-0.553079</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>-1.467261</td>\n",
       "      <td>0.783570</td>\n",
       "      <td>1.524212</td>\n",
       "      <td>0.639345</td>\n",
       "      <td>-1.396357</td>\n",
       "      <td>1.138232</td>\n",
       "      <td>0.857006</td>\n",
       "      <td>1.270194</td>\n",
       "      <td>0.993754</td>\n",
       "      <td>...</td>\n",
       "      <td>1.178621</td>\n",
       "      <td>1.072707</td>\n",
       "      <td>0.708063</td>\n",
       "      <td>1.481505</td>\n",
       "      <td>-1.023397</td>\n",
       "      <td>1.527659</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>-0.715887</td>\n",
       "      <td>0.868596</td>\n",
       "      <td>1.477729</td>\n",
       "      <td>0.671680</td>\n",
       "      <td>-0.906659</td>\n",
       "      <td>1.152253</td>\n",
       "      <td>0.691913</td>\n",
       "      <td>1.009645</td>\n",
       "      <td>1.038541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.874900</td>\n",
       "      <td>1.054781</td>\n",
       "      <td>0.578971</td>\n",
       "      <td>0.121450</td>\n",
       "      <td>-0.154876</td>\n",
       "      <td>0.019115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>-0.558495</td>\n",
       "      <td>0.899390</td>\n",
       "      <td>1.352693</td>\n",
       "      <td>0.504706</td>\n",
       "      <td>-0.775360</td>\n",
       "      <td>1.253158</td>\n",
       "      <td>0.563242</td>\n",
       "      <td>1.039944</td>\n",
       "      <td>1.110398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.896998</td>\n",
       "      <td>0.450693</td>\n",
       "      <td>0.865426</td>\n",
       "      <td>0.083449</td>\n",
       "      <td>1.039841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-0.626439</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>1.102009</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>-0.669538</td>\n",
       "      <td>0.874675</td>\n",
       "      <td>-0.309515</td>\n",
       "      <td>0.500579</td>\n",
       "      <td>0.800302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.656226</td>\n",
       "      <td>0.726259</td>\n",
       "      <td>-0.210982</td>\n",
       "      <td>-2.359776</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>-2.580108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-0.338666</td>\n",
       "      <td>0.604737</td>\n",
       "      <td>1.186923</td>\n",
       "      <td>0.312637</td>\n",
       "      <td>-0.681557</td>\n",
       "      <td>0.821070</td>\n",
       "      <td>0.105468</td>\n",
       "      <td>0.413493</td>\n",
       "      <td>0.731104</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.042254</td>\n",
       "      <td>0.724881</td>\n",
       "      <td>0.083086</td>\n",
       "      <td>0.061748</td>\n",
       "      <td>0.518063</td>\n",
       "      <td>-0.183864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_rr_12w_1  \\\n",
       "0                            -0.862899                            1.560382   \n",
       "1                            -0.093639                            5.036114   \n",
       "2                            -0.524505                            3.177144   \n",
       "3                            -0.666293                            3.205993   \n",
       "4                            -0.416695                            2.498195   \n",
       "..                                 ...                                 ...   \n",
       "406                           1.568770                           -1.467261   \n",
       "407                           0.812306                           -0.715887   \n",
       "408                           0.876968                           -0.558495   \n",
       "409                          -0.723696                           -0.626439   \n",
       "410                          -1.413870                           -0.338666   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_0  Adda_cyclostationary_mean_tg_24w_2  \\\n",
       "0                              1.711682                           -2.770704   \n",
       "1                              2.547788                           -0.879312   \n",
       "2                              1.634451                           -2.052028   \n",
       "3                              1.836713                           -1.425685   \n",
       "4                              1.795310                           -1.994518   \n",
       "..                                  ...                                 ...   \n",
       "406                            0.783570                            1.524212   \n",
       "407                            0.868596                            1.477729   \n",
       "408                            0.899390                            1.352693   \n",
       "409                            0.725991                            1.102009   \n",
       "410                            0.604737                            1.186923   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_24w_0  Adda_cyclostationary_mean_rr_24w_2  \\\n",
       "0                              1.914831                            1.558385   \n",
       "1                              2.856614                            5.651050   \n",
       "2                              1.827839                            3.585398   \n",
       "3                              2.055666                            3.473244   \n",
       "4                              2.009029                            2.635690   \n",
       "..                                  ...                                 ...   \n",
       "406                            0.639345                           -1.396357   \n",
       "407                            0.671680                           -0.906659   \n",
       "408                            0.504706                           -0.775360   \n",
       "409                            0.391753                           -0.669538   \n",
       "410                            0.312637                           -0.681557   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_2  Adda_cyclostationary_mean_tg_8w_3  \\\n",
       "0                             -3.062159                          -2.717835   \n",
       "1                             -1.604230                          -0.773323   \n",
       "2                             -2.492491                          -1.882391   \n",
       "3                             -1.901370                          -1.316877   \n",
       "4                             -2.302021                          -1.671404   \n",
       "..                                  ...                                ...   \n",
       "406                            1.138232                           0.857006   \n",
       "407                            1.152253                           0.691913   \n",
       "408                            1.253158                           0.563242   \n",
       "409                            0.874675                          -0.309515   \n",
       "410                            0.821070                           0.105468   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_12w_2  Adda_cyclostationary_mean_tg_16w_1  \\\n",
       "0                             -2.894908                           -1.573558   \n",
       "1                             -1.521259                           -0.081890   \n",
       "2                             -2.358171                           -1.022712   \n",
       "3                             -1.801222                           -0.568594   \n",
       "4                             -2.178712                           -0.939871   \n",
       "..                                  ...                                 ...   \n",
       "406                            1.270194                            0.993754   \n",
       "407                            1.009645                            1.038541   \n",
       "408                            1.039944                            1.110398   \n",
       "409                            0.500579                            0.800302   \n",
       "410                            0.413493                            0.731104   \n",
       "\n",
       "     ...  Oglio_Iseo_cyclostationary_mean_tg_1w_1  \\\n",
       "0    ...                                 0.354242   \n",
       "1    ...                                 0.814679   \n",
       "2    ...                                 0.209296   \n",
       "3    ...                                -0.056410   \n",
       "4    ...                                 0.188935   \n",
       "..   ...                                      ...   \n",
       "406  ...                                 1.178621   \n",
       "407  ...                                 0.874900   \n",
       "408  ...                                 0.552941   \n",
       "409  ...                                -0.656226   \n",
       "410  ...                                -1.042254   \n",
       "\n",
       "     Oglio_Iseo_cyclostationary_mean_tg_24w_0  \\\n",
       "0                                   -0.437988   \n",
       "1                                    0.943677   \n",
       "2                                   -0.174601   \n",
       "3                                    0.195684   \n",
       "4                                   -0.108776   \n",
       "..                                        ...   \n",
       "406                                  1.072707   \n",
       "407                                  1.054781   \n",
       "408                                  0.896998   \n",
       "409                                  0.726259   \n",
       "410                                  0.724881   \n",
       "\n",
       "     Oglio_Iseo_cyclostationary_mean_tg_8w_2  \\\n",
       "0                                  -1.562524   \n",
       "1                                  -0.432666   \n",
       "2                                  -1.152962   \n",
       "3                                  -0.862380   \n",
       "4                                  -1.137538   \n",
       "..                                       ...   \n",
       "406                                 0.708063   \n",
       "407                                 0.578971   \n",
       "408                                 0.450693   \n",
       "409                                -0.210982   \n",
       "410                                 0.083086   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_0  Ticino_cyclostationary_mean_rr_4w_0  \\\n",
       "0                           -0.432799                             0.611605   \n",
       "1                            0.776085                             1.691336   \n",
       "2                           -0.906320                             0.832271   \n",
       "3                            0.529173                             0.859041   \n",
       "4                           -0.687667                             0.647203   \n",
       "..                                ...                                  ...   \n",
       "406                          1.481505                            -1.023397   \n",
       "407                          0.121450                            -0.154876   \n",
       "408                          0.865426                             0.083449   \n",
       "409                         -2.359776                             0.001375   \n",
       "410                          0.061748                             0.518063   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1  Adda  Lambro_Olona  Oglio_Iseo  Ticino  \n",
       "0                           -0.442197     1             0           0       0  \n",
       "1                            0.807518     1             0           0       0  \n",
       "2                           -1.081813     1             0           0       0  \n",
       "3                            0.324392     1             0           0       0  \n",
       "4                           -0.553079     1             0           0       0  \n",
       "..                                ...   ...           ...         ...     ...  \n",
       "406                          1.527659     0             0           0       1  \n",
       "407                          0.019115     0             0           0       1  \n",
       "408                          1.039841     0             0           0       1  \n",
       "409                         -2.580108     0             0           0       1  \n",
       "410                         -0.183864     0             0           0       1  \n",
       "\n",
       "[1644 rows x 29 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "898be3ca",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2a2619c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.546951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.277191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.534156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.447894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>-0.563495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>-0.291984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>0.770822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>-0.412164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>-1.081585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    -2.546951\n",
       "1    -0.277191\n",
       "2    -0.534156\n",
       "3    -0.666789\n",
       "4    -0.447894\n",
       "...        ...\n",
       "1639 -0.563495\n",
       "1640 -0.291984\n",
       "1641  0.770822\n",
       "1642 -0.412164\n",
       "1643 -1.081585\n",
       "\n",
       "[1644 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_train_unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66016179",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.27602252513373093\n",
      "-0.33286368279662315\n",
      "-0.2930646584680894\n",
      "-0.22789296896759081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c011a5e5",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_24w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_8w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_12w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0_Ticino</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Adda</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Lambro_Olona</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Ticino</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Adda</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Lambro_Olona</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Ticino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>1.560382</td>\n",
       "      <td>1.711682</td>\n",
       "      <td>-2.770704</td>\n",
       "      <td>1.914831</td>\n",
       "      <td>1.558385</td>\n",
       "      <td>-3.062159</td>\n",
       "      <td>-2.717835</td>\n",
       "      <td>-2.894908</td>\n",
       "      <td>-1.573558</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.611605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.442197</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>5.036114</td>\n",
       "      <td>2.547788</td>\n",
       "      <td>-0.879312</td>\n",
       "      <td>2.856614</td>\n",
       "      <td>5.651050</td>\n",
       "      <td>-1.604230</td>\n",
       "      <td>-0.773323</td>\n",
       "      <td>-1.521259</td>\n",
       "      <td>-0.081890</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.691336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>3.177144</td>\n",
       "      <td>1.634451</td>\n",
       "      <td>-2.052028</td>\n",
       "      <td>1.827839</td>\n",
       "      <td>3.585398</td>\n",
       "      <td>-2.492491</td>\n",
       "      <td>-1.882391</td>\n",
       "      <td>-2.358171</td>\n",
       "      <td>-1.022712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.832271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.081813</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>3.205993</td>\n",
       "      <td>1.836713</td>\n",
       "      <td>-1.425685</td>\n",
       "      <td>2.055666</td>\n",
       "      <td>3.473244</td>\n",
       "      <td>-1.901370</td>\n",
       "      <td>-1.316877</td>\n",
       "      <td>-1.801222</td>\n",
       "      <td>-0.568594</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.859041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>2.498195</td>\n",
       "      <td>1.795310</td>\n",
       "      <td>-1.994518</td>\n",
       "      <td>2.009029</td>\n",
       "      <td>2.635690</td>\n",
       "      <td>-2.302021</td>\n",
       "      <td>-1.671404</td>\n",
       "      <td>-2.178712</td>\n",
       "      <td>-0.939871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.647203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.553079</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>-1.467261</td>\n",
       "      <td>0.783570</td>\n",
       "      <td>1.524212</td>\n",
       "      <td>0.639345</td>\n",
       "      <td>-1.396357</td>\n",
       "      <td>1.138232</td>\n",
       "      <td>0.857006</td>\n",
       "      <td>1.270194</td>\n",
       "      <td>0.993754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.481505</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.023397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.527659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>-0.715887</td>\n",
       "      <td>0.868596</td>\n",
       "      <td>1.477729</td>\n",
       "      <td>0.671680</td>\n",
       "      <td>-0.906659</td>\n",
       "      <td>1.152253</td>\n",
       "      <td>0.691913</td>\n",
       "      <td>1.009645</td>\n",
       "      <td>1.038541</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121450</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.154876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>-0.558495</td>\n",
       "      <td>0.899390</td>\n",
       "      <td>1.352693</td>\n",
       "      <td>0.504706</td>\n",
       "      <td>-0.775360</td>\n",
       "      <td>1.253158</td>\n",
       "      <td>0.563242</td>\n",
       "      <td>1.039944</td>\n",
       "      <td>1.110398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.039841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-0.626439</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>1.102009</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>-0.669538</td>\n",
       "      <td>0.874675</td>\n",
       "      <td>-0.309515</td>\n",
       "      <td>0.500579</td>\n",
       "      <td>0.800302</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-2.359776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-2.580108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-0.338666</td>\n",
       "      <td>0.604737</td>\n",
       "      <td>1.186923</td>\n",
       "      <td>0.312637</td>\n",
       "      <td>-0.681557</td>\n",
       "      <td>0.821070</td>\n",
       "      <td>0.105468</td>\n",
       "      <td>0.413493</td>\n",
       "      <td>0.731104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518063</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.183864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows  129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_rr_12w_1  \\\n",
       "0                            -0.862899                            1.560382   \n",
       "1                            -0.093639                            5.036114   \n",
       "2                            -0.524505                            3.177144   \n",
       "3                            -0.666293                            3.205993   \n",
       "4                            -0.416695                            2.498195   \n",
       "..                                 ...                                 ...   \n",
       "406                           1.568770                           -1.467261   \n",
       "407                           0.812306                           -0.715887   \n",
       "408                           0.876968                           -0.558495   \n",
       "409                          -0.723696                           -0.626439   \n",
       "410                          -1.413870                           -0.338666   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_0  Adda_cyclostationary_mean_tg_24w_2  \\\n",
       "0                              1.711682                           -2.770704   \n",
       "1                              2.547788                           -0.879312   \n",
       "2                              1.634451                           -2.052028   \n",
       "3                              1.836713                           -1.425685   \n",
       "4                              1.795310                           -1.994518   \n",
       "..                                  ...                                 ...   \n",
       "406                            0.783570                            1.524212   \n",
       "407                            0.868596                            1.477729   \n",
       "408                            0.899390                            1.352693   \n",
       "409                            0.725991                            1.102009   \n",
       "410                            0.604737                            1.186923   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_24w_0  Adda_cyclostationary_mean_rr_24w_2  \\\n",
       "0                              1.914831                            1.558385   \n",
       "1                              2.856614                            5.651050   \n",
       "2                              1.827839                            3.585398   \n",
       "3                              2.055666                            3.473244   \n",
       "4                              2.009029                            2.635690   \n",
       "..                                  ...                                 ...   \n",
       "406                            0.639345                           -1.396357   \n",
       "407                            0.671680                           -0.906659   \n",
       "408                            0.504706                           -0.775360   \n",
       "409                            0.391753                           -0.669538   \n",
       "410                            0.312637                           -0.681557   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_2  Adda_cyclostationary_mean_tg_8w_3  \\\n",
       "0                             -3.062159                          -2.717835   \n",
       "1                             -1.604230                          -0.773323   \n",
       "2                             -2.492491                          -1.882391   \n",
       "3                             -1.901370                          -1.316877   \n",
       "4                             -2.302021                          -1.671404   \n",
       "..                                  ...                                ...   \n",
       "406                            1.138232                           0.857006   \n",
       "407                            1.152253                           0.691913   \n",
       "408                            1.253158                           0.563242   \n",
       "409                            0.874675                          -0.309515   \n",
       "410                            0.821070                           0.105468   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_12w_2  Adda_cyclostationary_mean_tg_16w_1  \\\n",
       "0                             -2.894908                           -1.573558   \n",
       "1                             -1.521259                           -0.081890   \n",
       "2                             -2.358171                           -1.022712   \n",
       "3                             -1.801222                           -0.568594   \n",
       "4                             -2.178712                           -0.939871   \n",
       "..                                  ...                                 ...   \n",
       "406                            1.270194                            0.993754   \n",
       "407                            1.009645                            1.038541   \n",
       "408                            1.039944                            1.110398   \n",
       "409                            0.500579                            0.800302   \n",
       "410                            0.413493                            0.731104   \n",
       "\n",
       "     ...  Ticino_cyclostationary_mean_tg_0_Oglio_Iseo  \\\n",
       "0    ...                                         -0.0   \n",
       "1    ...                                          0.0   \n",
       "2    ...                                         -0.0   \n",
       "3    ...                                          0.0   \n",
       "4    ...                                         -0.0   \n",
       "..   ...                                          ...   \n",
       "406  ...                                          0.0   \n",
       "407  ...                                          0.0   \n",
       "408  ...                                          0.0   \n",
       "409  ...                                         -0.0   \n",
       "410  ...                                          0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_0_Ticino  \\\n",
       "0                                  -0.000000   \n",
       "1                                   0.000000   \n",
       "2                                  -0.000000   \n",
       "3                                   0.000000   \n",
       "4                                  -0.000000   \n",
       "..                                       ...   \n",
       "406                                 1.481505   \n",
       "407                                 0.121450   \n",
       "408                                 0.865426   \n",
       "409                                -2.359776   \n",
       "410                                 0.061748   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Adda  \\\n",
       "0                                    0.611605   \n",
       "1                                    1.691336   \n",
       "2                                    0.832271   \n",
       "3                                    0.859041   \n",
       "4                                    0.647203   \n",
       "..                                        ...   \n",
       "406                                 -0.000000   \n",
       "407                                 -0.000000   \n",
       "408                                  0.000000   \n",
       "409                                  0.000000   \n",
       "410                                  0.000000   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Lambro_Olona  \\\n",
       "0                                                 0.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 0.0   \n",
       "4                                                 0.0   \n",
       "..                                                ...   \n",
       "406                                              -0.0   \n",
       "407                                              -0.0   \n",
       "408                                               0.0   \n",
       "409                                               0.0   \n",
       "410                                               0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Oglio_Iseo  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "..                                              ...   \n",
       "406                                            -0.0   \n",
       "407                                            -0.0   \n",
       "408                                             0.0   \n",
       "409                                             0.0   \n",
       "410                                             0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Ticino  \\\n",
       "0                                      0.000000   \n",
       "1                                      0.000000   \n",
       "2                                      0.000000   \n",
       "3                                      0.000000   \n",
       "4                                      0.000000   \n",
       "..                                          ...   \n",
       "406                                   -1.023397   \n",
       "407                                   -0.154876   \n",
       "408                                    0.083449   \n",
       "409                                    0.001375   \n",
       "410                                    0.518063   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Adda  \\\n",
       "0                                -0.442197   \n",
       "1                                 0.807518   \n",
       "2                                -1.081813   \n",
       "3                                 0.324392   \n",
       "4                                -0.553079   \n",
       "..                                     ...   \n",
       "406                               0.000000   \n",
       "407                               0.000000   \n",
       "408                               0.000000   \n",
       "409                              -0.000000   \n",
       "410                              -0.000000   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Lambro_Olona  \\\n",
       "0                                             -0.0   \n",
       "1                                              0.0   \n",
       "2                                             -0.0   \n",
       "3                                              0.0   \n",
       "4                                             -0.0   \n",
       "..                                             ...   \n",
       "406                                            0.0   \n",
       "407                                            0.0   \n",
       "408                                            0.0   \n",
       "409                                           -0.0   \n",
       "410                                           -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Oglio_Iseo  \\\n",
       "0                                           -0.0   \n",
       "1                                            0.0   \n",
       "2                                           -0.0   \n",
       "3                                            0.0   \n",
       "4                                           -0.0   \n",
       "..                                           ...   \n",
       "406                                          0.0   \n",
       "407                                          0.0   \n",
       "408                                          0.0   \n",
       "409                                         -0.0   \n",
       "410                                         -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Ticino  \n",
       "0                                  -0.000000  \n",
       "1                                   0.000000  \n",
       "2                                  -0.000000  \n",
       "3                                   0.000000  \n",
       "4                                  -0.000000  \n",
       "..                                       ...  \n",
       "406                                 1.527659  \n",
       "407                                 0.019115  \n",
       "408                                 1.039841  \n",
       "409                                -2.580108  \n",
       "410                                -0.183864  \n",
       "\n",
       "[1644 rows x 129 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        clusterdf_train_withClass[clusterdf_train_withClass.columns[i]+'_'+j] = clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_val_withClass[clusterdf_val_withClass.columns[i]+'_'+j] = clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_test_withClass[clusterdf_test_withClass.columns[i]+'_'+j] = clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "302ddc6b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.20499319441165165\n",
      "-0.3968172263759986\n",
      "-0.2680275053692309\n",
      "-0.36298223709897326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f013ae1",
   "metadata": {},
   "source": [
    "### Adda - Lambro_Olona - Oglio_Iseo - Ticino: CMI best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b30215e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_basins = ['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino']\n",
    "colnames = [x for x in best5_CMI_fulldf_train.columns if x.startswith('Adda') or x.startswith('Lambro_Olona') or x.startswith('Oglio_Iseo') or x.startswith('Ticino')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((best5_CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((best5_CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((best5_CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5d5fc02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_6</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_0</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_4w_6</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_4w_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Oglio_Iseo_cyclostationary_mean_rr_16w_0</th>\n",
       "      <th>Oglio_Iseo_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Oglio_Iseo_cyclostationary_mean_tg_1w_1</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1</th>\n",
       "      <th>Adda</th>\n",
       "      <th>Lambro_Olona</th>\n",
       "      <th>Oglio_Iseo</th>\n",
       "      <th>Ticino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>1.560382</td>\n",
       "      <td>1.711682</td>\n",
       "      <td>-2.770704</td>\n",
       "      <td>1.914831</td>\n",
       "      <td>-0.044884</td>\n",
       "      <td>1.663515</td>\n",
       "      <td>-0.277460</td>\n",
       "      <td>-0.075383</td>\n",
       "      <td>-0.156545</td>\n",
       "      <td>...</td>\n",
       "      <td>3.151206</td>\n",
       "      <td>2.453362</td>\n",
       "      <td>0.354242</td>\n",
       "      <td>-0.432799</td>\n",
       "      <td>0.611605</td>\n",
       "      <td>-0.442197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>5.036114</td>\n",
       "      <td>2.547788</td>\n",
       "      <td>-0.879312</td>\n",
       "      <td>2.856614</td>\n",
       "      <td>1.221277</td>\n",
       "      <td>2.277544</td>\n",
       "      <td>0.841342</td>\n",
       "      <td>0.882621</td>\n",
       "      <td>0.761360</td>\n",
       "      <td>...</td>\n",
       "      <td>4.248395</td>\n",
       "      <td>3.334410</td>\n",
       "      <td>0.814679</td>\n",
       "      <td>0.776085</td>\n",
       "      <td>1.691336</td>\n",
       "      <td>0.807518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>3.177144</td>\n",
       "      <td>1.634451</td>\n",
       "      <td>-2.052028</td>\n",
       "      <td>1.827839</td>\n",
       "      <td>-0.221646</td>\n",
       "      <td>1.355767</td>\n",
       "      <td>-0.526335</td>\n",
       "      <td>0.474126</td>\n",
       "      <td>0.269224</td>\n",
       "      <td>...</td>\n",
       "      <td>2.790351</td>\n",
       "      <td>2.198281</td>\n",
       "      <td>0.209296</td>\n",
       "      <td>-0.906320</td>\n",
       "      <td>0.832271</td>\n",
       "      <td>-1.081813</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>3.205993</td>\n",
       "      <td>1.836713</td>\n",
       "      <td>-1.425685</td>\n",
       "      <td>2.055666</td>\n",
       "      <td>0.723165</td>\n",
       "      <td>1.429576</td>\n",
       "      <td>0.512276</td>\n",
       "      <td>0.627310</td>\n",
       "      <td>0.468910</td>\n",
       "      <td>...</td>\n",
       "      <td>2.608805</td>\n",
       "      <td>2.057737</td>\n",
       "      <td>-0.056410</td>\n",
       "      <td>0.529173</td>\n",
       "      <td>0.859041</td>\n",
       "      <td>0.324392</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>2.498195</td>\n",
       "      <td>1.795310</td>\n",
       "      <td>-1.994518</td>\n",
       "      <td>2.009029</td>\n",
       "      <td>-0.122716</td>\n",
       "      <td>0.994844</td>\n",
       "      <td>-0.056656</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.444387</td>\n",
       "      <td>...</td>\n",
       "      <td>1.808583</td>\n",
       "      <td>1.435161</td>\n",
       "      <td>0.188935</td>\n",
       "      <td>-0.687667</td>\n",
       "      <td>0.647203</td>\n",
       "      <td>-0.553079</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>-1.467261</td>\n",
       "      <td>0.783570</td>\n",
       "      <td>1.524212</td>\n",
       "      <td>0.639345</td>\n",
       "      <td>1.014590</td>\n",
       "      <td>-1.098764</td>\n",
       "      <td>1.296972</td>\n",
       "      <td>-0.144871</td>\n",
       "      <td>0.565375</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.033965</td>\n",
       "      <td>-0.632957</td>\n",
       "      <td>1.178621</td>\n",
       "      <td>1.481505</td>\n",
       "      <td>-1.023397</td>\n",
       "      <td>1.527659</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>-0.715887</td>\n",
       "      <td>0.868596</td>\n",
       "      <td>1.477729</td>\n",
       "      <td>0.671680</td>\n",
       "      <td>0.250478</td>\n",
       "      <td>-0.476556</td>\n",
       "      <td>0.495148</td>\n",
       "      <td>0.358805</td>\n",
       "      <td>1.260203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.789153</td>\n",
       "      <td>-0.636576</td>\n",
       "      <td>0.874900</td>\n",
       "      <td>0.121450</td>\n",
       "      <td>-0.154876</td>\n",
       "      <td>0.019115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>-0.558495</td>\n",
       "      <td>0.899390</td>\n",
       "      <td>1.352693</td>\n",
       "      <td>0.504706</td>\n",
       "      <td>0.305326</td>\n",
       "      <td>-0.152527</td>\n",
       "      <td>0.445862</td>\n",
       "      <td>0.439528</td>\n",
       "      <td>1.444956</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.735744</td>\n",
       "      <td>-0.408722</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.865426</td>\n",
       "      <td>0.083449</td>\n",
       "      <td>1.039841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-0.626439</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>1.102009</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>-1.995198</td>\n",
       "      <td>-0.192534</td>\n",
       "      <td>-1.610957</td>\n",
       "      <td>0.109550</td>\n",
       "      <td>1.067782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.704928</td>\n",
       "      <td>-0.283893</td>\n",
       "      <td>-0.656226</td>\n",
       "      <td>-2.359776</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>-2.580108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-0.338666</td>\n",
       "      <td>0.604737</td>\n",
       "      <td>1.186923</td>\n",
       "      <td>0.312637</td>\n",
       "      <td>-0.591923</td>\n",
       "      <td>0.302357</td>\n",
       "      <td>-0.580276</td>\n",
       "      <td>-0.315172</td>\n",
       "      <td>0.501525</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.545666</td>\n",
       "      <td>-0.159524</td>\n",
       "      <td>-1.042254</td>\n",
       "      <td>0.061748</td>\n",
       "      <td>0.518063</td>\n",
       "      <td>-0.183864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows  22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_rr_12w_1  \\\n",
       "0                            -0.862899                            1.560382   \n",
       "1                            -0.093639                            5.036114   \n",
       "2                            -0.524505                            3.177144   \n",
       "3                            -0.666293                            3.205993   \n",
       "4                            -0.416695                            2.498195   \n",
       "..                                 ...                                 ...   \n",
       "406                           1.568770                           -1.467261   \n",
       "407                           0.812306                           -0.715887   \n",
       "408                           0.876968                           -0.558495   \n",
       "409                          -0.723696                           -0.626439   \n",
       "410                          -1.413870                           -0.338666   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_0  Adda_cyclostationary_mean_tg_24w_2  \\\n",
       "0                              1.711682                           -2.770704   \n",
       "1                              2.547788                           -0.879312   \n",
       "2                              1.634451                           -2.052028   \n",
       "3                              1.836713                           -1.425685   \n",
       "4                              1.795310                           -1.994518   \n",
       "..                                  ...                                 ...   \n",
       "406                            0.783570                            1.524212   \n",
       "407                            0.868596                            1.477729   \n",
       "408                            0.899390                            1.352693   \n",
       "409                            0.725991                            1.102009   \n",
       "410                            0.604737                            1.186923   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_24w_0  \\\n",
       "0                              1.914831   \n",
       "1                              2.856614   \n",
       "2                              1.827839   \n",
       "3                              2.055666   \n",
       "4                              2.009029   \n",
       "..                                  ...   \n",
       "406                            0.639345   \n",
       "407                            0.671680   \n",
       "408                            0.504706   \n",
       "409                            0.391753   \n",
       "410                            0.312637   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_6  \\\n",
       "0                                 -0.044884   \n",
       "1                                  1.221277   \n",
       "2                                 -0.221646   \n",
       "3                                  0.723165   \n",
       "4                                 -0.122716   \n",
       "..                                      ...   \n",
       "406                                1.014590   \n",
       "407                                0.250478   \n",
       "408                                0.305326   \n",
       "409                               -1.995198   \n",
       "410                               -0.591923   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_rr_4w_1  \\\n",
       "0                                     1.663515   \n",
       "1                                     2.277544   \n",
       "2                                     1.355767   \n",
       "3                                     1.429576   \n",
       "4                                     0.994844   \n",
       "..                                         ...   \n",
       "406                                  -1.098764   \n",
       "407                                  -0.476556   \n",
       "408                                  -0.152527   \n",
       "409                                  -0.192534   \n",
       "410                                   0.302357   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_0  \\\n",
       "0                                 -0.277460   \n",
       "1                                  0.841342   \n",
       "2                                 -0.526335   \n",
       "3                                  0.512276   \n",
       "4                                 -0.056656   \n",
       "..                                      ...   \n",
       "406                                1.296972   \n",
       "407                                0.495148   \n",
       "408                                0.445862   \n",
       "409                               -1.610957   \n",
       "410                               -0.580276   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_4w_6  \\\n",
       "0                                    -0.075383   \n",
       "1                                     0.882621   \n",
       "2                                     0.474126   \n",
       "3                                     0.627310   \n",
       "4                                     0.463215   \n",
       "..                                         ...   \n",
       "406                                  -0.144871   \n",
       "407                                   0.358805   \n",
       "408                                   0.439528   \n",
       "409                                   0.109550   \n",
       "410                                  -0.315172   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_4w_5  ...  \\\n",
       "0                                    -0.156545  ...   \n",
       "1                                     0.761360  ...   \n",
       "2                                     0.269224  ...   \n",
       "3                                     0.468910  ...   \n",
       "4                                     0.444387  ...   \n",
       "..                                         ...  ...   \n",
       "406                                   0.565375  ...   \n",
       "407                                   1.260203  ...   \n",
       "408                                   1.444956  ...   \n",
       "409                                   1.067782  ...   \n",
       "410                                   0.501525  ...   \n",
       "\n",
       "     Oglio_Iseo_cyclostationary_mean_rr_16w_0  \\\n",
       "0                                    3.151206   \n",
       "1                                    4.248395   \n",
       "2                                    2.790351   \n",
       "3                                    2.608805   \n",
       "4                                    1.808583   \n",
       "..                                        ...   \n",
       "406                                 -1.033965   \n",
       "407                                 -0.789153   \n",
       "408                                 -0.735744   \n",
       "409                                 -0.704928   \n",
       "410                                 -0.545666   \n",
       "\n",
       "     Oglio_Iseo_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                   2.453362   \n",
       "1                                   3.334410   \n",
       "2                                   2.198281   \n",
       "3                                   2.057737   \n",
       "4                                   1.435161   \n",
       "..                                       ...   \n",
       "406                                -0.632957   \n",
       "407                                -0.636576   \n",
       "408                                -0.408722   \n",
       "409                                -0.283893   \n",
       "410                                -0.159524   \n",
       "\n",
       "     Oglio_Iseo_cyclostationary_mean_tg_1w_1  \\\n",
       "0                                   0.354242   \n",
       "1                                   0.814679   \n",
       "2                                   0.209296   \n",
       "3                                  -0.056410   \n",
       "4                                   0.188935   \n",
       "..                                       ...   \n",
       "406                                 1.178621   \n",
       "407                                 0.874900   \n",
       "408                                 0.552941   \n",
       "409                                -0.656226   \n",
       "410                                -1.042254   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_0  Ticino_cyclostationary_mean_rr_4w_0  \\\n",
       "0                           -0.432799                             0.611605   \n",
       "1                            0.776085                             1.691336   \n",
       "2                           -0.906320                             0.832271   \n",
       "3                            0.529173                             0.859041   \n",
       "4                           -0.687667                             0.647203   \n",
       "..                                ...                                  ...   \n",
       "406                          1.481505                            -1.023397   \n",
       "407                          0.121450                            -0.154876   \n",
       "408                          0.865426                             0.083449   \n",
       "409                         -2.359776                             0.001375   \n",
       "410                          0.061748                             0.518063   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1  Adda  Lambro_Olona  Oglio_Iseo  Ticino  \n",
       "0                           -0.442197     1             0           0       0  \n",
       "1                            0.807518     1             0           0       0  \n",
       "2                           -1.081813     1             0           0       0  \n",
       "3                            0.324392     1             0           0       0  \n",
       "4                           -0.553079     1             0           0       0  \n",
       "..                                ...   ...           ...         ...     ...  \n",
       "406                          1.527659     0             0           0       1  \n",
       "407                          0.019115     0             0           0       1  \n",
       "408                          1.039841     0             0           0       1  \n",
       "409                         -2.580108     0             0           0       1  \n",
       "410                         -0.183864     0             0           0       1  \n",
       "\n",
       "[1644 rows x 22 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "af11e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edae7c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.546951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.277191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.534156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.447894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>-0.563495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>-0.291984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>0.770822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>-0.412164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>-1.081585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    -2.546951\n",
       "1    -0.277191\n",
       "2    -0.534156\n",
       "3    -0.666789\n",
       "4    -0.447894\n",
       "...        ...\n",
       "1639 -0.563495\n",
       "1640 -0.291984\n",
       "1641  0.770822\n",
       "1642 -0.412164\n",
       "1643 -1.081585\n",
       "\n",
       "[1644 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_train_unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b12d3a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28265025081716755\n",
      "0.2624219499639573\n",
      "0.2676768314882756\n",
      "0.3019320480057843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6c0346f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.301930650938936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n",
    "\n",
    "plt.plot(res, color='blue',label=\"Predicted value\")\n",
    "plt.plot(targets_df_test['Ticino'].values, color='green',label=\"Real value\")\n",
    "plt.title(\"Ticino test result\")\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"R2 score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a90367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b1be5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "6f472b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_6</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_0</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_4w_6</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_4w_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0_Ticino</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Adda</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Lambro_Olona</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Ticino</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Adda</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Lambro_Olona</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Ticino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>1.560382</td>\n",
       "      <td>1.711682</td>\n",
       "      <td>-2.770704</td>\n",
       "      <td>1.914831</td>\n",
       "      <td>-0.044884</td>\n",
       "      <td>1.663515</td>\n",
       "      <td>-0.277460</td>\n",
       "      <td>-0.075383</td>\n",
       "      <td>-0.156545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.611605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.442197</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>5.036114</td>\n",
       "      <td>2.547788</td>\n",
       "      <td>-0.879312</td>\n",
       "      <td>2.856614</td>\n",
       "      <td>1.221277</td>\n",
       "      <td>2.277544</td>\n",
       "      <td>0.841342</td>\n",
       "      <td>0.882621</td>\n",
       "      <td>0.761360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.691336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>3.177144</td>\n",
       "      <td>1.634451</td>\n",
       "      <td>-2.052028</td>\n",
       "      <td>1.827839</td>\n",
       "      <td>-0.221646</td>\n",
       "      <td>1.355767</td>\n",
       "      <td>-0.526335</td>\n",
       "      <td>0.474126</td>\n",
       "      <td>0.269224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.832271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.081813</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>3.205993</td>\n",
       "      <td>1.836713</td>\n",
       "      <td>-1.425685</td>\n",
       "      <td>2.055666</td>\n",
       "      <td>0.723165</td>\n",
       "      <td>1.429576</td>\n",
       "      <td>0.512276</td>\n",
       "      <td>0.627310</td>\n",
       "      <td>0.468910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.859041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>2.498195</td>\n",
       "      <td>1.795310</td>\n",
       "      <td>-1.994518</td>\n",
       "      <td>2.009029</td>\n",
       "      <td>-0.122716</td>\n",
       "      <td>0.994844</td>\n",
       "      <td>-0.056656</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.444387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.647203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.553079</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>-1.467261</td>\n",
       "      <td>0.783570</td>\n",
       "      <td>1.524212</td>\n",
       "      <td>0.639345</td>\n",
       "      <td>1.014590</td>\n",
       "      <td>-1.098764</td>\n",
       "      <td>1.296972</td>\n",
       "      <td>-0.144871</td>\n",
       "      <td>0.565375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.481505</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.023397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.527659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>-0.715887</td>\n",
       "      <td>0.868596</td>\n",
       "      <td>1.477729</td>\n",
       "      <td>0.671680</td>\n",
       "      <td>0.250478</td>\n",
       "      <td>-0.476556</td>\n",
       "      <td>0.495148</td>\n",
       "      <td>0.358805</td>\n",
       "      <td>1.260203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121450</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.154876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>-0.558495</td>\n",
       "      <td>0.899390</td>\n",
       "      <td>1.352693</td>\n",
       "      <td>0.504706</td>\n",
       "      <td>0.305326</td>\n",
       "      <td>-0.152527</td>\n",
       "      <td>0.445862</td>\n",
       "      <td>0.439528</td>\n",
       "      <td>1.444956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.039841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-0.626439</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>1.102009</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>-1.995198</td>\n",
       "      <td>-0.192534</td>\n",
       "      <td>-1.610957</td>\n",
       "      <td>0.109550</td>\n",
       "      <td>1.067782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-2.359776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-2.580108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-0.338666</td>\n",
       "      <td>0.604737</td>\n",
       "      <td>1.186923</td>\n",
       "      <td>0.312637</td>\n",
       "      <td>-0.591923</td>\n",
       "      <td>0.302357</td>\n",
       "      <td>-0.580276</td>\n",
       "      <td>-0.315172</td>\n",
       "      <td>0.501525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518063</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.183864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows  94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_rr_12w_1  \\\n",
       "0                            -0.862899                            1.560382   \n",
       "1                            -0.093639                            5.036114   \n",
       "2                            -0.524505                            3.177144   \n",
       "3                            -0.666293                            3.205993   \n",
       "4                            -0.416695                            2.498195   \n",
       "..                                 ...                                 ...   \n",
       "406                           1.568770                           -1.467261   \n",
       "407                           0.812306                           -0.715887   \n",
       "408                           0.876968                           -0.558495   \n",
       "409                          -0.723696                           -0.626439   \n",
       "410                          -1.413870                           -0.338666   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_0  Adda_cyclostationary_mean_tg_24w_2  \\\n",
       "0                              1.711682                           -2.770704   \n",
       "1                              2.547788                           -0.879312   \n",
       "2                              1.634451                           -2.052028   \n",
       "3                              1.836713                           -1.425685   \n",
       "4                              1.795310                           -1.994518   \n",
       "..                                  ...                                 ...   \n",
       "406                            0.783570                            1.524212   \n",
       "407                            0.868596                            1.477729   \n",
       "408                            0.899390                            1.352693   \n",
       "409                            0.725991                            1.102009   \n",
       "410                            0.604737                            1.186923   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_24w_0  \\\n",
       "0                              1.914831   \n",
       "1                              2.856614   \n",
       "2                              1.827839   \n",
       "3                              2.055666   \n",
       "4                              2.009029   \n",
       "..                                  ...   \n",
       "406                            0.639345   \n",
       "407                            0.671680   \n",
       "408                            0.504706   \n",
       "409                            0.391753   \n",
       "410                            0.312637   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_6  \\\n",
       "0                                 -0.044884   \n",
       "1                                  1.221277   \n",
       "2                                 -0.221646   \n",
       "3                                  0.723165   \n",
       "4                                 -0.122716   \n",
       "..                                      ...   \n",
       "406                                1.014590   \n",
       "407                                0.250478   \n",
       "408                                0.305326   \n",
       "409                               -1.995198   \n",
       "410                               -0.591923   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_rr_4w_1  \\\n",
       "0                                     1.663515   \n",
       "1                                     2.277544   \n",
       "2                                     1.355767   \n",
       "3                                     1.429576   \n",
       "4                                     0.994844   \n",
       "..                                         ...   \n",
       "406                                  -1.098764   \n",
       "407                                  -0.476556   \n",
       "408                                  -0.152527   \n",
       "409                                  -0.192534   \n",
       "410                                   0.302357   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_0  \\\n",
       "0                                 -0.277460   \n",
       "1                                  0.841342   \n",
       "2                                 -0.526335   \n",
       "3                                  0.512276   \n",
       "4                                 -0.056656   \n",
       "..                                      ...   \n",
       "406                                1.296972   \n",
       "407                                0.495148   \n",
       "408                                0.445862   \n",
       "409                               -1.610957   \n",
       "410                               -0.580276   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_4w_6  \\\n",
       "0                                    -0.075383   \n",
       "1                                     0.882621   \n",
       "2                                     0.474126   \n",
       "3                                     0.627310   \n",
       "4                                     0.463215   \n",
       "..                                         ...   \n",
       "406                                  -0.144871   \n",
       "407                                   0.358805   \n",
       "408                                   0.439528   \n",
       "409                                   0.109550   \n",
       "410                                  -0.315172   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_4w_5  ...  \\\n",
       "0                                    -0.156545  ...   \n",
       "1                                     0.761360  ...   \n",
       "2                                     0.269224  ...   \n",
       "3                                     0.468910  ...   \n",
       "4                                     0.444387  ...   \n",
       "..                                         ...  ...   \n",
       "406                                   0.565375  ...   \n",
       "407                                   1.260203  ...   \n",
       "408                                   1.444956  ...   \n",
       "409                                   1.067782  ...   \n",
       "410                                   0.501525  ...   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_0_Oglio_Iseo  \\\n",
       "0                                           -0.0   \n",
       "1                                            0.0   \n",
       "2                                           -0.0   \n",
       "3                                            0.0   \n",
       "4                                           -0.0   \n",
       "..                                           ...   \n",
       "406                                          0.0   \n",
       "407                                          0.0   \n",
       "408                                          0.0   \n",
       "409                                         -0.0   \n",
       "410                                          0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_0_Ticino  \\\n",
       "0                                  -0.000000   \n",
       "1                                   0.000000   \n",
       "2                                  -0.000000   \n",
       "3                                   0.000000   \n",
       "4                                  -0.000000   \n",
       "..                                       ...   \n",
       "406                                 1.481505   \n",
       "407                                 0.121450   \n",
       "408                                 0.865426   \n",
       "409                                -2.359776   \n",
       "410                                 0.061748   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Adda  \\\n",
       "0                                    0.611605   \n",
       "1                                    1.691336   \n",
       "2                                    0.832271   \n",
       "3                                    0.859041   \n",
       "4                                    0.647203   \n",
       "..                                        ...   \n",
       "406                                 -0.000000   \n",
       "407                                 -0.000000   \n",
       "408                                  0.000000   \n",
       "409                                  0.000000   \n",
       "410                                  0.000000   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Lambro_Olona  \\\n",
       "0                                                 0.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 0.0   \n",
       "4                                                 0.0   \n",
       "..                                                ...   \n",
       "406                                              -0.0   \n",
       "407                                              -0.0   \n",
       "408                                               0.0   \n",
       "409                                               0.0   \n",
       "410                                               0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Oglio_Iseo  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "..                                              ...   \n",
       "406                                            -0.0   \n",
       "407                                            -0.0   \n",
       "408                                             0.0   \n",
       "409                                             0.0   \n",
       "410                                             0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Ticino  \\\n",
       "0                                      0.000000   \n",
       "1                                      0.000000   \n",
       "2                                      0.000000   \n",
       "3                                      0.000000   \n",
       "4                                      0.000000   \n",
       "..                                          ...   \n",
       "406                                   -1.023397   \n",
       "407                                   -0.154876   \n",
       "408                                    0.083449   \n",
       "409                                    0.001375   \n",
       "410                                    0.518063   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Adda  \\\n",
       "0                                -0.442197   \n",
       "1                                 0.807518   \n",
       "2                                -1.081813   \n",
       "3                                 0.324392   \n",
       "4                                -0.553079   \n",
       "..                                     ...   \n",
       "406                               0.000000   \n",
       "407                               0.000000   \n",
       "408                               0.000000   \n",
       "409                              -0.000000   \n",
       "410                              -0.000000   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Lambro_Olona  \\\n",
       "0                                             -0.0   \n",
       "1                                              0.0   \n",
       "2                                             -0.0   \n",
       "3                                              0.0   \n",
       "4                                             -0.0   \n",
       "..                                             ...   \n",
       "406                                            0.0   \n",
       "407                                            0.0   \n",
       "408                                            0.0   \n",
       "409                                           -0.0   \n",
       "410                                           -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Oglio_Iseo  \\\n",
       "0                                           -0.0   \n",
       "1                                            0.0   \n",
       "2                                           -0.0   \n",
       "3                                            0.0   \n",
       "4                                           -0.0   \n",
       "..                                           ...   \n",
       "406                                          0.0   \n",
       "407                                          0.0   \n",
       "408                                          0.0   \n",
       "409                                         -0.0   \n",
       "410                                         -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Ticino  \n",
       "0                                  -0.000000  \n",
       "1                                   0.000000  \n",
       "2                                  -0.000000  \n",
       "3                                   0.000000  \n",
       "4                                  -0.000000  \n",
       "..                                       ...  \n",
       "406                                 1.527659  \n",
       "407                                 0.019115  \n",
       "408                                 1.039841  \n",
       "409                                -2.580108  \n",
       "410                                -0.183864  \n",
       "\n",
       "[1644 rows x 94 columns]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        clusterdf_train_withClass[clusterdf_train_withClass.columns[i]+'_'+j] = clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_val_withClass[clusterdf_val_withClass.columns[i]+'_'+j] = clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_test_withClass[clusterdf_test_withClass.columns[i]+'_'+j] = clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "86504764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2934203975293319\n",
      "0.26426191622064354\n",
      "0.15121968885589177\n",
      "0.2495948097547407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05da958f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49292d66",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dora - Piemonte_Nord - Piemonte_Sud: wrapper best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "792d7635",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n",
    "colnames = [x for x in best5_wrapper_fulldf_train.columns if x.startswith('Dora') or x.startswith('Piemonte_Nord') or x.startswith('Piemonte_Sud')]\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass = pd.DataFrame()\n",
    "best5_wrapper_clusterdf_val_withClass = pd.DataFrame()\n",
    "best5_wrapper_clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    best5_wrapper_clusterdf_train_withClass = pd.concat((best5_wrapper_clusterdf_train_withClass,pd.concat((best5_wrapper_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_clusterdf_val_withClass = pd.concat((best5_wrapper_clusterdf_val_withClass,pd.concat((best5_wrapper_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    best5_wrapper_clusterdf_test_withClass = pd.concat((best5_wrapper_clusterdf_test_withClass,pd.concat((best5_wrapper_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_wrapper_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    best5_wrapper_clusterdf_train_withClass[clust_basins[i]] = best5_wrapper_clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_clusterdf_val_withClass[clust_basins[i]] = best5_wrapper_clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    best5_wrapper_clusterdf_test_withClass[clust_basins[i]] = best5_wrapper_clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass = best5_wrapper_clusterdf_train_withClass.loc[:,best5_wrapper_clusterdf_train_withClass.columns != 'basin']\n",
    "best5_wrapper_clusterdf_val_withClass = best5_wrapper_clusterdf_val_withClass.loc[:,best5_wrapper_clusterdf_val_withClass.columns != 'basin']\n",
    "best5_wrapper_clusterdf_test_withClass = best5_wrapper_clusterdf_test_withClass.loc[:,best5_wrapper_clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "3647d125",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dora_cyclostationary_mean_tg_1w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_1w_2</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_24w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_24w_1</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_2</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_1</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_1w_4</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_16w_1</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_16w_2</th>\n",
       "      <th>Dora</th>\n",
       "      <th>Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.858428</td>\n",
       "      <td>0.569944</td>\n",
       "      <td>-0.645734</td>\n",
       "      <td>-0.958059</td>\n",
       "      <td>-1.179177</td>\n",
       "      <td>-0.705198</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>0.993156</td>\n",
       "      <td>-1.444933</td>\n",
       "      <td>-1.056852</td>\n",
       "      <td>-0.374151</td>\n",
       "      <td>1.722357</td>\n",
       "      <td>0.566795</td>\n",
       "      <td>5.503456</td>\n",
       "      <td>3.450706</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.144075</td>\n",
       "      <td>2.777501</td>\n",
       "      <td>-0.040254</td>\n",
       "      <td>0.064877</td>\n",
       "      <td>-0.154668</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>1.141736</td>\n",
       "      <td>2.145937</td>\n",
       "      <td>0.399738</td>\n",
       "      <td>0.702337</td>\n",
       "      <td>0.845319</td>\n",
       "      <td>2.568972</td>\n",
       "      <td>1.162632</td>\n",
       "      <td>5.284243</td>\n",
       "      <td>3.406378</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.543433</td>\n",
       "      <td>1.425829</td>\n",
       "      <td>-0.727940</td>\n",
       "      <td>-1.002116</td>\n",
       "      <td>-0.919496</td>\n",
       "      <td>-0.312340</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>1.115539</td>\n",
       "      <td>-0.862634</td>\n",
       "      <td>-0.363026</td>\n",
       "      <td>-1.069465</td>\n",
       "      <td>1.502423</td>\n",
       "      <td>0.501665</td>\n",
       "      <td>3.124173</td>\n",
       "      <td>1.751610</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.723360</td>\n",
       "      <td>1.785519</td>\n",
       "      <td>-0.924722</td>\n",
       "      <td>-0.601101</td>\n",
       "      <td>-0.594848</td>\n",
       "      <td>-0.434823</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>1.140701</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.053932</td>\n",
       "      <td>0.510716</td>\n",
       "      <td>1.463618</td>\n",
       "      <td>-0.074694</td>\n",
       "      <td>2.734133</td>\n",
       "      <td>1.878484</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.540293</td>\n",
       "      <td>1.524603</td>\n",
       "      <td>-0.569035</td>\n",
       "      <td>-0.789653</td>\n",
       "      <td>-0.843317</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.742092</td>\n",
       "      <td>-0.535961</td>\n",
       "      <td>-0.202521</td>\n",
       "      <td>-0.448734</td>\n",
       "      <td>0.854895</td>\n",
       "      <td>0.107268</td>\n",
       "      <td>1.874214</td>\n",
       "      <td>1.117130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.462830</td>\n",
       "      <td>-0.520256</td>\n",
       "      <td>1.585661</td>\n",
       "      <td>0.807565</td>\n",
       "      <td>0.577376</td>\n",
       "      <td>1.346423</td>\n",
       "      <td>-0.938846</td>\n",
       "      <td>-1.118138</td>\n",
       "      <td>1.192105</td>\n",
       "      <td>0.686556</td>\n",
       "      <td>1.056166</td>\n",
       "      <td>-1.165656</td>\n",
       "      <td>-0.617574</td>\n",
       "      <td>-0.419856</td>\n",
       "      <td>0.118142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.599620</td>\n",
       "      <td>-0.530550</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>1.020805</td>\n",
       "      <td>0.776516</td>\n",
       "      <td>0.509539</td>\n",
       "      <td>-0.559070</td>\n",
       "      <td>-0.904049</td>\n",
       "      <td>1.080238</td>\n",
       "      <td>0.646899</td>\n",
       "      <td>0.308611</td>\n",
       "      <td>-0.855699</td>\n",
       "      <td>-0.290505</td>\n",
       "      <td>0.087685</td>\n",
       "      <td>0.753294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.344849</td>\n",
       "      <td>0.031726</td>\n",
       "      <td>0.422436</td>\n",
       "      <td>0.910086</td>\n",
       "      <td>0.715672</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>-0.769506</td>\n",
       "      <td>0.967415</td>\n",
       "      <td>0.491266</td>\n",
       "      <td>0.651470</td>\n",
       "      <td>-0.755765</td>\n",
       "      <td>-0.235027</td>\n",
       "      <td>0.110292</td>\n",
       "      <td>0.728345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-1.130239</td>\n",
       "      <td>-0.154282</td>\n",
       "      <td>-1.116372</td>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.083901</td>\n",
       "      <td>-1.353830</td>\n",
       "      <td>-0.253229</td>\n",
       "      <td>-0.635866</td>\n",
       "      <td>0.608651</td>\n",
       "      <td>0.209678</td>\n",
       "      <td>-2.101458</td>\n",
       "      <td>-0.632667</td>\n",
       "      <td>-0.224584</td>\n",
       "      <td>0.111368</td>\n",
       "      <td>0.550634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.598190</td>\n",
       "      <td>0.583732</td>\n",
       "      <td>-1.711036</td>\n",
       "      <td>-0.182408</td>\n",
       "      <td>-0.229108</td>\n",
       "      <td>-1.553763</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>-0.646653</td>\n",
       "      <td>0.748061</td>\n",
       "      <td>0.239362</td>\n",
       "      <td>-0.328858</td>\n",
       "      <td>-0.605880</td>\n",
       "      <td>1.003973</td>\n",
       "      <td>0.582957</td>\n",
       "      <td>0.714648</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dora_cyclostationary_mean_tg_1w_0  Dora_cyclostationary_mean_rr_4w_1  \\\n",
       "0                            -0.858428                           0.569944   \n",
       "1                            -0.144075                           2.777501   \n",
       "2                            -0.543433                           1.425829   \n",
       "3                            -0.723360                           1.785519   \n",
       "4                            -0.540293                           1.524603   \n",
       "..                                 ...                                ...   \n",
       "406                           1.462830                          -0.520256   \n",
       "407                           0.599620                          -0.530550   \n",
       "408                           0.344849                           0.031726   \n",
       "409                          -1.130239                          -0.154282   \n",
       "410                          -1.598190                           0.583732   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_1w_2  Dora_cyclostationary_mean_tg_4w_1  \\\n",
       "0                            -0.645734                          -0.958059   \n",
       "1                            -0.040254                           0.064877   \n",
       "2                            -0.727940                          -1.002116   \n",
       "3                            -0.924722                          -0.601101   \n",
       "4                            -0.569035                          -0.789653   \n",
       "..                                 ...                                ...   \n",
       "406                           1.585661                           0.807565   \n",
       "407                           0.724000                           1.020805   \n",
       "408                           0.422436                           0.910086   \n",
       "409                          -1.116372                           0.237759   \n",
       "410                          -1.711036                          -0.182408   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_4w_0  \\\n",
       "0                            -1.179177   \n",
       "1                            -0.154668   \n",
       "2                            -0.919496   \n",
       "3                            -0.594848   \n",
       "4                            -0.843317   \n",
       "..                                 ...   \n",
       "406                           0.577376   \n",
       "407                           0.776516   \n",
       "408                           0.715672   \n",
       "409                           0.083901   \n",
       "410                          -0.229108   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_3  \\\n",
       "0                                     -0.705198   \n",
       "1                                     -0.040533   \n",
       "2                                     -0.312340   \n",
       "3                                     -0.434823   \n",
       "4                                     -0.286705   \n",
       "..                                          ...   \n",
       "406                                    1.346423   \n",
       "407                                    0.509539   \n",
       "408                                    0.236097   \n",
       "409                                   -1.353830   \n",
       "410                                   -1.553763   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                      0.531161   \n",
       "1                                      1.141736   \n",
       "2                                      0.600533   \n",
       "3                                      0.613627   \n",
       "4                                      0.408259   \n",
       "..                                          ...   \n",
       "406                                   -0.938846   \n",
       "407                                   -0.559070   \n",
       "408                                   -0.113738   \n",
       "409                                   -0.253229   \n",
       "410                                    0.301057   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_24w_0  \\\n",
       "0                                       0.993156   \n",
       "1                                       2.145937   \n",
       "2                                       1.115539   \n",
       "3                                       1.140701   \n",
       "4                                       0.742092   \n",
       "..                                           ...   \n",
       "406                                    -1.118138   \n",
       "407                                    -0.904049   \n",
       "408                                    -0.769506   \n",
       "409                                    -0.635866   \n",
       "410                                    -0.646653   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_24w_0  \\\n",
       "0                                      -1.444933   \n",
       "1                                       0.399738   \n",
       "2                                      -0.862634   \n",
       "3                                       0.012866   \n",
       "4                                      -0.535961   \n",
       "..                                           ...   \n",
       "406                                     1.192105   \n",
       "407                                     1.080238   \n",
       "408                                     0.967415   \n",
       "409                                     0.608651   \n",
       "410                                     0.748061   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_24w_1  \\\n",
       "0                                      -1.056852   \n",
       "1                                       0.702337   \n",
       "2                                      -0.363026   \n",
       "3                                       0.053932   \n",
       "4                                      -0.202521   \n",
       "..                                           ...   \n",
       "406                                     0.686556   \n",
       "407                                     0.646899   \n",
       "408                                     0.491266   \n",
       "409                                     0.209678   \n",
       "410                                     0.239362   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_2  \\\n",
       "0                                 -0.374151   \n",
       "1                                  0.845319   \n",
       "2                                 -1.069465   \n",
       "3                                  0.510716   \n",
       "4                                 -0.448734   \n",
       "..                                      ...   \n",
       "406                                1.056166   \n",
       "407                                0.308611   \n",
       "408                                0.651470   \n",
       "409                               -2.101458   \n",
       "410                               -0.328858   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_1  \\\n",
       "0                                      1.722357   \n",
       "1                                      2.568972   \n",
       "2                                      1.502423   \n",
       "3                                      1.463618   \n",
       "4                                      0.854895   \n",
       "..                                          ...   \n",
       "406                                   -1.165656   \n",
       "407                                   -0.855699   \n",
       "408                                   -0.755765   \n",
       "409                                   -0.632667   \n",
       "410                                   -0.605880   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_1w_4  \\\n",
       "0                                     0.566795   \n",
       "1                                     1.162632   \n",
       "2                                     0.501665   \n",
       "3                                    -0.074694   \n",
       "4                                     0.107268   \n",
       "..                                         ...   \n",
       "406                                  -0.617574   \n",
       "407                                  -0.290505   \n",
       "408                                  -0.235027   \n",
       "409                                  -0.224584   \n",
       "410                                   1.003973   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_16w_1  \\\n",
       "0                                      5.503456   \n",
       "1                                      5.284243   \n",
       "2                                      3.124173   \n",
       "3                                      2.734133   \n",
       "4                                      1.874214   \n",
       "..                                          ...   \n",
       "406                                   -0.419856   \n",
       "407                                    0.087685   \n",
       "408                                    0.110292   \n",
       "409                                    0.111368   \n",
       "410                                    0.582957   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_16w_2  Dora  Piemonte_Nord  \\\n",
       "0                                      3.450706     1              0   \n",
       "1                                      3.406378     1              0   \n",
       "2                                      1.751610     1              0   \n",
       "3                                      1.878484     1              0   \n",
       "4                                      1.117130     1              0   \n",
       "..                                          ...   ...            ...   \n",
       "406                                    0.118142     0              0   \n",
       "407                                    0.753294     0              0   \n",
       "408                                    0.728345     0              0   \n",
       "409                                    0.550634     0              0   \n",
       "410                                    0.714648     0              0   \n",
       "\n",
       "     Piemonte_Sud  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "406             1  \n",
       "407             1  \n",
       "408             1  \n",
       "409             1  \n",
       "410             1  \n",
       "\n",
       "[1233 rows x 18 columns]"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best5_wrapper_clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "5e6bfe28",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "51a86a15",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.32287659170495364\n",
      "-0.20871592974219433\n",
      "-0.24715940372280998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((best5_wrapper_clusterdf_train_withClass,best5_wrapper_clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "be656261",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dora_cyclostationary_mean_tg_1w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_1w_2</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_24w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_24w_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_1_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_1w_4_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_1w_4_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_1w_4_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_16w_1_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_16w_1_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_16w_1_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_16w_2_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_16w_2_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_16w_2_Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.858428</td>\n",
       "      <td>0.569944</td>\n",
       "      <td>-0.645734</td>\n",
       "      <td>-0.958059</td>\n",
       "      <td>-1.179177</td>\n",
       "      <td>-0.705198</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>0.993156</td>\n",
       "      <td>-1.444933</td>\n",
       "      <td>-1.056852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.503456</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.450706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.144075</td>\n",
       "      <td>2.777501</td>\n",
       "      <td>-0.040254</td>\n",
       "      <td>0.064877</td>\n",
       "      <td>-0.154668</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>1.141736</td>\n",
       "      <td>2.145937</td>\n",
       "      <td>0.399738</td>\n",
       "      <td>0.702337</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.162632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.284243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.406378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.543433</td>\n",
       "      <td>1.425829</td>\n",
       "      <td>-0.727940</td>\n",
       "      <td>-1.002116</td>\n",
       "      <td>-0.919496</td>\n",
       "      <td>-0.312340</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>1.115539</td>\n",
       "      <td>-0.862634</td>\n",
       "      <td>-0.363026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501665</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.124173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.751610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.723360</td>\n",
       "      <td>1.785519</td>\n",
       "      <td>-0.924722</td>\n",
       "      <td>-0.601101</td>\n",
       "      <td>-0.594848</td>\n",
       "      <td>-0.434823</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>1.140701</td>\n",
       "      <td>0.012866</td>\n",
       "      <td>0.053932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.074694</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.734133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.878484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.540293</td>\n",
       "      <td>1.524603</td>\n",
       "      <td>-0.569035</td>\n",
       "      <td>-0.789653</td>\n",
       "      <td>-0.843317</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.742092</td>\n",
       "      <td>-0.535961</td>\n",
       "      <td>-0.202521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.874214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.117130</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.462830</td>\n",
       "      <td>-0.520256</td>\n",
       "      <td>1.585661</td>\n",
       "      <td>0.807565</td>\n",
       "      <td>0.577376</td>\n",
       "      <td>1.346423</td>\n",
       "      <td>-0.938846</td>\n",
       "      <td>-1.118138</td>\n",
       "      <td>1.192105</td>\n",
       "      <td>0.686556</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.165656</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.617574</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.419856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.599620</td>\n",
       "      <td>-0.530550</td>\n",
       "      <td>0.724000</td>\n",
       "      <td>1.020805</td>\n",
       "      <td>0.776516</td>\n",
       "      <td>0.509539</td>\n",
       "      <td>-0.559070</td>\n",
       "      <td>-0.904049</td>\n",
       "      <td>1.080238</td>\n",
       "      <td>0.646899</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.855699</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.290505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.753294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.344849</td>\n",
       "      <td>0.031726</td>\n",
       "      <td>0.422436</td>\n",
       "      <td>0.910086</td>\n",
       "      <td>0.715672</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>-0.769506</td>\n",
       "      <td>0.967415</td>\n",
       "      <td>0.491266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.755765</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.235027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-1.130239</td>\n",
       "      <td>-0.154282</td>\n",
       "      <td>-1.116372</td>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.083901</td>\n",
       "      <td>-1.353830</td>\n",
       "      <td>-0.253229</td>\n",
       "      <td>-0.635866</td>\n",
       "      <td>0.608651</td>\n",
       "      <td>0.209678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.632667</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.224584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111368</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.550634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.598190</td>\n",
       "      <td>0.583732</td>\n",
       "      <td>-1.711036</td>\n",
       "      <td>-0.182408</td>\n",
       "      <td>-0.229108</td>\n",
       "      <td>-1.553763</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>-0.646653</td>\n",
       "      <td>0.748061</td>\n",
       "      <td>0.239362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.605880</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.003973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.582957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows  63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dora_cyclostationary_mean_tg_1w_0  Dora_cyclostationary_mean_rr_4w_1  \\\n",
       "0                            -0.858428                           0.569944   \n",
       "1                            -0.144075                           2.777501   \n",
       "2                            -0.543433                           1.425829   \n",
       "3                            -0.723360                           1.785519   \n",
       "4                            -0.540293                           1.524603   \n",
       "..                                 ...                                ...   \n",
       "406                           1.462830                          -0.520256   \n",
       "407                           0.599620                          -0.530550   \n",
       "408                           0.344849                           0.031726   \n",
       "409                          -1.130239                          -0.154282   \n",
       "410                          -1.598190                           0.583732   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_1w_2  Dora_cyclostationary_mean_tg_4w_1  \\\n",
       "0                            -0.645734                          -0.958059   \n",
       "1                            -0.040254                           0.064877   \n",
       "2                            -0.727940                          -1.002116   \n",
       "3                            -0.924722                          -0.601101   \n",
       "4                            -0.569035                          -0.789653   \n",
       "..                                 ...                                ...   \n",
       "406                           1.585661                           0.807565   \n",
       "407                           0.724000                           1.020805   \n",
       "408                           0.422436                           0.910086   \n",
       "409                          -1.116372                           0.237759   \n",
       "410                          -1.711036                          -0.182408   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_4w_0  \\\n",
       "0                            -1.179177   \n",
       "1                            -0.154668   \n",
       "2                            -0.919496   \n",
       "3                            -0.594848   \n",
       "4                            -0.843317   \n",
       "..                                 ...   \n",
       "406                           0.577376   \n",
       "407                           0.776516   \n",
       "408                           0.715672   \n",
       "409                           0.083901   \n",
       "410                          -0.229108   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_3  \\\n",
       "0                                     -0.705198   \n",
       "1                                     -0.040533   \n",
       "2                                     -0.312340   \n",
       "3                                     -0.434823   \n",
       "4                                     -0.286705   \n",
       "..                                          ...   \n",
       "406                                    1.346423   \n",
       "407                                    0.509539   \n",
       "408                                    0.236097   \n",
       "409                                   -1.353830   \n",
       "410                                   -1.553763   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                      0.531161   \n",
       "1                                      1.141736   \n",
       "2                                      0.600533   \n",
       "3                                      0.613627   \n",
       "4                                      0.408259   \n",
       "..                                          ...   \n",
       "406                                   -0.938846   \n",
       "407                                   -0.559070   \n",
       "408                                   -0.113738   \n",
       "409                                   -0.253229   \n",
       "410                                    0.301057   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_24w_0  \\\n",
       "0                                       0.993156   \n",
       "1                                       2.145937   \n",
       "2                                       1.115539   \n",
       "3                                       1.140701   \n",
       "4                                       0.742092   \n",
       "..                                           ...   \n",
       "406                                    -1.118138   \n",
       "407                                    -0.904049   \n",
       "408                                    -0.769506   \n",
       "409                                    -0.635866   \n",
       "410                                    -0.646653   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_24w_0  \\\n",
       "0                                      -1.444933   \n",
       "1                                       0.399738   \n",
       "2                                      -0.862634   \n",
       "3                                       0.012866   \n",
       "4                                      -0.535961   \n",
       "..                                           ...   \n",
       "406                                     1.192105   \n",
       "407                                     1.080238   \n",
       "408                                     0.967415   \n",
       "409                                     0.608651   \n",
       "410                                     0.748061   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_24w_1  ...  \\\n",
       "0                                      -1.056852  ...   \n",
       "1                                       0.702337  ...   \n",
       "2                                      -0.363026  ...   \n",
       "3                                       0.053932  ...   \n",
       "4                                      -0.202521  ...   \n",
       "..                                           ...  ...   \n",
       "406                                     0.686556  ...   \n",
       "407                                     0.646899  ...   \n",
       "408                                     0.491266  ...   \n",
       "409                                     0.209678  ...   \n",
       "410                                     0.239362  ...   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_1_Piemonte_Sud  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -1.165656         \n",
       "407                                          -0.855699         \n",
       "408                                          -0.755765         \n",
       "409                                          -0.632667         \n",
       "410                                          -0.605880         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_1w_4_Dora  \\\n",
       "0                                          0.566795   \n",
       "1                                          1.162632   \n",
       "2                                          0.501665   \n",
       "3                                         -0.074694   \n",
       "4                                          0.107268   \n",
       "..                                              ...   \n",
       "406                                       -0.000000   \n",
       "407                                       -0.000000   \n",
       "408                                       -0.000000   \n",
       "409                                       -0.000000   \n",
       "410                                        0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_1w_4_Piemonte_Nord  \\\n",
       "0                                                  0.0         \n",
       "1                                                  0.0         \n",
       "2                                                  0.0         \n",
       "3                                                 -0.0         \n",
       "4                                                  0.0         \n",
       "..                                                 ...         \n",
       "406                                               -0.0         \n",
       "407                                               -0.0         \n",
       "408                                               -0.0         \n",
       "409                                               -0.0         \n",
       "410                                                0.0         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_1w_4_Piemonte_Sud  \\\n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                            -0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                          -0.617574        \n",
       "407                                          -0.290505        \n",
       "408                                          -0.235027        \n",
       "409                                          -0.224584        \n",
       "410                                           1.003973        \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_16w_1_Dora  \\\n",
       "0                                           5.503456   \n",
       "1                                           5.284243   \n",
       "2                                           3.124173   \n",
       "3                                           2.734133   \n",
       "4                                           1.874214   \n",
       "..                                               ...   \n",
       "406                                        -0.000000   \n",
       "407                                         0.000000   \n",
       "408                                         0.000000   \n",
       "409                                         0.000000   \n",
       "410                                         0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_16w_1_Piemonte_Nord  \\\n",
       "0                                                  0.0          \n",
       "1                                                  0.0          \n",
       "2                                                  0.0          \n",
       "3                                                  0.0          \n",
       "4                                                  0.0          \n",
       "..                                                 ...          \n",
       "406                                               -0.0          \n",
       "407                                                0.0          \n",
       "408                                                0.0          \n",
       "409                                                0.0          \n",
       "410                                                0.0          \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_16w_1_Piemonte_Sud  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.419856         \n",
       "407                                           0.087685         \n",
       "408                                           0.110292         \n",
       "409                                           0.111368         \n",
       "410                                           0.582957         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_16w_2_Dora  \\\n",
       "0                                           3.450706   \n",
       "1                                           3.406378   \n",
       "2                                           1.751610   \n",
       "3                                           1.878484   \n",
       "4                                           1.117130   \n",
       "..                                               ...   \n",
       "406                                         0.000000   \n",
       "407                                         0.000000   \n",
       "408                                         0.000000   \n",
       "409                                         0.000000   \n",
       "410                                         0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_16w_2_Piemonte_Nord  \\\n",
       "0                                                  0.0          \n",
       "1                                                  0.0          \n",
       "2                                                  0.0          \n",
       "3                                                  0.0          \n",
       "4                                                  0.0          \n",
       "..                                                 ...          \n",
       "406                                                0.0          \n",
       "407                                                0.0          \n",
       "408                                                0.0          \n",
       "409                                                0.0          \n",
       "410                                                0.0          \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_16w_2_Piemonte_Sud  \n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                             0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                           0.118142        \n",
       "407                                           0.753294        \n",
       "408                                           0.728345        \n",
       "409                                           0.550634        \n",
       "410                                           0.714648        \n",
       "\n",
       "[1233 rows x 63 columns]"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(best5_wrapper_clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        best5_wrapper_clusterdf_train_withClass[best5_wrapper_clusterdf_train_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        best5_wrapper_clusterdf_val_withClass[best5_wrapper_clusterdf_val_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        best5_wrapper_clusterdf_test_withClass[best5_wrapper_clusterdf_test_withClass.columns[i]+'_'+j] = best5_wrapper_clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "best5_wrapper_clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "cb74d5a6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4605342062519393\n",
      "-0.20089066605171646\n",
      "-0.12280727670971792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((best5_wrapper_clusterdf_train_withClass,best5_wrapper_clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(best5_wrapper_clusterdf_test_withClass.loc[best5_wrapper_clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc406cae",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dora - Piemonte_Nord - Piemonte_Sud: CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "07b350b7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n",
    "colnames = [x for x in CMI_fulldf_train.columns if x.startswith('Dora') or x.startswith('Piemonte_Nord') or x.startswith('Piemonte_Sud')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "377be712",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_12w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_24w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_1</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0</th>\n",
       "      <th>Dora</th>\n",
       "      <th>Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.958059</td>\n",
       "      <td>-1.692206</td>\n",
       "      <td>-0.181114</td>\n",
       "      <td>-1.852227</td>\n",
       "      <td>-1.694637</td>\n",
       "      <td>-0.483868</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>-0.070058</td>\n",
       "      <td>-0.705198</td>\n",
       "      <td>-0.039471</td>\n",
       "      <td>-0.449672</td>\n",
       "      <td>3.146477</td>\n",
       "      <td>1.939769</td>\n",
       "      <td>3.863262</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064877</td>\n",
       "      <td>-0.279226</td>\n",
       "      <td>0.886182</td>\n",
       "      <td>-0.351196</td>\n",
       "      <td>0.267105</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>1.141736</td>\n",
       "      <td>0.669777</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>0.697310</td>\n",
       "      <td>0.880344</td>\n",
       "      <td>3.822355</td>\n",
       "      <td>2.431148</td>\n",
       "      <td>4.345114</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.002116</td>\n",
       "      <td>-1.256740</td>\n",
       "      <td>0.223731</td>\n",
       "      <td>-2.234919</td>\n",
       "      <td>-1.713098</td>\n",
       "      <td>-0.898083</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>-0.312340</td>\n",
       "      <td>0.527444</td>\n",
       "      <td>-0.833249</td>\n",
       "      <td>2.115109</td>\n",
       "      <td>1.348554</td>\n",
       "      <td>2.533689</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.601101</td>\n",
       "      <td>-0.825053</td>\n",
       "      <td>0.383765</td>\n",
       "      <td>-1.590347</td>\n",
       "      <td>-0.953714</td>\n",
       "      <td>0.358463</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>0.245062</td>\n",
       "      <td>-0.434823</td>\n",
       "      <td>0.271867</td>\n",
       "      <td>0.865639</td>\n",
       "      <td>2.006293</td>\n",
       "      <td>1.282061</td>\n",
       "      <td>2.314067</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.789653</td>\n",
       "      <td>-1.182962</td>\n",
       "      <td>0.295643</td>\n",
       "      <td>-1.665547</td>\n",
       "      <td>-1.374058</td>\n",
       "      <td>-0.555381</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.468525</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>0.537510</td>\n",
       "      <td>-0.246418</td>\n",
       "      <td>1.307787</td>\n",
       "      <td>0.836693</td>\n",
       "      <td>1.603089</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.807565</td>\n",
       "      <td>1.079275</td>\n",
       "      <td>-0.712766</td>\n",
       "      <td>1.021359</td>\n",
       "      <td>0.953999</td>\n",
       "      <td>0.862196</td>\n",
       "      <td>-0.938846</td>\n",
       "      <td>0.949782</td>\n",
       "      <td>1.346423</td>\n",
       "      <td>0.952736</td>\n",
       "      <td>1.374448</td>\n",
       "      <td>-0.767792</td>\n",
       "      <td>-0.476107</td>\n",
       "      <td>-0.467565</td>\n",
       "      <td>1.427917</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1.020805</td>\n",
       "      <td>0.749908</td>\n",
       "      <td>-0.597343</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0.900047</td>\n",
       "      <td>-0.160042</td>\n",
       "      <td>-0.559070</td>\n",
       "      <td>0.569543</td>\n",
       "      <td>0.509539</td>\n",
       "      <td>0.579810</td>\n",
       "      <td>-0.119108</td>\n",
       "      <td>-0.482430</td>\n",
       "      <td>-0.420562</td>\n",
       "      <td>0.030758</td>\n",
       "      <td>0.760111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.910086</td>\n",
       "      <td>0.754701</td>\n",
       "      <td>-0.152386</td>\n",
       "      <td>0.925106</td>\n",
       "      <td>0.802985</td>\n",
       "      <td>0.528382</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>0.111790</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>0.086513</td>\n",
       "      <td>0.643035</td>\n",
       "      <td>-0.396456</td>\n",
       "      <td>-0.215110</td>\n",
       "      <td>0.110519</td>\n",
       "      <td>0.315694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.155479</td>\n",
       "      <td>-0.396304</td>\n",
       "      <td>0.610253</td>\n",
       "      <td>0.441811</td>\n",
       "      <td>-2.715411</td>\n",
       "      <td>-0.253229</td>\n",
       "      <td>-1.115423</td>\n",
       "      <td>-1.353830</td>\n",
       "      <td>-1.099133</td>\n",
       "      <td>-2.247923</td>\n",
       "      <td>-0.311937</td>\n",
       "      <td>-0.353737</td>\n",
       "      <td>0.230804</td>\n",
       "      <td>-0.971253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.182408</td>\n",
       "      <td>0.098752</td>\n",
       "      <td>0.173050</td>\n",
       "      <td>0.674977</td>\n",
       "      <td>0.536299</td>\n",
       "      <td>0.147712</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>-1.606865</td>\n",
       "      <td>-1.553763</td>\n",
       "      <td>-1.579153</td>\n",
       "      <td>-0.167457</td>\n",
       "      <td>-0.130149</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>-1.460435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dora_cyclostationary_mean_tg_4w_1  Dora_cyclostationary_mean_tg_12w_0  \\\n",
       "0                            -0.958059                           -1.692206   \n",
       "1                             0.064877                           -0.279226   \n",
       "2                            -1.002116                           -1.256740   \n",
       "3                            -0.601101                           -0.825053   \n",
       "4                            -0.789653                           -1.182962   \n",
       "..                                 ...                                 ...   \n",
       "406                           0.807565                            1.079275   \n",
       "407                           1.020805                            0.749908   \n",
       "408                           0.910086                            0.754701   \n",
       "409                           0.237759                            0.155479   \n",
       "410                          -0.182408                            0.098752   \n",
       "\n",
       "     Dora_cyclostationary_mean_rr_4w_0  Dora_cyclostationary_mean_tg_24w_1  \\\n",
       "0                            -0.181114                           -1.852227   \n",
       "1                             0.886182                           -0.351196   \n",
       "2                             0.223731                           -2.234919   \n",
       "3                             0.383765                           -1.590347   \n",
       "4                             0.295643                           -1.665547   \n",
       "..                                 ...                                 ...   \n",
       "406                          -0.712766                            1.021359   \n",
       "407                          -0.597343                            1.000397   \n",
       "408                          -0.152386                            0.925106   \n",
       "409                          -0.396304                            0.610253   \n",
       "410                           0.173050                            0.674977   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_24w_2  \\\n",
       "0                             -1.694637   \n",
       "1                              0.267105   \n",
       "2                             -1.713098   \n",
       "3                             -0.953714   \n",
       "4                             -1.374058   \n",
       "..                                  ...   \n",
       "406                            0.953999   \n",
       "407                            0.900047   \n",
       "408                            0.802985   \n",
       "409                            0.441811   \n",
       "410                            0.536299   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_3  \\\n",
       "0                                  -0.483868   \n",
       "1                                   0.673096   \n",
       "2                                  -0.898083   \n",
       "3                                   0.358463   \n",
       "4                                  -0.555381   \n",
       "..                                       ...   \n",
       "406                                 0.862196   \n",
       "407                                -0.160042   \n",
       "408                                 0.528382   \n",
       "409                                -2.715411   \n",
       "410                                 0.147712   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                      0.531161   \n",
       "1                                      1.141736   \n",
       "2                                      0.600533   \n",
       "3                                      0.613627   \n",
       "4                                      0.408259   \n",
       "..                                          ...   \n",
       "406                                   -0.938846   \n",
       "407                                   -0.559070   \n",
       "408                                   -0.113738   \n",
       "409                                   -0.253229   \n",
       "410                                    0.301057   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_1  \\\n",
       "0                                     -0.070058   \n",
       "1                                      0.669777   \n",
       "2                                      0.518292   \n",
       "3                                      0.245062   \n",
       "4                                      0.468525   \n",
       "..                                          ...   \n",
       "406                                    0.949782   \n",
       "407                                    0.569543   \n",
       "408                                    0.111790   \n",
       "409                                   -1.115423   \n",
       "410                                   -1.606865   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_3  \\\n",
       "0                                     -0.705198   \n",
       "1                                     -0.040533   \n",
       "2                                     -0.312340   \n",
       "3                                     -0.434823   \n",
       "4                                     -0.286705   \n",
       "..                                          ...   \n",
       "406                                    1.346423   \n",
       "407                                    0.509539   \n",
       "408                                    0.236097   \n",
       "409                                   -1.353830   \n",
       "410                                   -1.553763   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                     -0.039471   \n",
       "1                                      0.697310   \n",
       "2                                      0.527444   \n",
       "3                                      0.271867   \n",
       "4                                      0.537510   \n",
       "..                                          ...   \n",
       "406                                    0.952736   \n",
       "407                                    0.579810   \n",
       "408                                    0.086513   \n",
       "409                                   -1.099133   \n",
       "410                                   -1.579153   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_0  \\\n",
       "0                                 -0.449672   \n",
       "1                                  0.880344   \n",
       "2                                 -0.833249   \n",
       "3                                  0.865639   \n",
       "4                                 -0.246418   \n",
       "..                                      ...   \n",
       "406                                1.374448   \n",
       "407                               -0.119108   \n",
       "408                                0.643035   \n",
       "409                               -2.247923   \n",
       "410                               -0.167457   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_0  \\\n",
       "0                                      3.146477   \n",
       "1                                      3.822355   \n",
       "2                                      2.115109   \n",
       "3                                      2.006293   \n",
       "4                                      1.307787   \n",
       "..                                          ...   \n",
       "406                                   -0.767792   \n",
       "407                                   -0.482430   \n",
       "408                                   -0.396456   \n",
       "409                                   -0.311937   \n",
       "410                                   -0.130149   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                     1.939769   \n",
       "1                                     2.431148   \n",
       "2                                     1.348554   \n",
       "3                                     1.282061   \n",
       "4                                     0.836693   \n",
       "..                                         ...   \n",
       "406                                  -0.476107   \n",
       "407                                  -0.420562   \n",
       "408                                  -0.215110   \n",
       "409                                  -0.353737   \n",
       "410                                   0.044753   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1  \\\n",
       "0                                      3.863262   \n",
       "1                                      4.345114   \n",
       "2                                      2.533689   \n",
       "3                                      2.314067   \n",
       "4                                      1.603089   \n",
       "..                                          ...   \n",
       "406                                   -0.467565   \n",
       "407                                    0.030758   \n",
       "408                                    0.110519   \n",
       "409                                    0.230804   \n",
       "410                                    0.566531   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0  Dora  Piemonte_Nord  \\\n",
       "0                                    -0.551685     1              0   \n",
       "1                                     0.256218     1              0   \n",
       "2                                     0.029187     1              0   \n",
       "3                                     0.023661     1              0   \n",
       "4                                     0.376389     1              0   \n",
       "..                                         ...   ...            ...   \n",
       "406                                   1.427917     0              0   \n",
       "407                                   0.760111     0              0   \n",
       "408                                   0.315694     0              0   \n",
       "409                                  -0.971253     0              0   \n",
       "410                                  -1.460435     0              0   \n",
       "\n",
       "     Piemonte_Sud  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "406             1  \n",
       "407             1  \n",
       "408             1  \n",
       "409             1  \n",
       "410             1  \n",
       "\n",
       "[1233 rows x 18 columns]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "06181670",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "71eb99d6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6392008270590532\n",
      "-0.4196218844269948\n",
      "-0.49841482385224056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "c8b24f47",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_12w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_24w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_1</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_0_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.958059</td>\n",
       "      <td>-1.692206</td>\n",
       "      <td>-0.181114</td>\n",
       "      <td>-1.852227</td>\n",
       "      <td>-1.694637</td>\n",
       "      <td>-0.483868</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>-0.070058</td>\n",
       "      <td>-0.705198</td>\n",
       "      <td>-0.039471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.939769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.863262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064877</td>\n",
       "      <td>-0.279226</td>\n",
       "      <td>0.886182</td>\n",
       "      <td>-0.351196</td>\n",
       "      <td>0.267105</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>1.141736</td>\n",
       "      <td>0.669777</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>0.697310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.431148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.345114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.002116</td>\n",
       "      <td>-1.256740</td>\n",
       "      <td>0.223731</td>\n",
       "      <td>-2.234919</td>\n",
       "      <td>-1.713098</td>\n",
       "      <td>-0.898083</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>-0.312340</td>\n",
       "      <td>0.527444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.348554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.533689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.601101</td>\n",
       "      <td>-0.825053</td>\n",
       "      <td>0.383765</td>\n",
       "      <td>-1.590347</td>\n",
       "      <td>-0.953714</td>\n",
       "      <td>0.358463</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>0.245062</td>\n",
       "      <td>-0.434823</td>\n",
       "      <td>0.271867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.282061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.314067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.789653</td>\n",
       "      <td>-1.182962</td>\n",
       "      <td>0.295643</td>\n",
       "      <td>-1.665547</td>\n",
       "      <td>-1.374058</td>\n",
       "      <td>-0.555381</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.468525</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>0.537510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.836693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.603089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.807565</td>\n",
       "      <td>1.079275</td>\n",
       "      <td>-0.712766</td>\n",
       "      <td>1.021359</td>\n",
       "      <td>0.953999</td>\n",
       "      <td>0.862196</td>\n",
       "      <td>-0.938846</td>\n",
       "      <td>0.949782</td>\n",
       "      <td>1.346423</td>\n",
       "      <td>0.952736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.767792</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.476107</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.467565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.427917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1.020805</td>\n",
       "      <td>0.749908</td>\n",
       "      <td>-0.597343</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0.900047</td>\n",
       "      <td>-0.160042</td>\n",
       "      <td>-0.559070</td>\n",
       "      <td>0.569543</td>\n",
       "      <td>0.509539</td>\n",
       "      <td>0.579810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482430</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.420562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.760111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.910086</td>\n",
       "      <td>0.754701</td>\n",
       "      <td>-0.152386</td>\n",
       "      <td>0.925106</td>\n",
       "      <td>0.802985</td>\n",
       "      <td>0.528382</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>0.111790</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>0.086513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396456</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.215110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.155479</td>\n",
       "      <td>-0.396304</td>\n",
       "      <td>0.610253</td>\n",
       "      <td>0.441811</td>\n",
       "      <td>-2.715411</td>\n",
       "      <td>-0.253229</td>\n",
       "      <td>-1.115423</td>\n",
       "      <td>-1.353830</td>\n",
       "      <td>-1.099133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.311937</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.353737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230804</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.971253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.182408</td>\n",
       "      <td>0.098752</td>\n",
       "      <td>0.173050</td>\n",
       "      <td>0.674977</td>\n",
       "      <td>0.536299</td>\n",
       "      <td>0.147712</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>-1.606865</td>\n",
       "      <td>-1.553763</td>\n",
       "      <td>-1.579153</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.460435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows  63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dora_cyclostationary_mean_tg_4w_1  Dora_cyclostationary_mean_tg_12w_0  \\\n",
       "0                            -0.958059                           -1.692206   \n",
       "1                             0.064877                           -0.279226   \n",
       "2                            -1.002116                           -1.256740   \n",
       "3                            -0.601101                           -0.825053   \n",
       "4                            -0.789653                           -1.182962   \n",
       "..                                 ...                                 ...   \n",
       "406                           0.807565                            1.079275   \n",
       "407                           1.020805                            0.749908   \n",
       "408                           0.910086                            0.754701   \n",
       "409                           0.237759                            0.155479   \n",
       "410                          -0.182408                            0.098752   \n",
       "\n",
       "     Dora_cyclostationary_mean_rr_4w_0  Dora_cyclostationary_mean_tg_24w_1  \\\n",
       "0                            -0.181114                           -1.852227   \n",
       "1                             0.886182                           -0.351196   \n",
       "2                             0.223731                           -2.234919   \n",
       "3                             0.383765                           -1.590347   \n",
       "4                             0.295643                           -1.665547   \n",
       "..                                 ...                                 ...   \n",
       "406                          -0.712766                            1.021359   \n",
       "407                          -0.597343                            1.000397   \n",
       "408                          -0.152386                            0.925106   \n",
       "409                          -0.396304                            0.610253   \n",
       "410                           0.173050                            0.674977   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_24w_2  \\\n",
       "0                             -1.694637   \n",
       "1                              0.267105   \n",
       "2                             -1.713098   \n",
       "3                             -0.953714   \n",
       "4                             -1.374058   \n",
       "..                                  ...   \n",
       "406                            0.953999   \n",
       "407                            0.900047   \n",
       "408                            0.802985   \n",
       "409                            0.441811   \n",
       "410                            0.536299   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_3  \\\n",
       "0                                  -0.483868   \n",
       "1                                   0.673096   \n",
       "2                                  -0.898083   \n",
       "3                                   0.358463   \n",
       "4                                  -0.555381   \n",
       "..                                       ...   \n",
       "406                                 0.862196   \n",
       "407                                -0.160042   \n",
       "408                                 0.528382   \n",
       "409                                -2.715411   \n",
       "410                                 0.147712   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                      0.531161   \n",
       "1                                      1.141736   \n",
       "2                                      0.600533   \n",
       "3                                      0.613627   \n",
       "4                                      0.408259   \n",
       "..                                          ...   \n",
       "406                                   -0.938846   \n",
       "407                                   -0.559070   \n",
       "408                                   -0.113738   \n",
       "409                                   -0.253229   \n",
       "410                                    0.301057   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_1  \\\n",
       "0                                     -0.070058   \n",
       "1                                      0.669777   \n",
       "2                                      0.518292   \n",
       "3                                      0.245062   \n",
       "4                                      0.468525   \n",
       "..                                          ...   \n",
       "406                                    0.949782   \n",
       "407                                    0.569543   \n",
       "408                                    0.111790   \n",
       "409                                   -1.115423   \n",
       "410                                   -1.606865   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_3  \\\n",
       "0                                     -0.705198   \n",
       "1                                     -0.040533   \n",
       "2                                     -0.312340   \n",
       "3                                     -0.434823   \n",
       "4                                     -0.286705   \n",
       "..                                          ...   \n",
       "406                                    1.346423   \n",
       "407                                    0.509539   \n",
       "408                                    0.236097   \n",
       "409                                   -1.353830   \n",
       "410                                   -1.553763   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_4  ...  \\\n",
       "0                                     -0.039471  ...   \n",
       "1                                      0.697310  ...   \n",
       "2                                      0.527444  ...   \n",
       "3                                      0.271867  ...   \n",
       "4                                      0.537510  ...   \n",
       "..                                          ...  ...   \n",
       "406                                    0.952736  ...   \n",
       "407                                    0.579810  ...   \n",
       "408                                    0.086513  ...   \n",
       "409                                   -1.099133  ...   \n",
       "410                                   -1.579153  ...   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_0_Piemonte_Sud  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.767792         \n",
       "407                                          -0.482430         \n",
       "408                                          -0.396456         \n",
       "409                                          -0.311937         \n",
       "410                                          -0.130149         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0_Dora  \\\n",
       "0                                          1.939769   \n",
       "1                                          2.431148   \n",
       "2                                          1.348554   \n",
       "3                                          1.282061   \n",
       "4                                          0.836693   \n",
       "..                                              ...   \n",
       "406                                       -0.000000   \n",
       "407                                       -0.000000   \n",
       "408                                       -0.000000   \n",
       "409                                       -0.000000   \n",
       "410                                        0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Nord  \\\n",
       "0                                                  0.0         \n",
       "1                                                  0.0         \n",
       "2                                                  0.0         \n",
       "3                                                  0.0         \n",
       "4                                                  0.0         \n",
       "..                                                 ...         \n",
       "406                                               -0.0         \n",
       "407                                               -0.0         \n",
       "408                                               -0.0         \n",
       "409                                               -0.0         \n",
       "410                                                0.0         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Sud  \\\n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                             0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                          -0.476107        \n",
       "407                                          -0.420562        \n",
       "408                                          -0.215110        \n",
       "409                                          -0.353737        \n",
       "410                                           0.044753        \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1_Dora  \\\n",
       "0                                           3.863262   \n",
       "1                                           4.345114   \n",
       "2                                           2.533689   \n",
       "3                                           2.314067   \n",
       "4                                           1.603089   \n",
       "..                                               ...   \n",
       "406                                        -0.000000   \n",
       "407                                         0.000000   \n",
       "408                                         0.000000   \n",
       "409                                         0.000000   \n",
       "410                                         0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Nord  \\\n",
       "0                                                  0.0          \n",
       "1                                                  0.0          \n",
       "2                                                  0.0          \n",
       "3                                                  0.0          \n",
       "4                                                  0.0          \n",
       "..                                                 ...          \n",
       "406                                               -0.0          \n",
       "407                                                0.0          \n",
       "408                                                0.0          \n",
       "409                                                0.0          \n",
       "410                                                0.0          \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Sud  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.467565         \n",
       "407                                           0.030758         \n",
       "408                                           0.110519         \n",
       "409                                           0.230804         \n",
       "410                                           0.566531         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0_Dora  \\\n",
       "0                                         -0.551685   \n",
       "1                                          0.256218   \n",
       "2                                          0.029187   \n",
       "3                                          0.023661   \n",
       "4                                          0.376389   \n",
       "..                                              ...   \n",
       "406                                        0.000000   \n",
       "407                                        0.000000   \n",
       "408                                        0.000000   \n",
       "409                                       -0.000000   \n",
       "410                                       -0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Nord  \\\n",
       "0                                                 -0.0         \n",
       "1                                                  0.0         \n",
       "2                                                  0.0         \n",
       "3                                                  0.0         \n",
       "4                                                  0.0         \n",
       "..                                                 ...         \n",
       "406                                                0.0         \n",
       "407                                                0.0         \n",
       "408                                                0.0         \n",
       "409                                               -0.0         \n",
       "410                                               -0.0         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Sud  \n",
       "0                                            -0.000000       \n",
       "1                                             0.000000       \n",
       "2                                             0.000000       \n",
       "3                                             0.000000       \n",
       "4                                             0.000000       \n",
       "..                                                 ...       \n",
       "406                                           1.427917       \n",
       "407                                           0.760111       \n",
       "408                                           0.315694       \n",
       "409                                          -0.971253       \n",
       "410                                          -1.460435       \n",
       "\n",
       "[1233 rows x 63 columns]"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        clusterdf_train_withClass[clusterdf_train_withClass.columns[i]+'_'+j] = clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_val_withClass[clusterdf_val_withClass.columns[i]+'_'+j] = clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_test_withClass[clusterdf_test_withClass.columns[i]+'_'+j] = clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "66540431",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4233289032849736\n",
      "-0.18216047822349557\n",
      "-0.3055385087801512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84096a5d",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Dora - Piemonte_Nord - Piemonte_Sud: CMI best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "32be3d47",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Dora', 'Piemonte_Nord', 'Piemonte_Sud']\n",
    "colnames = [x for x in best5_CMI_fulldf_train.columns if x.startswith('Dora') or x.startswith('Piemonte_Nord') or x.startswith('Piemonte_Sud')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((best5_CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((best5_CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((best5_CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "ad2802ad",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_12w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_24w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_1</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0</th>\n",
       "      <th>Dora</th>\n",
       "      <th>Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.958059</td>\n",
       "      <td>-1.692206</td>\n",
       "      <td>-0.181114</td>\n",
       "      <td>-1.852227</td>\n",
       "      <td>-1.694637</td>\n",
       "      <td>-0.483868</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>-0.070058</td>\n",
       "      <td>-0.705198</td>\n",
       "      <td>-0.039471</td>\n",
       "      <td>-0.449672</td>\n",
       "      <td>3.146477</td>\n",
       "      <td>1.939769</td>\n",
       "      <td>3.863262</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064877</td>\n",
       "      <td>-0.279226</td>\n",
       "      <td>0.886182</td>\n",
       "      <td>-0.351196</td>\n",
       "      <td>0.267105</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>1.141736</td>\n",
       "      <td>0.669777</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>0.697310</td>\n",
       "      <td>0.880344</td>\n",
       "      <td>3.822355</td>\n",
       "      <td>2.431148</td>\n",
       "      <td>4.345114</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.002116</td>\n",
       "      <td>-1.256740</td>\n",
       "      <td>0.223731</td>\n",
       "      <td>-2.234919</td>\n",
       "      <td>-1.713098</td>\n",
       "      <td>-0.898083</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>-0.312340</td>\n",
       "      <td>0.527444</td>\n",
       "      <td>-0.833249</td>\n",
       "      <td>2.115109</td>\n",
       "      <td>1.348554</td>\n",
       "      <td>2.533689</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.601101</td>\n",
       "      <td>-0.825053</td>\n",
       "      <td>0.383765</td>\n",
       "      <td>-1.590347</td>\n",
       "      <td>-0.953714</td>\n",
       "      <td>0.358463</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>0.245062</td>\n",
       "      <td>-0.434823</td>\n",
       "      <td>0.271867</td>\n",
       "      <td>0.865639</td>\n",
       "      <td>2.006293</td>\n",
       "      <td>1.282061</td>\n",
       "      <td>2.314067</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.789653</td>\n",
       "      <td>-1.182962</td>\n",
       "      <td>0.295643</td>\n",
       "      <td>-1.665547</td>\n",
       "      <td>-1.374058</td>\n",
       "      <td>-0.555381</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.468525</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>0.537510</td>\n",
       "      <td>-0.246418</td>\n",
       "      <td>1.307787</td>\n",
       "      <td>0.836693</td>\n",
       "      <td>1.603089</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.807565</td>\n",
       "      <td>1.079275</td>\n",
       "      <td>-0.712766</td>\n",
       "      <td>1.021359</td>\n",
       "      <td>0.953999</td>\n",
       "      <td>0.862196</td>\n",
       "      <td>-0.938846</td>\n",
       "      <td>0.949782</td>\n",
       "      <td>1.346423</td>\n",
       "      <td>0.952736</td>\n",
       "      <td>1.374448</td>\n",
       "      <td>-0.767792</td>\n",
       "      <td>-0.476107</td>\n",
       "      <td>-0.467565</td>\n",
       "      <td>1.427917</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1.020805</td>\n",
       "      <td>0.749908</td>\n",
       "      <td>-0.597343</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0.900047</td>\n",
       "      <td>-0.160042</td>\n",
       "      <td>-0.559070</td>\n",
       "      <td>0.569543</td>\n",
       "      <td>0.509539</td>\n",
       "      <td>0.579810</td>\n",
       "      <td>-0.119108</td>\n",
       "      <td>-0.482430</td>\n",
       "      <td>-0.420562</td>\n",
       "      <td>0.030758</td>\n",
       "      <td>0.760111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.910086</td>\n",
       "      <td>0.754701</td>\n",
       "      <td>-0.152386</td>\n",
       "      <td>0.925106</td>\n",
       "      <td>0.802985</td>\n",
       "      <td>0.528382</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>0.111790</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>0.086513</td>\n",
       "      <td>0.643035</td>\n",
       "      <td>-0.396456</td>\n",
       "      <td>-0.215110</td>\n",
       "      <td>0.110519</td>\n",
       "      <td>0.315694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.155479</td>\n",
       "      <td>-0.396304</td>\n",
       "      <td>0.610253</td>\n",
       "      <td>0.441811</td>\n",
       "      <td>-2.715411</td>\n",
       "      <td>-0.253229</td>\n",
       "      <td>-1.115423</td>\n",
       "      <td>-1.353830</td>\n",
       "      <td>-1.099133</td>\n",
       "      <td>-2.247923</td>\n",
       "      <td>-0.311937</td>\n",
       "      <td>-0.353737</td>\n",
       "      <td>0.230804</td>\n",
       "      <td>-0.971253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.182408</td>\n",
       "      <td>0.098752</td>\n",
       "      <td>0.173050</td>\n",
       "      <td>0.674977</td>\n",
       "      <td>0.536299</td>\n",
       "      <td>0.147712</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>-1.606865</td>\n",
       "      <td>-1.553763</td>\n",
       "      <td>-1.579153</td>\n",
       "      <td>-0.167457</td>\n",
       "      <td>-0.130149</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>-1.460435</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dora_cyclostationary_mean_tg_4w_1  Dora_cyclostationary_mean_tg_12w_0  \\\n",
       "0                            -0.958059                           -1.692206   \n",
       "1                             0.064877                           -0.279226   \n",
       "2                            -1.002116                           -1.256740   \n",
       "3                            -0.601101                           -0.825053   \n",
       "4                            -0.789653                           -1.182962   \n",
       "..                                 ...                                 ...   \n",
       "406                           0.807565                            1.079275   \n",
       "407                           1.020805                            0.749908   \n",
       "408                           0.910086                            0.754701   \n",
       "409                           0.237759                            0.155479   \n",
       "410                          -0.182408                            0.098752   \n",
       "\n",
       "     Dora_cyclostationary_mean_rr_4w_0  Dora_cyclostationary_mean_tg_24w_1  \\\n",
       "0                            -0.181114                           -1.852227   \n",
       "1                             0.886182                           -0.351196   \n",
       "2                             0.223731                           -2.234919   \n",
       "3                             0.383765                           -1.590347   \n",
       "4                             0.295643                           -1.665547   \n",
       "..                                 ...                                 ...   \n",
       "406                          -0.712766                            1.021359   \n",
       "407                          -0.597343                            1.000397   \n",
       "408                          -0.152386                            0.925106   \n",
       "409                          -0.396304                            0.610253   \n",
       "410                           0.173050                            0.674977   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_24w_2  \\\n",
       "0                             -1.694637   \n",
       "1                              0.267105   \n",
       "2                             -1.713098   \n",
       "3                             -0.953714   \n",
       "4                             -1.374058   \n",
       "..                                  ...   \n",
       "406                            0.953999   \n",
       "407                            0.900047   \n",
       "408                            0.802985   \n",
       "409                            0.441811   \n",
       "410                            0.536299   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_3  \\\n",
       "0                                  -0.483868   \n",
       "1                                   0.673096   \n",
       "2                                  -0.898083   \n",
       "3                                   0.358463   \n",
       "4                                  -0.555381   \n",
       "..                                       ...   \n",
       "406                                 0.862196   \n",
       "407                                -0.160042   \n",
       "408                                 0.528382   \n",
       "409                                -2.715411   \n",
       "410                                 0.147712   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                      0.531161   \n",
       "1                                      1.141736   \n",
       "2                                      0.600533   \n",
       "3                                      0.613627   \n",
       "4                                      0.408259   \n",
       "..                                          ...   \n",
       "406                                   -0.938846   \n",
       "407                                   -0.559070   \n",
       "408                                   -0.113738   \n",
       "409                                   -0.253229   \n",
       "410                                    0.301057   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_1  \\\n",
       "0                                     -0.070058   \n",
       "1                                      0.669777   \n",
       "2                                      0.518292   \n",
       "3                                      0.245062   \n",
       "4                                      0.468525   \n",
       "..                                          ...   \n",
       "406                                    0.949782   \n",
       "407                                    0.569543   \n",
       "408                                    0.111790   \n",
       "409                                   -1.115423   \n",
       "410                                   -1.606865   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_3  \\\n",
       "0                                     -0.705198   \n",
       "1                                     -0.040533   \n",
       "2                                     -0.312340   \n",
       "3                                     -0.434823   \n",
       "4                                     -0.286705   \n",
       "..                                          ...   \n",
       "406                                    1.346423   \n",
       "407                                    0.509539   \n",
       "408                                    0.236097   \n",
       "409                                   -1.353830   \n",
       "410                                   -1.553763   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                     -0.039471   \n",
       "1                                      0.697310   \n",
       "2                                      0.527444   \n",
       "3                                      0.271867   \n",
       "4                                      0.537510   \n",
       "..                                          ...   \n",
       "406                                    0.952736   \n",
       "407                                    0.579810   \n",
       "408                                    0.086513   \n",
       "409                                   -1.099133   \n",
       "410                                   -1.579153   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_0  \\\n",
       "0                                 -0.449672   \n",
       "1                                  0.880344   \n",
       "2                                 -0.833249   \n",
       "3                                  0.865639   \n",
       "4                                 -0.246418   \n",
       "..                                      ...   \n",
       "406                                1.374448   \n",
       "407                               -0.119108   \n",
       "408                                0.643035   \n",
       "409                               -2.247923   \n",
       "410                               -0.167457   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_0  \\\n",
       "0                                      3.146477   \n",
       "1                                      3.822355   \n",
       "2                                      2.115109   \n",
       "3                                      2.006293   \n",
       "4                                      1.307787   \n",
       "..                                          ...   \n",
       "406                                   -0.767792   \n",
       "407                                   -0.482430   \n",
       "408                                   -0.396456   \n",
       "409                                   -0.311937   \n",
       "410                                   -0.130149   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                     1.939769   \n",
       "1                                     2.431148   \n",
       "2                                     1.348554   \n",
       "3                                     1.282061   \n",
       "4                                     0.836693   \n",
       "..                                         ...   \n",
       "406                                  -0.476107   \n",
       "407                                  -0.420562   \n",
       "408                                  -0.215110   \n",
       "409                                  -0.353737   \n",
       "410                                   0.044753   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1  \\\n",
       "0                                      3.863262   \n",
       "1                                      4.345114   \n",
       "2                                      2.533689   \n",
       "3                                      2.314067   \n",
       "4                                      1.603089   \n",
       "..                                          ...   \n",
       "406                                   -0.467565   \n",
       "407                                    0.030758   \n",
       "408                                    0.110519   \n",
       "409                                    0.230804   \n",
       "410                                    0.566531   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0  Dora  Piemonte_Nord  \\\n",
       "0                                    -0.551685     1              0   \n",
       "1                                     0.256218     1              0   \n",
       "2                                     0.029187     1              0   \n",
       "3                                     0.023661     1              0   \n",
       "4                                     0.376389     1              0   \n",
       "..                                         ...   ...            ...   \n",
       "406                                   1.427917     0              0   \n",
       "407                                   0.760111     0              0   \n",
       "408                                   0.315694     0              0   \n",
       "409                                  -0.971253     0              0   \n",
       "410                                  -1.460435     0              0   \n",
       "\n",
       "     Piemonte_Sud  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "..            ...  \n",
       "406             1  \n",
       "407             1  \n",
       "408             1  \n",
       "409             1  \n",
       "410             1  \n",
       "\n",
       "[1233 rows x 18 columns]"
      ]
     },
     "execution_count": 560,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "15a20e81",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "cbcadb84",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6392008270590532\n",
      "-0.4196218844269948\n",
      "-0.49841482385224056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "47a4cece",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.01504430512315813\n",
      "0.13117472371892347\n",
      "0.05676185616132012\n",
      "-0.03601767681354562\n",
      "-0.005255834060018172\n",
      "-0.0031161954632632494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but Ridge was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but Lasso was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### Ridge and Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model_DPNPS_ridge = Ridge(alpha=1000.0)\n",
    "model_DPNPS_ridge.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ridge.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ridge.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ridge.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n",
    "\n",
    "### Ridge and Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model_DPNPS_Lasso = Lasso(alpha=1.0)\n",
    "model_DPNPS_Lasso.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_Lasso.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_Lasso.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_Lasso.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "f2ccda3e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02711149, -0.03885853,  0.07353019,  0.07686813,  0.02255927,\n",
       "        -0.09960836,  0.0584774 , -0.03485143, -0.06731712, -0.02067332,\n",
       "        -0.06599726,  0.09936724, -0.00150094, -0.02554435, -0.0359069 ,\n",
       "        -0.01003827,  0.0052231 ,  0.00481518]])"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_DPNPS_ridge.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "b1ea21d4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2d0f140d0>]"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(targets_df_test['Piemonte_Sud'].values)\n",
    "plt.plot(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "ba9a9bcf",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dora_cyclostationary_mean_tg_4w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_12w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_24w_1</th>\n",
       "      <th>Dora_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_1</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_0_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0_Dora</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.958059</td>\n",
       "      <td>-1.692206</td>\n",
       "      <td>-0.181114</td>\n",
       "      <td>-1.852227</td>\n",
       "      <td>-1.694637</td>\n",
       "      <td>-0.483868</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>-0.070058</td>\n",
       "      <td>-0.705198</td>\n",
       "      <td>-0.039471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.939769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.863262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064877</td>\n",
       "      <td>-0.279226</td>\n",
       "      <td>0.886182</td>\n",
       "      <td>-0.351196</td>\n",
       "      <td>0.267105</td>\n",
       "      <td>0.673096</td>\n",
       "      <td>1.141736</td>\n",
       "      <td>0.669777</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>0.697310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.431148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.345114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.002116</td>\n",
       "      <td>-1.256740</td>\n",
       "      <td>0.223731</td>\n",
       "      <td>-2.234919</td>\n",
       "      <td>-1.713098</td>\n",
       "      <td>-0.898083</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>-0.312340</td>\n",
       "      <td>0.527444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.348554</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.533689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.601101</td>\n",
       "      <td>-0.825053</td>\n",
       "      <td>0.383765</td>\n",
       "      <td>-1.590347</td>\n",
       "      <td>-0.953714</td>\n",
       "      <td>0.358463</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>0.245062</td>\n",
       "      <td>-0.434823</td>\n",
       "      <td>0.271867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.282061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.314067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.789653</td>\n",
       "      <td>-1.182962</td>\n",
       "      <td>0.295643</td>\n",
       "      <td>-1.665547</td>\n",
       "      <td>-1.374058</td>\n",
       "      <td>-0.555381</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.468525</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>0.537510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.836693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.603089</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.807565</td>\n",
       "      <td>1.079275</td>\n",
       "      <td>-0.712766</td>\n",
       "      <td>1.021359</td>\n",
       "      <td>0.953999</td>\n",
       "      <td>0.862196</td>\n",
       "      <td>-0.938846</td>\n",
       "      <td>0.949782</td>\n",
       "      <td>1.346423</td>\n",
       "      <td>0.952736</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.767792</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.476107</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.467565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.427917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1.020805</td>\n",
       "      <td>0.749908</td>\n",
       "      <td>-0.597343</td>\n",
       "      <td>1.000397</td>\n",
       "      <td>0.900047</td>\n",
       "      <td>-0.160042</td>\n",
       "      <td>-0.559070</td>\n",
       "      <td>0.569543</td>\n",
       "      <td>0.509539</td>\n",
       "      <td>0.579810</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482430</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.420562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.760111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.910086</td>\n",
       "      <td>0.754701</td>\n",
       "      <td>-0.152386</td>\n",
       "      <td>0.925106</td>\n",
       "      <td>0.802985</td>\n",
       "      <td>0.528382</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>0.111790</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>0.086513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.396456</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.215110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.110519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.315694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>0.237759</td>\n",
       "      <td>0.155479</td>\n",
       "      <td>-0.396304</td>\n",
       "      <td>0.610253</td>\n",
       "      <td>0.441811</td>\n",
       "      <td>-2.715411</td>\n",
       "      <td>-0.253229</td>\n",
       "      <td>-1.115423</td>\n",
       "      <td>-1.353830</td>\n",
       "      <td>-1.099133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.311937</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.353737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230804</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.971253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-0.182408</td>\n",
       "      <td>0.098752</td>\n",
       "      <td>0.173050</td>\n",
       "      <td>0.674977</td>\n",
       "      <td>0.536299</td>\n",
       "      <td>0.147712</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>-1.606865</td>\n",
       "      <td>-1.553763</td>\n",
       "      <td>-1.579153</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.460435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1233 rows  63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dora_cyclostationary_mean_tg_4w_1  Dora_cyclostationary_mean_tg_12w_0  \\\n",
       "0                            -0.958059                           -1.692206   \n",
       "1                             0.064877                           -0.279226   \n",
       "2                            -1.002116                           -1.256740   \n",
       "3                            -0.601101                           -0.825053   \n",
       "4                            -0.789653                           -1.182962   \n",
       "..                                 ...                                 ...   \n",
       "406                           0.807565                            1.079275   \n",
       "407                           1.020805                            0.749908   \n",
       "408                           0.910086                            0.754701   \n",
       "409                           0.237759                            0.155479   \n",
       "410                          -0.182408                            0.098752   \n",
       "\n",
       "     Dora_cyclostationary_mean_rr_4w_0  Dora_cyclostationary_mean_tg_24w_1  \\\n",
       "0                            -0.181114                           -1.852227   \n",
       "1                             0.886182                           -0.351196   \n",
       "2                             0.223731                           -2.234919   \n",
       "3                             0.383765                           -1.590347   \n",
       "4                             0.295643                           -1.665547   \n",
       "..                                 ...                                 ...   \n",
       "406                          -0.712766                            1.021359   \n",
       "407                          -0.597343                            1.000397   \n",
       "408                          -0.152386                            0.925106   \n",
       "409                          -0.396304                            0.610253   \n",
       "410                           0.173050                            0.674977   \n",
       "\n",
       "     Dora_cyclostationary_mean_tg_24w_2  \\\n",
       "0                             -1.694637   \n",
       "1                              0.267105   \n",
       "2                             -1.713098   \n",
       "3                             -0.953714   \n",
       "4                             -1.374058   \n",
       "..                                  ...   \n",
       "406                            0.953999   \n",
       "407                            0.900047   \n",
       "408                            0.802985   \n",
       "409                            0.441811   \n",
       "410                            0.536299   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_3  \\\n",
       "0                                  -0.483868   \n",
       "1                                   0.673096   \n",
       "2                                  -0.898083   \n",
       "3                                   0.358463   \n",
       "4                                  -0.555381   \n",
       "..                                       ...   \n",
       "406                                 0.862196   \n",
       "407                                -0.160042   \n",
       "408                                 0.528382   \n",
       "409                                -2.715411   \n",
       "410                                 0.147712   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                      0.531161   \n",
       "1                                      1.141736   \n",
       "2                                      0.600533   \n",
       "3                                      0.613627   \n",
       "4                                      0.408259   \n",
       "..                                          ...   \n",
       "406                                   -0.938846   \n",
       "407                                   -0.559070   \n",
       "408                                   -0.113738   \n",
       "409                                   -0.253229   \n",
       "410                                    0.301057   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_1  \\\n",
       "0                                     -0.070058   \n",
       "1                                      0.669777   \n",
       "2                                      0.518292   \n",
       "3                                      0.245062   \n",
       "4                                      0.468525   \n",
       "..                                          ...   \n",
       "406                                    0.949782   \n",
       "407                                    0.569543   \n",
       "408                                    0.111790   \n",
       "409                                   -1.115423   \n",
       "410                                   -1.606865   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_3  \\\n",
       "0                                     -0.705198   \n",
       "1                                     -0.040533   \n",
       "2                                     -0.312340   \n",
       "3                                     -0.434823   \n",
       "4                                     -0.286705   \n",
       "..                                          ...   \n",
       "406                                    1.346423   \n",
       "407                                    0.509539   \n",
       "408                                    0.236097   \n",
       "409                                   -1.353830   \n",
       "410                                   -1.553763   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_4  ...  \\\n",
       "0                                     -0.039471  ...   \n",
       "1                                      0.697310  ...   \n",
       "2                                      0.527444  ...   \n",
       "3                                      0.271867  ...   \n",
       "4                                      0.537510  ...   \n",
       "..                                          ...  ...   \n",
       "406                                    0.952736  ...   \n",
       "407                                    0.579810  ...   \n",
       "408                                    0.086513  ...   \n",
       "409                                   -1.099133  ...   \n",
       "410                                   -1.579153  ...   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_0_Piemonte_Sud  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.767792         \n",
       "407                                          -0.482430         \n",
       "408                                          -0.396456         \n",
       "409                                          -0.311937         \n",
       "410                                          -0.130149         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0_Dora  \\\n",
       "0                                          1.939769   \n",
       "1                                          2.431148   \n",
       "2                                          1.348554   \n",
       "3                                          1.282061   \n",
       "4                                          0.836693   \n",
       "..                                              ...   \n",
       "406                                       -0.000000   \n",
       "407                                       -0.000000   \n",
       "408                                       -0.000000   \n",
       "409                                       -0.000000   \n",
       "410                                        0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Nord  \\\n",
       "0                                                  0.0         \n",
       "1                                                  0.0         \n",
       "2                                                  0.0         \n",
       "3                                                  0.0         \n",
       "4                                                  0.0         \n",
       "..                                                 ...         \n",
       "406                                               -0.0         \n",
       "407                                               -0.0         \n",
       "408                                               -0.0         \n",
       "409                                               -0.0         \n",
       "410                                                0.0         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Sud  \\\n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                             0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                          -0.476107        \n",
       "407                                          -0.420562        \n",
       "408                                          -0.215110        \n",
       "409                                          -0.353737        \n",
       "410                                           0.044753        \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1_Dora  \\\n",
       "0                                           3.863262   \n",
       "1                                           4.345114   \n",
       "2                                           2.533689   \n",
       "3                                           2.314067   \n",
       "4                                           1.603089   \n",
       "..                                               ...   \n",
       "406                                        -0.000000   \n",
       "407                                         0.000000   \n",
       "408                                         0.000000   \n",
       "409                                         0.000000   \n",
       "410                                         0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Nord  \\\n",
       "0                                                  0.0          \n",
       "1                                                  0.0          \n",
       "2                                                  0.0          \n",
       "3                                                  0.0          \n",
       "4                                                  0.0          \n",
       "..                                                 ...          \n",
       "406                                               -0.0          \n",
       "407                                                0.0          \n",
       "408                                                0.0          \n",
       "409                                                0.0          \n",
       "410                                                0.0          \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Sud  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.467565         \n",
       "407                                           0.030758         \n",
       "408                                           0.110519         \n",
       "409                                           0.230804         \n",
       "410                                           0.566531         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0_Dora  \\\n",
       "0                                         -0.551685   \n",
       "1                                          0.256218   \n",
       "2                                          0.029187   \n",
       "3                                          0.023661   \n",
       "4                                          0.376389   \n",
       "..                                              ...   \n",
       "406                                        0.000000   \n",
       "407                                        0.000000   \n",
       "408                                        0.000000   \n",
       "409                                       -0.000000   \n",
       "410                                       -0.000000   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Nord  \\\n",
       "0                                                 -0.0         \n",
       "1                                                  0.0         \n",
       "2                                                  0.0         \n",
       "3                                                  0.0         \n",
       "4                                                  0.0         \n",
       "..                                                 ...         \n",
       "406                                                0.0         \n",
       "407                                                0.0         \n",
       "408                                                0.0         \n",
       "409                                               -0.0         \n",
       "410                                               -0.0         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Sud  \n",
       "0                                            -0.000000       \n",
       "1                                             0.000000       \n",
       "2                                             0.000000       \n",
       "3                                             0.000000       \n",
       "4                                             0.000000       \n",
       "..                                                 ...       \n",
       "406                                           1.427917       \n",
       "407                                           0.760111       \n",
       "408                                           0.315694       \n",
       "409                                          -0.971253       \n",
       "410                                          -1.460435       \n",
       "\n",
       "[1233 rows x 63 columns]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        clusterdf_train_withClass[clusterdf_train_withClass.columns[i]+'_'+j] = clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_val_withClass[clusterdf_val_withClass.columns[i]+'_'+j] = clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_test_withClass[clusterdf_test_withClass.columns[i]+'_'+j] = clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "dde60360",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4233289032849736\n",
      "-0.18216047822349557\n",
      "-0.3055385087801512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Dora==1].values)\n",
    "print(r2_score(targets_df_test['Dora'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a00950",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Piemonte_Nord - Piemonte_Sud: CMI best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "1207333f",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Piemonte_Nord', 'Piemonte_Sud']\n",
    "colnames = [x for x in best5_CMI_fulldf_train.columns if x.startswith('Piemonte_Nord') or x.startswith('Piemonte_Sud')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((best5_CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((best5_CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((best5_CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "588c324b",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_1</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0</th>\n",
       "      <th>Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.483868</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>-0.070058</td>\n",
       "      <td>-0.705198</td>\n",
       "      <td>-0.039471</td>\n",
       "      <td>-0.449672</td>\n",
       "      <td>3.146477</td>\n",
       "      <td>1.939769</td>\n",
       "      <td>3.863262</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.673096</td>\n",
       "      <td>1.141736</td>\n",
       "      <td>0.669777</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>0.697310</td>\n",
       "      <td>0.880344</td>\n",
       "      <td>3.822355</td>\n",
       "      <td>2.431148</td>\n",
       "      <td>4.345114</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.898083</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>-0.312340</td>\n",
       "      <td>0.527444</td>\n",
       "      <td>-0.833249</td>\n",
       "      <td>2.115109</td>\n",
       "      <td>1.348554</td>\n",
       "      <td>2.533689</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.358463</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>0.245062</td>\n",
       "      <td>-0.434823</td>\n",
       "      <td>0.271867</td>\n",
       "      <td>0.865639</td>\n",
       "      <td>2.006293</td>\n",
       "      <td>1.282061</td>\n",
       "      <td>2.314067</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.555381</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.468525</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>0.537510</td>\n",
       "      <td>-0.246418</td>\n",
       "      <td>1.307787</td>\n",
       "      <td>0.836693</td>\n",
       "      <td>1.603089</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.862196</td>\n",
       "      <td>-0.938846</td>\n",
       "      <td>0.949782</td>\n",
       "      <td>1.346423</td>\n",
       "      <td>0.952736</td>\n",
       "      <td>1.374448</td>\n",
       "      <td>-0.767792</td>\n",
       "      <td>-0.476107</td>\n",
       "      <td>-0.467565</td>\n",
       "      <td>1.427917</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.160042</td>\n",
       "      <td>-0.559070</td>\n",
       "      <td>0.569543</td>\n",
       "      <td>0.509539</td>\n",
       "      <td>0.579810</td>\n",
       "      <td>-0.119108</td>\n",
       "      <td>-0.482430</td>\n",
       "      <td>-0.420562</td>\n",
       "      <td>0.030758</td>\n",
       "      <td>0.760111</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.528382</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>0.111790</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>0.086513</td>\n",
       "      <td>0.643035</td>\n",
       "      <td>-0.396456</td>\n",
       "      <td>-0.215110</td>\n",
       "      <td>0.110519</td>\n",
       "      <td>0.315694</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-2.715411</td>\n",
       "      <td>-0.253229</td>\n",
       "      <td>-1.115423</td>\n",
       "      <td>-1.353830</td>\n",
       "      <td>-1.099133</td>\n",
       "      <td>-2.247923</td>\n",
       "      <td>-0.311937</td>\n",
       "      <td>-0.353737</td>\n",
       "      <td>0.230804</td>\n",
       "      <td>-0.971253</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0.147712</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>-1.606865</td>\n",
       "      <td>-1.553763</td>\n",
       "      <td>-1.579153</td>\n",
       "      <td>-0.167457</td>\n",
       "      <td>-0.130149</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>-1.460435</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Piemonte_Nord_cyclostationary_mean_tg_3  \\\n",
       "0                                  -0.483868   \n",
       "1                                   0.673096   \n",
       "2                                  -0.898083   \n",
       "3                                   0.358463   \n",
       "4                                  -0.555381   \n",
       "..                                       ...   \n",
       "406                                 0.862196   \n",
       "407                                -0.160042   \n",
       "408                                 0.528382   \n",
       "409                                -2.715411   \n",
       "410                                 0.147712   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                      0.531161   \n",
       "1                                      1.141736   \n",
       "2                                      0.600533   \n",
       "3                                      0.613627   \n",
       "4                                      0.408259   \n",
       "..                                          ...   \n",
       "406                                   -0.938846   \n",
       "407                                   -0.559070   \n",
       "408                                   -0.113738   \n",
       "409                                   -0.253229   \n",
       "410                                    0.301057   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_1  \\\n",
       "0                                     -0.070058   \n",
       "1                                      0.669777   \n",
       "2                                      0.518292   \n",
       "3                                      0.245062   \n",
       "4                                      0.468525   \n",
       "..                                          ...   \n",
       "406                                    0.949782   \n",
       "407                                    0.569543   \n",
       "408                                    0.111790   \n",
       "409                                   -1.115423   \n",
       "410                                   -1.606865   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_3  \\\n",
       "0                                     -0.705198   \n",
       "1                                     -0.040533   \n",
       "2                                     -0.312340   \n",
       "3                                     -0.434823   \n",
       "4                                     -0.286705   \n",
       "..                                          ...   \n",
       "406                                    1.346423   \n",
       "407                                    0.509539   \n",
       "408                                    0.236097   \n",
       "409                                   -1.353830   \n",
       "410                                   -1.553763   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                     -0.039471   \n",
       "1                                      0.697310   \n",
       "2                                      0.527444   \n",
       "3                                      0.271867   \n",
       "4                                      0.537510   \n",
       "..                                          ...   \n",
       "406                                    0.952736   \n",
       "407                                    0.579810   \n",
       "408                                    0.086513   \n",
       "409                                   -1.099133   \n",
       "410                                   -1.579153   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_0  \\\n",
       "0                                 -0.449672   \n",
       "1                                  0.880344   \n",
       "2                                 -0.833249   \n",
       "3                                  0.865639   \n",
       "4                                 -0.246418   \n",
       "..                                      ...   \n",
       "406                                1.374448   \n",
       "407                               -0.119108   \n",
       "408                                0.643035   \n",
       "409                               -2.247923   \n",
       "410                               -0.167457   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_0  \\\n",
       "0                                      3.146477   \n",
       "1                                      3.822355   \n",
       "2                                      2.115109   \n",
       "3                                      2.006293   \n",
       "4                                      1.307787   \n",
       "..                                          ...   \n",
       "406                                   -0.767792   \n",
       "407                                   -0.482430   \n",
       "408                                   -0.396456   \n",
       "409                                   -0.311937   \n",
       "410                                   -0.130149   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                     1.939769   \n",
       "1                                     2.431148   \n",
       "2                                     1.348554   \n",
       "3                                     1.282061   \n",
       "4                                     0.836693   \n",
       "..                                         ...   \n",
       "406                                  -0.476107   \n",
       "407                                  -0.420562   \n",
       "408                                  -0.215110   \n",
       "409                                  -0.353737   \n",
       "410                                   0.044753   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1  \\\n",
       "0                                      3.863262   \n",
       "1                                      4.345114   \n",
       "2                                      2.533689   \n",
       "3                                      2.314067   \n",
       "4                                      1.603089   \n",
       "..                                          ...   \n",
       "406                                   -0.467565   \n",
       "407                                    0.030758   \n",
       "408                                    0.110519   \n",
       "409                                    0.230804   \n",
       "410                                    0.566531   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0  Piemonte_Nord  Piemonte_Sud  \n",
       "0                                    -0.551685              1             0  \n",
       "1                                     0.256218              1             0  \n",
       "2                                     0.029187              1             0  \n",
       "3                                     0.023661              1             0  \n",
       "4                                     0.376389              1             0  \n",
       "..                                         ...            ...           ...  \n",
       "406                                   1.427917              0             1  \n",
       "407                                   0.760111              0             1  \n",
       "408                                   0.315694              0             1  \n",
       "409                                  -0.971253              0             1  \n",
       "410                                  -1.460435              0             1  \n",
       "\n",
       "[822 rows x 12 columns]"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "28cd60f2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "8d88b20f",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.146332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.371173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.379474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.099118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.292244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>-0.021388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>-0.086330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>0.576347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>0.146632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>-0.818877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0   -1.146332\n",
       "1    0.371173\n",
       "2    0.379474\n",
       "3   -0.099118\n",
       "4   -0.292244\n",
       "..        ...\n",
       "817 -0.021388\n",
       "818 -0.086330\n",
       "819  0.576347\n",
       "820  0.146632\n",
       "821 -0.818877\n",
       "\n",
       "[822 rows x 1 columns]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_train_unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "id": "9fb82d0d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06977081725961665\n",
      "-0.01398677438947682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858ef598",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "06befe0a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_1</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Piemonte_Nord_cyclostationary_mean_tg_1w_4</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0</th>\n",
       "      <th>...</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_0_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_0_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_0_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_24w_0_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Sud</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.483868</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>-0.070058</td>\n",
       "      <td>-0.705198</td>\n",
       "      <td>-0.039471</td>\n",
       "      <td>-0.449672</td>\n",
       "      <td>3.146477</td>\n",
       "      <td>1.939769</td>\n",
       "      <td>3.863262</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.449672</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>3.146477</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.939769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.863262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.673096</td>\n",
       "      <td>1.141736</td>\n",
       "      <td>0.669777</td>\n",
       "      <td>-0.040533</td>\n",
       "      <td>0.697310</td>\n",
       "      <td>0.880344</td>\n",
       "      <td>3.822355</td>\n",
       "      <td>2.431148</td>\n",
       "      <td>4.345114</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>...</td>\n",
       "      <td>0.880344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.822355</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.431148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.345114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.898083</td>\n",
       "      <td>0.600533</td>\n",
       "      <td>0.518292</td>\n",
       "      <td>-0.312340</td>\n",
       "      <td>0.527444</td>\n",
       "      <td>-0.833249</td>\n",
       "      <td>2.115109</td>\n",
       "      <td>1.348554</td>\n",
       "      <td>2.533689</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.833249</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>2.115109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.348554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.533689</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.358463</td>\n",
       "      <td>0.613627</td>\n",
       "      <td>0.245062</td>\n",
       "      <td>-0.434823</td>\n",
       "      <td>0.271867</td>\n",
       "      <td>0.865639</td>\n",
       "      <td>2.006293</td>\n",
       "      <td>1.282061</td>\n",
       "      <td>2.314067</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865639</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.006293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.282061</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.314067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.555381</td>\n",
       "      <td>0.408259</td>\n",
       "      <td>0.468525</td>\n",
       "      <td>-0.286705</td>\n",
       "      <td>0.537510</td>\n",
       "      <td>-0.246418</td>\n",
       "      <td>1.307787</td>\n",
       "      <td>0.836693</td>\n",
       "      <td>1.603089</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246418</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>1.307787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.836693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.603089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0.862196</td>\n",
       "      <td>-0.938846</td>\n",
       "      <td>0.949782</td>\n",
       "      <td>1.346423</td>\n",
       "      <td>0.952736</td>\n",
       "      <td>1.374448</td>\n",
       "      <td>-0.767792</td>\n",
       "      <td>-0.476107</td>\n",
       "      <td>-0.467565</td>\n",
       "      <td>1.427917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.374448</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.767792</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.476107</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.467565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.427917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-0.160042</td>\n",
       "      <td>-0.559070</td>\n",
       "      <td>0.569543</td>\n",
       "      <td>0.509539</td>\n",
       "      <td>0.579810</td>\n",
       "      <td>-0.119108</td>\n",
       "      <td>-0.482430</td>\n",
       "      <td>-0.420562</td>\n",
       "      <td>0.030758</td>\n",
       "      <td>0.760111</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.119108</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.482430</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.420562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.760111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.528382</td>\n",
       "      <td>-0.113738</td>\n",
       "      <td>0.111790</td>\n",
       "      <td>0.236097</td>\n",
       "      <td>0.086513</td>\n",
       "      <td>0.643035</td>\n",
       "      <td>-0.396456</td>\n",
       "      <td>-0.215110</td>\n",
       "      <td>0.110519</td>\n",
       "      <td>0.315694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.643035</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.396456</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.215110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.315694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-2.715411</td>\n",
       "      <td>-0.253229</td>\n",
       "      <td>-1.115423</td>\n",
       "      <td>-1.353830</td>\n",
       "      <td>-1.099133</td>\n",
       "      <td>-2.247923</td>\n",
       "      <td>-0.311937</td>\n",
       "      <td>-0.353737</td>\n",
       "      <td>0.230804</td>\n",
       "      <td>-0.971253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-2.247923</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.311937</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.353737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230804</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.971253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0.147712</td>\n",
       "      <td>0.301057</td>\n",
       "      <td>-1.606865</td>\n",
       "      <td>-1.553763</td>\n",
       "      <td>-1.579153</td>\n",
       "      <td>-0.167457</td>\n",
       "      <td>-0.130149</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>-1.460435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.167457</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.130149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044753</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566531</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-1.460435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Piemonte_Nord_cyclostationary_mean_tg_3  \\\n",
       "0                                  -0.483868   \n",
       "1                                   0.673096   \n",
       "2                                  -0.898083   \n",
       "3                                   0.358463   \n",
       "4                                  -0.555381   \n",
       "..                                       ...   \n",
       "406                                 0.862196   \n",
       "407                                -0.160042   \n",
       "408                                 0.528382   \n",
       "409                                -2.715411   \n",
       "410                                 0.147712   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_rr_4w_0  \\\n",
       "0                                      0.531161   \n",
       "1                                      1.141736   \n",
       "2                                      0.600533   \n",
       "3                                      0.613627   \n",
       "4                                      0.408259   \n",
       "..                                          ...   \n",
       "406                                   -0.938846   \n",
       "407                                   -0.559070   \n",
       "408                                   -0.113738   \n",
       "409                                   -0.253229   \n",
       "410                                    0.301057   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_1  \\\n",
       "0                                     -0.070058   \n",
       "1                                      0.669777   \n",
       "2                                      0.518292   \n",
       "3                                      0.245062   \n",
       "4                                      0.468525   \n",
       "..                                          ...   \n",
       "406                                    0.949782   \n",
       "407                                    0.569543   \n",
       "408                                    0.111790   \n",
       "409                                   -1.115423   \n",
       "410                                   -1.606865   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_3  \\\n",
       "0                                     -0.705198   \n",
       "1                                     -0.040533   \n",
       "2                                     -0.312340   \n",
       "3                                     -0.434823   \n",
       "4                                     -0.286705   \n",
       "..                                          ...   \n",
       "406                                    1.346423   \n",
       "407                                    0.509539   \n",
       "408                                    0.236097   \n",
       "409                                   -1.353830   \n",
       "410                                   -1.553763   \n",
       "\n",
       "     Piemonte_Nord_cyclostationary_mean_tg_1w_4  \\\n",
       "0                                     -0.039471   \n",
       "1                                      0.697310   \n",
       "2                                      0.527444   \n",
       "3                                      0.271867   \n",
       "4                                      0.537510   \n",
       "..                                          ...   \n",
       "406                                    0.952736   \n",
       "407                                    0.579810   \n",
       "408                                    0.086513   \n",
       "409                                   -1.099133   \n",
       "410                                   -1.579153   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_0  \\\n",
       "0                                 -0.449672   \n",
       "1                                  0.880344   \n",
       "2                                 -0.833249   \n",
       "3                                  0.865639   \n",
       "4                                 -0.246418   \n",
       "..                                      ...   \n",
       "406                                1.374448   \n",
       "407                               -0.119108   \n",
       "408                                0.643035   \n",
       "409                               -2.247923   \n",
       "410                               -0.167457   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_0  \\\n",
       "0                                      3.146477   \n",
       "1                                      3.822355   \n",
       "2                                      2.115109   \n",
       "3                                      2.006293   \n",
       "4                                      1.307787   \n",
       "..                                          ...   \n",
       "406                                   -0.767792   \n",
       "407                                   -0.482430   \n",
       "408                                   -0.396456   \n",
       "409                                   -0.311937   \n",
       "410                                   -0.130149   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0  \\\n",
       "0                                     1.939769   \n",
       "1                                     2.431148   \n",
       "2                                     1.348554   \n",
       "3                                     1.282061   \n",
       "4                                     0.836693   \n",
       "..                                         ...   \n",
       "406                                  -0.476107   \n",
       "407                                  -0.420562   \n",
       "408                                  -0.215110   \n",
       "409                                  -0.353737   \n",
       "410                                   0.044753   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1  \\\n",
       "0                                      3.863262   \n",
       "1                                      4.345114   \n",
       "2                                      2.533689   \n",
       "3                                      2.314067   \n",
       "4                                      1.603089   \n",
       "..                                          ...   \n",
       "406                                   -0.467565   \n",
       "407                                    0.030758   \n",
       "408                                    0.110519   \n",
       "409                                    0.230804   \n",
       "410                                    0.566531   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0  ...  \\\n",
       "0                                    -0.551685  ...   \n",
       "1                                     0.256218  ...   \n",
       "2                                     0.029187  ...   \n",
       "3                                     0.023661  ...   \n",
       "4                                     0.376389  ...   \n",
       "..                                         ...  ...   \n",
       "406                                   1.427917  ...   \n",
       "407                                   0.760111  ...   \n",
       "408                                   0.315694  ...   \n",
       "409                                  -0.971253  ...   \n",
       "410                                  -1.460435  ...   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_0_Piemonte_Nord  \\\n",
       "0                                            -0.449672      \n",
       "1                                             0.880344      \n",
       "2                                            -0.833249      \n",
       "3                                             0.865639      \n",
       "4                                            -0.246418      \n",
       "..                                                 ...      \n",
       "406                                           0.000000      \n",
       "407                                          -0.000000      \n",
       "408                                           0.000000      \n",
       "409                                          -0.000000      \n",
       "410                                          -0.000000      \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_0_Piemonte_Sud  \\\n",
       "0                                            -0.000000     \n",
       "1                                             0.000000     \n",
       "2                                            -0.000000     \n",
       "3                                             0.000000     \n",
       "4                                            -0.000000     \n",
       "..                                                 ...     \n",
       "406                                           1.374448     \n",
       "407                                          -0.119108     \n",
       "408                                           0.643035     \n",
       "409                                          -2.247923     \n",
       "410                                          -0.167457     \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_0_Piemonte_Nord  \\\n",
       "0                                             3.146477          \n",
       "1                                             3.822355          \n",
       "2                                             2.115109          \n",
       "3                                             2.006293          \n",
       "4                                             1.307787          \n",
       "..                                                 ...          \n",
       "406                                          -0.000000          \n",
       "407                                          -0.000000          \n",
       "408                                          -0.000000          \n",
       "409                                          -0.000000          \n",
       "410                                          -0.000000          \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_24w_0_Piemonte_Sud  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.767792         \n",
       "407                                          -0.482430         \n",
       "408                                          -0.396456         \n",
       "409                                          -0.311937         \n",
       "410                                          -0.130149         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Nord  \\\n",
       "0                                             1.939769         \n",
       "1                                             2.431148         \n",
       "2                                             1.348554         \n",
       "3                                             1.282061         \n",
       "4                                             0.836693         \n",
       "..                                                 ...         \n",
       "406                                          -0.000000         \n",
       "407                                          -0.000000         \n",
       "408                                          -0.000000         \n",
       "409                                          -0.000000         \n",
       "410                                           0.000000         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_8w_0_Piemonte_Sud  \\\n",
       "0                                             0.000000        \n",
       "1                                             0.000000        \n",
       "2                                             0.000000        \n",
       "3                                             0.000000        \n",
       "4                                             0.000000        \n",
       "..                                                 ...        \n",
       "406                                          -0.476107        \n",
       "407                                          -0.420562        \n",
       "408                                          -0.215110        \n",
       "409                                          -0.353737        \n",
       "410                                           0.044753        \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Nord  \\\n",
       "0                                             3.863262          \n",
       "1                                             4.345114          \n",
       "2                                             2.533689          \n",
       "3                                             2.314067          \n",
       "4                                             1.603089          \n",
       "..                                                 ...          \n",
       "406                                          -0.000000          \n",
       "407                                           0.000000          \n",
       "408                                           0.000000          \n",
       "409                                           0.000000          \n",
       "410                                           0.000000          \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_rr_12w_1_Piemonte_Sud  \\\n",
       "0                                             0.000000         \n",
       "1                                             0.000000         \n",
       "2                                             0.000000         \n",
       "3                                             0.000000         \n",
       "4                                             0.000000         \n",
       "..                                                 ...         \n",
       "406                                          -0.467565         \n",
       "407                                           0.030758         \n",
       "408                                           0.110519         \n",
       "409                                           0.230804         \n",
       "410                                           0.566531         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Nord  \\\n",
       "0                                            -0.551685         \n",
       "1                                             0.256218         \n",
       "2                                             0.029187         \n",
       "3                                             0.023661         \n",
       "4                                             0.376389         \n",
       "..                                                 ...         \n",
       "406                                           0.000000         \n",
       "407                                           0.000000         \n",
       "408                                           0.000000         \n",
       "409                                          -0.000000         \n",
       "410                                          -0.000000         \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0_Piemonte_Sud  \n",
       "0                                            -0.000000       \n",
       "1                                             0.000000       \n",
       "2                                             0.000000       \n",
       "3                                             0.000000       \n",
       "4                                             0.000000       \n",
       "..                                                 ...       \n",
       "406                                           1.427917       \n",
       "407                                           0.760111       \n",
       "408                                           0.315694       \n",
       "409                                          -0.971253       \n",
       "410                                          -1.460435       \n",
       "\n",
       "[822 rows x 32 columns]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        clusterdf_train_withClass[clusterdf_train_withClass.columns[i]+'_'+j] = clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_val_withClass[clusterdf_val_withClass.columns[i]+'_'+j] = clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_test_withClass[clusterdf_test_withClass.columns[i]+'_'+j] = clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "de402c36",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04132440440468077\n",
      "0.017446449998085978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_DPNPS_ohe = LinearRegression()\n",
    "model_DPNPS_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_DPNPS_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff2d510",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Adda - Lambro_Olona - Oglio_Iseo - Ticino - Piemonte Sud - Piemonte Nord: CMI best 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "46954b61",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "clust_basins = ['Adda', 'Lambro_Olona', 'Oglio_Iseo', 'Ticino', 'Piemonte_Nord', 'Piemonte_Sud']\n",
    "colnames = [x for x in best5_CMI_fulldf_train.columns if x.startswith('Adda') or x.startswith('Lambro_Olona') or x.startswith('Oglio_Iseo') or x.startswith('Ticino') or x.startswith('Piemonte_Nord') or x.startswith('Piemonte_Sud')]\n",
    "\n",
    "clusterdf_train_withClass = pd.DataFrame()\n",
    "clusterdf_val_withClass = pd.DataFrame()\n",
    "clusterdf_test_withClass = pd.DataFrame()\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass = pd.concat((clusterdf_train_withClass,pd.concat((best5_CMI_fulldf_train[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_train)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_val_withClass = pd.concat((clusterdf_val_withClass,pd.concat((best5_CMI_fulldf_val[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_val)),columns=['basin'])),axis=1)),axis=0)\n",
    "    clusterdf_test_withClass = pd.concat((clusterdf_test_withClass,pd.concat((best5_CMI_fulldf_test[colnames],pd.DataFrame(1+i*np.ones(len(best5_CMI_fulldf_test)),columns=['basin'])),axis=1)),axis=0)\n",
    "\n",
    "for i in range(len(clust_basins)):\n",
    "    clusterdf_train_withClass[clust_basins[i]] = clusterdf_train_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_val_withClass[clust_basins[i]] = clusterdf_val_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "    clusterdf_test_withClass[clust_basins[i]] = clusterdf_test_withClass.apply(lambda x: int(x.basin==i+1),axis=1)\n",
    "\n",
    "clusterdf_train_withClass = clusterdf_train_withClass.loc[:,clusterdf_train_withClass.columns != 'basin']\n",
    "clusterdf_val_withClass = clusterdf_val_withClass.loc[:,clusterdf_val_withClass.columns != 'basin']\n",
    "clusterdf_test_withClass = clusterdf_test_withClass.loc[:,clusterdf_test_withClass.columns != 'basin']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "c899cc5a",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_6</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_0</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_4w_6</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_4w_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Piemonte_Sud_cyclostationary_mean_tg_1w_0</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1</th>\n",
       "      <th>Adda</th>\n",
       "      <th>Lambro_Olona</th>\n",
       "      <th>Oglio_Iseo</th>\n",
       "      <th>Ticino</th>\n",
       "      <th>Piemonte_Nord</th>\n",
       "      <th>Piemonte_Sud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>1.560382</td>\n",
       "      <td>1.711682</td>\n",
       "      <td>-2.770704</td>\n",
       "      <td>1.914831</td>\n",
       "      <td>-0.044884</td>\n",
       "      <td>1.663515</td>\n",
       "      <td>-0.277460</td>\n",
       "      <td>-0.075383</td>\n",
       "      <td>-0.156545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.551685</td>\n",
       "      <td>-0.432799</td>\n",
       "      <td>0.611605</td>\n",
       "      <td>-0.442197</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>5.036114</td>\n",
       "      <td>2.547788</td>\n",
       "      <td>-0.879312</td>\n",
       "      <td>2.856614</td>\n",
       "      <td>1.221277</td>\n",
       "      <td>2.277544</td>\n",
       "      <td>0.841342</td>\n",
       "      <td>0.882621</td>\n",
       "      <td>0.761360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.256218</td>\n",
       "      <td>0.776085</td>\n",
       "      <td>1.691336</td>\n",
       "      <td>0.807518</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>3.177144</td>\n",
       "      <td>1.634451</td>\n",
       "      <td>-2.052028</td>\n",
       "      <td>1.827839</td>\n",
       "      <td>-0.221646</td>\n",
       "      <td>1.355767</td>\n",
       "      <td>-0.526335</td>\n",
       "      <td>0.474126</td>\n",
       "      <td>0.269224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029187</td>\n",
       "      <td>-0.906320</td>\n",
       "      <td>0.832271</td>\n",
       "      <td>-1.081813</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>3.205993</td>\n",
       "      <td>1.836713</td>\n",
       "      <td>-1.425685</td>\n",
       "      <td>2.055666</td>\n",
       "      <td>0.723165</td>\n",
       "      <td>1.429576</td>\n",
       "      <td>0.512276</td>\n",
       "      <td>0.627310</td>\n",
       "      <td>0.468910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>0.529173</td>\n",
       "      <td>0.859041</td>\n",
       "      <td>0.324392</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>2.498195</td>\n",
       "      <td>1.795310</td>\n",
       "      <td>-1.994518</td>\n",
       "      <td>2.009029</td>\n",
       "      <td>-0.122716</td>\n",
       "      <td>0.994844</td>\n",
       "      <td>-0.056656</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.444387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376389</td>\n",
       "      <td>-0.687667</td>\n",
       "      <td>0.647203</td>\n",
       "      <td>-0.553079</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>-1.467261</td>\n",
       "      <td>0.783570</td>\n",
       "      <td>1.524212</td>\n",
       "      <td>0.639345</td>\n",
       "      <td>1.014590</td>\n",
       "      <td>-1.098764</td>\n",
       "      <td>1.296972</td>\n",
       "      <td>-0.144871</td>\n",
       "      <td>0.565375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.427917</td>\n",
       "      <td>1.481505</td>\n",
       "      <td>-1.023397</td>\n",
       "      <td>1.527659</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>-0.715887</td>\n",
       "      <td>0.868596</td>\n",
       "      <td>1.477729</td>\n",
       "      <td>0.671680</td>\n",
       "      <td>0.250478</td>\n",
       "      <td>-0.476556</td>\n",
       "      <td>0.495148</td>\n",
       "      <td>0.358805</td>\n",
       "      <td>1.260203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760111</td>\n",
       "      <td>0.121450</td>\n",
       "      <td>-0.154876</td>\n",
       "      <td>0.019115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>-0.558495</td>\n",
       "      <td>0.899390</td>\n",
       "      <td>1.352693</td>\n",
       "      <td>0.504706</td>\n",
       "      <td>0.305326</td>\n",
       "      <td>-0.152527</td>\n",
       "      <td>0.445862</td>\n",
       "      <td>0.439528</td>\n",
       "      <td>1.444956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.315694</td>\n",
       "      <td>0.865426</td>\n",
       "      <td>0.083449</td>\n",
       "      <td>1.039841</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-0.626439</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>1.102009</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>-1.995198</td>\n",
       "      <td>-0.192534</td>\n",
       "      <td>-1.610957</td>\n",
       "      <td>0.109550</td>\n",
       "      <td>1.067782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.971253</td>\n",
       "      <td>-2.359776</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>-2.580108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-0.338666</td>\n",
       "      <td>0.604737</td>\n",
       "      <td>1.186923</td>\n",
       "      <td>0.312637</td>\n",
       "      <td>-0.591923</td>\n",
       "      <td>0.302357</td>\n",
       "      <td>-0.580276</td>\n",
       "      <td>-0.315172</td>\n",
       "      <td>0.501525</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.460435</td>\n",
       "      <td>0.061748</td>\n",
       "      <td>0.518063</td>\n",
       "      <td>-0.183864</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2466 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_rr_12w_1  \\\n",
       "0                            -0.862899                            1.560382   \n",
       "1                            -0.093639                            5.036114   \n",
       "2                            -0.524505                            3.177144   \n",
       "3                            -0.666293                            3.205993   \n",
       "4                            -0.416695                            2.498195   \n",
       "..                                 ...                                 ...   \n",
       "406                           1.568770                           -1.467261   \n",
       "407                           0.812306                           -0.715887   \n",
       "408                           0.876968                           -0.558495   \n",
       "409                          -0.723696                           -0.626439   \n",
       "410                          -1.413870                           -0.338666   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_0  Adda_cyclostationary_mean_tg_24w_2  \\\n",
       "0                              1.711682                           -2.770704   \n",
       "1                              2.547788                           -0.879312   \n",
       "2                              1.634451                           -2.052028   \n",
       "3                              1.836713                           -1.425685   \n",
       "4                              1.795310                           -1.994518   \n",
       "..                                  ...                                 ...   \n",
       "406                            0.783570                            1.524212   \n",
       "407                            0.868596                            1.477729   \n",
       "408                            0.899390                            1.352693   \n",
       "409                            0.725991                            1.102009   \n",
       "410                            0.604737                            1.186923   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_24w_0  \\\n",
       "0                              1.914831   \n",
       "1                              2.856614   \n",
       "2                              1.827839   \n",
       "3                              2.055666   \n",
       "4                              2.009029   \n",
       "..                                  ...   \n",
       "406                            0.639345   \n",
       "407                            0.671680   \n",
       "408                            0.504706   \n",
       "409                            0.391753   \n",
       "410                            0.312637   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_6  \\\n",
       "0                                 -0.044884   \n",
       "1                                  1.221277   \n",
       "2                                 -0.221646   \n",
       "3                                  0.723165   \n",
       "4                                 -0.122716   \n",
       "..                                      ...   \n",
       "406                                1.014590   \n",
       "407                                0.250478   \n",
       "408                                0.305326   \n",
       "409                               -1.995198   \n",
       "410                               -0.591923   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_rr_4w_1  \\\n",
       "0                                     1.663515   \n",
       "1                                     2.277544   \n",
       "2                                     1.355767   \n",
       "3                                     1.429576   \n",
       "4                                     0.994844   \n",
       "..                                         ...   \n",
       "406                                  -1.098764   \n",
       "407                                  -0.476556   \n",
       "408                                  -0.152527   \n",
       "409                                  -0.192534   \n",
       "410                                   0.302357   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_0  \\\n",
       "0                                 -0.277460   \n",
       "1                                  0.841342   \n",
       "2                                 -0.526335   \n",
       "3                                  0.512276   \n",
       "4                                 -0.056656   \n",
       "..                                      ...   \n",
       "406                                1.296972   \n",
       "407                                0.495148   \n",
       "408                                0.445862   \n",
       "409                               -1.610957   \n",
       "410                               -0.580276   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_4w_6  \\\n",
       "0                                    -0.075383   \n",
       "1                                     0.882621   \n",
       "2                                     0.474126   \n",
       "3                                     0.627310   \n",
       "4                                     0.463215   \n",
       "..                                         ...   \n",
       "406                                  -0.144871   \n",
       "407                                   0.358805   \n",
       "408                                   0.439528   \n",
       "409                                   0.109550   \n",
       "410                                  -0.315172   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_4w_5  ...  \\\n",
       "0                                    -0.156545  ...   \n",
       "1                                     0.761360  ...   \n",
       "2                                     0.269224  ...   \n",
       "3                                     0.468910  ...   \n",
       "4                                     0.444387  ...   \n",
       "..                                         ...  ...   \n",
       "406                                   0.565375  ...   \n",
       "407                                   1.260203  ...   \n",
       "408                                   1.444956  ...   \n",
       "409                                   1.067782  ...   \n",
       "410                                   0.501525  ...   \n",
       "\n",
       "     Piemonte_Sud_cyclostationary_mean_tg_1w_0  \\\n",
       "0                                    -0.551685   \n",
       "1                                     0.256218   \n",
       "2                                     0.029187   \n",
       "3                                     0.023661   \n",
       "4                                     0.376389   \n",
       "..                                         ...   \n",
       "406                                   1.427917   \n",
       "407                                   0.760111   \n",
       "408                                   0.315694   \n",
       "409                                  -0.971253   \n",
       "410                                  -1.460435   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_0  Ticino_cyclostationary_mean_rr_4w_0  \\\n",
       "0                           -0.432799                             0.611605   \n",
       "1                            0.776085                             1.691336   \n",
       "2                           -0.906320                             0.832271   \n",
       "3                            0.529173                             0.859041   \n",
       "4                           -0.687667                             0.647203   \n",
       "..                                ...                                  ...   \n",
       "406                          1.481505                            -1.023397   \n",
       "407                          0.121450                            -0.154876   \n",
       "408                          0.865426                             0.083449   \n",
       "409                         -2.359776                             0.001375   \n",
       "410                          0.061748                             0.518063   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1  Adda  Lambro_Olona  Oglio_Iseo  Ticino  \\\n",
       "0                           -0.442197     1             0           0       0   \n",
       "1                            0.807518     1             0           0       0   \n",
       "2                           -1.081813     1             0           0       0   \n",
       "3                            0.324392     1             0           0       0   \n",
       "4                           -0.553079     1             0           0       0   \n",
       "..                                ...   ...           ...         ...     ...   \n",
       "406                          1.527659     0             0           0       0   \n",
       "407                          0.019115     0             0           0       0   \n",
       "408                          1.039841     0             0           0       0   \n",
       "409                         -2.580108     0             0           0       0   \n",
       "410                         -0.183864     0             0           0       0   \n",
       "\n",
       "     Piemonte_Nord  Piemonte_Sud  \n",
       "0                0             0  \n",
       "1                0             0  \n",
       "2                0             0  \n",
       "3                0             0  \n",
       "4                0             0  \n",
       "..             ...           ...  \n",
       "406              0             1  \n",
       "407              0             1  \n",
       "408              0             1  \n",
       "409              0             1  \n",
       "410              0             1  \n",
       "\n",
       "[2466 rows x 34 columns]"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "949bb9ab",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "targets_df_train_unfolded = pd.DataFrame()\n",
    "targets_df_val_unfolded = pd.DataFrame()\n",
    "targets_df_test_unfolded = pd.DataFrame()\n",
    "\n",
    "for basin in clust_basins:\n",
    "    targets_df_train_unfolded =  pd.concat((targets_df_train_unfolded,targets_df_train[basin]),axis=0)\n",
    "    targets_df_val_unfolded =  pd.concat((targets_df_val_unfolded,targets_df_val[basin]),axis=0)\n",
    "    targets_df_test_unfolded =  pd.concat((targets_df_test_unfolded,targets_df_test[basin]),axis=0)\n",
    "targets_df_train_unfolded = targets_df_train_unfolded.reset_index(drop=True)\n",
    "targets_df_val_unfolded = targets_df_val_unfolded.reset_index(drop=True)\n",
    "targets_df_test_unfolded = targets_df_test_unfolded.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "e75cfd95",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.546951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.277191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.534156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.447894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>-0.021388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <td>-0.086330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463</th>\n",
       "      <td>0.576347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2464</th>\n",
       "      <td>0.146632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2465</th>\n",
       "      <td>-0.818877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2466 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0    -2.546951\n",
       "1    -0.277191\n",
       "2    -0.534156\n",
       "3    -0.666789\n",
       "4    -0.447894\n",
       "...        ...\n",
       "2461 -0.021388\n",
       "2462 -0.086330\n",
       "2463  0.576347\n",
       "2464  0.146632\n",
       "2465 -0.818877\n",
       "\n",
       "[2466 rows x 1 columns]"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_train_unfolded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "1d00904c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11462100115005325\n",
      "0.021193225708093122\n",
      "0.07493349366613022\n",
      "0.10994573262591845\n",
      "0.06505433486884604\n",
      "-0.04293174762262808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Nord==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Nord'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Piemonte_Sud==1].values)\n",
    "print(r2_score(targets_df_test['Piemonte_Sud'].values, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "c6ac79d1",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adda_cyclostationary_mean_tg_1w_3</th>\n",
       "      <th>Adda_cyclostationary_mean_rr_12w_1</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_16w_0</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_2</th>\n",
       "      <th>Adda_cyclostationary_mean_tg_24w_0</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_6</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_rr_4w_1</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_0</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_4w_6</th>\n",
       "      <th>Lambro_Olona_cyclostationary_mean_tg_4w_5</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_0_Ticino</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Adda</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Lambro_Olona</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_rr_4w_0_Ticino</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Adda</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Lambro_Olona</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Oglio_Iseo</th>\n",
       "      <th>Ticino_cyclostationary_mean_tg_1_Ticino</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.862899</td>\n",
       "      <td>1.560382</td>\n",
       "      <td>1.711682</td>\n",
       "      <td>-2.770704</td>\n",
       "      <td>1.914831</td>\n",
       "      <td>-0.044884</td>\n",
       "      <td>1.663515</td>\n",
       "      <td>-0.277460</td>\n",
       "      <td>-0.075383</td>\n",
       "      <td>-0.156545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.611605</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.442197</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.093639</td>\n",
       "      <td>5.036114</td>\n",
       "      <td>2.547788</td>\n",
       "      <td>-0.879312</td>\n",
       "      <td>2.856614</td>\n",
       "      <td>1.221277</td>\n",
       "      <td>2.277544</td>\n",
       "      <td>0.841342</td>\n",
       "      <td>0.882621</td>\n",
       "      <td>0.761360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.691336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.524505</td>\n",
       "      <td>3.177144</td>\n",
       "      <td>1.634451</td>\n",
       "      <td>-2.052028</td>\n",
       "      <td>1.827839</td>\n",
       "      <td>-0.221646</td>\n",
       "      <td>1.355767</td>\n",
       "      <td>-0.526335</td>\n",
       "      <td>0.474126</td>\n",
       "      <td>0.269224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.832271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.081813</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.666293</td>\n",
       "      <td>3.205993</td>\n",
       "      <td>1.836713</td>\n",
       "      <td>-1.425685</td>\n",
       "      <td>2.055666</td>\n",
       "      <td>0.723165</td>\n",
       "      <td>1.429576</td>\n",
       "      <td>0.512276</td>\n",
       "      <td>0.627310</td>\n",
       "      <td>0.468910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.859041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.324392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.416695</td>\n",
       "      <td>2.498195</td>\n",
       "      <td>1.795310</td>\n",
       "      <td>-1.994518</td>\n",
       "      <td>2.009029</td>\n",
       "      <td>-0.122716</td>\n",
       "      <td>0.994844</td>\n",
       "      <td>-0.056656</td>\n",
       "      <td>0.463215</td>\n",
       "      <td>0.444387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.647203</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.553079</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.568770</td>\n",
       "      <td>-1.467261</td>\n",
       "      <td>0.783570</td>\n",
       "      <td>1.524212</td>\n",
       "      <td>0.639345</td>\n",
       "      <td>1.014590</td>\n",
       "      <td>-1.098764</td>\n",
       "      <td>1.296972</td>\n",
       "      <td>-0.144871</td>\n",
       "      <td>0.565375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.481505</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-1.023397</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.527659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0.812306</td>\n",
       "      <td>-0.715887</td>\n",
       "      <td>0.868596</td>\n",
       "      <td>1.477729</td>\n",
       "      <td>0.671680</td>\n",
       "      <td>0.250478</td>\n",
       "      <td>-0.476556</td>\n",
       "      <td>0.495148</td>\n",
       "      <td>0.358805</td>\n",
       "      <td>1.260203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.121450</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.154876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.876968</td>\n",
       "      <td>-0.558495</td>\n",
       "      <td>0.899390</td>\n",
       "      <td>1.352693</td>\n",
       "      <td>0.504706</td>\n",
       "      <td>0.305326</td>\n",
       "      <td>-0.152527</td>\n",
       "      <td>0.445862</td>\n",
       "      <td>0.439528</td>\n",
       "      <td>1.444956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.865426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.039841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-0.723696</td>\n",
       "      <td>-0.626439</td>\n",
       "      <td>0.725991</td>\n",
       "      <td>1.102009</td>\n",
       "      <td>0.391753</td>\n",
       "      <td>-1.995198</td>\n",
       "      <td>-0.192534</td>\n",
       "      <td>-1.610957</td>\n",
       "      <td>0.109550</td>\n",
       "      <td>1.067782</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-2.359776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001375</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-2.580108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-1.413870</td>\n",
       "      <td>-0.338666</td>\n",
       "      <td>0.604737</td>\n",
       "      <td>1.186923</td>\n",
       "      <td>0.312637</td>\n",
       "      <td>-0.591923</td>\n",
       "      <td>0.302357</td>\n",
       "      <td>-0.580276</td>\n",
       "      <td>-0.315172</td>\n",
       "      <td>0.501525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518063</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.183864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1644 rows  94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Adda_cyclostationary_mean_tg_1w_3  Adda_cyclostationary_mean_rr_12w_1  \\\n",
       "0                            -0.862899                            1.560382   \n",
       "1                            -0.093639                            5.036114   \n",
       "2                            -0.524505                            3.177144   \n",
       "3                            -0.666293                            3.205993   \n",
       "4                            -0.416695                            2.498195   \n",
       "..                                 ...                                 ...   \n",
       "406                           1.568770                           -1.467261   \n",
       "407                           0.812306                           -0.715887   \n",
       "408                           0.876968                           -0.558495   \n",
       "409                          -0.723696                           -0.626439   \n",
       "410                          -1.413870                           -0.338666   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_16w_0  Adda_cyclostationary_mean_tg_24w_2  \\\n",
       "0                              1.711682                           -2.770704   \n",
       "1                              2.547788                           -0.879312   \n",
       "2                              1.634451                           -2.052028   \n",
       "3                              1.836713                           -1.425685   \n",
       "4                              1.795310                           -1.994518   \n",
       "..                                  ...                                 ...   \n",
       "406                            0.783570                            1.524212   \n",
       "407                            0.868596                            1.477729   \n",
       "408                            0.899390                            1.352693   \n",
       "409                            0.725991                            1.102009   \n",
       "410                            0.604737                            1.186923   \n",
       "\n",
       "     Adda_cyclostationary_mean_tg_24w_0  \\\n",
       "0                              1.914831   \n",
       "1                              2.856614   \n",
       "2                              1.827839   \n",
       "3                              2.055666   \n",
       "4                              2.009029   \n",
       "..                                  ...   \n",
       "406                            0.639345   \n",
       "407                            0.671680   \n",
       "408                            0.504706   \n",
       "409                            0.391753   \n",
       "410                            0.312637   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_6  \\\n",
       "0                                 -0.044884   \n",
       "1                                  1.221277   \n",
       "2                                 -0.221646   \n",
       "3                                  0.723165   \n",
       "4                                 -0.122716   \n",
       "..                                      ...   \n",
       "406                                1.014590   \n",
       "407                                0.250478   \n",
       "408                                0.305326   \n",
       "409                               -1.995198   \n",
       "410                               -0.591923   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_rr_4w_1  \\\n",
       "0                                     1.663515   \n",
       "1                                     2.277544   \n",
       "2                                     1.355767   \n",
       "3                                     1.429576   \n",
       "4                                     0.994844   \n",
       "..                                         ...   \n",
       "406                                  -1.098764   \n",
       "407                                  -0.476556   \n",
       "408                                  -0.152527   \n",
       "409                                  -0.192534   \n",
       "410                                   0.302357   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_0  \\\n",
       "0                                 -0.277460   \n",
       "1                                  0.841342   \n",
       "2                                 -0.526335   \n",
       "3                                  0.512276   \n",
       "4                                 -0.056656   \n",
       "..                                      ...   \n",
       "406                                1.296972   \n",
       "407                                0.495148   \n",
       "408                                0.445862   \n",
       "409                               -1.610957   \n",
       "410                               -0.580276   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_4w_6  \\\n",
       "0                                    -0.075383   \n",
       "1                                     0.882621   \n",
       "2                                     0.474126   \n",
       "3                                     0.627310   \n",
       "4                                     0.463215   \n",
       "..                                         ...   \n",
       "406                                  -0.144871   \n",
       "407                                   0.358805   \n",
       "408                                   0.439528   \n",
       "409                                   0.109550   \n",
       "410                                  -0.315172   \n",
       "\n",
       "     Lambro_Olona_cyclostationary_mean_tg_4w_5  ...  \\\n",
       "0                                    -0.156545  ...   \n",
       "1                                     0.761360  ...   \n",
       "2                                     0.269224  ...   \n",
       "3                                     0.468910  ...   \n",
       "4                                     0.444387  ...   \n",
       "..                                         ...  ...   \n",
       "406                                   0.565375  ...   \n",
       "407                                   1.260203  ...   \n",
       "408                                   1.444956  ...   \n",
       "409                                   1.067782  ...   \n",
       "410                                   0.501525  ...   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_0_Oglio_Iseo  \\\n",
       "0                                           -0.0   \n",
       "1                                            0.0   \n",
       "2                                           -0.0   \n",
       "3                                            0.0   \n",
       "4                                           -0.0   \n",
       "..                                           ...   \n",
       "406                                          0.0   \n",
       "407                                          0.0   \n",
       "408                                          0.0   \n",
       "409                                         -0.0   \n",
       "410                                          0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_0_Ticino  \\\n",
       "0                                  -0.000000   \n",
       "1                                   0.000000   \n",
       "2                                  -0.000000   \n",
       "3                                   0.000000   \n",
       "4                                  -0.000000   \n",
       "..                                       ...   \n",
       "406                                 1.481505   \n",
       "407                                 0.121450   \n",
       "408                                 0.865426   \n",
       "409                                -2.359776   \n",
       "410                                 0.061748   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Adda  \\\n",
       "0                                    0.611605   \n",
       "1                                    1.691336   \n",
       "2                                    0.832271   \n",
       "3                                    0.859041   \n",
       "4                                    0.647203   \n",
       "..                                        ...   \n",
       "406                                 -0.000000   \n",
       "407                                 -0.000000   \n",
       "408                                  0.000000   \n",
       "409                                  0.000000   \n",
       "410                                  0.000000   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Lambro_Olona  \\\n",
       "0                                                 0.0   \n",
       "1                                                 0.0   \n",
       "2                                                 0.0   \n",
       "3                                                 0.0   \n",
       "4                                                 0.0   \n",
       "..                                                ...   \n",
       "406                                              -0.0   \n",
       "407                                              -0.0   \n",
       "408                                               0.0   \n",
       "409                                               0.0   \n",
       "410                                               0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Oglio_Iseo  \\\n",
       "0                                               0.0   \n",
       "1                                               0.0   \n",
       "2                                               0.0   \n",
       "3                                               0.0   \n",
       "4                                               0.0   \n",
       "..                                              ...   \n",
       "406                                            -0.0   \n",
       "407                                            -0.0   \n",
       "408                                             0.0   \n",
       "409                                             0.0   \n",
       "410                                             0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_rr_4w_0_Ticino  \\\n",
       "0                                      0.000000   \n",
       "1                                      0.000000   \n",
       "2                                      0.000000   \n",
       "3                                      0.000000   \n",
       "4                                      0.000000   \n",
       "..                                          ...   \n",
       "406                                   -1.023397   \n",
       "407                                   -0.154876   \n",
       "408                                    0.083449   \n",
       "409                                    0.001375   \n",
       "410                                    0.518063   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Adda  \\\n",
       "0                                -0.442197   \n",
       "1                                 0.807518   \n",
       "2                                -1.081813   \n",
       "3                                 0.324392   \n",
       "4                                -0.553079   \n",
       "..                                     ...   \n",
       "406                               0.000000   \n",
       "407                               0.000000   \n",
       "408                               0.000000   \n",
       "409                              -0.000000   \n",
       "410                              -0.000000   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Lambro_Olona  \\\n",
       "0                                             -0.0   \n",
       "1                                              0.0   \n",
       "2                                             -0.0   \n",
       "3                                              0.0   \n",
       "4                                             -0.0   \n",
       "..                                             ...   \n",
       "406                                            0.0   \n",
       "407                                            0.0   \n",
       "408                                            0.0   \n",
       "409                                           -0.0   \n",
       "410                                           -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Oglio_Iseo  \\\n",
       "0                                           -0.0   \n",
       "1                                            0.0   \n",
       "2                                           -0.0   \n",
       "3                                            0.0   \n",
       "4                                           -0.0   \n",
       "..                                           ...   \n",
       "406                                          0.0   \n",
       "407                                          0.0   \n",
       "408                                          0.0   \n",
       "409                                         -0.0   \n",
       "410                                         -0.0   \n",
       "\n",
       "     Ticino_cyclostationary_mean_tg_1_Ticino  \n",
       "0                                  -0.000000  \n",
       "1                                   0.000000  \n",
       "2                                  -0.000000  \n",
       "3                                   0.000000  \n",
       "4                                  -0.000000  \n",
       "..                                       ...  \n",
       "406                                 1.527659  \n",
       "407                                 0.019115  \n",
       "408                                 1.039841  \n",
       "409                                -2.580108  \n",
       "410                                -0.183864  \n",
       "\n",
       "[1644 rows x 94 columns]"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(clusterdf_train_withClass.shape[1]-len(clust_basins)):\n",
    "    for j in clust_basins:\n",
    "        clusterdf_train_withClass[clusterdf_train_withClass.columns[i]+'_'+j] = clusterdf_train_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_val_withClass[clusterdf_val_withClass.columns[i]+'_'+j] = clusterdf_val_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "        clusterdf_test_withClass[clusterdf_test_withClass.columns[i]+'_'+j] = clusterdf_test_withClass.apply(lambda x:x[i]*x[j], axis=1)\n",
    "\n",
    "clusterdf_train_withClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "cc4acb1e",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2934203975293319\n",
      "0.26426191622064354\n",
      "0.15121968885589177\n",
      "0.2495948097547407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/paolo/opt/miniconda3/envs/tensorflow/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_ALOT_ohe = LinearRegression()\n",
    "model_ALOT_ohe.fit(pd.concat((clusterdf_train_withClass,clusterdf_val_withClass)),pd.concat((targets_df_train_unfolded,targets_df_val_unfolded)))\n",
    "\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Adda==1].values)\n",
    "print(r2_score(targets_df_test['Adda'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Lambro_Olona==1].values)\n",
    "print(r2_score(targets_df_test['Lambro_Olona'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Oglio_Iseo==1].values)\n",
    "print(r2_score(targets_df_test['Oglio_Iseo'].values, res))\n",
    "res = model_ALOT_ohe.predict(clusterdf_test_withClass.loc[clusterdf_test_withClass.Ticino==1].values)\n",
    "print(r2_score(targets_df_test['Ticino'].values, res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51745de2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dd737e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ae2177",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e81f6696",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6940b5",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c245c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Riassunto wrapper - CMI - CMI best5\n",
    "\n",
    "Emiliani1: 0.30       0.19       0.40\n",
    "Emiliani2: 0.17       0.15       0.26\n",
    "Together:  0.14/0.04  0.07/0.04  0.12/0.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f3b764",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1641f1aa",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd55d2d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c0e64",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb4e280",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb97ef65",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d36f10b2",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6b5d365",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.039373    0.00  2001     1 -2.546951\n",
      "1    2001-01-13  0.380618    0.43  2001     2 -0.277191\n",
      "2    2001-01-21  0.341985    0.38  2001     3 -0.534156\n",
      "3    2001-01-29  0.322044    0.35  2001     5 -0.666789\n",
      "4    2001-02-06  0.354954    0.40  2001     6 -0.447894\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.382706    0.40  2009    48 -0.263306\n",
      "407  2009-12-05  0.409921    0.46  2009    49 -0.082282\n",
      "408  2009-12-13  0.472087    0.53  2009    50  0.331204\n",
      "409  2009-12-21  0.324728    0.00  2009    52 -0.648940\n",
      "410  2009-12-29  0.086512    0.00  2009    53 -2.233412\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.010645    0.00  2001     1 -2.129508\n",
      "1    2001-01-13  0.206769    0.00  2001     2 -0.927136\n",
      "2    2001-01-21  0.267313    0.00  2001     3 -0.555958\n",
      "3    2001-01-29  0.240836    0.20  2001     5 -0.718282\n",
      "4    2001-02-06  0.193417    0.15  2001     6 -1.008995\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.230073    0.25  2009    48 -0.784269\n",
      "407  2009-12-05  0.243632    0.24  2009    49 -0.701139\n",
      "408  2009-12-13  0.251111    0.00  2009    50 -0.655289\n",
      "409  2009-12-21  0.099246    0.00  2009    52 -1.586325\n",
      "410  2009-12-29  0.064990    0.00  2009    53 -1.796340\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.379890    0.50  2001     1 -0.382765\n",
      "1    2001-01-13  0.482679    0.58  2001     2  0.319215\n",
      "2    2001-01-21  0.516259    0.59  2001     3  0.548542\n",
      "3    2001-01-29  0.434421    0.50  2001     5 -0.010351\n",
      "4    2001-02-06  0.494805    0.54  2001     6  0.402030\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.427085    0.43  2009    48 -0.060454\n",
      "407  2009-12-05  0.547380    0.57  2009    49  0.761079\n",
      "408  2009-12-13  0.531070    0.58  2009    50  0.649694\n",
      "409  2009-12-21  0.295704    0.00  2009    52 -0.957702\n",
      "410  2009-12-29  0.027861    0.00  2009    53 -2.786888\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.214281    0.00  2001     1 -1.339879\n",
      "1    2001-01-13  0.484737    0.52  2001     2  0.402993\n",
      "2    2001-01-21  0.466071    0.47  2001     3  0.282703\n",
      "3    2001-01-29  0.417470    0.44  2001     5 -0.030490\n",
      "4    2001-02-06  0.492202    0.53  2001     6  0.451097\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.436464    0.46  2009    48  0.091910\n",
      "407  2009-12-05  0.466152    0.49  2009    49  0.283224\n",
      "408  2009-12-13  0.553659    0.59  2009    50  0.847138\n",
      "409  2009-12-21  0.507978    0.65  2009    52  0.552758\n",
      "410  2009-12-29  0.083046    0.00  2009    53 -2.185583\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.102270    0.00  2001     1 -1.996014\n",
      "1    2001-01-13  0.454431    0.53  2001     2  0.498869\n",
      "2    2001-01-21  0.323514    0.32  2001     3 -0.428613\n",
      "3    2001-01-29  0.301661    0.31  2001     5 -0.583432\n",
      "4    2001-02-06  0.394733    0.44  2001     6  0.075938\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.388573    0.44  2009    48  0.032299\n",
      "407  2009-12-05  0.402760    0.47  2009    49  0.132804\n",
      "408  2009-12-13  0.353782    0.44  2009    50 -0.214182\n",
      "409  2009-12-21  0.043947    0.00  2009    52 -2.409204\n",
      "410  2009-12-29  0.006670    0.00  2009    53 -2.673294\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.369625    0.45  2001     1 -0.439541\n",
      "1    2001-01-13  0.429563    0.43  2001     2 -0.019547\n",
      "2    2001-01-21  0.470784    0.48  2001     3  0.269293\n",
      "3    2001-01-29  0.370358    0.37  2001     5 -0.434406\n",
      "4    2001-02-06  0.372263    0.37  2001     6 -0.421060\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.402059    0.40  2009    48 -0.212272\n",
      "407  2009-12-05  0.389658    0.39  2009    49 -0.299172\n",
      "408  2009-12-13  0.545184    0.56  2009    50  0.790614\n",
      "409  2009-12-21  0.447916    0.55  2009    52  0.109054\n",
      "410  2009-12-29  0.277300    0.32  2009    53 -1.086474\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.243674    0.26  2001     1 -1.223671\n",
      "1    2001-01-13  0.424116    0.44  2001     2 -0.087252\n",
      "2    2001-01-21  0.393786    0.39  2001     3 -0.278268\n",
      "3    2001-01-29  0.314939    0.31  2001     5 -0.774846\n",
      "4    2001-02-06  0.464902    0.48  2001     6  0.169616\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.465734    0.48  2009    48  0.174854\n",
      "407  2009-12-05  0.447390    0.47  2009    49  0.059327\n",
      "408  2009-12-13  0.556760    0.59  2009    50  0.748131\n",
      "409  2009-12-21  0.307880    0.00  2009    52 -0.819305\n",
      "410  2009-12-29  0.034211    0.00  2009    53 -2.542862\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278983    0.00  2001     1 -1.146332\n",
      "1    2001-01-13  0.494910    0.51  2001     2  0.371173\n",
      "2    2001-01-21  0.496092    0.51  2001     3  0.379474\n",
      "3    2001-01-29  0.427992    0.43  2001     5 -0.099118\n",
      "4    2001-02-06  0.400512    0.41  2001     6 -0.292244\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.363952    0.37  2009    48 -0.549184\n",
      "407  2009-12-05  0.400487    0.40  2009    49 -0.292423\n",
      "408  2009-12-13  0.506771    0.52  2009    50  0.454529\n",
      "409  2009-12-21  0.387530    0.53  2009    52 -0.383480\n",
      "410  2009-12-29  0.279894    0.27  2009    53 -1.139931\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.278060    0.09  2001     1 -0.967137\n",
      "1    2001-01-13  0.445159    0.48  2001     2  0.070382\n",
      "2    2001-01-21  0.488982    0.52  2001     3  0.342478\n",
      "3    2001-01-29  0.362487    0.37  2001     5 -0.442927\n",
      "4    2001-02-06  0.430732    0.45  2001     6 -0.019192\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.430379    0.44  2009    48 -0.021388\n",
      "407  2009-12-05  0.419919    0.43  2009    49 -0.086330\n",
      "408  2009-12-13  0.526648    0.55  2009    50  0.576347\n",
      "409  2009-12-21  0.457440    0.61  2009    52  0.146632\n",
      "410  2009-12-29  0.301938    0.38  2009    53 -0.818877\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n",
      "target samples:            date      mean  median  year  week  mean_std\n",
      "0    2001-01-05  0.264043    0.00  2001     1 -1.060146\n",
      "1    2001-01-13  0.354618    0.39  2001     2 -0.405065\n",
      "2    2001-01-21  0.427990    0.47  2001     3  0.125603\n",
      "3    2001-01-29  0.339495    0.35  2001     5 -0.514438\n",
      "4    2001-02-06  0.324134    0.34  2001     6 -0.625540\n",
      "..          ...       ...     ...   ...   ...       ...\n",
      "406  2009-11-27  0.332713    0.35  2009    48 -0.563495\n",
      "407  2009-12-05  0.370253    0.40  2009    49 -0.291984\n",
      "408  2009-12-13  0.517201    0.57  2009    50  0.770822\n",
      "409  2009-12-21  0.353636    0.45  2009    52 -0.412164\n",
      "410  2009-12-29  0.261079    0.00  2009    53 -1.081585\n",
      "\n",
      "[411 rows x 6 columns]\n",
      " target shapes: ((411, 6), (228, 6), (639, 6), (228, 6))\n"
     ]
    }
   ],
   "source": [
    "basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona','Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n",
    "path_target = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/csv_VHI/'\n",
    "\n",
    "targets_train = {}\n",
    "targets_val = {}\n",
    "targets_test = {}\n",
    "targets_trainVal = {}\n",
    "for basin in basins:\n",
    "    target_df_train,target_df_val,target_df_test,target_df_trainVal = prepare_target('',max_train='2010-01-01', max_val='2015-01-01', max_test='2020-01-01', path=path_target+basin+'.csv')\n",
    "    targets_train[basin] = target_df_train\n",
    "    targets_val[basin] = target_df_val\n",
    "    targets_test[basin] = target_df_test\n",
    "    targets_trainVal[basin] = target_df_trainVal\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49fa2ec",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Best 5 wrapper clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e03cfd07",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Load the selected features: best 5 Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8ab30ba",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "basins = ['Adda','Dora','Emiliani1','Emiliani2','Garda_Mincio','Lambro_Olona','Oglio_Iseo','Piemonte_Nord','Piemonte_Sud','Ticino']\n",
    "folder = '/Users/paolo/Documents/OneDrive - Politecnico di Milano/droughts/reduced_features/'\n",
    "filelist = [file for file in os.listdir(folder) if file.endswith('_nonLinCFA_wrapper_best5_train.csv')]\n",
    "\n",
    "train_best5_wrapper = {}\n",
    "for file in filelist:\n",
    "    train_best5_wrapper[file] = pd.read_csv((folder+file))\n",
    "    \n",
    "filelist = [file for file in os.listdir(folder) if file.endswith('_nonLinCFA_wrapper_best5_val.csv')]\n",
    "\n",
    "val_best5_wrapper = {}\n",
    "for file in filelist:\n",
    "    val_best5_wrapper[file] = pd.read_csv((folder+file))\n",
    "    \n",
    "filelist = [file for file in os.listdir(folder) if file.endswith('_nonLinCFA_wrapper_best5_test.csv')]\n",
    "\n",
    "test_best5_wrapper = {}\n",
    "for file in filelist:\n",
    "    test_best5_wrapper[file] = pd.read_csv((folder+file))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "708812f6",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "hierarchical_clustering = AgglomerativeClustering(linkage=\"average\", \n",
    "                                distance_threshold = None, \n",
    "                                n_clusters=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50054c36",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>401</th>\n",
       "      <th>402</th>\n",
       "      <th>403</th>\n",
       "      <th>404</th>\n",
       "      <th>405</th>\n",
       "      <th>406</th>\n",
       "      <th>407</th>\n",
       "      <th>408</th>\n",
       "      <th>409</th>\n",
       "      <th>410</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adda</th>\n",
       "      <td>-2.546951</td>\n",
       "      <td>-0.277191</td>\n",
       "      <td>-0.534156</td>\n",
       "      <td>-0.666789</td>\n",
       "      <td>-0.447894</td>\n",
       "      <td>-1.060644</td>\n",
       "      <td>-0.930783</td>\n",
       "      <td>0.130445</td>\n",
       "      <td>-0.182764</td>\n",
       "      <td>0.285961</td>\n",
       "      <td>...</td>\n",
       "      <td>1.245203</td>\n",
       "      <td>0.071188</td>\n",
       "      <td>1.085285</td>\n",
       "      <td>0.531438</td>\n",
       "      <td>-0.638894</td>\n",
       "      <td>-0.263306</td>\n",
       "      <td>-0.082282</td>\n",
       "      <td>0.331204</td>\n",
       "      <td>-0.648940</td>\n",
       "      <td>-2.233412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dora</th>\n",
       "      <td>-2.129508</td>\n",
       "      <td>-0.927136</td>\n",
       "      <td>-0.555958</td>\n",
       "      <td>-0.718282</td>\n",
       "      <td>-1.008995</td>\n",
       "      <td>-1.279207</td>\n",
       "      <td>-1.444875</td>\n",
       "      <td>-0.224922</td>\n",
       "      <td>-0.513422</td>\n",
       "      <td>-0.331122</td>\n",
       "      <td>...</td>\n",
       "      <td>1.521211</td>\n",
       "      <td>-0.076805</td>\n",
       "      <td>0.663966</td>\n",
       "      <td>0.023314</td>\n",
       "      <td>-1.370886</td>\n",
       "      <td>-0.784269</td>\n",
       "      <td>-0.701139</td>\n",
       "      <td>-0.655289</td>\n",
       "      <td>-1.586325</td>\n",
       "      <td>-1.796340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emiliani1</th>\n",
       "      <td>-0.382765</td>\n",
       "      <td>0.319215</td>\n",
       "      <td>0.548542</td>\n",
       "      <td>-0.010351</td>\n",
       "      <td>0.402030</td>\n",
       "      <td>-0.272581</td>\n",
       "      <td>-0.163632</td>\n",
       "      <td>0.537451</td>\n",
       "      <td>0.523582</td>\n",
       "      <td>0.764119</td>\n",
       "      <td>...</td>\n",
       "      <td>1.027290</td>\n",
       "      <td>0.055590</td>\n",
       "      <td>0.692477</td>\n",
       "      <td>0.361799</td>\n",
       "      <td>-0.418498</td>\n",
       "      <td>-0.060454</td>\n",
       "      <td>0.761079</td>\n",
       "      <td>0.649694</td>\n",
       "      <td>-0.957702</td>\n",
       "      <td>-2.786888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Emiliani2</th>\n",
       "      <td>-1.339879</td>\n",
       "      <td>0.402993</td>\n",
       "      <td>0.282703</td>\n",
       "      <td>-0.030490</td>\n",
       "      <td>0.451097</td>\n",
       "      <td>-0.461545</td>\n",
       "      <td>-0.616218</td>\n",
       "      <td>0.586097</td>\n",
       "      <td>0.324908</td>\n",
       "      <td>0.490785</td>\n",
       "      <td>...</td>\n",
       "      <td>1.475893</td>\n",
       "      <td>0.723830</td>\n",
       "      <td>1.270697</td>\n",
       "      <td>1.013738</td>\n",
       "      <td>0.032229</td>\n",
       "      <td>0.091910</td>\n",
       "      <td>0.283224</td>\n",
       "      <td>0.847138</td>\n",
       "      <td>0.552758</td>\n",
       "      <td>-2.185583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Garda_Mincio</th>\n",
       "      <td>-1.996014</td>\n",
       "      <td>0.498869</td>\n",
       "      <td>-0.428613</td>\n",
       "      <td>-0.583432</td>\n",
       "      <td>0.075938</td>\n",
       "      <td>-1.170667</td>\n",
       "      <td>-0.994278</td>\n",
       "      <td>0.347932</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.282736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590168</td>\n",
       "      <td>-0.213240</td>\n",
       "      <td>0.570796</td>\n",
       "      <td>0.032382</td>\n",
       "      <td>-0.449253</td>\n",
       "      <td>0.032299</td>\n",
       "      <td>0.132804</td>\n",
       "      <td>-0.214182</td>\n",
       "      <td>-2.409204</td>\n",
       "      <td>-2.673294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lambro_Olona</th>\n",
       "      <td>-0.439541</td>\n",
       "      <td>-0.019547</td>\n",
       "      <td>0.269293</td>\n",
       "      <td>-0.434406</td>\n",
       "      <td>-0.421060</td>\n",
       "      <td>-1.360391</td>\n",
       "      <td>-1.488261</td>\n",
       "      <td>0.143476</td>\n",
       "      <td>-0.131799</td>\n",
       "      <td>0.022348</td>\n",
       "      <td>...</td>\n",
       "      <td>1.343884</td>\n",
       "      <td>-0.011918</td>\n",
       "      <td>1.203688</td>\n",
       "      <td>0.840946</td>\n",
       "      <td>-0.353547</td>\n",
       "      <td>-0.212272</td>\n",
       "      <td>-0.299172</td>\n",
       "      <td>0.790614</td>\n",
       "      <td>0.109054</td>\n",
       "      <td>-1.086474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oglio_Iseo</th>\n",
       "      <td>-1.223671</td>\n",
       "      <td>-0.087252</td>\n",
       "      <td>-0.278268</td>\n",
       "      <td>-0.774846</td>\n",
       "      <td>0.169616</td>\n",
       "      <td>-1.193040</td>\n",
       "      <td>-1.058212</td>\n",
       "      <td>0.153692</td>\n",
       "      <td>-0.057888</td>\n",
       "      <td>0.467061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.956288</td>\n",
       "      <td>0.122784</td>\n",
       "      <td>1.199917</td>\n",
       "      <td>0.568570</td>\n",
       "      <td>-0.268606</td>\n",
       "      <td>0.174854</td>\n",
       "      <td>0.059327</td>\n",
       "      <td>0.748131</td>\n",
       "      <td>-0.819305</td>\n",
       "      <td>-2.542862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Piemonte_Nord</th>\n",
       "      <td>-1.146332</td>\n",
       "      <td>0.371173</td>\n",
       "      <td>0.379474</td>\n",
       "      <td>-0.099118</td>\n",
       "      <td>-0.292244</td>\n",
       "      <td>-0.980959</td>\n",
       "      <td>-1.406861</td>\n",
       "      <td>0.562514</td>\n",
       "      <td>0.185923</td>\n",
       "      <td>0.419812</td>\n",
       "      <td>...</td>\n",
       "      <td>1.482606</td>\n",
       "      <td>-0.405493</td>\n",
       "      <td>1.139576</td>\n",
       "      <td>0.674711</td>\n",
       "      <td>-1.020396</td>\n",
       "      <td>-0.549184</td>\n",
       "      <td>-0.292423</td>\n",
       "      <td>0.454529</td>\n",
       "      <td>-0.383480</td>\n",
       "      <td>-1.139931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Piemonte_Sud</th>\n",
       "      <td>-0.967137</td>\n",
       "      <td>0.070382</td>\n",
       "      <td>0.342478</td>\n",
       "      <td>-0.442927</td>\n",
       "      <td>-0.019192</td>\n",
       "      <td>-0.759762</td>\n",
       "      <td>-0.853231</td>\n",
       "      <td>1.163451</td>\n",
       "      <td>0.341598</td>\n",
       "      <td>-0.003145</td>\n",
       "      <td>...</td>\n",
       "      <td>1.875714</td>\n",
       "      <td>0.694293</td>\n",
       "      <td>1.392717</td>\n",
       "      <td>1.349087</td>\n",
       "      <td>-0.551938</td>\n",
       "      <td>-0.021388</td>\n",
       "      <td>-0.086330</td>\n",
       "      <td>0.576347</td>\n",
       "      <td>0.146632</td>\n",
       "      <td>-0.818877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticino</th>\n",
       "      <td>-1.060146</td>\n",
       "      <td>-0.405065</td>\n",
       "      <td>0.125603</td>\n",
       "      <td>-0.514438</td>\n",
       "      <td>-0.625540</td>\n",
       "      <td>-1.434559</td>\n",
       "      <td>-1.530712</td>\n",
       "      <td>0.090771</td>\n",
       "      <td>-0.235814</td>\n",
       "      <td>0.024990</td>\n",
       "      <td>...</td>\n",
       "      <td>1.467046</td>\n",
       "      <td>-0.063035</td>\n",
       "      <td>1.071194</td>\n",
       "      <td>0.899153</td>\n",
       "      <td>-0.606295</td>\n",
       "      <td>-0.563495</td>\n",
       "      <td>-0.291984</td>\n",
       "      <td>0.770822</td>\n",
       "      <td>-0.412164</td>\n",
       "      <td>-1.081585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  411 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0         1         2         3         4         5    \\\n",
       "Adda          -2.546951 -0.277191 -0.534156 -0.666789 -0.447894 -1.060644   \n",
       "Dora          -2.129508 -0.927136 -0.555958 -0.718282 -1.008995 -1.279207   \n",
       "Emiliani1     -0.382765  0.319215  0.548542 -0.010351  0.402030 -0.272581   \n",
       "Emiliani2     -1.339879  0.402993  0.282703 -0.030490  0.451097 -0.461545   \n",
       "Garda_Mincio  -1.996014  0.498869 -0.428613 -0.583432  0.075938 -1.170667   \n",
       "Lambro_Olona  -0.439541 -0.019547  0.269293 -0.434406 -0.421060 -1.360391   \n",
       "Oglio_Iseo    -1.223671 -0.087252 -0.278268 -0.774846  0.169616 -1.193040   \n",
       "Piemonte_Nord -1.146332  0.371173  0.379474 -0.099118 -0.292244 -0.980959   \n",
       "Piemonte_Sud  -0.967137  0.070382  0.342478 -0.442927 -0.019192 -0.759762   \n",
       "Ticino        -1.060146 -0.405065  0.125603 -0.514438 -0.625540 -1.434559   \n",
       "\n",
       "                    6         7         8         9    ...       401  \\\n",
       "Adda          -0.930783  0.130445 -0.182764  0.285961  ...  1.245203   \n",
       "Dora          -1.444875 -0.224922 -0.513422 -0.331122  ...  1.521211   \n",
       "Emiliani1     -0.163632  0.537451  0.523582  0.764119  ...  1.027290   \n",
       "Emiliani2     -0.616218  0.586097  0.324908  0.490785  ...  1.475893   \n",
       "Garda_Mincio  -0.994278  0.347932  0.270386  0.282736  ...  0.590168   \n",
       "Lambro_Olona  -1.488261  0.143476 -0.131799  0.022348  ...  1.343884   \n",
       "Oglio_Iseo    -1.058212  0.153692 -0.057888  0.467061  ...  0.956288   \n",
       "Piemonte_Nord -1.406861  0.562514  0.185923  0.419812  ...  1.482606   \n",
       "Piemonte_Sud  -0.853231  1.163451  0.341598 -0.003145  ...  1.875714   \n",
       "Ticino        -1.530712  0.090771 -0.235814  0.024990  ...  1.467046   \n",
       "\n",
       "                    402       403       404       405       406       407  \\\n",
       "Adda           0.071188  1.085285  0.531438 -0.638894 -0.263306 -0.082282   \n",
       "Dora          -0.076805  0.663966  0.023314 -1.370886 -0.784269 -0.701139   \n",
       "Emiliani1      0.055590  0.692477  0.361799 -0.418498 -0.060454  0.761079   \n",
       "Emiliani2      0.723830  1.270697  1.013738  0.032229  0.091910  0.283224   \n",
       "Garda_Mincio  -0.213240  0.570796  0.032382 -0.449253  0.032299  0.132804   \n",
       "Lambro_Olona  -0.011918  1.203688  0.840946 -0.353547 -0.212272 -0.299172   \n",
       "Oglio_Iseo     0.122784  1.199917  0.568570 -0.268606  0.174854  0.059327   \n",
       "Piemonte_Nord -0.405493  1.139576  0.674711 -1.020396 -0.549184 -0.292423   \n",
       "Piemonte_Sud   0.694293  1.392717  1.349087 -0.551938 -0.021388 -0.086330   \n",
       "Ticino        -0.063035  1.071194  0.899153 -0.606295 -0.563495 -0.291984   \n",
       "\n",
       "                    408       409       410  \n",
       "Adda           0.331204 -0.648940 -2.233412  \n",
       "Dora          -0.655289 -1.586325 -1.796340  \n",
       "Emiliani1      0.649694 -0.957702 -2.786888  \n",
       "Emiliani2      0.847138  0.552758 -2.185583  \n",
       "Garda_Mincio  -0.214182 -2.409204 -2.673294  \n",
       "Lambro_Olona   0.790614  0.109054 -1.086474  \n",
       "Oglio_Iseo     0.748131 -0.819305 -2.542862  \n",
       "Piemonte_Nord  0.454529 -0.383480 -1.139931  \n",
       "Piemonte_Sud   0.576347  0.146632 -0.818877  \n",
       "Ticino         0.770822 -0.412164 -1.081585  \n",
       "\n",
       "[10 rows x 411 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_all_df = pd.DataFrame()\n",
    "for basin in basins:\n",
    "    row = targets_train[basin].mean_std.rename(basin)\n",
    "    target_all_df = pd.concat((target_all_df,row),axis=1)\n",
    "target_all_df = target_all_df.transpose()\n",
    "target_all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d08e51af",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hierarchical_clustering_result = hierarchical_clustering.fit(target_all_df)\n",
    "plot_dendrogram(hierarchical_clustering_result, labels=hierarchical_clustering_result.labels_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f706dd8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 7-1: Piemonte nord da solo o con Dora\n",
    "# 0-9: Ticino e Adda simili, vicino anche 3, emiliani2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "76742011",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adda', 'Dora', 'Emiliani1', 'Emiliani2', 'Garda_Mincio',\n",
       "       'Lambro_Olona', 'Oglio_Iseo', 'Piemonte_Nord', 'Piemonte_Sud',\n",
       "       'Ticino'], dtype=object)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_all_df.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "0f2c8aa6",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "linkage_data = linkage(np.transpose(targets_df_trainVal), method='ward', metric='euclidean')\n",
    "dendrogram(linkage_data)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "ff39286d",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGhCAYAAABCse9yAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqJklEQVR4nO3deXhU9aHG8XeyTRIlYSeJhE02BVkEScMFgZJCQsumIFJ8WASsXlB5UqmNlUUWU69VtBcKeK8sPgoCXgXrkhZ4DGhZJEBui60KlJCwJCxCQhaynvtHL1OmSSCDM5zfhO/nec7z5PzO75x5Rybycs6ZGYdlWZYAAAAMFmB3AAAAgOuhsAAAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjBdkdwBvqKqq0qlTp9SgQQM5HA674wAAgDqwLEuXLl1STEyMAgKufQ6lXhSWU6dOKTY21u4YAADgBuTk5Khly5bXnFMvCkuDBg0k/eMJR0RE2JwGAADURUFBgWJjY11/j19LvSgsVy4DRUREUFgAAPAzdbmdg5tuAQCA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxKCwAAMB4FBYAAGA8CgsAADBevfjyw5vBsiyVlFfaHQO4IWHBgXX6cjEAMBWFpQ4sy9KYFbu1//gFu6MAN6R360ba9Hg8pQWA3+KSUB2UlFdSVuDXMo5f4AwhAL/GGRYPZTyfoPCQQLtjAHVSXFap3ou22R0DAL43CouHwkMCFR7CfzYAAG4mLgkBAADjUVgAAIDxKCwAAMB4FBYAAGA8jwvLzp07NXz4cMXExMjhcGjz5s1u2x0OR43Lyy+/XOsx58+fX21+586dPX4yAACgfvK4sBQVFal79+5atmxZjdtPnz7ttqxatUoOh0MPPvjgNY/bpUsXt/2++OILT6MBAIB6yuP35yYlJSkpKanW7VFRUW7rW7Zs0aBBg9SuXbtrBwkKqrYvAACA5ON7WPLy8vTxxx9r6tSp1517+PBhxcTEqF27dpowYYKys7NrnVtaWqqCggK3BQAA1F8+LSxr165VgwYN9MADD1xzXlxcnNasWaO0tDQtX75cx44dU//+/XXp0qUa56empioyMtK1xMbG+iI+AAAwhE8Ly6pVqzRhwgSFhoZec15SUpLGjh2rbt26aejQofrkk0908eJFbdy4scb5KSkpys/Pdy05OTm+iA8AAAzhs8+Y//zzz/XNN99ow4YNHu/bsGFDdezYUUeOHKlxu9PplNPp/L4RAQCAn/DZGZY333xTvXr1Uvfu3T3et7CwUEePHlV0dLQPkgEAAH/jcWEpLCxUZmamMjMzJUnHjh1TZmam202yBQUF2rRpk6ZNm1bjMQYPHqylS5e61p955hnt2LFDWVlZ2rVrl0aPHq3AwECNHz/e03gAAKAe8viSUEZGhgYNGuRaT05OliRNmjRJa9askSS9++67siyr1sJx9OhRnTt3zrV+4sQJjR8/XufPn1ezZs3Ur18/7dmzR82aNfM0HgAAqIc8LiwDBw6UZVnXnPPYY4/pscceq3V7VlaW2/q7777raQwAAHAL4buEAACA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxKCwAAMB4FBYAAGA8CgsAADAehQUAABiPwgIAAIxHYQEAAMajsAAAAONRWAAAgPGC7A4AWJalkvJKu2PUS8VlFTX+DO8LCw6Uw+GwOwZQb1FYYCvLsjRmxW7tP37B7ij1Xu9F2+2OUK/1bt1Imx6Pp7QAPsIlIdiqpLySsoJ6IeP4Bc4UAj7EGRYYI+P5BIWHBNodA/BIcVmlei/aZncMoN6jsMAY4SGBCg/hJQkAqI5LQgAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhAQAAxqOwAAAA41FYAACA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxPC4sO3fu1PDhwxUTEyOHw6HNmze7bZ88ebIcDofbkpiYeN3jLlu2TG3atFFoaKji4uL05ZdfehoNAADUUx4XlqKiInXv3l3Lli2rdU5iYqJOnz7tWtavX3/NY27YsEHJycmaN2+eDhw4oO7du2vo0KE6c+aMp/EAAEA9FOTpDklJSUpKSrrmHKfTqaioqDof89VXX9X06dM1ZcoUSdKKFSv08ccfa9WqVfrlL3/paUQAAFDP+OQelvT0dDVv3lydOnXSE088ofPnz9c6t6ysTPv371dCQsI/QwUEKCEhQbt3765xn9LSUhUUFLgtAACg/vJ6YUlMTNRbb72l7du366WXXtKOHTuUlJSkysrKGuefO3dOlZWVatGihdt4ixYtlJubW+M+qampioyMdC2xsbHefhoAAMAgHl8Sup6HH37Y9fM999yjbt266c4771R6eroGDx7slcdISUlRcnKya72goIDSAgBAPebztzW3a9dOTZs21ZEjR2rc3rRpUwUGBiovL89tPC8vr9b7YJxOpyIiItwWAABQf/m8sJw4cULnz59XdHR0jdtDQkLUq1cvbd++3TVWVVWl7du3Kz4+3tfxAACAH/C4sBQWFiozM1OZmZmSpGPHjikzM1PZ2dkqLCzU7NmztWfPHmVlZWn79u0aOXKk2rdvr6FDh7qOMXjwYC1dutS1npycrP/6r//S2rVr9be//U1PPPGEioqKXO8aAgAAtzaP72HJyMjQoEGDXOtX7iWZNGmSli9frj//+c9au3atLl68qJiYGA0ZMkQLFy6U0+l07XP06FGdO3fOtT5u3DidPXtWc+fOVW5urnr06KG0tLRqN+ICAIBbk8eFZeDAgbIsq9btf/jDH657jKysrGpjM2fO1MyZMz2NAwAAbgF8lxAAADAehQUAABiPwgIAAIxHYQEAAMajsAAAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGM/jj+aHf7MsSyXllXbHcCkuq6jxZxOEBQfK4XDYHcN4pr2mbjaTX8M3G78z8CUKyy3EsiyNWbFb+49fsDtKjXov2m53BDe9WzfSpsfj+R/wNZj+mrrZTHsN32z8zsCXuCR0Cykpr+QvFg9kHL9wS585qAteU7gavzPwJc6w3KIynk9QeEig3TGMVFxWqd6Lttkdw+/wmrp18TuDm4HCcosKDwlUeAh//PAeXlMAfIlLQgAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhAQAAxqOwAAAA41FYAACA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxKCwAAMB4FBYAAGA8CgsAADAehQUAABiPwgIAAIxHYQEAAMbzuLDs3LlTw4cPV0xMjBwOhzZv3uzaVl5ermeffVb33HOPbrvtNsXExGjixIk6derUNY85f/58ORwOt6Vz584ePxkAAFA/eVxYioqK1L17dy1btqzatuLiYh04cEBz5szRgQMH9P777+ubb77RiBEjrnvcLl266PTp067liy++8DQaAACop4I83SEpKUlJSUk1bouMjNTWrVvdxpYuXao+ffooOztbrVq1qj1IUJCioqI8jQMAAG4BPr+HJT8/Xw6HQw0bNrzmvMOHDysmJkbt2rXThAkTlJ2d7etoAADAT3h8hsUTly9f1rPPPqvx48crIiKi1nlxcXFas2aNOnXqpNOnT+uFF15Q//79dejQITVo0KDa/NLSUpWWlrrWCwoKfJIfAACYwWeFpby8XA899JAsy9Ly5cuvOffqS0zdunVTXFycWrdurY0bN2rq1KnV5qempuqFF17wemYAAGAmn1wSulJWjh8/rq1bt17z7EpNGjZsqI4dO+rIkSM1bk9JSVF+fr5rycnJ8UZsAABgKK8Xlitl5fDhw9q2bZuaNGni8TEKCwt19OhRRUdH17jd6XQqIiLCbQEAAPWXx4WlsLBQmZmZyszMlCQdO3ZMmZmZys7OVnl5ucaMGaOMjAy98847qqysVG5urnJzc1VWVuY6xuDBg7V06VLX+jPPPKMdO3YoKytLu3bt0ujRoxUYGKjx48d//2cIAAD8nsf3sGRkZGjQoEGu9eTkZEnSpEmTNH/+fH344YeSpB49erjt99lnn2ngwIGSpKNHj+rcuXOubSdOnND48eN1/vx5NWvWTP369dOePXvUrFkzT+PhVmBZUnmx745fVnnVz8WSAn33WMHhksPhu+PDGJZlqaSixO4YPlFcXnnVzyWSw4e/MzYKCwqTg99X23hcWAYOHCjLsmrdfq1tV2RlZbmtv/vuu57GwK3KsqRVQ6WcvT58DKek1f/4+eX2kqP0mtO/l9gfSI+mUVrqOcuyNPHTico8m2l3FJ+wqoIlLZQkDdw4QI6AcnsD+UjP5j21NnEtpcUmPn1bM+B15cW+LSuSwh2lygr9qU8fwyVnzz+eU8htN+fxYIuSipJ6W1YkyRFQrgZ3/dLuGD538MxBlVSUKDw43O4otyQKC/zXM0ekED/9H0dZsfSb9nangA3SH0pXWFCY3THggZKKEg3cONDuGLc8Cgv8V0g4Zybgd8KCwvgXOnADfP7R/AAAAN8XhQUAABiPwgIAAIxHYQEAAMajsAAAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhAQAAxqOwAAAA41FYAACA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxKCwAAMB4FBYAAGA8CgsAADAehQUAABiPwgIAAIxHYQEAAMajsAAAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjOdxYdm5c6eGDx+umJgYORwObd682W27ZVmaO3euoqOjFRYWpoSEBB0+fPi6x122bJnatGmj0NBQxcXF6csvv/Q0GgAAqKc8LixFRUXq3r27li1bVuP2//iP/9Bvf/tbrVixQnv37tVtt92moUOH6vLly7Uec8OGDUpOTta8efN04MABde/eXUOHDtWZM2c8jQcAAOohjwtLUlKSFi1apNGjR1fbZlmWXnvtNT3//PMaOXKkunXrprfeekunTp2qdibmaq+++qqmT5+uKVOm6O6779aKFSsUHh6uVatWeRoPAADUQ169h+XYsWPKzc1VQkKCaywyMlJxcXHavXt3jfuUlZVp//79bvsEBAQoISGh1n1KS0tVUFDgtgAAgPrLq4UlNzdXktSiRQu38RYtWri2/atz586psrLSo31SU1MVGRnpWmJjY72QHgAAmMov3yWUkpKi/Px815KTk2N3JAAA4ENeLSxRUVGSpLy8PLfxvLw817Z/1bRpUwUGBnq0j9PpVEREhNsCAADqL68WlrZt2yoqKkrbt293jRUUFGjv3r2Kj4+vcZ+QkBD16tXLbZ+qqipt37691n0AAMCtJcjTHQoLC3XkyBHX+rFjx5SZmanGjRurVatWmjVrlhYtWqQOHTqobdu2mjNnjmJiYjRq1CjXPoMHD9bo0aM1c+ZMSVJycrImTZqk3r17q0+fPnrttddUVFSkKVOmfP9nCAAA/J7HhSUjI0ODBg1yrScnJ0uSJk2apDVr1ugXv/iFioqK9Nhjj+nixYvq16+f0tLSFBoa6trn6NGjOnfunGt93LhxOnv2rObOnavc3Fz16NFDaWlp1W7EBQAAtyaPC8vAgQNlWVat2x0OhxYsWKAFCxbUOicrK6va2MyZM11nXAAAAK7ml+8SAgAAtxaPz7AAAOArlmWppKLE7hhurs5jWrawoDA5HA67Y9wUFBYAgBEsy9LETycq82ym3VFqNXDjQLsjuOnZvKfWJq69JUoLl4QAAEYoqSgxuqyY6OCZg8ad9fEVzrAAAIyT/lC6woLC7I5hrJKKEuPO9vgahQUAYJywoDCFB4fbHQMG4ZIQAAAwHoUFAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxKCwAAMB4FBYAAGA8CgsAADAehQUAABiPwgIAAIxHYQEAAMajsAAAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhAQAAxqOwAAAA41FYAACA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAYL8juAABgN8uyVFJR4rPjX31sXz6OJIUFhcnhcPj0MQA7UFgA3NIsy9LETycq82zmTXm8gRsH+vT4PZv31NrEtZQW1DtcEgJwSyupKLlpZeVmOHjmoM/P4gB24AwLAPy/9IfSFRYUZneMG1JSUeLzszeAnSgsAPD/woLCFB4cbncMADXgkhAAADCe1wtLmzZt5HA4qi0zZsyocf6aNWuqzQ0NDfV2LAAA4Me8fklo3759qqysdK0fOnRIP/rRjzR27Nha94mIiNA333zjWufudgAAcDWvF5ZmzZq5rf/617/WnXfeqQEDBtS6j8PhUFRUlLejAACAesKn97CUlZXp7bff1qOPPnrNsyaFhYVq3bq1YmNjNXLkSH311VfXPG5paakKCgrcFgAAUH/5tLBs3rxZFy9e1OTJk2ud06lTJ61atUpbtmzR22+/raqqKvXt21cnTpyodZ/U1FRFRka6ltjYWB+kBwAApvBpYXnzzTeVlJSkmJiYWufEx8dr4sSJ6tGjhwYMGKD3339fzZo108qVK2vdJyUlRfn5+a4lJyfHF/EBAIAhfPY5LMePH9e2bdv0/vvve7RfcHCwevbsqSNHjtQ6x+l0yul0ft+IAADAT/jsDMvq1avVvHlz/fjHP/Zov8rKSv3lL39RdHS0j5IBAAB/45PCUlVVpdWrV2vSpEkKCnI/iTNx4kSlpKS41hcsWKA//vGP+vvf/64DBw7okUce0fHjxzVt2jRfRAMAAH7IJ5eEtm3bpuzsbD366KPVtmVnZysg4J896cKFC5o+fbpyc3PVqFEj9erVS7t27dLdd9/ti2gAAMAP+aSwDBkyRJZl1bgtPT3dbX3JkiVasmSJL2IAAIB6gu8SAgAAxqOwAAAA41FYAACA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxKCwAAMB4FBYAAGA8CgsAADAehQUAABiPwgIAAIxHYQEAAMajsAAAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhAQAAxqOwAAAA41FYAACA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxguwOAABAfWNZlkoqSnx2/KuP7cvHkaSwoDA5HA6fPkZdUFgAAPAiy7I08dOJyjybeVMeb+DGgT49fs/mPbU2ca3tpYVLQgAAeFFJRclNKys3w8EzB31+FqcuvH6GZf78+XrhhRfcxjp16qSvv/661n02bdqkOXPmKCsrSx06dNBLL72kYcOGeTsaAAA3VfpD6QoLCrM7xg0pqSjx+dkbT/jkklCXLl20bdu2fz5IUO0Ps2vXLo0fP16pqan6yU9+onXr1mnUqFE6cOCAunbt6ot4AADcFGFBYQoPDrc7Rr3gk0tCQUFBioqKci1Nmzatde7rr7+uxMREzZ49W3fddZcWLlyoe++9V0uXLvVFNAAA4Id8UlgOHz6smJgYtWvXThMmTFB2dnatc3fv3q2EhAS3saFDh2r37t217lNaWqqCggK3BQAA1F9eLyxxcXFas2aN0tLStHz5ch07dkz9+/fXpUuXapyfm5urFi1auI21aNFCubm5tT5GamqqIiMjXUtsbKxXnwMAADCL1wtLUlKSxo4dq27dumno0KH65JNPdPHiRW3cuNFrj5GSkqL8/HzXkpOT47VjAwAA8/j8c1gaNmyojh076siRIzVuj4qKUl5enttYXl6eoqKiaj2m0+mU0+n0ak4AAGAun38OS2FhoY4eParo6Ogat8fHx2v79u1uY1u3blV8fLyvowEAAD/h9cLyzDPPaMeOHcrKytKuXbs0evRoBQYGavz48ZKkiRMnKiUlxTX/6aefVlpaml555RV9/fXXmj9/vjIyMjRz5kxvRwMAAH7K65eETpw4ofHjx+v8+fNq1qyZ+vXrpz179qhZs2aSpOzsbAUE/LMn9e3bV+vWrdPzzz+v5557Th06dNDmzZv5DBYAAODi9cLy7rvvXnN7enp6tbGxY8dq7Nix3o4CAADqCb5LCAAAGI/CAgAAjEdhAQAAxqOwAAAA41FYAACA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxKCwAAMB4FBYAAGA8CgsAADAehQUAABiPwgIAAIxHYQEAAMajsAAAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhAQAAxqOwAAAA41FYAACA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxvF5YUlNTdd9996lBgwZq3ry5Ro0apW+++eaa+6xZs0YOh8NtCQ0N9XY0AADgp7xeWHbs2KEZM2Zoz5492rp1q8rLyzVkyBAVFRVdc7+IiAidPn3atRw/ftzb0QAAgJ8K8vYB09LS3NbXrFmj5s2ba//+/br//vtr3c/hcCgqKsrbcQAAQD3g83tY8vPzJUmNGze+5rzCwkK1bt1asbGxGjlypL766itfRwMAAH7Cp4WlqqpKs2bN0r/927+pa9eutc7r1KmTVq1apS1btujtt99WVVWV+vbtqxMnTtQ4v7S0VAUFBW4LAACov7x+SehqM2bM0KFDh/TFF19cc158fLzi4+Nd63379tVdd92llStXauHChdXmp6am6oUXXvB6XgAAYCafnWGZOXOmPvroI3322Wdq2bKlR/sGBwerZ8+eOnLkSI3bU1JSlJ+f71pycnK8ERkAABjK62dYLMvSk08+qQ8++EDp6elq27atx8eorKzUX/7yFw0bNqzG7U6nU06n8/tGBQAAfsLrhWXGjBlat26dtmzZogYNGig3N1eSFBkZqbCwMEnSxIkTdccddyg1NVWStGDBAv3gBz9Q+/btdfHiRb388ss6fvy4pk2b5u14AADAD3m9sCxfvlySNHDgQLfx1atXa/LkyZKk7OxsBQT882rUhQsXNH36dOXm5qpRo0bq1auXdu3apbvvvtvb8QAAgB/yySWh60lPT3dbX7JkiZYsWeLtKAAAoJ7gu4QAAIDxKCwAAMB4FBYAAGA8CgsAADAehQUAABiPwgIAAIxHYQEAAMajsAAAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhAQAAxqOwAAAA41FYAACA8SgsAADAeBQWAABgPAoLAAAwHoUFAAAYj8ICAACMR2EBAADGo7AAAADjUVgAAIDxKCwAAMB4FBYAAGA8CgsAADAehQUAABiPwgIAAIxHYQEAAMajsAAAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjOezwrJs2TK1adNGoaGhiouL05dffnnN+Zs2bVLnzp0VGhqqe+65R5988omvogEAAD/jk8KyYcMGJScna968eTpw4IC6d++uoUOH6syZMzXO37Vrl8aPH6+pU6fq4MGDGjVqlEaNGqVDhw75Ih4AAPAzPiksr776qqZPn64pU6bo7rvv1ooVKxQeHq5Vq1bVOP/1119XYmKiZs+erbvuuksLFy7Uvffeq6VLl/oiHgAA8DNB3j5gWVmZ9u/fr5SUFNdYQECAEhIStHv37hr32b17t5KTk93Ghg4dqs2bN9c4v7S0VKWlpa71/Px8SVJBQcH3TF+z4rIKVZUWux6jIsTr/9luinrxPMqKpFLrHz8XFEghlfbmuVH15HnUh9dUcXmxKkv+8d+/oKBAFcEVNie6MfXhedSH5yDxPDxx5e9ty7KuP9nyspMnT1qSrF27drmNz5492+rTp0+N+wQHB1vr1q1zG1u2bJnVvHnzGufPmzfPksTCwsLCwsJSD5acnJzr9gv/++eQpJSUFLczMlVVVfruu+/UpEkTORwOG5MBAIC6sixLly5dUkxMzHXner2wNG3aVIGBgcrLy3Mbz8vLU1RUVI37REVFeTTf6XTK6XS6jTVs2PDGQwMAAFtERkbWaZ7Xb7oNCQlRr169tH37dtdYVVWVtm/frvj4+Br3iY+Pd5svSVu3bq11PgAAuLX45JJQcnKyJk2apN69e6tPnz567bXXVFRUpClTpkiSJk6cqDvuuEOpqamSpKeffloDBgzQK6+8oh//+Md69913lZGRoTfeeMMX8QAAgJ/xSWEZN26czp49q7lz5yo3N1c9evRQWlqaWrRoIUnKzs5WQMA/T+707dtX69at0/PPP6/nnntOHTp00ObNm9W1a1dfxAMAAH7GYVl1eS8RAACAffguIQAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhuY7CwkLNmzdPiYmJaty4sRwOh9asWWN3rO9l8eLFcjgcfvUurH379mnmzJnq0qWLbrvtNrVq1UoPPfSQvv32W7ujeeSrr77S2LFj1a5dO4WHh6tp06a6//779fvf/97uaB47fPiwHn74YbVs2VLh4eHq3LmzFixYoOLiYruj1VlpaameffZZxcTEKCwsTHFxcdq6davdsW7IgQMHNGLECDVu3Fjh4eHq2rWrfvvb39odq84mT54sh8NR63Ly5Em7I15Xenp6rfn37Nljd7w6279/vxITExUREaEGDRpoyJAhyszMtDuWb97WXJ+cO3dOCxYsUKtWrdS9e3elp6fbHel7OXHihF588UXddtttdkfxyEsvvaQ//elPGjt2rLp166bc3FwtXbpU9957r/bs2eM35ev48eO6dOmSJk2apJiYGBUXF+t//ud/NGLECK1cuVKPPfaY3RHrJCcnR3369FFkZKRmzpypxo0ba/fu3Zo3b57279+vLVu22B2xTiZPnqz33ntPs2bNUocOHbRmzRoNGzZMn332mfr162d3vDr74x//qOHDh6tnz56aM2eObr/9dh09elQnTpywO1qd/exnP1NCQoLbmGVZevzxx9WmTRvdcccdNiXz3FNPPaX77rvPbax9+/Y2pfHMgQMH1K9fP8XGxmrevHmqqqrS7373Ow0YMEBffvmlOnXqZF+4Onyf4S3t8uXL1unTpy3Lsqx9+/ZZkqzVq1fbG+p7GDdunPXDH/7QGjBggNWlSxe749TZn/70J6u0tNRt7Ntvv7WcTqc1YcIEm1J5R0VFhdW9e3erU6dOdkeps8WLF1uSrEOHDrmNT5w40ZJkfffddzYlq7u9e/dakqyXX37ZNVZSUmLdeeedVnx8vI3JPJOfn2+1aNHCGj16tFVZWWl3HK/6/PPPLUnW4sWL7Y5SJ5999pklydq0aZPdUW7YsGHDrEaNGlnnzp1zjZ06dcq6/fbbrQceeMDGZJbFJaHrcDqdtX6nkb/ZuXOn3nvvPb322mt2R/FY3759FRIS4jbWoUMHdenSRX/7299sSuUdgYGBio2N1cWLF+2OUmdXvhL+yodBXhEdHa2AgIBqf1Ymeu+99xQYGOh2Vis0NFRTp07V7t27lZOTY2O6ulu3bp3y8vK0ePFiBQQEqKioSFVVVXbH8op169bJ4XDopz/9qd1RPHbp0iVVVFTYHcNjn3/+uRISEtSkSRPXWHR0tAYMGKCPPvpIhYWFtmWjsNwiKisr9eSTT2ratGm655577I7jFZZlKS8vT02bNrU7iseKiop07tw5HT16VEuWLNGnn36qwYMH2x2rzgYOHChJmjp1qjIzM5WTk6MNGzZo+fLleuqpp/zikuPBgwfVsWNHRUREuI336dNHkoy4Zl8X27ZtU0REhE6ePKlOnTrp9ttvV0REhJ544gldvnzZ7ng3rLy8XBs3blTfvn3Vpk0bu+N4ZMqUKYqIiFBoaKgGDRqkjIwMuyPVWWlpqcLCwqqNh4eHq6ysTIcOHbIh1T9wD8stYsWKFTp+/Li2bdtmdxSveeedd3Ty5EktWLDA7ige+/nPf66VK1dKkgICAvTAAw9o6dKlNqequ8TERC1cuFAvvviiPvzwQ9f4r371Ky1atMjGZHV3+vRpRUdHVxu/Mnbq1KmbHemGHD58WBUVFRo5cqSmTp2q1NRUpaen6z//8z918eJFrV+/3u6IN+QPf/iDzp8/rwkTJtgdpc5CQkL04IMPatiwYWratKn++te/6je/+Y369++vXbt2qWfPnnZHvK5OnTppz549qqysVGBgoCSprKxMe/fulSRbb36msNwCzp8/r7lz52rOnDlq1qyZ3XG84uuvv9aMGTMUHx+vSZMm2R3HY7NmzdKYMWN06tQpbdy4UZWVlSorK7M7lkfatGmj+++/Xw8++KCaNGmijz/+WC+++KKioqI0c+ZMu+NdV0lJiZxOZ7Xx0NBQ13Z/UFhYqOLiYj3++OOudwU98MADKisr08qVK7VgwQJ16NDB5pSeW7dunYKDg/XQQw/ZHaXO+vbtq759+7rWR4wYoTFjxqhbt25KSUlRWlqajenq5t///d/1xBNPaOrUqfrFL36hqqoqLVq0SKdPn5Zk8++FrXfQ+Bl/ven28ccft9q3b+9206q/3XR7tdOnT1vt2rWzYmNjrZMnT9odxyt+9KMfWffdd59VVVVld5Q6Wb9+vRUWFmbl5OS4jU+ePNkKDw93u2HPVF26dLF++MMfVhv/6quvLEnWihUrbEjluS5duliSrB07driN79ixw5JkrV271qZkN+7SpUtWeHi49ZOf/MTuKF7x8MMPWyEhIVZFRYXdUerkueees4KDgy1JliSrd+/e1q9+9StLkvXBBx/Ylot7WOq5w4cP64033tBTTz2lU6dOKSsrS1lZWbp8+bLKy8uVlZWl7777zu6YdZafn6+kpCRdvHhRaWlpiomJsTuSV4wZM0b79u3zm8+V+d3vfqeePXuqZcuWbuMjRoxQcXGxDh48aFOyuouOjnb9q/FqV8b85bV1Jee/3gDdvHlzSdKFCxdueqbva/PmzSouLvary0HXEhsbq7KyMhUVFdkdpU4WL16svLw8ff755/rzn/+sffv2uW7k7tixo225KCz13MmTJ1VVVaWnnnpKbdu2dS179+7Vt99+q7Zt2/rNPSCXL1/W8OHD9e233+qjjz7S3XffbXckr7lymjU/P9/mJHWTl5enysrKauPl5eWS5BfvjujRo4e+/fZb1zuerrhyrb5Hjx42pPJcr169JFW/t+DKPTj+eBn4nXfe0e23364RI0bYHcUr/v73vys0NFS333673VHqrFGjRurXr5/rTRrbtm1Ty5Yt1blzZ9syUVjqua5du+qDDz6otnTp0kWtWrXSBx98oKlTp9od87oqKys1btw47d69W5s2bVJ8fLzdkW7ImTNnqo2Vl5frrbfeUlhYmN+UsI4dO+rgwYPVzgitX79eAQEB6tatm03J6m7MmDGqrKzUG2+84RorLS3V6tWrFRcXp9jYWBvT1d2VezzefPNNt/H//u//VlBQkOsdXf7i7Nmz2rZtm0aPHq3w8HC743jk7Nmz1cb+93//Vx9++KGGDBmigAD//Ct3w4YN2rdvn2bNmmXrc+Cm2zpYunSpLl686PoXy+9//3vXJ0g++eSTioyMtDPeNTVt2lSjRo2qNn7ls1hq2main//85/rwww81fPhwfffdd3r77bfdtj/yyCM2JfPMz372MxUUFOj+++/XHXfcodzcXL3zzjv6+uuv9corr/jNv8Bmz56tTz/9VP3799fMmTPVpEkTffTRR/r00081bdo0v7icEhcXp7FjxyolJUVnzpxR+/bttXbtWmVlZVX7y99kPXv21KOPPqpVq1apoqJCAwYMUHp6ujZt2qSUlBS/+LO42oYNG1RRUeGXl4PGjRunsLAw9e3bV82bN9df//pXvfHGGwoPD9evf/1ru+PVyc6dO7VgwQINGTJETZo00Z49e7R69WolJibq6aeftjecbXfP+JHWrVu7bj761+XYsWN2x7sh/nbT7YABA2r9M/Cnl/H69euthIQEq0WLFlZQUJDVqFEjKyEhwdqyZYvd0Ty2d+9eKykpyYqKirKCg4Otjh07WosXL7bKy8vtjlZnJSUl1jPPPGNFRUVZTqfTuu+++6y0tDS7Y3msrKzMmj9/vtW6dWsrODjYat++vbVkyRK7Y92QH/zgB1bz5s395gbVq73++utWnz59rMaNG1tBQUFWdHS09cgjj1iHDx+2O1qdHTlyxBoyZIjVtGlTy+l0Wp07d7ZSU1OrfdK4HRyWZVm2NCUAAIA68s8LagAA4JZCYQEAAMajsAAAAONRWAAAgPEoLAAAwHgUFgAAYDwKCwAAMB6FBQAAGI/CAgAAjEdhAQAAxqOwAAAA41FYAACA8SgsAADAeP8H2oTexaFq2MgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "linkage_data = linkage(np.transpose(targets_df_trainVal), method='average', metric='euclidean')\n",
    "dendrogram(linkage_data)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "de295dc4",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Adda', 'Dora', 'Emiliani1', 'Emiliani2', 'Garda_Mincio',\n",
       "       'Lambro_Olona', 'Oglio_Iseo', 'Piemonte_Nord', 'Piemonte_Sud',\n",
       "       'Ticino'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df_trainVal.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
